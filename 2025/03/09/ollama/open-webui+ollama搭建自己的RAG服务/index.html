<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>open-webui+ollama搭建自己的RAG服务 | 易锦风的博客</title><meta name="author" content="formeasy"><meta name="copyright" content="formeasy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="open-webui+ollama搭建自己的RAG服务"><meta property="og:type" content="article"><meta property="og:title" content="open-webui+ollama搭建自己的RAG服务"><meta property="og:url" content="http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/index.html"><meta property="og:site_name" content="易锦风的博客"><meta property="og:description" content="open-webui+ollama搭建自己的RAG服务"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/44b3ae72821b496d891fafa1f55976d8.png"><meta property="article:published_time" content="2025-03-09T02:56:11.000Z"><meta property="article:modified_time" content="2025-04-25T01:31:19.898Z"><meta property="article:author" content="formeasy"><meta property="article:tag" content="ollama"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/44b3ae72821b496d891fafa1f55976d8.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>(()=>{var e={set:(e,t,a)=>{a&&(a=Date.now()+864e5*a,localStorage.setItem(e,JSON.stringify({value:t,expiry:a})))},get:e=>{var t=localStorage.getItem(e);if(t){var{value:t,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return t;localStorage.removeItem(e)}}},t=(window.btf={saveToLocal:e,getScript:(o,n={})=>new Promise((e,t)=>{const a=document.createElement("script");a.src=o,a.async=!0,Object.entries(n).forEach(([e,t])=>a.setAttribute(e,t)),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),getCSS:(o,n)=>new Promise((e,t)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),addGlobalFn:(e,t,a=!1,o=window)=>{var n;e.startsWith("pjax")||((n=o.globalFn||{})[e]=n[e]||{},n[e][a||Object.keys(n[e]).length]=t,o.globalFn=n)}},()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")}),a=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")},o=(btf.activateDarkMode=t,btf.activateLightMode=a,e.get("theme")),t=("dark"===o?t():"light"===o&&a(),e.get("aside-status"));void 0!==t&&document.documentElement.classList.toggle("hide-aside","hide"===t);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!1,languages:{hits_empty:"未找到符合您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"open-webui+ollama搭建自己的RAG服务",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,isShuoshuo:!1}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="易锦风的博客" type="application/atom+xml"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/butterfly-icon.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">202</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我们</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/2025/03/09/ollama/open-webui+ollama搭建自己的RAG服务/44b3ae72821b496d891fafa1f55976d8.png)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/icon.png" alt="Logo"><span class="site-name">易锦风的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">open-webui+ollama搭建自己的RAG服务</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我们</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">open-webui+ollama搭建自己的RAG服务</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-09T02:56:11.000Z" title="发表于 2025-03-09 10:56:11">2025-03-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-25T01:31:19.898Z" title="更新于 2025-04-25 09:31:19">2025-04-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%99%BA%E8%83%BD/">智能</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>8分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="一-rag是什么"><a class="markdownIt-Anchor" href="#一-rag是什么"></a> <strong>一、RAG是什么</strong></h2><pre><code>检索增强生成(RAG, Retrieval-Augmented Generation）。该架构巧妙地整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精准的答案，从而显著提升了回答的准确性。
</code></pre><p>RAG可以简单的总结为数据处理、检索、增强和生成四个阶段：</p><p>数据处理阶段：对原始数据进行清洗和处理，并转换为检索模型可用的格式，然后写入到向量数据库中。</p><ul><li>检索阶段：将用户的问题输入到检索系统中，并从数据库中搜索相关信息。</li><li>增强阶段：将搜索的相关信息进行处理和增强，以便可以更好的理解和使用。</li><li>生成阶段：将增强后的信息输入到生成模型中，生成模型根据这些信息生成答案。</li></ul><p>RAG方法使得我们不需要为每个特定任务都重新训练一个大模型，仅仅挂上知识库，即可以为模型提供额外的知识，提高回答的准确性。</p><p>可扩展性：减少模型大小和训练成本，仅仅更新特定领域的知识，即可提升回答效果</p><ul><li>准确性：引用我们自己的知识库，增强人们对模型输出结果的信任</li><li>可控性：允许更新和定制知识库</li><li>及时性：通过更新我们的知识库，从而使我们可以在不重新训练模型的前提下，保证回答问题的准确性。</li><li>安全性：通过在数据库中设置不同的角色和权限，保证数据的保密性。</li></ul><p>虽然RAG在一定程度上可以增强其生成的结果，但它仍有一些弊端，如：</p><ul><li>检索效果依赖embedding和检索算法</li><li>LLM如何利用检索到的信息仍是黑盒</li><li>对所有任务都无差别检索K个文本片段，效率不高</li></ul><h2 id="二-搭建自己的rag服务"><a class="markdownIt-Anchor" href="#二-搭建自己的rag服务"></a> 二、搭建自己的RAG服务</h2><h3 id="1准备自己的知识库文件"><a class="markdownIt-Anchor" href="#1准备自己的知识库文件"></a> 1.准备自己的知识库文件</h3><p>常见的文档格式一般为txt、doc、PDF等，这里我将选择最简单的txt文档进行导入，需要注意以下几点：</p><ul><li>由于目前LLM均有token的限制，所以在写入向量库时会对我们上传的文档进行分割、切块，将较长的文本切分成较小的文本，每段文本即为一个单位的知识。</li><li>当PDF、doc中设计到表格、图片时，需要特殊处理，现有框架如open-webui或者lang chain等在加载该类文档时，仅仅会处理文字部分，图片和表格部分均会忽略，如果图片内容对你来说也非常重要的话，需要自己转换下，如OCR识别或者WPS转换（效果针对与具体文档而言，这里不给评价）</li></ul><p>这里，我以一个最简单的txt来作为参考，为了方便演示，内容相对简单且简洁，具体如下：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="44b3ae72821b496d891fafa1f55976d8.png" alt=""></p><h3 id="2open-webui-前期准备工作"><a class="markdownIt-Anchor" href="#2open-webui-前期准备工作"></a> 2.open-webui 前期准备工作</h3><p>文档准备完成后，写入向量库之前，我们需要先在open-web ui中进行一些前置设置，open-webui的搭建指南可参考“系列文章三”。</p><ul><li>首先，我们需要选择选择我们的词向量模型，如m3e,bge等，这里我们拿ollama支持的向量模型，如nomic-embed-text、mxbai-embeded-large来作为示例，模型需要提前在自己的o llama服务中下载，下载方式可参考“系列文章一”。</li><li>其次，我们进入我们open-webui的界面，点击“文档”栏，如下：        <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="551c658f64774d7fb9a321b380773e4e.png" alt=""></li></ul><p>点击文档之后，再点击右上角的文档设置，会出现如下图的设置页面：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="195d7a8081dd46ac84fff698a9cea09c.png" alt=""></p><p>点击红框中的箭头，然后会看到我们当前ollama下载的所有模型，如下图：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="ed264863a3f2409b85c7792836e574f1.png" alt=""></p><p>如果没有列出模型，说明你的ollama中没有模型，可以结合我的往期文章来看看自己少了哪一步。这里我以mxbai-embeded-large为例，选择好模型之后，按照下方指示进行保存设置。如下图：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="7c61d532d753486a8a9d65e2ea4fd875.png" alt=""></p><p>注意：这里的块参数表示将你的文档切块的大小以及块和块之间文本的重叠度，相关介绍见末尾扩展知识，这个参数按照自己的需求进行设置。因为上方我提供的知识库文字较少，所以这里的块大小我设置为30，块重叠设置为5。</p><h3 id="3导入知识库并写入向量库"><a class="markdownIt-Anchor" href="#3导入知识库并写入向量库"></a> 3.导入知识库并写入向量库</h3><p>经历了前边几步的配置，我们的所需的基础建设就基本搭建完成了，现在我们便可以导入我们的文档并写入向量数据库。</p><ul><li>导入：首先我们在“文档”界面点击“+”，以上传自己的文档，如图：</li></ul><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="28c61a1bef614bbca2ff5d5b56a38607.png" alt=""></p><p>选择我们要上传的文档即可，如图：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="40b3a9d75e7c4ea6acf2ad7e7ede140f.png" alt=""></p><ul><li><p>查看：上传成功后，等段时间我们的文档会显示在当前界面里，如图：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="d8369055e2574856af9034d86e568f0b.png" alt=""></p><p>注意：你上传完文档后，会等一段时间（耗时根据文档的大小而定）才会显示出来，这段时间是embedding的过程</p></li><li><p>另外，我们还可以在“系列文章三中”设置的open-webui挂载的宿主机目录下的vector_db里查看是否有新生成的文件，如图：</p></li><li><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="5d2b339859dc43b694f64d0ba5c5ed9b.png" alt=""></p></li><li><p>如上所示，正常写入向量库时，会在这里生成文件，如果没有，先确定自己查看的目录有没有问题，其次再去查看embedding的过程中是否出现了问题。</p></li></ul><h3 id="4搭建并使用自己的rag服务"><a class="markdownIt-Anchor" href="#4搭建并使用自己的rag服务"></a> 4.搭建并使用自己的RAG服务</h3><p>经历如上几步，我们的知识库便挂载进去了，现在我们便可以利用我们的知识库进行聊天。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="fee5505955304a49911822cd135200e5.png" alt=""></p><p>如上图所示，我们新建个聊天窗口并选择所要用的模型，这里以qwen2:1.5b为例，当不使用知识库时间，大模型回答如下：        <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="e81fe5be7e434981a84d168696047321.png" alt=""></p><p>当使用知识库时，只需要在输入问题之前输入“#”，然后选择要挂载的文档即可，如：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="90c623dee6c14577ab83a147d0306bb1.png" alt=""></p><p>这里选择我门要使用的知识库，然后再输入问题即可，如下：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="f9c5c89da89a414482b6469a715d4801.png" alt=""></p><p>可以看到，挂了知识库后，大模型的回答和我们想要的基本一致，如此，我们便可以使用自己的知识库来搭建自己的RAG服务了。</p><h2 id="三-扩展知识"><a class="markdownIt-Anchor" href="#三-扩展知识"></a> 三、扩展知识</h2><h3 id="1词向量"><a class="markdownIt-Anchor" href="#1词向量"></a> 1.词向量</h3><p>在机器学习和自然语言处理（NLP）中，词向量（Embeddings）是一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。如图所示：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="fbe4b9214c094796a0dd92ce0126e011.png" alt=""></p><p>它的优势主要包括以下两点：</p><ul><li>词向量比文字更适合检索。当我们在数据库检索时，如果数据库存储的是文字，主要通过检索关键词（词法搜索）等方法找到相对匹配的数据，匹配的程度是取决于关键词的数量或者是否完全匹配查询句的；但是词向量中包含了原文本的语义信息，可以通过计算问题与数据库中数据的点积、余弦距离、欧几里得距离等指标，直接获取问题与数据在语义层面上的相似度；</li><li>词向量比其它媒介的综合信息能力更强，当传统数据库存储文字、声音、图像、视频等多种媒介时，很难去将上述多种媒介构建起关联与跨模态的查询方法；但是词向量却可以通过多种向量模型将多种数据映射成统一的向量形式。</li></ul><h3 id="2向量数据库"><a class="markdownIt-Anchor" href="#2向量数据库"></a> 2.向量数据库</h3><p>向量数据库是用于高效计算和管理大量向量数据的解决方案。向量数据库是一种专门用于存储和检索向量数据（embedding）的数据库系统。它与传统的基于关系模型的数据库不同，它主要关注的是向量数据的特性和相似性。</p><p>在向量数据库中，数据被表示为向量形式，每个向量代表一个数据项。这些向量可以是数字、文本、图像或其他类型的数据。向量数据库使用高效的索引和查询算法来加速向量数据的存储和检索过程。</p><p>常见的向量数据库如下：</p><ul><li>Chroma:一个轻量级、易用的向量数据库，专注于提供高效的近似最近邻搜索（ANN）。它支持多种向量数据类型和索引方法，使得用户可以轻松集成到现有的应用程序中。Chroma特别适用于小型到中型数据集，是初学者和小型项目的理想选择</li><li>Pinecone:一个实时、高性能的向量数据库，专为大规模向量集的高效索引和检索而设计。</li><li>Weaviate:结合了向量搜索和图数据库特性的多模态语义搜索引擎。它支持多模态数据（文本、图像等）的语义搜索，让用户能够以前所未有的方式探索和理解数据。</li><li>Milvus:支持多种索引类型和查询优化策略，提供卓越的查询性能和扩展性。它特别适用于大规模内容检索、图像和视频搜索等场景</li><li>Faiss:提供高效的相似度搜索和稠密向量聚类能力，支持多种索引构建方法和查询策略优化。Faiss易于与深度学习框架集成（如PyTorch），使得用户可以轻松将向量检索功能嵌入到深度学习应用中</li></ul><h3 id="3文档切割"><a class="markdownIt-Anchor" href="#3文档切割"></a> 3.文档切割</h3><p>在二.2中我们提到了两个概念，一个是“块大小”，一个是“块重叠”。这里我们简单介绍下这两个的由来及作用。</p><p>由来：由于单个文档的长度往往会超过模型支持的上下文，导致检索得到的知识太长超出模型的处理能力，因此，在构建向量知识库的过程中，我们往往需要对文档进行分割，将单个文档按长度或者按固定的规则分割成若干个块，然后将每个块转化为词向量，存储到向量数据库中。在检索时，我们会以块作为检索的元单位，也就是每一次检索到 k 个块作为模型可以参考来回答用户问题的知识，这个 k 是我们可以自由设定的。</p><p>块大小：每个块包含的字符或 Token （如单词、句子等）的数量</p><p>块重叠：两个块之间共享的字符数量，用于保持上下文的连贯性，避免分割丢失上下文信息。</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://www.formeasy.cc">formeasy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/">http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama搭建自己的RAG服务/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://www.formeasy.cc" target="_blank">易锦风的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ollama/">ollama</a></div><div class="post-share"><div class="social-share" data-image="/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/44b3ae72821b496d891fafa1f55976d8.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/09/proxmox/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%AE%89%E8%A3%85proxmox%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8Evmware%20workstation%EF%BC%89/" title="史上最全安装proxmox教程（基于vmware workstation）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/09/proxmox/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%AE%89%E8%A3%85proxmox%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8Evmware%20workstation%EF%BC%89/x-image-process=image.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">史上最全安装proxmox教程（基于vmware workstation）</div></div><div class="info-2"><div class="info-item-1">安装Proxmox 使用vmware workstation新建虚拟机 选择install Proxmox...</div></div></div></a><a class="pagination-related" href="/2025/03/09/ollama/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95open-webui%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/" title="史上最简单open-webui安装方式"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/09/ollama/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95open-webui%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/e24635c8bcb74f6f83a22850c470f59b.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">史上最简单open-webui安装方式</div></div><div class="info-2"><div class="info-item-1">史上最简单open-webui安装方式 一、安装python3.11 这里需要注意，不要用python3.11以上的版本，否则不兼容 1、到python官网下载python3.11 链接：https://www.python.org/ftp/python/3.11.9/python-3.11.9-amd64.exe 2.双击安装包，开始安装，注意勾选[Add python 3.11 to Path]选项！！ 3.选择Customize install选项，建议把安装路径改为其他盘（注意！安装路径中不能有中文） 二、测试python 1、按下win+r打开运行框，输入cmd，回车 2、在命令提示符中输入python 3、自动显示： 3、输入exit()退出python 4、输入pip list，显示： 三、pip换源 在cmd中输入： pip config set global.index-url https://mirrors.aliyun.com/pypi/simple 四、安装open-webui 1、打开cmd，输入： pip install...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/02/12/Docker/%E4%BD%BF%E7%94%A8Docker%E6%90%AD%E5%BB%BAOllama%20DeepSeek%E5%92%8COpen%20Web%20UI%E7%9A%84%E6%AD%A5%E9%AA%A4/" title="使用Docker搭建Ollama DeepSeek和Open Web UI的步骤"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-12</div><div class="info-item-2">使用Docker搭建Ollama DeepSeek和Open Web UI的步骤</div></div><div class="info-2"><div class="info-item-1">一、准备工作 安装Docker： 确保你的系统中已经安装了Docker。如果尚未安装，可以从Docker官方网站下载并安装适合你操作系统的Docker版本。 拉取镜像： 从Docker Hub或其他镜像仓库中拉取Ollama、DeepSeek（通常作为Ollama的一个模型存在）和Open Web UI的镜像。 对于不同操作系统，重启命令可能有所不同。 例如，在Ubuntu/Debian系统上，可以使用systemctl daemon-reload和systemctl restart ollama命令；在CentOS系统上，则可能需要使用sudo yum update、sudo yum install lsof、stop ollama、lsof -i :11434、kill 和ollama serve等命令组合。 二、部署Ollama 拉取Ollama镜像： 1docker pull...</div></div></div></a><a class="pagination-related" href="/2025/03/09/ollama/Ollama%20+%20Open%20WebUIChatbox%E6%9C%AC%E5%9C%B0Windows%E9%83%A8%E7%BD%B2/" title="Ollama + Open WebUIChatbox本地Windows部署"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/09/ollama/Ollama%20+%20Open%20WebUIChatbox%E6%9C%AC%E5%9C%B0Windows%E9%83%A8%E7%BD%B2/79edc646bba2482d8f44f0e734098c1f~tplv-73owjymdk6-jj-mark-v100005o6Y6YeR5oqA5pyv56S-5Yy6IEAg54Gv54Gr54Ob5aSpq75.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-09</div><div class="info-item-2">Ollama + Open WebUIChatbox本地Windows部署</div></div><div class="info-2"><div class="info-item-1">一、安装Ollama 访问 Ollama 下载页面。 选择（Windows、Linux 或 macOS）并下载相应的版本。 按指引流程安装 Ollama。 验证 win+r打开cmd命令行工具，输入 ollama --version 二、下载deepseek-r1模型 访问 deepseek-r1模型下载页面。 根据硬件条件选择模型，复制命令在cmd执行 3.安装完成即可在cmd开始使用（下次运行模型仍在cmd中执行上述命令，例ollama run deepseek-r1:1.5b） 当前即可本地使用deeseek-r1，以下为添加对话UI，可选 三、安装open-webui（可选） 准备 安装Python 3.11或更高版本。 安装Node.js和npm 备注：安装完成后pip、npm记得先设置镜像源 1. 打开Git Bash或终端，输入以下命令克隆open-webui项目到本地： 1git clone https://github.com/open-webui/open-webui ps: 如果未安装Git，可直接下载压缩包 或 ...</div></div></div></a><a class="pagination-related" href="/2025/03/25/ollama/ollama%E6%A8%A1%E5%9E%8B%E7%A6%BB%E7%BA%BF%E8%BF%81%E7%A7%BB%E5%A4%8D%E5%88%B6/" title="ollama模型离线迁移&#x2F;复制"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/25/ollama%E6%A8%A1%E5%9E%8B%E7%A6%BB%E7%BA%BF%E8%BF%81%E7%A7%BB%E5%A4%8D%E5%88%B6/v2-bc39552763b810cac1bd8ddf0759f60e_1440w.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-25</div><div class="info-item-2">ollama模型离线迁移&#x2F;复制</div></div><div class="info-2"><div class="info-item-1">在ollama中可以使用命令ollama pull deepseek-r1:7b下载模型，但在某些特殊情况下（如：离线环境）需要手动迁移模型，本文详细讲解了ollama中离线迁移模型的方式。 一、下载特定模型 在一个有网的环境中，使用ollama pull命令下载模型，如：deepseek-r1:7b 二、进行离线迁移 迁移之前首先需要确定ollama主目录。在windows系统中，通常是用户主目录下的.ollama文件夹，例如： C:\Users\wangk\.ollama；在Linux系统中，同样的，通常也是用户主目录下的.ollama文件夹，例如：/root/.ollama windows系统下的ollama主目录 linux系统下的ollama主目录 在ollama主目录下，有两部分内容需要迁移 ...</div></div></div></a><a class="pagination-related" href="/2025/03/25/ollama/vs%20code%E6%8F%92%E4%BB%B6Continue+%E6%9C%AC%E5%9C%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="vs code插件Continue + 本地语言模型使用方法"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/25/vs%20code%E6%8F%92%E4%BB%B6Continue+%E6%9C%AC%E5%9C%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/28869bfaf46440358ecf0eb894c8365a.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-25</div><div class="info-item-2">vs code插件Continue + 本地语言模型使用方法</div></div><div class="info-2"><div class="info-item-1">ollama如何运行模型，此文不涉及，随便查一查很简单。 1. 在拓展商店中找到Continue 2. 安装好continue插件以后，左侧会多出continue的图标，进去 2.1 现在我们先设置一下对话模型，点右上角加号进入new session，下拉框选择模型，选择add chat model provider选择ollama，model可以自己找，官方推荐用Qwen 2.5 1.5b，我这里用的是7b，根据你自己的条件和个人喜好决定。 添加完json配置里的models列表就会多出一个模型选项，有时候模型名称与你本地跑的有出入，报错的话，你自己到这里改一下。 或者添加表单里，有自动检测模型选项，可以用。 2.2...</div></div></div></a><a class="pagination-related" href="/2025/03/09/ollama/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95open-webui%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/" title="史上最简单open-webui安装方式"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/03/09/ollama/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95open-webui%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/e24635c8bcb74f6f83a22850c470f59b.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-09</div><div class="info-item-2">史上最简单open-webui安装方式</div></div><div class="info-2"><div class="info-item-1">史上最简单open-webui安装方式 一、安装python3.11 这里需要注意，不要用python3.11以上的版本，否则不兼容 1、到python官网下载python3.11 链接：https://www.python.org/ftp/python/3.11.9/python-3.11.9-amd64.exe 2.双击安装包，开始安装，注意勾选[Add python 3.11 to Path]选项！！ 3.选择Customize install选项，建议把安装路径改为其他盘（注意！安装路径中不能有中文） 二、测试python 1、按下win+r打开运行框，输入cmd，回车 2、在命令提示符中输入python 3、自动显示： 3、输入exit()退出python 4、输入pip list，显示： 三、pip换源 在cmd中输入： pip config set global.index-url https://mirrors.aliyun.com/pypi/simple 四、安装open-webui 1、打开cmd，输入： pip install...</div></div></div></a><a class="pagination-related" href="/2025/02/12/ollama/%E5%A4%A7%E6%A8%A1%E5%9E%8Bollama%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%E5%A4%A7%E5%85%A8/" title="大模型ollama命令详解大全"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-12</div><div class="info-item-2">大模型ollama命令详解大全</div></div><div class="info-2"><div class="info-item-1">一、启动与停止服务 启动Ollama服务 ollama serve：启动Ollama服务器，以便运行模型和处理请求。首次启动可能会生成ssh私钥文件，并提示服务端口状态。如果服务已在运行中，可以通过netstat -tulpn | grep 11434命令进行确认。 重启Ollama服务 对于不同操作系统，重启命令可能有所不同。例如，在Ubuntu/Debian系统上，可以使用systemctl daemon-reload和systemctl restart ollama命令；在CentOS系统上，则可能需要使用sudo yum update、sudo yum install lsof、stop ollama、lsof -i :11434、kill 和ollama serve等命令组合。 二、模型管理 创建模型 ollama create [Modelfile路径]：使用包含模型信息的Modelfile来创建一个新模型。 显示模型信息 ollama show：显示特定模型的详细信息，如模型名称、版本等。 列出模型 ollama...</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/butterfly-icon.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">formeasy</div><div class="author-info-description">专注互联网和软件技术</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">202</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/formeasy"><i class="fab fa-github"></i><span>关注我</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/formeasy" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:formeasy@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">用学习，面对遭遇的变化；用斗志，面对每天的挫折；用坚持，面对失去的动力!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-rag%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.</span> <span class="toc-text">一、RAG是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84rag%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.</span> <span class="toc-text">二、搭建自己的RAG服务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E5%87%86%E5%A4%87%E8%87%AA%E5%B7%B1%E7%9A%84%E7%9F%A5%E8%AF%86%E5%BA%93%E6%96%87%E4%BB%B6"><span class="toc-number">2.1.</span> <span class="toc-text">1.准备自己的知识库文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2open-webui-%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">2.2.</span> <span class="toc-text">2.open-webui 前期准备工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E5%AF%BC%E5%85%A5%E7%9F%A5%E8%AF%86%E5%BA%93%E5%B9%B6%E5%86%99%E5%85%A5%E5%90%91%E9%87%8F%E5%BA%93"><span class="toc-number">2.3.</span> <span class="toc-text">3.导入知识库并写入向量库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E6%90%AD%E5%BB%BA%E5%B9%B6%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B7%B1%E7%9A%84rag%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.4.</span> <span class="toc-text">4.搭建并使用自己的RAG服务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%89%A9%E5%B1%95%E7%9F%A5%E8%AF%86"><span class="toc-number">3.</span> <span class="toc-text">三、扩展知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E8%AF%8D%E5%90%91%E9%87%8F"><span class="toc-number">3.1.</span> <span class="toc-text">1.词向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.2.</span> <span class="toc-text">2.向量数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E6%96%87%E6%A1%A3%E5%88%87%E5%89%B2"><span class="toc-number">3.3.</span> <span class="toc-text">3.文档切割</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/07/Springboot/%E6%8F%AD%E7%A7%98Swagger%E4%B8%8EOpenAPI%E9%9B%86%E6%88%90%E7%9A%84%E7%BB%88%E6%9E%81%E6%94%BB%E7%95%A5/" title="揭秘Swagger与OpenAPI集成的终极攻略"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="揭秘Swagger与OpenAPI集成的终极攻略"></a><div class="content"><a class="title" href="/2025/09/07/Springboot/%E6%8F%AD%E7%A7%98Swagger%E4%B8%8EOpenAPI%E9%9B%86%E6%88%90%E7%9A%84%E7%BB%88%E6%9E%81%E6%94%BB%E7%95%A5/" title="揭秘Swagger与OpenAPI集成的终极攻略">揭秘Swagger与OpenAPI集成的终极攻略</a><time datetime="2025-09-07T07:52:12.000Z" title="发表于 2025-09-07 15:52:12">2025-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/07/Python/Anaconda%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/" title="Anaconda安装与使用详细教程"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/09/07/Python/Anaconda%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/1b965ee301b941ceab6d8a2c09ac5567.jpeg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Anaconda安装与使用详细教程"></a><div class="content"><a class="title" href="/2025/09/07/Python/Anaconda%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/" title="Anaconda安装与使用详细教程">Anaconda安装与使用详细教程</a><time datetime="2025-09-07T07:35:15.000Z" title="发表于 2025-09-07 15:35:15">2025-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/04/Other/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A4%B4%E5%8F%91%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A%EF%BC%9A%E4%BB%8E%E4%BB%A3%E7%A0%81%E5%88%B0%E5%8F%91%E9%99%85%E7%BA%BF%E7%9A%84%E7%A7%91%E5%AD%A6%E6%8E%A2%E7%B4%A2/" title="程序员头发研究报告：从代码到发际线的科学探索"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/09/04/Other/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A4%B4%E5%8F%91%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A%EF%BC%9A%E4%BB%8E%E4%BB%A3%E7%A0%81%E5%88%B0%E5%8F%91%E9%99%85%E7%BA%BF%E7%9A%84%E7%A7%91%E5%AD%A6%E6%8E%A2%E7%B4%A2/eb931b13e76647dbb8400b9d52e70dfc.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="程序员头发研究报告：从代码到发际线的科学探索"></a><div class="content"><a class="title" href="/2025/09/04/Other/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A4%B4%E5%8F%91%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A%EF%BC%9A%E4%BB%8E%E4%BB%A3%E7%A0%81%E5%88%B0%E5%8F%91%E9%99%85%E7%BA%BF%E7%9A%84%E7%A7%91%E5%AD%A6%E6%8E%A2%E7%B4%A2/" title="程序员头发研究报告：从代码到发际线的科学探索">程序员头发研究报告：从代码到发际线的科学探索</a><time datetime="2025-09-04T06:42:12.000Z" title="发表于 2025-09-04 14:42:12">2025-09-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/27/Springboot/Spring%20Boot%203%20%E6%95%B4%E5%90%88%20MyBatis-Plus%20%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B/" title="Spring Boot 3 整合 MyBatis-Plus 完整示例"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Spring Boot 3 整合 MyBatis-Plus 完整示例"></a><div class="content"><a class="title" href="/2025/08/27/Springboot/Spring%20Boot%203%20%E6%95%B4%E5%90%88%20MyBatis-Plus%20%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B/" title="Spring Boot 3 整合 MyBatis-Plus 完整示例">Spring Boot 3 整合 MyBatis-Plus 完整示例</a><time datetime="2025-08-27T09:06:33.000Z" title="发表于 2025-08-27 17:06:33">2025-08-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/27/Springboot/SpringBoot%E6%95%B4%E5%90%88Spring%20Security%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83/" title="SpringBoot整合Spring Security实现认证与授权"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2025/08/27/Springboot/SpringBoot%E6%95%B4%E5%90%88Spring%20Security%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83/gqnkyc66e4gn2_9e13ac55ee084f79bb67aa80cffde80a.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="SpringBoot整合Spring Security实现认证与授权"></a><div class="content"><a class="title" href="/2025/08/27/Springboot/SpringBoot%E6%95%B4%E5%90%88Spring%20Security%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83/" title="SpringBoot整合Spring Security实现认证与授权">SpringBoot整合Spring Security实现认证与授权</a><time datetime="2025-08-27T05:38:56.000Z" title="发表于 2025-08-27 13:38:56">2025-08-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By formeasy</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(async()=>{window.katex_js_css||(window.katex_js_css=!0,await btf.getCSS("https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"),await btf.getScript("https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js")),document.querySelectorAll("#article-container .katex").forEach(t=>t.classList.add("katex-show"))})()</script><script>(()=>{var e=()=>{var e;0!==(e=document.querySelectorAll("pre > code.mermaid")).length&&e.forEach(e=>{var t=document.createElement("pre"),n=(t.className="mermaid-src",t.hidden=!0,t.textContent=e.textContent,document.createElement("div"));n.className="mermaid-wrap",n.appendChild(t),e.parentNode.replaceWith(n)});const t=document.querySelectorAll("#article-container .mermaid-wrap");0!==t.length&&(e=()=>{{var e=t;window.loadMermaid=!0;const a="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";e.forEach((e,t)=>{const n=e.firstElementChild;e=`%%{init:{ 'theme':'${a}'}}%%
`+n.textContent,t=mermaid.render("mermaid-"+t,e);const d=e=>{n.insertAdjacentHTML("afterend",e)};"string"==typeof t?d(t):t.then(({svg:e})=>d(e))})}},btf.addGlobalFn("themeChange",e,"mermaid"),window.loadMermaid?e():btf.getScript("https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js").then(e))};btf.addGlobalFn("encrypt",e,"mermaid"),window.pjax?e():document.addEventListener("DOMContentLoaded",e)})()</script><script>(()=>{const a=GLOBAL_CONFIG_SITE.isShuoshuo,s=null,n=t=>"dark"===t?"dark":"light";var t=(t=document,e)=>{e=a?{"data-mapping":"specific","data-term":e}:{"data-mapping":(s,"pathname")},e=(t=>{const a=document.createElement("script");return Object.entries(t).forEach(([t,e])=>{a.setAttribute(t,e)}),a})({src:"https://giscus.app/client.js","data-repo":"formeasy/blog","data-repo-id":"R_kgDOJ2sA5A","data-category-id":"DIC_kwDOJ2sA5M4CktKh","data-theme":n(document.documentElement.getAttribute("data-theme")),"data-reactions-enabled":"1",crossorigin:"anonymous",async:!0,...s,...e});t.querySelector("#giscus-wrap").appendChild(e),a&&(window.shuoshuoComment.destroyGiscus=()=>{t.children.length&&(t.innerHTML="",t.classList.add("no-comment"))})};btf.addGlobalFn("themeChange",t=>{var e=document.querySelector("#giscus-wrap iframe");e&&(t={giscus:{setConfig:{theme:n(t)}}},e.contentWindow.postMessage(t,"https://giscus.app"))},"giscus"),a?window.shuoshuoComment={loadComment:t}:t()})()</script></div><script defer id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zindex="-1" mobile="false" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="请输入搜索关键字" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>