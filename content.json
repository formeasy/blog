{"meta":{"title":"易锦风的博客","subtitle":"专注互联网和软件技术","description":"专注互联网和软件技术","author":"formeasy","url":"http://www.formeasy.cc","root":"/"},"pages":[{"title":"关于","date":"2024-12-03T01:25:47.254Z","updated":"2024-12-03T01:25:47.254Z","comments":false,"path":"about/index.html","permalink":"http://www.formeasy.cc/about/index.html","excerpt":"","text":"易锦风(formeasy) 专注互联网和软件技术 formeasy@163.com"},{"title":"404 Not Found：该页无法显示","date":"2023-07-05T03:00:21.690Z","updated":"2023-07-05T03:00:21.690Z","comments":false,"path":"/404.html","permalink":"http://www.formeasy.cc/404.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-11-29T06:25:41.218Z","updated":"2024-11-29T06:25:41.218Z","comments":false,"path":"links/index.html","permalink":"http://www.formeasy.cc/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2025-04-08T06:31:03.341Z","updated":"2025-04-08T06:31:03.341Z","comments":false,"path":"categories/index.html","permalink":"http://www.formeasy.cc/categories/index.html","excerpt":"","text":"操作系统 虚拟化 数据库 串行通讯 网络通讯 技术 管理 智能 设计 测试 软件工程"},{"title":"Repositories","date":"2023-07-05T03:00:21.694Z","updated":"2023-07-05T03:00:21.694Z","comments":false,"path":"repository/index.html","permalink":"http://www.formeasy.cc/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2025-08-21T07:42:32.170Z","updated":"2025-08-21T07:42:32.170Z","comments":false,"path":"tags/index.html","permalink":"http://www.formeasy.cc/tags/index.html","excerpt":"","text":"Other Hexo 1553B C Qt Python VS Docker DDS UDPTCP RPC MySQL Redis Neo4j kafka Navicat NVIDIA Ubuntu UE EA ROS kubernetes ollama LLM proxmox MCP OpenDroneMap vosk VUE Springboot TEST Editor algo"},{"title":"书单","date":"2023-07-05T03:00:21.692Z","updated":"2023-07-05T03:00:21.692Z","comments":false,"path":"books/index.html","permalink":"http://www.formeasy.cc/books/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring Boot 3 整合 MyBatis-Plus 完整示例","slug":"Springboot/Spring Boot 3 整合 MyBatis-Plus 完整示例","date":"2025-08-27T09:06:33.000Z","updated":"2025-08-27T09:20:39.099Z","comments":true,"path":"2025/08/27/Springboot/Spring Boot 3 整合 MyBatis-Plus 完整示例/","link":"","permalink":"http://www.formeasy.cc/2025/08/27/Springboot/Spring%20Boot%203%20%E6%95%B4%E5%90%88%20MyBatis-Plus%20%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"下面我将按照需求，创建一个完整的 Spring Boot 3 整合 MyBatis-Plus 的示例，实现规范的 CRUD 操作。 1. 首先添加 Maven 依赖 (pom.xml) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.1.3&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;phone-area-code&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;phone-area-code&lt;/name&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;mybatis-plus.version&gt;3.5.3.1&lt;/mybatis-plus.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Starter Web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL Driver --&gt; &lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- springdoc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;!-- 推荐使用最新稳定版本 --&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Starter Test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2. 配置文件 (application.yml) 1234567891011121314151617spring: datasource: url: jdbc:mysql://localhost:3306/your_database_name?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai username: root password: password driver-class-name: com.mysql.cj.jdbc.Drivermybatis-plus: mapper-locations: classpath*:mapper/**/*.xml global-config: db-config: logic-delete-field: idDeleted # 全局逻辑删除的实体字段名 logic-delete-value: 1 # 逻辑已删除值(默认为1) logic-not-delete-value: 0 # 逻辑未删除值(默认为0) configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # 打印SQL日志 map-underscore-to-camel-case: true # 开启驼峰命名转换 3. 基础 PO 类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.example.phoneareacode.po;import com.baomidou.mybatisplus.annotation.FieldFill;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableLogic;import lombok.Data;import java.time.LocalDateTime;/** * 基础PO类，包含公共字段 */@Datapublic class BasePO &#123; /** * 状态：0-禁用 1-启用 */ private Integer status; /** * 备注 */ private String remark; /** * 创建时间 */ @TableField(fill = FieldFill.INSERT) private LocalDateTime createdTime; /** * 更新时间 */ @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updatedTime; /** * 创建人 */ @TableField(fill = FieldFill.INSERT) private String createdBy; /** * 更新人 */ @TableField(fill = FieldFill.INSERT_UPDATE) private String updatedBy; /** * 是否删除：0-未删除 1-已删除 */ @TableLogic private Integer idDeleted;&#125; 4. 实体类 PhoneAreaCodePO 12345678910111213141516171819202122232425262728293031323334353637package com.example.phoneareacode.po;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;import lombok.EqualsAndHashCode;/** * 全球手机区号实体类 */@Data@EqualsAndHashCode(callSuper = true)@TableName(&quot;app_phone_area_code&quot;)public class PhoneAreaCodePO extends BasePO &#123; /** * 主键ID */ @TableId(type = IdType.AUTO) private Integer id; /** * 国家/地区名称 */ private String countryName; /** * 手机区号 */ private String areaCode; /** * 排序字段，值越大越靠前 */ private Integer sortOrder;&#125; 5. MyBatis-Plus 自动填充处理器 123456789101112131415161718192021222324252627282930313233343536package com.example.phoneareacode.config;import com.baomidou.mybatisplus.core.handlers.MetaObjectHandler;import org.apache.ibatis.reflection.MetaObject;import org.springframework.stereotype.Component;import java.time.LocalDateTime;/** * MyBatis-Plus 自动填充处理器 */@Componentpublic class MyMetaObjectHandler implements MetaObjectHandler &#123; /** * 插入时的填充策略 */ @Override public void insertFill(MetaObject metaObject) &#123; // 自动填充创建时间和更新时间 this.strictInsertFill(metaObject, &quot;createdTime&quot;, LocalDateTime.class, LocalDateTime.now()); this.strictInsertFill(metaObject, &quot;updatedTime&quot;, LocalDateTime.class, LocalDateTime.now()); // 默认状态为启用 this.strictInsertFill(metaObject, &quot;status&quot;, Integer.class, 1); &#125; /** * 更新时的填充策略 */ @Override public void updateFill(MetaObject metaObject) &#123; // 自动填充更新时间 this.strictUpdateFill(metaObject, &quot;updatedTime&quot;, LocalDateTime.class, LocalDateTime.now()); &#125;&#125; 6. 通用分页请求对象 123456789101112131415161718package com.example.phoneareacode.dto;import io.swagger.v3.oas.annotations.media.Schema;import lombok.Data;/** * 通用分页请求对象 */@Data@Schema(description = &quot;分页请求参数&quot;)public class PageRequest &#123; @Schema(description = &quot;页码，从1开始&quot;, example = &quot;1&quot;) private Integer pageNum = 1; @Schema(description = &quot;每页条数&quot;, example = &quot;10&quot;) private Integer pageSize = 10;&#125; 7. 通用响应对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.example.phoneareacode.common;import io.swagger.v3.oas.annotations.media.Schema;import lombok.Data;/** * 通用API响应对象 */@Data@Schema(description = &quot;API响应结果&quot;)public class ApiResponse&lt;T&gt; &#123; @Schema(description = &quot;状态码：200表示成功，其他表示失败&quot;, example = &quot;200&quot;) private int code; @Schema(description = &quot;响应消息&quot;, example = &quot;操作成功&quot;) private String message; @Schema(description = &quot;响应数据&quot;) private T data; /** * 成功响应 */ public static &lt;T&gt; ApiResponse&lt;T&gt; success(T data) &#123; ApiResponse&lt;T&gt; response = new ApiResponse&lt;&gt;(); response.setCode(200); response.setMessage(&quot;操作成功&quot;); response.setData(data); return response; &#125; /** * 成功响应（无数据） */ public static &lt;T&gt; ApiResponse&lt;T&gt; success() &#123; return success(null); &#125; /** * 失败响应 */ public static &lt;T&gt; ApiResponse&lt;T&gt; fail(int code, String message) &#123; ApiResponse&lt;T&gt; response = new ApiResponse&lt;&gt;(); response.setCode(code); response.setMessage(message); response.setData(null); return response; &#125; /** * 失败响应（默认错误码） */ public static &lt;T&gt; ApiResponse&lt;T&gt; fail(String message) &#123; return fail(500, message); &#125;&#125; 8. Mapper 接口 123456789101112package com.example.phoneareacode.mapper;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.example.phoneareacode.po.PhoneAreaCodePO;import org.apache.ibatis.annotations.Mapper;/** * 手机区号Mapper接口 */@Mapperpublic interface PhoneAreaCodeMapper extends BaseMapper&lt;PhoneAreaCodePO&gt; &#123;&#125; 9. Service 接口及实现 12345678910111213141516171819202122232425262728293031323334353637package com.example.phoneareacode.service;import com.baomidou.mybatisplus.core.metadata.IPage;import com.baomidou.mybatisplus.extension.service.IService;import com.example.phoneareacode.dto.PageRequest;import com.example.phoneareacode.po.PhoneAreaCodePO;/** * 手机区号Service接口 */public interface PhoneAreaCodeService extends IService&lt;PhoneAreaCodePO&gt; &#123; /** * 分页查询手机区号列表 */ IPage&lt;PhoneAreaCodePO&gt; getPageList(PageRequest pageRequest); /** * 根据ID查询 */ PhoneAreaCodePO getById(Integer id); /** * 新增 */ boolean save(PhoneAreaCodePO phoneAreaCodePO); /** * 更新 */ boolean update(PhoneAreaCodePO phoneAreaCodePO); /** * 删除（逻辑删除） */ boolean removeById(Integer id);&#125; PhoneAreaCodeServiceImpl实现类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.example.phoneareacode.service.impl;import com.baomidou.mybatisplus.core.metadata.IPage;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import com.example.phoneareacode.dto.PageRequest;import com.example.phoneareacode.mapper.PhoneAreaCodeMapper;import com.example.phoneareacode.po.PhoneAreaCodePO;import com.example.phoneareacode.service.PhoneAreaCodeService;import org.springframework.stereotype.Service;/** * 手机区号Service实现类 */@Servicepublic class PhoneAreaCodeServiceImpl extends ServiceImpl&lt;PhoneAreaCodeMapper, PhoneAreaCodePO&gt; implements PhoneAreaCodeService &#123; @Override public IPage&lt;PhoneAreaCodePO&gt; getPageList(PageRequest pageRequest) &#123; // 使用 MyBatis-Plus 的分页查询 return this.page( new com.baomidou.mybatisplus.extension.plugins.pagination.Page&lt;&gt;( pageRequest.getPageNum(), pageRequest.getPageSize() ) ); &#125; @Override public PhoneAreaCodePO getById(Integer id) &#123; // 直接调用父类方法 return super.getById(id); &#125; @Override public boolean save(PhoneAreaCodePO phoneAreaCodePO) &#123; // 直接调用父类方法 return super.save(phoneAreaCodePO); &#125; @Override public boolean update(PhoneAreaCodePO phoneAreaCodePO) &#123; // 直接调用父类方法 return super.updateById(phoneAreaCodePO); &#125; @Override public boolean removeById(Integer id) &#123; // 逻辑删除，直接调用父类方法 return super.removeById(id); &#125;&#125; 10. Controller 层 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.example.phoneareacode.controller;import com.baomidou.mybatisplus.core.metadata.IPage;import com.example.phoneareacode.common.ApiResponse;import com.example.phoneareacode.dto.PageRequest;import com.example.phoneareacode.po.PhoneAreaCodePO;import com.example.phoneareacode.service.PhoneAreaCodeService;import io.swagger.v3.oas.annotations.Operation;import io.swagger.v3.oas.annotations.tags.Tag;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 手机区号Controller * 统一使用POST请求 */@RestController@RequestMapping(&quot;/api/phone-area-code&quot;)@Tag(name = &quot;手机区号管理&quot;, description = &quot;手机区号CRUD操作&quot;)public class PhoneAreaCodeController &#123; @Autowired private PhoneAreaCodeService phoneAreaCodeService; /** * 分页查询列表 */ @PostMapping(&quot;/page&quot;) @Operation(summary = &quot;分页查询手机区号列表&quot;) public ApiResponse&lt;IPage&lt;PhoneAreaCodePO&gt;&gt; getPageList(@RequestBody PageRequest pageRequest) &#123; return ApiResponse.success(phoneAreaCodeService.getPageList(pageRequest)); &#125; /** * 根据ID查询 */ @PostMapping(&quot;/getById&quot;) @Operation(summary = &quot;根据ID查询手机区号&quot;) public ApiResponse&lt;PhoneAreaCodePO&gt; getById(@RequestBody Integer id) &#123; return ApiResponse.success(phoneAreaCodeService.getById(id)); &#125; /** * 新增 */ @PostMapping(&quot;/save&quot;) @Operation(summary = &quot;新增手机区号&quot;) public ApiResponse&lt;Boolean&gt; save(@RequestBody PhoneAreaCodePO phoneAreaCodePO) &#123; return ApiResponse.success(phoneAreaCodeService.save(phoneAreaCodePO)); &#125; /** * 更新 */ @PostMapping(&quot;/update&quot;) @Operation(summary = &quot;更新手机区号&quot;) public ApiResponse&lt;Boolean&gt; update(@RequestBody PhoneAreaCodePO phoneAreaCodePO) &#123; return ApiResponse.success(phoneAreaCodeService.update(phoneAreaCodePO)); &#125; /** * 删除 */ @PostMapping(&quot;/delete&quot;) @Operation(summary = &quot;删除手机区号&quot;) public ApiResponse&lt;Boolean&gt; delete(@RequestBody Integer id) &#123; return ApiResponse.success(phoneAreaCodeService.removeById(id)); &#125;&#125; 11. MyBatis-Plus 配置类（分页插件） 12345678910111213141516171819202122232425package com.example.phoneareacode.config;import com.baomidou.mybatisplus.annotation.DbType;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * MyBatis-Plus配置类 */@Configurationpublic class MyBatisPlusConfig &#123; /** * 配置分页插件 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 添加分页插件 interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; &#125;&#125; 12. 启动类 1234567891011121314package com.example.phoneareacode;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication@MapperScan(&quot;com.example.phoneareacode.mapper&quot;) // 扫描Mapper接口public class PhoneAreaCodeApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PhoneAreaCodeApplication.class, args); &#125;&#125; 13. 数据表 1234567891011121314create table `your_database_name`.`app_phone_area_code`( `id` int(8) NOT NULL AUTO_INCREMENT , `countryName` varchar(200) DEFAULT &#x27;&#x27; , `areaCode` varchar(20) DEFAULT &#x27;&#x27; , `sortOrder` int(8) DEFAULT &#x27;0&#x27; , `status` int(1) DEFAULT &#x27;1&#x27; , `remark` varchar(200) DEFAULT &#x27;&#x27; , `createdTime` timestamp , `updatedTime` timestamp , `createdBy` varchar(100) DEFAULT &#x27;&#x27; , `updatedBy` varchar(100) DEFAULT &#x27;&#x27; , `idDeleted` int(1) DEFAULT &#x27;0&#x27; , PRIMARY KEY (`id`) ) 项目结构说明 整个项目按照标准的分层架构设计： PO层：存放实体类，继承基础BasePO，包含公共字段 Mapper层：数据访问层，继承MyBatis-Plus的BaseMapper Service层：业务逻辑层，实现具体的业务逻辑 Controller层：控制层，只负责接收请求和返回响应，不包含业务逻辑 Common：存放通用响应对象等公共类 Config：存放配置类 DTO：存放数据传输对象，如分页请求对象 为了测试上述接口，我们可以使用Postman或编写单元测试来验证接口的正确性。下面提供两种测试方案： 一、使用Postman测试接口 所有接口都使用POST方法，以下是各接口的测试示例： 分页查询接口 URL: http://localhost:8080/api/phone-area-code/page 请求体: 1234&#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 10&#125; 新增接口 URL: http://localhost:8080/api/phone-area-code/save 请求体: 123456&#123; &quot;countryName&quot;: &quot;中国&quot;, &quot;areaCode&quot;: &quot;+86&quot;, &quot;sortOrder&quot;: 100, &quot;remark&quot;: &quot;中国大陆地区&quot;&#125; 查询单个接口 URL: http://localhost:8080/api/phone-area-code/getById 请求体: 1 (要查询的ID) 更新接口 URL: http://localhost:8080/api/phone-area-code/update 请求体: 1234567&#123; &quot;id&quot;: 1, &quot;countryName&quot;: &quot;中国&quot;, &quot;areaCode&quot;: &quot;+86&quot;, &quot;sortOrder&quot;: 200, &quot;remark&quot;: &quot;中国大陆地区手机号&quot;&#125; 删除接口 URL: http://localhost:8080/api/phone-area-code/delete 请求体: 1 (要删除的ID) 二、编写单元测试 下面是使用Spring Boot Test编写的单元测试代码： 三、测试注意事项 数据库准备： 确保测试前已创建好数据库表结构 可以在测试类上添加@Sql注解自动执行初始化SQL脚本 测试顺序： 建议先执行新增测试，再执行查询、更新测试 最后执行删除测试 测试环境： 可以在application-test.yml中配置测试环境的数据库，避免影响生产数据 12345spring: datasource: url: jdbc:mysql://localhost:3306/test_database?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai username: root password: password 添加测试依赖： 如果需要更丰富的测试支持，可以在pom.xml中添加： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 通过以上测试方法，可以全面验证我们实现的接口功能是否正常，确保代码的质量和稳定性。 实现特点 统一响应格式：使用ApiResponse统一封装响应结果 通用分页：实现了通用的PageRequest分页请求对象 统一使用POST请求：所有接口都使用POST方法 逻辑删除：通过MyBatis-Plus实现逻辑删除功能 自动填充：自动填充创建时间、更新时间等公共字段 Lombok：使用@Data等注解减少getter、setter等模板代码 控制层无业务逻辑：Controller只负责转发请求和响应结果 通过以上实现，我们构建了一个规范、高效的Spring Boot 3整合MyBatis-Plus的项目，实现了对手机区号表的完整CRUD操作。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":"zhuguanbo"},{"title":"SpringBoot整合Spring Security实现认证与授权","slug":"Springboot/SpringBoot整合Spring Security实现认证与授权","date":"2025-08-27T05:38:56.000Z","updated":"2025-08-27T09:27:30.667Z","comments":true,"path":"2025/08/27/Springboot/SpringBoot整合Spring Security实现认证与授权/","link":"","permalink":"http://www.formeasy.cc/2025/08/27/Springboot/SpringBoot%E6%95%B4%E5%90%88Spring%20Security%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83/","excerpt":"","text":"本文通过逐步学习Spring Security，由浅入深，SpringBoot整合Spring Security 分别实现自定义的HTTP Basic认证和Form表单认证。 本文是学习笔记，网上的教程五花八门，由于时间久远，很难拿来就用。 主要内容： 用户信息管理 敏感信息加密解密 用户认证 权限控制 跨站点请求伪造保护 跨域支持 全局安全方法 单点登录 一、Spring Security 快速开始一个例子 创建SpringBoot项目 1234567891011121314151617$ tree -I test.├── pom.xml└── src └── main ├── java │ └── com │ └── example │ └── demo │ ├── Application.java │ └── controller │ └── IndexController.java └── resources ├── application.yml ├── static └── templates 引入Spring Security依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 完整依赖 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.7.7&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置 application.yml 12server: port: 8080 启动类 Application.java 1234567891011121314package com.example.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 控制器 IndexController.java 12345678910111213package com.example.demo.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class IndexController &#123; @GetMapping(&quot;/&quot;) public String index()&#123; return &quot;Hello&quot;; &#125;&#125; 直接访问应用会被重定向到登录页面 123http://localhost:8080/=&gt; 302http://localhost:8080/login 现在使用默认的账号密码登录 默认的用户名：user 默认的密码：(控制台打印出的密码) 1Using generated security password: cdd28beb-9a64-4130-be58-6bde1684476d 再次访问 http://localhost:8080/ 可以看到返回结果 看到上图说明成功集成Spring Security。 二、认证与授权说明 认证authentication用户身份 授权authorization用户权限 单体应用 微服务架构 三、Spring Security基础认证与表单认证 用户对象 UserDetails 内存存储 数据库存储 认证对象 Authentication HTTP基础认证 HTTP表单认证 1、HTTP基础认证 通过HTTP请求头携带用户名和密码进行登录认证 HTTP请求头格式 12# 用户名和密码的Base64编码Authonrization: Basic Base64-encoded(username:password) Spring Boot2.4版本以前 12345678910111213141516171819package com.example.demo.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.Customizer;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; // 所有请求都需要认证，认证方式：httpBasic http.authorizeHttpRequests((auth) -&gt; &#123; auth.anyRequest().authenticated(); &#125;).httpBasic(Customizer.withDefaults()); &#125;&#125; Spring Boot2.4版本之后 1234567891011121314151617181920212223package com.example.demo.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.Customizer;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.web.SecurityFilterChain;@Configurationpublic class SecurityConfiguration &#123; @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception &#123; // 所有请求都需要认证，认证方式：httpBasic http.authorizeHttpRequests((auth) -&gt; &#123; auth.anyRequest().authenticated(); &#125;).httpBasic(Customizer.withDefaults()); return http.build(); &#125;&#125; 发送HTTP请求 12GET http://localhost:8080/Authorization: Basic dXNlcjo2ZjRhMGY5ZS1hY2ZkLTRmNTYtYjIzNy01MTZmYmZjMTk3NGM= 可以获得响应数据 1Hello base64解码之后可以得到用户名和密码 123atob(&#x27;dXNlcjo2ZjRhMGY5ZS1hY2ZkLTRmNTYtYjIzNy01MTZmYmZjMTk3NGM=&#x27;)&#x27;user:6f4a0f9e-acfd-4f56-b237-516fbfc1974c&#x27; 2、HTTP表单认证 Spring Security的默认认证方式 四、Spring Security 用户与认证对象说明 1、用户对象 UserDetails 用户对象接口说明 123456789101112131415161718192021222324252627282930package org.springframework.security.core.userdetails;import java.io.Serializable;import java.util.Collection;import org.springframework.security.core.GrantedAuthority;public interface UserDetails extends Serializable &#123; // 获取用户权限信息 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // 获取密码 java.lang.String getPassword(); // 获取用户名 java.lang.String getUsername(); // 判断账户是否失效 boolean isAccountNonExpired(); // 判断账户是否锁定 boolean isAccountNonLocked(); // 判断账户凭证信息是否已失效 boolean isCredentialsNonExpired(); // 判断账户是否可用 boolean isEnabled();&#125; GrantedAuthority 用户拥有权限接口说明 12345678package org.springframework.security.core;import java.io.Serializable;public interface GrantedAuthority extends Serializable &#123; // 获取权限信息 String getAuthority();&#125; UserDetailsService 用户查询操作说明 123456789package org.springframework.security.core.userdetails;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UsernameNotFoundException;public interface UserDetailsService &#123; // 根据用户名获取用户信息 UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;&#125; UserDetailsManager 用户CRUD操作说明 12345678910111213141516171819202122232425package org.springframework.security.provisioning;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;public interface UserDetailsManager extends UserDetailsService &#123; // 创建用户 void createUser(UserDetails user); // 更新用户 void updateUser(UserDetails user); // 删除用户 void deleteUser(String username); // 修改密码 void changePassword(String oldPassword, String newPassword); // 判断用户是否存在 boolean userExists(String username);&#125; 2、认证对象 Authentication 认证请求详细信息 12345678910111213141516171819202122232425262728293031package org.springframework.security.core;import java.io.Serializable;import java.security.Principal;import java.util.Collection;import org.springframework.security.authentication.AuthenticationManager;import org.springframework.security.core.context.SecurityContextHolder;public interface Authentication extends Principal, Serializable &#123; // 安全主体所具有的的权限 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // 证明主体有效性的凭证 Object getCredentials(); // 认证请求的明细信息 Object getDetails(); // 主体的标识信息 Object getPrincipal(); // 是否认证通过 boolean isAuthenticated(); // 设置认证结果 void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;&#125; AuthenticationProvider 认证的业务执行者 1234567891011121314package org.springframework.security.authentication;import org.springframework.security.core.Authentication;import org.springframework.security.core.AuthenticationException;public interface AuthenticationProvider &#123; // 执行认证，返回认证结果 Authentication authenticate(Authentication authentication) throws AuthenticationException; // 判断是否支持当前的认证对象 boolean supports(Class&lt;?&gt; authentication);&#125; 五、基于MySQL自定义认证过程例子 1、项目结构 123456789101112131415161718192021222324252627282930313233$ tree -I target.├── pom.xml└── src ├── main │ ├── java │ │ └── com.example.springboot │ │ ├── Application.java │ │ ├── controller │ │ │ └── IndexController.java │ │ ├── entity │ │ │ └── User.java │ │ ├── mapper │ │ │ └── UserMapper.java │ │ ├── security │ │ │ ├── SecurityConfiguration.java │ │ │ └── UserAuthenticationProvider.java │ │ └── service │ │ ├── UserService.java │ │ └── impl │ │ └── UserServiceImpl.java │ └── resources │ ├── application.yml │ ├── sql │ │ └── schema.sql │ ├── static │ │ └── login.html │ └── templates └── test └── java └── com.example.springboot └── ApplicationTests.java 2、用户表 默认表结构的SQL路径 spring-security-core-5.7.6.jar!/org/springframework/security/core/userdetails/jdbc/users.ddl 1234567891011create table users( username varchar_ignorecase(50) not null primary key, password varchar_ignorecase(500) not null, enabled boolean not null);create table authorities ( username varchar_ignorecase(50) not null, authority varchar_ignorecase(50) not null, constraint fk_authorities_users foreign key(username) references users(username));create unique index ix_auth_username on authorities (username,authority); 一般情况下，我们使用自己创建的用户表 schema.sql 123456789101112131415-- 创建用户表CREATE TABLE `tb_user` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `username` varchar(255) COLLATE utf8mb4_general_ci NOT NULL COMMENT &#x27;用户名&#x27;, `password` varchar(255) COLLATE utf8mb4_general_ci NOT NULL COMMENT &#x27;密码&#x27;, `nickname` varchar(32) COLLATE utf8mb4_general_ci NOT NULL DEFAULT &#x27;昵称&#x27;, `enabled` tinyint NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;账号可用标识&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `idx_username` (`username`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT=&#x27;用户表&#x27;;-- 添加初始数据insert into `tb_user` values (1, &quot;zhangsan&quot;, &quot;zhangsan&quot;, &quot;张三&quot;, 1);insert into `tb_user` values (2, &quot;lisi&quot;, &quot;lisi&quot;, &quot;李四&quot;, 1);insert into `tb_user` values (3, &quot;wangwu&quot;, &quot;wangwu&quot;, &quot;王五&quot;, 1); 3、依赖 Spring Security MyBatis-Plus MySQL8 JDBC Lombok 完整依赖 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;springboot学习&lt;/description&gt; &lt;url/&gt; &lt;licenses&gt; &lt;license/&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer/&gt; &lt;/developers&gt; &lt;scm&gt; &lt;connection/&gt; &lt;developerConnection/&gt; &lt;tag/&gt; &lt;url/&gt; &lt;/scm&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--starter-web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--thymeleaf--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--spring-security--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- 添加 JDBC Starter 以引入 HikariCP --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;version&gt;8.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--MyBatisPlus核心库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 4、数据库配置 application.yml 123456789101112131415161718192021222324252627282930313233343536373839404142server: port: 8080#数据库配置spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai username: root password: zaq1xsw2 hikari: maximum-pool-size: 10 # 最大连接数 minimum-idle: 5 # 最小空闲连接数 idle-timeout: 300000 # 空闲连接超时时间（毫秒） connection-timeout: 20000 # 连接超时时间（毫秒）#配置mybatis实体配置mybatis: mapper-locations: - classpath:mapper/*.xml #映射到resources/mapper/User.xml里#mybatis-plus相关配置mybatis-plus: # xml扫描，多个目录用逗号或者分号分隔（告诉 Mapper 所对应的 XML 文件位置） mapper-locations: classpath:mapper/*.xml # 以下配置均有默认值,可以不设置 global-config: db-config: #主键类型 AUTO:&quot;数据库ID自增&quot; INPUT:&quot;用户输入ID&quot;,ID_WORKER:&quot;全局唯一ID (数字类型唯一ID)&quot;, UUID:&quot;全局唯一ID UUID&quot;; id-type: auto #字段策略 IGNORED:&quot;忽略判断&quot; NOT_NULL:&quot;非 NULL 判断&quot;) NOT_EMPTY:&quot;非空判断&quot; field-strategy: NOT_EMPTY #数据库类型 db-type: MYSQL configuration: # 是否开启自动驼峰命名规则映射:从数据库列名到Java属性驼峰命名的类似映射 map-underscore-to-camel-case: true # 如果查询结果中包含空值的列，则 MyBatis 在映射的时候，不会映射这个字段 call-setters-on-nulls: true # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 5、SpringBoot基本框架 启动类 Application.java 1234567891011121314package com.example.springboot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class SpringbootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootApplication.class, args); &#125;&#125; 实体类 User.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.example.springboot.entity;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.UserDetails;import java.util.Arrays;import java.util.Collection;@Data@TableName(&quot;tb_user&quot;)public class User implements UserDetails &#123; /** * 主键id */ @TableId private Long id; /** * 用户名 */ private String username; /** * 密码 */ private String password; /** * 昵称 */ private String nickname; /** * 账号可用标识 */ private Integer enabled; /** * 获取用户权限信息 * * @return */ @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return Arrays.asList(new SimpleGrantedAuthority(&quot;ROLE_USER&quot;)); &#125; /** * 判断账户是否失效 * * @return */ @Override public boolean isAccountNonExpired() &#123; return true; &#125; /** * 判断账户是否锁定 * * @return */ @Override public boolean isAccountNonLocked() &#123; return true; &#125; /** * 判断账户凭证信息是否已失效 * * @return */ @Override public boolean isCredentialsNonExpired() &#123; return true; &#125; /** * 判断账户是否可用 * * @return */ @Override public boolean isEnabled() &#123; return this.enabled == 1; &#125;&#125; UserMapper.java 12345678910package com.example.springboot.mapper;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.example.springboot.entity.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; UserService.java 12345678package com.example.springboot.service;import com.baomidou.mybatisplus.extension.service.IService;import com.example.springboot.entity.User;public interface UserService extends IService&lt;User&gt; &#123;&#125; UserServiceImpl.java 12345678910111213141516171819202122232425262728293031323334353637383940package com.example.springboot.service.impl;import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import com.example.springboot.entity.User;import com.example.springboot.mapper.UserMapper;import com.example.springboot.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Service;@Service@Slf4jpublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService, UserDetailsService &#123; /** * 根据用户名获取用户信息 * @param username * @return UserDetails * @throws UsernameNotFoundException */ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(User::getUsername, username); User user = super.getOne(queryWrapper); if(user == null)&#123; log.error(&quot;Access Denied, user not found:&quot; + username); throw new UsernameNotFoundException(&quot;user not found:&quot; + username); &#125; return user; &#125;&#125; IndexController.java 12345678910111213package com.example.springboot.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class IndexController &#123; @GetMapping(&quot;/hello&quot;) public String hello()&#123; return &quot;Hello&quot;; &#125;&#125; 6、自动定义Spring Security SecurityConfiguration.java 1234567891011121314151617181920212223242526272829package com.example.springboot.security;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.Customizer;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.web.SecurityFilterChain;@Configurationpublic class SecurityConfiguration &#123; /** * 基于基础认证模式 * @param http * @return * @throws Exception */ @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception &#123; // 所有请求都需要认证，认证方式：httpBasic http.authorizeHttpRequests((auth) -&gt; &#123; auth.anyRequest().authenticated(); &#125;).httpBasic(Customizer.withDefaults()); return http.build(); &#125;&#125; UserAuthenticationProvider.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.example.springboot.security;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.authentication.AuthenticationProvider;import org.springframework.security.authentication.BadCredentialsException;import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;import org.springframework.security.core.Authentication;import org.springframework.security.core.AuthenticationException;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.stereotype.Component;@Component@Slf4jpublic class UserAuthenticationProvider implements AuthenticationProvider &#123; @Autowired private UserDetailsService userService; /** * 自己实现认证过程 * * @param authentication * @return * @throws AuthenticationException */ @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; // 从Authentication 对象中获取用户名和密码 String username = authentication.getName(); String password = authentication.getCredentials().toString(); UserDetails user = userService.loadUserByUsername(username); if (password.equals(user.getPassword())) &#123; // 密码匹配成功 log.info(&quot;Access Success: &quot; + user); return new UsernamePasswordAuthenticationToken(username, password, user.getAuthorities()); &#125; else &#123; // 密码匹配失败 log.error(&quot;Access Denied: The username or password is wrong!&quot;); throw new BadCredentialsException(&quot;The username or password is wrong!&quot;); &#125; &#125; @Override public boolean supports(Class&lt;?&gt; authentication) &#123; return authentication.equals(UsernamePasswordAuthenticationToken.class); &#125;&#125; 7、接口测试 IndexController.http 1234567891011121314#### 不提供认证信息GET http://localhost:8080/hello#### 提供错误的认证信息GET http://localhost:8080/helloAuthorization: Basic dXNlcjo2YzVlMTUyOS1kMTc2LTRkYjItYmZlMy0zZTIzOTNlMjY2MTk=#### 提供正确的认证信息GET http://localhost:8080/helloAuthorization: Basic emhhbmdzYW46emhhbmdzYW4=### 六、使用PasswordEncoder加密密码 PasswordEncoder接口说明 12345678910111213141516package org.springframework.security.crypto.password;public interface PasswordEncoder &#123; // 对原始密码编码 String encode(CharSequence rawPassword); // 密码比对 boolean matches(CharSequence rawPassword, String encodedPassword); // 判断加密密码是否需要再次加密 default boolean upgradeEncoding(String encodedPassword) &#123; return false; &#125;&#125; 常见的实现类 Bcrypt算法简介 例如： 12345678910111213141516package com.example.sprintboot;import org.junit.jupiter.api.Test;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;public class BCryptPasswordEncoderTest &#123; @Test public void encode()&#123; BCryptPasswordEncoder bCryptPasswordEncoder = new BCryptPasswordEncoder(); String encode = bCryptPasswordEncoder.encode(&quot;123456&quot;); System.out.println(encode); &#125;&#125; 输出 1$2a$10$lKqmIKbEPNDx/RXssgN6POgb8YssAK7pVtMFDosmC8FxozUgQq58K 解释 123456$是分隔符2a表示Bcrypt算法版本10表示算法强度中间22位表示盐值中间面的位数表示加密后的文本总长度60位 使用Bcrypt算法加密密码后的数据 123456789101112131415-- 建表CREATE TABLE `tb_user` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `username` varchar(255) COLLATE utf8mb4_general_ci NOT NULL COMMENT &#x27;用户名&#x27;, `password` varchar(255) COLLATE utf8mb4_general_ci NOT NULL COMMENT &#x27;密码&#x27;, `nickname` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;昵称&#x27;, `enabled` tinyint NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;账号可用标识&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `idx_username` (`username`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT=&#x27;用户表&#x27;;-- 数据INSERT INTO `tb_user` VALUES (1, &#x27;zhangsan&#x27;, &#x27;$2a$10$/1XHgJYXtF4g/AiR41si8uvVC6Zc.Z9xVmXX4hO2z.b4.DX.H2j5W&#x27;, &#x27;张三&#x27;, 1);INSERT INTO `tb_user` VALUES (2, &#x27;lisi&#x27;, &#x27;$2a$10$PEcF03ina7x9mmt2VbB0ueVkLZWQo/yoKOfvfQpoL09/faBlNuuZ.&#x27;, &#x27;李四&#x27;, 1);INSERT INTO `tb_user` VALUES (3, &#x27;wangwu&#x27;, &#x27;$2a$10$PMumxkwwrELTbNDXCj0N4.jD/e/Hv.JiiZTFkdFqlDNLU2TahdYNq&#x27;, &#x27;王五&#x27;, 1); UserAuthenticationProvider实现类替换如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.example.springboot.security;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.security.authentication.AuthenticationProvider;import org.springframework.security.authentication.BadCredentialsException;import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;import org.springframework.security.core.Authentication;import org.springframework.security.core.AuthenticationException;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;import org.springframework.stereotype.Component;@Component@Slf4jpublic class UserAuthenticationProvider implements AuthenticationProvider &#123; @Autowired private UserDetailsService userService; // 密码加密 public PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; /** * 自己实现认证过程 * * @param authentication * @return * @throws AuthenticationException */ @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; // 从Authentication 对象中获取用户名和密码 String username = authentication.getName(); String password = authentication.getCredentials().toString(); UserDetails user = userService.loadUserByUsername(username); // 替换密码比对方式 // if (password.equals(user.getPassword())) &#123; if (this.passwordEncoder().matches(password, user.getPassword())) &#123; // 密码匹配成功 log.info(&quot;Access Success: &quot; + user); return new UsernamePasswordAuthenticationToken(username, password, user.getAuthorities()); &#125; else &#123; // 密码匹配失败 log.error(&quot;Access Denied: The username or password is wrong!&quot;); throw new BadCredentialsException(&quot;The username or password is wrong!&quot;); &#125; &#125; @Override public boolean supports(Class&lt;?&gt; authentication) &#123; return authentication.equals(UsernamePasswordAuthenticationToken.class); &#125;&#125; 七、Session会话控制 改为基于基础认证模式 修改配置类SecurityConfiguration 1234567891011121314151617181920212223242526272829303132package com.example.springboot.security;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.Customizer;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.http.SessionCreationPolicy;import org.springframework.security.web.SecurityFilterChain;@Configurationpublic class SecurityConfiguration &#123; /** * 基于基础认证模式 * @param http * @return * @throws Exception */ @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception &#123; // 禁用session会话 http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); // 所有请求都需要认证，认证方式：httpBasic http.authorizeHttpRequests((auth) -&gt; &#123; auth.anyRequest().authenticated(); &#125;).httpBasic(Customizer.withDefaults()); return http.build(); &#125;&#125; 八、基于表单模式实现自定义认证 SecurityFormConfiguration 配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.example.springboot.security;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.http.SessionCreationPolicy;import org.springframework.security.web.SecurityFilterChain;@Configurationpublic class SecurityFormConfiguration &#123; /** * 基于表单认证模式 * @param http * @return * @throws Exception */ @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception &#123; // 启用session会话 http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED); // 认证方式：Form http.authorizeRequests() //.requestMatchers(&quot;/login.html&quot;).permitAll() // 放行登录页面 // 所有请求都需要认证 .anyRequest().authenticated() .and() // 启动表单认证模式 .formLogin() // 登录页面 .loginPage(&quot;/login.html&quot;) // 请求提交地址 .loginProcessingUrl(&quot;/login&quot;) // 成功跳转页面 .defaultSuccessUrl(&quot;/hello&quot;, true) // 放行上面的两个地址 .permitAll() // 设置提交的参数名 .usernameParameter(&quot;username&quot;) .passwordParameter(&quot;password&quot;) .and() // 开始设置注销功能 .logout() // 注销的url .logoutUrl(&quot;/logout&quot;) // session直接过期 .invalidateHttpSession(true) // 清除认证信息 .clearAuthentication(true) // 注销成功后跳转地址 .logoutSuccessUrl(&quot;/login.html&quot;) .and() // 禁用csrf安全防护 .csrf().disable(); return http.build(); &#125;&#125; 登录页面 static/login.html 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;Login&lt;/h2&gt;&lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; &lt;div&gt;&lt;label&gt;username：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;label&gt;password：&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;input type=&quot;submit&quot;&gt;&lt;/div&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 显示效果","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":null},{"title":"Spring Boot入门指南(案例篇)","slug":"Springboot/Spring Boot入门指南(案例篇)","date":"2025-08-26T05:33:37.000Z","updated":"2025-08-26T05:49:14.305Z","comments":true,"path":"2025/08/26/Springboot/Spring Boot入门指南(案例篇)/","link":"","permalink":"http://www.formeasy.cc/2025/08/26/Springboot/Spring%20Boot%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97(%E6%A1%88%E4%BE%8B%E7%AF%87)/","excerpt":"","text":"Spring Boot是一个开源的Java基础框架，它使得创建独立的、生产级别的Spring应用变得更容易。它“跑起来”即可用，内嵌了Tomcat、Jetty等Servlet容器，无需部署WAR文件，也无需单独的Servlet容器。 环境准备 在开始之前，请确保你的开发环境中安装了以下软件： Java Development Kit (JDK) 8 或更高版本 Maven 3.0 或更高版本 一个文本编辑器或IDE（如IntelliJ IDEA或Eclipse） Git 创建Spring Boot项目 我们可以通过Spring Initializr快速生成一个Spring Boot项目的基础结构。 访问 Spring Initializr 选择生成Maven项目，选择Java语言 指定项目元数据（Group, Artifact, Name, Description） 添加依赖（Dependencies），我们至少需要Spring Web依赖 点击“Generate”生成项目，下载并解压 项目架构图 图展示了Spring Boot应用的基本架构，包括启动类、控制器、服务、仓库和实体类，以及它们之间的关系。 项目结构 解压后的项目结构大致如下： my-application/ ├── src/ │ ├── main/ │ │ ├── java/ │ │ │ └── com/ │ │ │ └── example/ │ │ │ └── myapplication/ │ │ │ ├── MyApplication.java │ │ │ └── controller/ │ │ │ └── HelloController.java │ │ └── resources/ │ │ ├── application.properties │ │ └── static/ │ │ └── index.html ├── pom.xml └── README.md 编写Hello World应用 1. 启动类 在com.example.myapplication包中创建一个启动类MyApplication.java： 123456789101112package com.example.myapplication;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication // 标注这是一个Spring Boot应用public class MyApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyApplication.class, args); // 启动应用 &#125;&#125; 2. 控制器 在com.example.myapplication.controller包中创建一个控制器类HelloController.java： 12345678910111213package com.example.myapplication.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestController // 标注这是一个REST控制器public class HelloController &#123; @GetMapping(&quot;/hello&quot;) // 映射GET请求到/hello public String sayHello() &#123; return &quot;Hello, World!&quot;; // 返回字符串 &#125;&#125; 3. 运行应用 在项目根目录下运行以下命令来启动应用： 1mvn spring-boot:run 应用启动后，访问http://localhost:8080/hello，你将看到输出Hello, World!。 案例：Todo应用 1. 添加依赖 在pom.xml中添加以下依赖： 123456789101112131415161718&lt;dependencies&gt; &lt;!-- Spring Web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Data JPA --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- H2 Database --&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2. 实体类 创建Todo实体类： 123456789101112131415161718package com.example.myapplication.model;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;@Entity // 标注这是一个JPA实体public class Todo &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; private String description; private boolean completed; // 构造函数、getter和setter省略&#125; 3. 仓库接口 创建TodoRepository接口： 1234567package com.example.myapplication.repository;import com.example.myapplication.model.Todo;import org.springframework.data.repository.CrudRepository;public interface TodoRepository extends CrudRepository&lt;Todo, Long&gt; &#123;&#125; 4. 服务类 创建TodoService服务类： 12345678910111213141516171819202122232425package com.example.myapplication.service;import com.example.myapplication.model.Todo;import com.example.myapplication.repository.TodoRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class TodoService &#123; @Autowired private TodoRepository todoRepository; public List&lt;Todo&gt; getAllTodos() &#123; return todoRepository.findAll(); &#125; public Todo addTodo(Todo todo) &#123; return todoRepository.save(todo); &#125; // 其他方法省略&#125; 5. 控制器 更新HelloController为TodoController： 12345678910111213141516171819202122232425262728package com.example.myapplication.controller;import com.example.myapplication.model.Todo;import com.example.myapplication.service.TodoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;@RestController@RequestMapping(&quot;/todos&quot;)public class TodoController &#123; @Autowired private TodoService todoService; @GetMapping public List&lt;Todo&gt; getAllTodos() &#123; return todoService.getAllTodos(); &#125; @PostMapping public Todo addTodo(@RequestBody Todo todo) &#123; return todoService.addTodo(todo); &#125; // 其他方法省略&#125; 6. 运行应用 运行应用后，你可以使用Postman或curl来测试API： 获取所有Todo：GET http://localhost:8080/todos 添加Todo：POST http://localhost:8080/todos，请求体为JSON格式的Todo对象。 总结 Spring Boot简化了Spring应用的创建和配置，使得开发者可以专注于业务逻辑。通过本文，你已经学会了如何创建一个简单的Spring Boot应用，并了解了一个Todo应用的实现。希望这能帮助你快速上手Spring Boot。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":"alises1314"},{"title":"IntelliJ IDEA-Gradle-SpringBoot搭建","slug":"Springboot/IntelliJ IDEA-Gradle-SpringBoot搭建","date":"2025-08-25T06:53:06.000Z","updated":"2025-08-25T07:02:14.860Z","comments":true,"path":"2025/08/25/Springboot/IntelliJ IDEA-Gradle-SpringBoot搭建/","link":"","permalink":"http://www.formeasy.cc/2025/08/25/Springboot/IntelliJ%20IDEA-Gradle-SpringBoot%E6%90%AD%E5%BB%BA/","excerpt":"","text":"前提条件 JAVA安装 Gradle安装 创建项目 配置项目设置 指定自己的gradle的安装位置,以及仓库位置(用户主目录) 用户主目录: Gradle仓库目录用于存储全局配置属性和初始化脚本以及缓存和日志文件。 结构 build.gradle 1234567891011121314151617181920212223242526272829303132333435plugins &#123; id &#x27;java&#x27; id &#x27;org.springframework.boot&#x27; version &#x27;2.7.7&#x27; id &#x27;io.spring.dependency-management&#x27; version &#x27;1.0.15.RELEASE&#x27;&#125;group = &#x27;com.example&#x27;version = &#x27;0.0.1-SNAPSHOT&#x27;sourceCompatibility = &#x27;1.8&#x27;configurations &#123; compileOnly &#123; extendsFrom annotationProcessor &#125;&#125;repositories &#123; mavenLocal() mavenCentral()&#125;dependencies &#123; implementation &#x27;org.springframework.boot:spring-boot-starter-web&#x27; implementation &#x27;org.mybatis.spring.boot:mybatis-spring-boot-starter:2.3.0&#x27; compileOnly &#x27;org.projectlombok:lombok&#x27; runtimeOnly &#x27;com.mysql:mysql-connector-j&#x27; annotationProcessor &#x27;org.springframework.boot:spring-boot-configuration-processor&#x27; annotationProcessor &#x27;org.projectlombok:lombok&#x27; testImplementation &#x27;org.springframework.boot:spring-boot-starter-test&#x27;&#125;tasks.named(&#x27;test&#x27;) &#123; useJUnitPlatform()&#125; 其他 application.yml 123456789101112131415161718server: port: 9874spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root url: jdbc:mysql://127.0.0.1:3306/demo?characterEncoding=utf8&amp;autoReconnect=true&amp;failOverReadOnly=false&amp;maxReconnects=10&amp;useSSL=falsemybatis: #1.classpath：只会到你的classes路径中查找找文件。 #2.classpath*：不仅会到classes路径，还包括jar文件中(classes路径)进行查找。 mapper-locations: classpath*:/mapper/**/*Mapper.xml # mapper映射文件位置 type-aliases-package: com.**.entity # 实体类所在的位置 configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #用于控制台打印sql语句 map-underscore-to-camel-case: true #开启将带有下划线的表字段 映射为驼峰格式的实体类属性 UserMapper.xml 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;!--命名空间 绑定 接口类--&gt;&lt;mapper namespace=&quot;com.example.gradledemo.dao.UserDao&quot;&gt; &lt;!--查询全部数据条数--&gt; &lt;select id=&quot;users&quot; resultType=&quot;com.example.gradledemo.entity.UserEntity&quot;&gt; SELECT * FROM t_user limit 10 &lt;/select&gt;&lt;/mapper&gt; UserDao 12345678910111213141516171819202122package com.example.gradledemo.dao;import com.example.gradledemo.entity.UserEntity;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Select;import org.apache.ibatis.annotations.Update;import java.util.List;@Mapperpublic interface UserDao &#123; @Select(&quot;select count(*) from t_user&quot;) String userCount(); List&lt;UserEntity&gt; users(); @Update(&quot;UPDATE t_user SET age=#&#123;add&#125; WHERE id=#&#123;id&#125;&quot;) Integer upDateAge(int add,int id); @Select(&quot;SELECT age FROM t_user WHERE id=#&#123;id&#125;&quot;) Integer getdateAge(int id);&#125; UserEntity 123456789101112131415161718192021package com.example.gradledemo.entity;import lombok.*;import java.util.Date;import java.util.Objects;@Datapublic class UserEntity &#123; private Long id; private String name; private String email; private String phone; private String password; private Integer age; private Integer sex; private Integer status; private Date creationTime; private String site;&#125; UserController 1234567891011121314151617181920212223package com.example.gradledemo.controller;import com.example.gradledemo.dao.UserDao;import com.example.gradledemo.entity.UserEntity;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;@RestControllerpublic class UserController &#123; @Autowired private UserDao userDao; @GetMapping(&quot;/user&quot;) public ResponseEntity&lt;List&lt;UserEntity&gt;&gt; getUser()&#123; return ResponseEntity.ok(userDao.users()) ; &#125;&#125; GradleDemoApplication 12345678910111213package com.example.gradledemo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GradleDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GradleDemoApplication.class, args); &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":null},{"title":"Gradle 安装和下载","slug":"Springboot/Gradle 安装和下载","date":"2025-08-25T06:27:17.000Z","updated":"2025-08-25T06:34:28.599Z","comments":true,"path":"2025/08/25/Springboot/Gradle 安装和下载/","link":"","permalink":"http://www.formeasy.cc/2025/08/25/Springboot/Gradle%20%E5%AE%89%E8%A3%85%E5%92%8C%E4%B8%8B%E8%BD%BD/","excerpt":"","text":"1. Gradle安装说明 SpringBoot 官方文档明确指出,目前SpringBoot的Gradle插件需要gradle6.8版本及以上。 其中SpringBoot与Gradle存在版本兼容问题，Gradle与Idea也存在兼容问题， 所以要选择6.8版本及高于6.8版本的Gradl，那么相应的idea版本也要升级，不能太老。 2. 安装JDK JDK（Java SE Development Kit）建议使用17及以上的版本，其官方下载路径为： https://www.oracle.com/java/technologies/downloads/#java17 3. Gradle 下载 https://gradle.org/releases/ 下载二进制包 配置环境变量 特别注意：这里再配置一个GRALE_USER_HOME环境变量， GRALE_USER_HOME相当于配置Gradle本地仓库位置和GradleWrapper缓存目录。 检测是否安装成功 gradle 仓库可以和本地的 Maven仓库放在同一个目录下，建议放在不同的目录下 4. Gradle 项目目录结构 Gradle 项目默认目录结构和Maven项目的目录结构一致,都是基于约定大于配置【ConventionOverConfiguration】。 其完整项目目录结构如下所示： Tips: 只有war工程才有webapp目录，对于普通的jar工程并没有webapp目录 gradlew与gradlew.bat执行的指定wrapper版本中的gradle指令,不是本地安装的gradle指令。 5. Gradle 创建第一个项目 借助于spring脚手架创建gradle第一个项目：https://start.spring.io 查看生成的gradle项目目录结构如下所示: 6. Gradle 中的常用指令 需要注意的是：gradle的指令要在含有build.gradle的目录执行。 7. 修改maven下载源 Gradle自带的Maven源地址是国外的，该Maven源在国内的访问速度是很慢的，除非使用了特别的手段。一般情况下建议使用国内的第三方开放的Maven源或企业内部自建Maven源。 认识init.d文件夹 可以在gradle的init.d目录下创建以.gradle结尾的文件，.gradle文件可以实现在build开始之前执行，所以可以在这个文件配置一些你想预先加载的操作。 在init.d文件夹创建init.gradle文件 12345678910111213141516allprojects&#123; repositories&#123; mavenLocal() maven&#123;name&quot;Alibaba&quot;;url&quot;https://maven.aliyun.com/repository/public&quot;&#125; maven&#123;name&quot;Bstek&quot;;url&quot;https://nexus.bsdn.org/content/groups/public/&quot;&#125; mavenCentral() &#125; buildscript&#123; repositories&#123; maven&#123;name&quot;Alibaba&quot;;url &#x27;https://maven.aliyun.com/repository/public&#x27;&#125; maven&#123;name&quot;Bstek&quot;;url &#x27;https://nexus.bsdn.org/content/groups/public/&#x27;&#125; maven&#123;name&quot;M2&quot;;url &#x27;https://plugins.gradle.org/m2/&#x27;&#125; &#125; &#125;&#125; 拓展1：启用init.gradle文件的方法有： 在命令行指定文件，例如：gradle--init-script yourdir/init.gradle -q taskName。可以多次输入此命令来指定多个init文件 把init.gradle文件放到USER_HOME/.gradle/目录下 把以.gradle结尾的文件放到USER_HOME/.gradle/init.d/目录下 把以.gradle结尾的文件放到GRADLE_HOME/init.d/目录下 如果存在上面的4种方式的2种以上，gradle会按上面的1-4序号依次执行这些文件，如果给定目录下存在多个init脚本，会按拼音a-z顺序执行这些脚本，每个init脚本都存在一个对应的gradle实例，在这个文件中调用的所有方法和属性，都会委托给这个gradle实例，每个init脚本都实现了Script接口。 拓展2：仓库地址说明 mavenLocal():指定使用maven本地仓库，而本地仓库在配置maven时settings文件指定的仓库位置。如E:/repository， gradle查找jar包顺序如下：USER_HOME/.m2/settings.xml&gt;&gt;M2_HOME/conf/settings.xml&gt;&gt;USER_HOME/.m2/repository maven{url地址}，指定maven仓库，一般用私有仓库地址或其它的第三方库【比如阿里镜像仓库地址】。 mavenCentral()：这是Maven的中央仓库，无需配置，直接声明就可以使用。 jcenter():JCenter中央仓库，实际也是是用的maven搭建的，但相比Maven仓库更友好，通过CDN分发，并且支持https访 问，在新版本中已经废弃了，替换为了mavenCentral()。 总之，gradle可以通过指定仓库地址为本地maven仓库地址和远程仓库地址相结合的方式，避免每次都会去远程仓库下载依赖库。这种方式也有一定的问题，如果本地maven仓库有这个依赖，就会从直接加载本地依赖，如果本地仓库没有该 依赖，那么还是会从远程下载。但是下载的jar不是存储在本地maven仓库中，而是放在自己的缓存目录中，默认在USER_HOME/.gradle/caches目录，当然如果我们配置过GRADLE_USER_HOME环境变量，则会放在GRADLE_USER_HOME/caches目录，那么可不可以将gradle caches指向mavenrepository。我们说这是不行的，caches下载 文件不是按照maven仓库中存放的方式。 拓展3：阿里云仓库地址请参考：https://developer.aliyun.com/mvn/guide 在gradle 中的使用说明： 8. Wrapper 包装器 Gradle Wrapper 实际上就是对Gradle的一层包装，用于解决实际开发中可能会遇到的不同的项目需要不同版本的Gradle问题。例如：把自己的代码共享给其他人使用，可能出现如下情况: 1.对方电脑没有安装 gradle 2.对方电脑安装过 gradle，但是版本太旧了 这时候，我们就可以考虑使用Gradle Wrapper了。这也是官方建议使用Gradle Wrapper的原因。实际上有了Gradle Wrapper 之后，我们本地是可以不配置Gradle的，下载Gradle项目后，使用gradle项目自带的wrapper操作也是可以的。 那如何使用GradleWrapper呢？ 项目中的gradlew、gradlew.cmd脚本用的就是wrapper中规定的gradle版本。参见源码 而我们上面提到的gradle指令用的是本地gradle，所以gradle指令和gradlew指令所使用的gradle版本有可能是不一样的。 gradlew、gradlew.cmd的使用方式与gradle使用方式完全一致，只不过把gradle指令换成了gradlew指令。 当然，我们也可在终端执行 gradlew 指令时，指定指定一些参数，来控制Wrapper的生成，比如依赖的版本等，如下： 具体操作如下所示 ： 1、gradle wrapper--gradle-version=4.4：升级wrapper版本号，只是修改gradle.properties中wrapper版本，未实际下载 2、gradle wrapper--gradle-version 5.2.1--distribution-type all ：关联源码用 GradleWrapper的执行流程： 当我们第一次执行 ./gradlewbuild 命令的时候，gradlew 会读取 gradle-wrapper.properties 文件的配置信息 准确的将指定版本的 gradle 下载并解压到指定的位置(GRADLE_USER_HOME目录下的wrapper/dists目录中) 并构建本地缓存(GRADLE_USER_HOME目录下的caches目录中)，下载再使用相同版本的gradle就不用下载了 之后执行的 ./gradlew 所有命令都是使用指定的 gradle 版本。如下图所示： gradle-wrapper.properties 文件解读： 注意：前面提到的GRALE_USER_HOME环境变量用于这里的Gradle Wrapper下载的特定版本的gradle存储目录。如果我们没有配置过GRALE_USER_HOME环境变量，默认在当前用户家目录下的.gradle文件夹中 那什么时候选择使用gradlewrapper、什么时候选择使用本地gradle? 下载别人的项目或者使用操作以前自己写的不同版本的gradle项目时：用Gradle wrapper，也即：gradlew 什么时候使用本地gradle？新建一个项目时: 使用gradle指令即可","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":"qq_41684621"},{"title":"Spring Boot 部署与打包方式详解（Jar vs War）","slug":"Springboot/Spring Boot 部署与打包方式详解（Jar vs War）","date":"2025-08-25T06:02:41.000Z","updated":"2025-08-25T06:11:12.304Z","comments":true,"path":"2025/08/25/Springboot/Spring Boot 部署与打包方式详解（Jar vs War）/","link":"","permalink":"http://www.formeasy.cc/2025/08/25/Springboot/Spring%20Boot%20%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%89%93%E5%8C%85%E6%96%B9%E5%BC%8F%E8%AF%A6%E8%A7%A3%EF%BC%88Jar%20vs%20War%EF%BC%89/","excerpt":"","text":"Spring Boot 提供了灵活的打包选项，支持两种主要部署方式：可执行 JAR 和 传统 WAR。以下是全面的对比与实践指南，帮助你根据项目需求选择最适合的部署方案。 📦 一、打包方式对比 特性 可执行 JAR (默认) 传统 WAR 启动方式 java -jar app.jar 部署到外部 Servlet 容器 (如 Tomcat) 内嵌服务器 ✅ 包含 Tomcat/Jetty/Undertow ❌ 需外部容器 部署复杂度 ⭐ 极简 (单文件部署) ⭐⭐⭐ 需容器环境 依赖管理 所有依赖打包进单个 FAT JAR 依赖由容器管理 (部分依赖可打包进 WAR) 热更新 需第三方工具 (JRebel) 支持容器级热部署 生产适用场景 微服务/云原生环境 传统企业级应用服务器环境 文件大小 较大 (包含内嵌容器) 较小 (仅应用代码) 🛠️ 二、JAR 打包部署 (默认方式) 1. 打包配置 (Maven) 确保你的 pom.xml 文件中有如下插件配置： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2. 打包命令 使用 Maven 进行构建： 12mvn clean package# 生成 target/appname-0.0.1-SNAPSHOT.jar 3. 运行方式 可以采用多种方式运行 JAR 文件： 12345678# 标准启动java -jar app.jar# 带配置文件启动java -jar -Dspring.profiles.active=prod app.jar# 内存限制启动java -Xms512m -Xmx1024m -jar app.jar 4. 生产环境增强 为了更好地适应生产环境，你可以采取以下措施： 系统服务化 (Systemd): 12345678[Unit]Description=Spring Boot ServiceAfter=syslog.target[Service]User=appuserExecStart=/usr/bin/java -jar /opt/app/app.jarSuccessExitStatus=143 启动脚本封装 (带日志分割): 1nohup java -jar app.jar &gt; app.log 2&gt;&amp;1 &amp; 🧩 三、WAR 打包部署 (传统方式) 1. 修改打包类型 首先，在 pom.xml 中将 &lt;packaging&gt; 修改为 war： 1&lt;packaging&gt;war&lt;/packaging&gt; 2. 排除内嵌容器 (Tomcat) 由于 WAR 文件需要部署到外部容器中，因此需要排除内置的 Tomcat： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3. 初始化 Servlet 入口 修改主类以继承 SpringBootServletInitializer： 12345678910public class Application extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Application.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 4. 构建与部署 完成上述步骤后，执行打包命令并部署到 Tomcat： 12345mvn clean package# 生成 target/appname-0.0.1-SNAPSHOT.war# 部署到 Tomcatcp target/app.war $TOMCAT_HOME/webapps/ ☁️ 四、云原生部署最佳实践 1. Docker 容器化部署 (JAR 方式) 编写 Dockerfile 来创建镜像： 1234FROM eclipse-temurin:17-jreVOLUME /tmpCOPY target/*.jar app.jarENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 然后构建和运行 Docker 镜像： 12docker build -t myapp:1.0 .docker run -d -p 8080:8080 myapp:1.0 2. 多阶段构建优化镜像 利用多阶段构建来减小最终镜像体积： 1234567891011# 阶段1：构建应用FROM maven:3.8.6 AS buildCOPY src /app/srcCOPY pom.xml /appRUN mvn -f /app/pom.xml clean package# 阶段2：运行镜像FROM eclipse-temurin:17-jre-alpineCOPY --from=build /app/target/*.jar app.jarEXPOSE 8080ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 3. Kubernetes 部署 定义 Deployment 和 Service YAML 文件来进行 Kubernetes 部署： 123456789101112131415161718192021222324252627282930313233343536# deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: springboot-appspec: replicas: 3 selector: matchLabels: app: springboot template: metadata: labels: app: springboot spec: containers: - name: app image: myregistry/springboot-app:1.0 ports: - containerPort: 8080 env: - name: SPRING_PROFILES_ACTIVE value: prod---# service.yamlapiVersion: v1kind: Servicemetadata: name: springboot-servicespec: selector: app: springboot ports: - protocol: TCP port: 80 targetPort: 8080 ⚠️ 五、关键注意事项 静态资源处理 JAR 模式：资源放在 src/main/resources/static WAR 模式：资源放在 src/main/webapp 配置文件优先级 Spring Boot 加载顺序： jar 内部 application.properties jar 同级 /config/ 目录 jar 同级目录 类路径 /config 类路径根目录 上下文路径设置 JAR 模式：server.servlet.context-path=/api WAR 模式：通过容器设置或 application.properties 端口冲突解决 12# 避免与容器端口冲突server.port=8081 WAR 部署常见问题 类冲突：使用 &lt;scope&gt;provided&lt;/scope&gt; 排除容器已有库 路径错误：确保 SpringBootServletInitializer 正确配置 🔍 六、部署决策树 🚀 七、高级部署方案 性能优化启动 12# 开启 AOT 优化 (Spring Boot 3+)java -Dspring.aot.enabled=true -jar app.jar GraalVM 原生镜像 12# 需配置 spring-boot-starter-parent 3.xmvn native:compile -Pnative 蓝绿部署方案 健康检查端点 12345678910management: endpoint: health: probes: enabled: true # 启用K8s就绪/存活检查 health: livenessstate: enabled: true readinessstate: enabled: true 💎 总结建议 优先选择 JAR: 对于大多数微服务和云原生应用来说，JAR 是理想的选择。 选择 WAR 当: 需要与遗留系统集成或必须在特定应用服务器上运行时考虑使用 WAR。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":"qq_45572615"},{"title":"AI探索大模型权重的分类：Chat、Code、Embedding和Rerank","slug":"LLM/AI探索大模型权重的分类：Chat、Code、Embedding和Rerank","date":"2025-08-25T02:46:21.000Z","updated":"2025-08-25T02:51:52.672Z","comments":true,"path":"2025/08/25/LLM/AI探索大模型权重的分类：Chat、Code、Embedding和Rerank/","link":"","permalink":"http://www.formeasy.cc/2025/08/25/LLM/AI%E6%8E%A2%E7%B4%A2%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%86%E7%B1%BB%EF%BC%9AChat%E3%80%81Code%E3%80%81Embedding%E5%92%8CRerank/","excerpt":"","text":"在机器学习和自然语言处理领域，大模型（如GPT-3、BERT等）已经成为了强大且广泛应用的工具。大模型的权重通常可以根据其应用场景分为不同的类别，如Chat、Code、Embedding和Rerank。了解这些分类及其差异对于我们在实际应用中选择合适的模型至关重要。本文将详细讲解这四种权重分类，并说明它们的差异。 1. Chat（对话） Chat模型专注于对话生成和自然语言理解。这些模型经过专门训练，能够理解并生成连贯、自然的对话。Chat模型通常用于客服机器人、虚拟助手等场景。 特点： 自然语言生成：能够生成流畅且有意义的对话。 上下文理解：能够记住对话的上下文并进行相关的回答。 人性化交互：与用户进行类人互动，提供友好的用户体验。 应用场景： 在线客服 智能助手（如Siri、Alexa） 社交媒体聊天机器人 2. Code（代码） Code模型专注于代码生成和理解。这些模型可以帮助开发者自动补全代码、生成代码片段、修复代码错误等。Code模型在集成开发环境（IDE）中得到了广泛应用，提高了开发效率。 特点： 代码生成：根据自然语言描述生成相应的代码片段。 错误检测与修复：识别代码中的错误并提供修复建议。 代码补全：在开发过程中自动补全代码，节省时间。 应用场景： 集成开发环境（如VS Code的Copilot） 代码审查工具 自动化测试生成 3. Embedding（嵌入） Embedding模型专注于将文本、图像或其他数据转换为固定长度的向量表示。这些向量表示保留了数据的语义信息，便于后续的相似度计算、分类等任务。 特点： 语义表示：将数据转换为保留语义信息的向量。 高效计算：向量表示便于在大规模数据上进行高效计算。 通用性：可以应用于多种数据类型，如文本、图像等。 应用场景： 文本相似度计算 图像检索 聚类分析 4. Rerank（重新排序） Rerank模型用于对初步检索结果进行重新排序，以提高检索系统的精度。这些模型通常结合上下文信息和用户意图，对初步检索到的结果进行排序优化，提供更相关的结果。 特点： 上下文敏感：结合上下文信息进行结果排序。 用户意图：理解用户意图，提供更相关的结果。 高精度：显著提高检索结果的相关性和精度。 应用场景： 搜索引擎 推荐系统 问答系统 差异分析 虽然这四种权重分类都属于大模型的范畴，但它们在应用领域和技术特点上有显著差异： 应用领域：Chat模型用于对话生成，Code模型用于代码生成与理解，Embedding模型用于数据表示，Rerank模型用于结果排序优化。 技术特点：Chat模型强调上下文理解和自然语言生成，Code模型侧重代码相关任务，Embedding模型关注数据的语义表示，Rerank模型专注于提高检索精度。 用户体验：Chat模型和Rerank模型直接影响用户交互体验，Embedding模型和Code模型则更多地提高开发效率和技术实现。 为什么Embedding和Rerank权重少见 尽管Embedding和Rerank模型在自然语言处理和机器学习领域具有重要作用，但它们的开源情况却远不如Chat和Code模型普遍。这主要是由于数据隐私、商业价值、模型专用性以及高昂的数据标注成本等原因所致。 1. Embedding模型权重少见的原因 数据隐私和安全性 Embedding模型的训练通常涉及大量的用户数据，如文本、图像等。这些数据往往包含敏感信息，出于隐私和安全性考虑，很多机构和公司不愿意公开这些模型的权重，以避免数据泄露的风险。 商业价值 Embedding模型在推荐系统、搜索引擎和其他需要高效相似度计算的应用中具有巨大的商业价值。许多公司利用这些模型获得竞争优势，因此不愿意将这些权重公开，以保护其商业机密和市场份额。 模型专用性 Embedding模型通常是高度定制化的，针对特定数据集和应用场景进行训练。公开这些权重可能并不能直接用于其他应用，需要大量的调整和再训练。这使得这些模型的通用性较低，限制了开源的动机。 2. Rerank模型权重少见的原因 复杂性和专用性 Rerank模型通常是在特定领域和应用场景下进行训练的，结合了大量上下文信息和用户行为数据。这样的模型在其他场景下可能效果不佳，需要重新训练或调整。这种专用性使得它们不适合广泛开源。 数据稀缺和标注成本 Rerank模型需要大量的标注数据，这些数据需要手动标注并且通常涉及复杂的上下文关系。收集和标注这些数据成本高昂，且标注数据往往具有高度的专用性，公开模型权重的同时也难以提供相应的数据集，限制了其开源的可能性。 商业和战略考量 像搜索引擎和推荐系统这样的应用，对于Rerank模型有着至关重要的依赖。这些领域的公司往往通过这些模型优化用户体验和提升商业效果。因此，出于商业和战略考虑，这些模型的权重通常不会公开，以保持竞争优势。 结论 理解大模型权重的不同分类及其差异，可以帮助我们更好地选择和应用适合的模型，从而在各自的领域中发挥其最大潜力。无论是用于对话生成的Chat模型，还是用于代码生成的Code模型，或是用于数据表示的Embedding模型，以及用于结果排序的Rerank模型，它们都在各自的应用场景中展现了强大的能力和广泛的应用前景。 未来，随着技术的发展和开源社区的壮大，或许会有更多的Embedding和Rerank模型权重逐渐公开，为广泛的研究和应用提供支持。但在此之前，我们需要理解这些模型权重不公开的合理性，并在现有资源的基础上继续前行。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"}],"author":null},{"title":"Ubuntu下部署SpringBoot","slug":"Springboot/Ubuntu下部署SpringBoot","date":"2025-08-22T06:26:22.000Z","updated":"2025-08-22T13:51:47.320Z","comments":true,"path":"2025/08/22/Springboot/Ubuntu下部署SpringBoot/","link":"","permalink":"http://www.formeasy.cc/2025/08/22/Springboot/Ubuntu%E4%B8%8B%E9%83%A8%E7%BD%B2SpringBoot/","excerpt":"","text":"Ubuntu下部署SpringBoot 第一步： 安装java环境 123456# 更新软件源sudo apt update# 安装OpenJDK 17（开源免费，推荐）sudo apt install openjdk-17-jdk# 验证安装：输出JDK版本即成功java -version 第二步： 安装下载Idea并新建SpringBoot项目 到官网下载(https://www.jetbrains.com/idea/download/?section=windows) 这里把 pom.xml 文件、包结构、新增的控制器代码贴一下 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 第三步： 打包 .jar 文件 对于Maven 可以使用使令：mvn clean package 对于Gradle 可以使用使令：./gradlew clean bootJar 第四步： 在 Ubuntu 上部署 .jar 包 mkdir demo 命令创建一个名为 demo 的目录 cd demo 命令进入该目录 nohup java -jar demo-0.0.1-SNAPSHOT.jar 命令启动 jar 包。 nohup xxx &amp; ： 是 no hang up 的缩写，意为不挂起，用于在系统后台不断运行命令，退出终端不会影响程序的运行 运行完之后会生成一个 nohup.out 文件，里面是启动过程的一些日志 打开 nohup.out 文件，如果正常启动的话，会看到类似这样的输出 Started DemoApplication in xxx seconds 但是，我就没那么幸运了，我遇到的是这样的 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.5.2) 2021-07-14 22:42:22.087 INFO 39193 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication v0.0.1-SNAPSHOT using Java 1.8.0_291 on iZwz92d94t8mb03s9z327hZ with PID 39193 (/opt/xiaodudu/demo/demo-0.0.1-SNAPSHOT.jar started by root in /opt/xiaodudu/demo) 2021-07-14 22:42:22.090 INFO 39193 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to default profiles: default 2021-07-14 22:42:23.276 INFO 39193 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2021-07-14 22:42:23.291 INFO 39193 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2021-07-14 22:42:23.291 INFO 39193 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.48] 2021-07-14 22:42:23.345 INFO 39193 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2021-07-14 22:42:23.345 INFO 39193 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1141 ms 2021-07-14 22:42:23.673 WARN 39193 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'webServerStartStop'; nested exception is org.springframework.boot.web.server.PortInUseException: Port 8080 is already in use 2021-07-14 22:42:23.677 INFO 39193 --- [ main] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2021-07-14 22:42:23.691 INFO 39193 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-07-14 22:42:23.713 ERROR 39193 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Web server failed to start. Port 8080 was already in use. Action: Identify and stop the process that's listening on port 8080 or configure this application to listen on another port. Port 8080 was already in use. 端口被占用，是比较常见的一个异常。 执行 netstat -anp | grep 8080 查看占用端口的程序 pid。（netstat 有很多参数，可以使用 netstat -h 查询） root@iZwz92d94t8mb03s9z327hZ:~# netstat -anp | grep 8080 tcp6 0 0 :::8080 :::* LISTEN 19032/java 执行 kill -9 xxxxx 命令终止该程序 root@iZwz92d94t8mb03s9z327hZ:~# kill -9 19032 重新执行 nohup xxx &amp; 命令部署 jar 程序。(nohup.out 是否删除可以自己决定，删除就是重新生成，不删除就是追加内容) root@iZwz92d94t8mb03s9z327hZ:/opt/xiaodudu/demo# nohup java -jar demo-0.0.1-SNAPSHOT.jar &amp; [1] 39342 root@iZwz92d94t8mb03s9z327hZ:/opt/xiaodudu/demo# nohup: ignoring input and appending output to 'nohup.out' 查看 nohup.out 文件 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.5.2) 2021-07-14 23:05:16.089 INFO 39342 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication v0.0.1-SNAPSHOT using Java 1.8.0_291 on iZwz92d94t8mb03s9z327hZ with PID 39342 (/opt/xiaodudu/demo/demo-0.0.1-SNAPSHOT.jar started by root in /opt/xiaodudu/demo) 2021-07-14 23:05:16.093 INFO 39342 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to default profiles: default 2021-07-14 23:05:17.228 INFO 39342 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2021-07-14 23:05:17.239 INFO 39342 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2021-07-14 23:05:17.240 INFO 39342 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.48] 2021-07-14 23:05:17.300 INFO 39342 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2021-07-14 23:05:17.300 INFO 39342 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1095 ms 2021-07-14 23:05:17.755 INFO 39342 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2021-07-14 23:05:17.764 INFO 39342 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 2.338 seconds (JVM running for 2.769) 远程访问接口 访问 Ubuntu 服务器IP: 8080/hello/springboot 第五步： 在 Ubuntu 上使用进程管理 直接用 java -jar 启动的应用在终端关闭后会终止，且意外崩溃后无法自动重启。 可使用进程管理工具（systemd）确保应用后台运行并自动恢复，通过系统服务管理 JAR 应用，支持开机自启、状态监控、日志管理。 1.创建服务文件（如 /etc/systemd/system/myapp.service）： 12345678910111213141516[Unit]Description=My Spring Boot ApplicationAfter=network.target[Service]User=formeasyGroup=formeasy#WorkingDirectory=/opt/xiaodudu/demo/ # JAR 文件所在目录，建议不注释ExecStart=/usr/bin/java -jar /opt/xiaodudu/demo/demo-0.0.1-SNAPSHOT.jar --server.port=8080SuccessExitStatus=143 # 兼容 Spring Boot 的优雅退出码Restart=always # 崩溃后自动重启RestartSec=5 # 重启间隔（秒）[Install]WantedBy=multi-user.target 2.启用并启动服务： 123sudo systemctl daemon-reload # 刷新配置sudo systemctl start myapp # 启动应用sudo systemctl enable myapp # 设置开机自启 3.常用命令： 123sudo systemctl status myapp # 查看状态sudo systemctl stop myapp # 停止应用journalctl -u myapp -f # 实时查看日志 4.如果出错，按照以下排查： 检查目录和文件是否存在 123456789# 检查工作目录是否存在ls -la /opt/xiaodudu/demo/# 检查 JAR 文件是否存在ls -la /opt/xiaodudu/demo/demo-0.0.1-SNAPSHOT.jar# 检查 Java 安装which javajava -version 创建缺失的目录和权限 12345678# 创建应用目录sudo mkdir -p /opt/xiaodudu/demo/# 设置正确的权限sudo chown -R formeasy:formeasy /opt/xiaodudu/demo/# 确保 JAR 文件在正确的位置# 如果还没有，上传或复制您的 JAR 文件到这个目录","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":null},{"title":"手机已安装应用导出apk","slug":"Other/手机已安装应用导出apk客","date":"2025-08-22T06:21:47.000Z","updated":"2025-08-22T06:25:07.253Z","comments":true,"path":"2025/08/22/Other/手机已安装应用导出apk客/","link":"","permalink":"http://www.formeasy.cc/2025/08/22/Other/%E6%89%8B%E6%9C%BA%E5%B7%B2%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8%E5%AF%BC%E5%87%BAapk%E5%AE%A2/","excerpt":"","text":"方法一：通过应用管理器 下载并安装应用管理器：可以使用应用管理器如“ES文件浏览器”或“APK Extractor”。 提取APK文件： 打开应用管理器。 找到已安装的应用程序列表。 选择你想要提取的应用程序，然后选择“提取”或“备份”选项。 提取的APK文件将保存在指定的文件夹中，通常是在内部存储或SD卡中的“ExtractedApks”文件夹。 方法二：通过ADB工具 安装ADB工具： 在电脑上下载并安装ADB工具包。 连接手机： 在手机上启用“开发者选项”和“USB调试”。 使用USB线将手机连接到电脑。 使用ADB命令提取应用： 打开命令行窗口。 输入以下命令以查看已安装的应用列表： 1adb shell pm list packages 找到你想提取的应用的包名，然后运行以下命令提取APK文件： 1adb shell pm path &lt;package-name&gt; 例如： 1adb shell pm path com.example.app 该命令会返回APK文件的路径。接着运行以下命令将APK文件复制到电脑： 1adb pull &lt;apk-file-path&gt; &lt;destination-path&gt; 例如： 1adb pull /data/app/com.example.app-1/base.apk C:\\Users\\YourUsername\\Desktop","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"qq_32898021"},{"title":"SpringBoot 项目，自动编译，热部署，立刻看到效果","slug":"Springboot/SpringBoot 项目，自动编译，热部署，立刻看到效果","date":"2025-08-21T08:55:31.000Z","updated":"2025-08-22T02:29:03.318Z","comments":true,"path":"2025/08/21/Springboot/SpringBoot 项目，自动编译，热部署，立刻看到效果/","link":"","permalink":"http://www.formeasy.cc/2025/08/21/Springboot/SpringBoot%20%E9%A1%B9%E7%9B%AE%EF%BC%8C%E8%87%AA%E5%8A%A8%E7%BC%96%E8%AF%91%EF%BC%8C%E7%83%AD%E9%83%A8%E7%BD%B2%EF%BC%8C%E7%AB%8B%E5%88%BB%E7%9C%8B%E5%88%B0%E6%95%88%E6%9E%9C/","excerpt":"","text":"1：在pom.xml 中 配置 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 注意：并不是pom.xml 的标签中 2： 如果有页面的话 禁止页面缓存 123456789spring: application: name: XXX aop: proxy-target-class: true thymeleaf: cache: false prefix: classpath:/templates/ mode: LEGACYHTML5 3：开启idea工具的自动编译功能 4：开启idea允许运行时编译 在 Advanced Settings 中，勾选 Allow auto-make to start even if the application is currently running 完成以上步骤 即可实现SpringBoot项目自动编译+热部署，这我们修改后的代码能够立刻看到效果，提高效率！","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":null},{"title":"Springboot框架的快速搭建和mybatis的整合","slug":"Springboot/Springboot框架的快速搭建和mybatis的整合","date":"2025-08-21T08:31:20.000Z","updated":"2025-08-26T07:41:08.356Z","comments":true,"path":"2025/08/21/Springboot/Springboot框架的快速搭建和mybatis的整合/","link":"","permalink":"http://www.formeasy.cc/2025/08/21/Springboot/Springboot%E6%A1%86%E6%9E%B6%E7%9A%84%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%92%8Cmybatis%E7%9A%84%E6%95%B4%E5%90%88/","excerpt":"","text":"环境安装 在开始学习Spring Boot之前，我们需要准备好开发环境。本节将以Windows操作系统为例，介绍如何安装JDK、Intellij IDEA及Apache Maven。如果你的电脑上已经安装了JDK、Intellij IDEA或者Apache Maven，可以跳过本节内容。 安装JDK JDK（Java SE Development Kit）建议使用17及以上的版本，其官方下载路径为： https://www.oracle.com/java/technologies/downloads/#java17 下载后正常安装，安装完成后，需要配置环境变量JAVA_HOME，具体步骤如下： 1）在电脑桌面上，右击【我的电脑】→【属性】→【高级系统设置】→【环境变量】→【系统变量(S)】→【新建】出现新建环境变量的窗口。 2）在【变量名】和【变量值】中分别输入JAVA_HOME和C:\\Program Files\\Java\\jdk-17，单击【确定】按钮。 3）JAVA_HOME配置好之后，将%JAVA_HOME%\\bin加入到【系统变量】的path中。完成后，打开命令行窗口，输入命令java-version，如出现如下所示的提示，即表示安装成功。 1234c:\\XXX\\java -versionjava version &quot;17.0.16&quot; 2025-07-15 LTSJava(TM) SE Runtime Environment (build 17.0.16+12-LTS-247)Java HotSpot(TM) 64-Bit Server VM (build 17.0.16+12-LTS-247, mixed mode, sharing) 安装Intellij IDEA 在Intellij IDEA的官方网站 http://www.jetbrains.com/idea/ 上可以免费下载IDEA。下载完IDEA后，运行安装程序，按提示安装即可。 安装Apache Maven Apache Maven是目前流行的项目管理和构建自动化工具。虽然IDEA已经包含了Maven插件，但是笔者还是希望大家在工作中能够安装自己的Maven插件，方便以后项目配置需要。大家可以通过Maven的官方网站 http://maven.apache.org/download.cgi 下载最新版的Maven，本文的Maven版本为apache-maven-3.6.3。 下载完成后解压缩即可，例如，解压到D：盘上，然后将Maven的安装路径D:\\apache-maven-3.6.3\\bin加入到Windows的环境变量path中。安装完成后，在命令行窗口执行命令：mvn -v，如果输出&quot;Apache Maven 3.6.3&quot;，表示Maven安装成功。 一、创建一个空的Springboot项目工程 在一个你喜欢的地方，创建一个springboot项目文件夹.比如我使用：springboot 启动IDEA–&gt;New Project–&gt;spring boot(spring initializr） 按下面的选 jdk版本不一样，所选的spring boot版本不一样，因为我用的是jdk是17，所以用的是3.0以上的 二、 项目工程配置一下Maven 三、 创建常见的包 在com.example下面把每个层的包创建好，用于后续我们在不同的包里创建java文件，后端我们是分层的。 controller调用service service调用dao dao调用entity controller:后端接口的入口，主要编写各种xxxController,提供接口给前端调用 service:后端业务层，主要编写一些后端业务逻辑。controller–:service dao(mapper):后端持久层，主要映射数据库，操作数据库表数据。service– entity:实体类，对应数据库表，实体类的属性对应表的字段信息 结果图: 四、编写你的第一个hello word controller是后台接口的入口，这个“接口”与java基础里面的接口不一样，这里的接口是针对前端来说的，前端操作数据会调用后端的接口，是前后台交互的入口 在controller下面新建一个UserController类 123456789101112131415161718192021222324package com.example.springboot.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;//表明是接口的入口@RestController//匹配一个地址,相当于打开家门的钥匙.为了规范，地址最好和类名前几个单词一样@RequestMapping(&quot;/user&quot;)public class UserController &#123;/** * controller里的一个方法，它其实就是我们平常说的web项目里的一个接口的入口 * 可以在这个方法上再加上一个url * 也可以指定请求方式(增删改查)：GET POST PUT DELETE */@GetMapping public String start()&#123; return &quot;欢迎来到我的第一个Springboot工程：已经启动&quot;; &#125;&#125; 运行SpingbootApplication,结果如下，可以看到端口为8080 去搜http://localhost:8080/user 在entity下面创建User类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.example.springboot.entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;public class User &#123;// 表明Id是主键 @Id// 策略,表明主键是递增的 @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; private String name; private String sex; private int age; private String password; private String phone; //构造方法 public User(String id,String name,String sex,String age,String password,String phone )&#123; this.id= Integer.parseInt(id); this.name=name; this.sex=sex; this.age= Integer.parseInt(age); this.password=password; this.phone=phone; &#125;// mybatis需要 public User() &#123; // 无参构造方法 &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getSex()&#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125;&#125; 搜索http://localhost:8080/user/start 五、整合MyBatis 可以去搜mvn repository的官网，在里面搜mysql，可以找到相关依赖的代码 引入依赖：pox.xml里导入mybatis和数据库mysql的依赖(这里的mybatis依赖版本要看清楚，我这个版本不适用3.0，所以后面我换了，可以看第七点的1） 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.13&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.5&lt;/version&gt;&lt;/dependency&gt; 例为官方mybatis-spring-boot-starter，建议使用mybatis-plus-spring-boot3-starter替代 在application.yml里进行数据库配置（若文件后缀不是yml,可看下面第七的2） 注意：冒号“：”后面一定要加空格，不然会报错 12345678910server: port: 8080#数据库配置spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver username: root #你本地的数据库用户名 password: cjm2003 #你本地的数据库密码 url: jdbc:mysql://localhost:3306/springboot?useSSL=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=Asia/Shanghai 3.配置mybatis实体和xml映射 （1）先如下面结构创建UserMapper.xml用于被mybatis映射 （2）在application.yml里配置 1234#配置mybatis实体配置mybatis: mapper-locations: classpath:mapper/*.xml #映射到resources/mapper/User.xml里 type-aliases-package: com.example.springboot.entity 六、结合MyBatis将数据库打通 创建数据库springboot和user表 创建数据库 12345678910DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &#x27;主键ID&#x27;, `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT &#x27;姓名&#x27;, `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT &#x27;密码&#x27;, `sex` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT &#x27;性别&#x27;, `age` int NULL DEFAULT NULL COMMENT &#x27;年龄&#x27;, `phone` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL COMMENT &#x27;电话&#x27;, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci COMMENT = &#x27;用户信息表&#x27; ROW_FORMAT = Dynamic; 补充数据 12INSERT INTO `user` VALUES (1, &#x27;张三&#x27;, &#x27;123456&#x27;, &#x27;男&#x27;, 21, &#x27;10000000000&#x27;);INSERT INTO `user` VALUES (2, &#x27;李四&#x27;, &#x27;123456&#x27;, &#x27;女&#x27;, 22, &#x27;18888888888&#x27;); 最终结果： 2. 在User类里加映射 123import javax.persistence.Table;//把user表映射到类里面去@Table(name = &quot;user&quot;) 修改UserController 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.example.springboot.controller;import com.example.springboot.entity.User;import com.example.springboot.service.UserService;import jakarta.annotation.Resource;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;//表明是接口的入口@RestController//匹配一个地址,相当于打开家门的钥匙.为了规范，地址最好和类名前几个单词一样@RequestMapping(&quot;/user&quot;)public class UserController &#123;// controller要调用service @Resource private UserService userService; /** * controller里的一个方法，它其实就是我们平常说的web项目里的一个接口的入口 * 可以在这个方法上再加上一个url * 也可以指定请求方式(增删改查)：GET POST PUT DELETE */ @GetMapping public String start()&#123; return &quot;欢迎来到我的第一个Springboot工程：已经启动&quot;; &#125; @GetMapping(&quot;/start&quot;)// 导入表的各条信息 public List&lt;User&gt; getUser() &#123; //拿userService的getUser,返回值也是List return userService.getUser(); &#125;&#125; 创建其他的类和接口，因为 controller调用service service调用dao dao调用entity UserService: 12345678910111213141516171819202122package com.example.springboot.service;import com.example.springboot.dao.UserDao;import com.example.springboot.entity.User;import jakarta.annotation.Resource;import org.springframework.stereotype.Service;import java.util.List;//表明是service层@Servicepublic class UserService &#123;// service调用dao @Resource private UserDao userDao; public List&lt;User&gt; getUser() &#123; return (List&lt;User&gt;) userDao.getUser(); &#125;&#125; UserDao接口： 12345678910111213141516171819package com.example.springboot.dao;import com.example.springboot.entity.User;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import tk.mybatis.mapper.common.Mapper;import java.util.List;//表示是持久层的@Repository//继承Mapper里User的实体public interface UserDao extends Mapper&lt;User&gt; &#123; // 基于注解的方式,查询user表里的全部信息 @Select(&quot;select * from user&quot;) List&lt;User&gt; getUser();&#125; 搜索http://localhost:8080/user/start （这里若是打不开，可以看看是否是数据库没启动或者是路径错误，可看第七点3） 七、可能会遇到的问题 1.mybatis版本不兼容，去pom.xml里替换依赖 123456&lt;!-- 替换旧依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;!-- 支持 Spring Boot 3.x --&gt;&lt;/dependency&gt; 方法：通过IDE创建（以IntelliJ IDEA为例） （1）新建Spring Boot项目 使用 Spring Initializr 创建项目（默认生成 .properties）。 （2）右键资源目录 定位到 src/main/resources → 右键选择 New → File。 （3）输入文件名 直接输入 application.yml → 确认创建。 路径错误或者是数据库没启动 （1）检查yml里的mybatis配置路径：是否在对应包的下面 检查数据库配置是否是自己的数据库名称出错 （2）去cmd里面查看服务器是否启动 1net start mysql 注意mysql为自己的，一般为mysql,但是我的是mysql8.0,所以我的效果图如下 八、打包应用 在项目目录下，打开终端并使用以下命令打包应用： 对于 Maven： mvn clean package 对于 Gradle： ./gradlew clean bootJar 注释： mvn clean package 命令会清理项目并构建一个新的 JAR 文件。 ./gradlew clean bootJar 对于 Gradle 项目同样会完成清理并生成可执行的 JAR 文件。 打包完成后，您可以在以下路径找到生成的 JAR 文件： Maven：target 目录下，如 target/springboot-0.0.1-SNAPSHOT.jar Gradle：build/libs 目录下，如 build/libs/springboot-0.0.1-SNAPSHOT.jar 九、代码 UserController 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.example.springboot.controller;import com.example.springboot.entity.User;import com.example.springboot.service.UserService;import jakarta.annotation.Resource;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;//表明是接口的入口@RestController//匹配一个地址,相当于打开家门的钥匙.为了规范，地址最好和类名前几个单词一样@RequestMapping(&quot;/user&quot;)public class UserController &#123;// controller要调用service @Resource private UserService userService; /** * controller里的一个方法，它其实就是我们平常说的web项目里的一个接口的入口 * 可以在这个方法上再加上一个url * 也可以指定请求方式(增删改查)：GET POST PUT DELETE */ @GetMapping public String start()&#123; return &quot;欢迎来到我的第一个Springboot工程：已经启动&quot;; &#125; @GetMapping(&quot;/start&quot;)// 导入表的各条信息 public List&lt;User&gt; getUser() &#123; //拿userService的getUser,返回值也是List return userService.getUser(); &#125;&#125; UserDao 12345678910111213141516171819package com.example.springboot.dao;import com.example.springboot.entity.User;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import tk.mybatis.mapper.common.Mapper;import java.util.List;//表示是持久层的@Repository//继承Mapper里User的实体public interface UserDao extends Mapper&lt;User&gt; &#123; // 基于注解的方式,查询user表里的全部信息 @Select(&quot;select * from user&quot;) List&lt;User&gt; getUser();&#125; User 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.example.springboot.entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;//把user表映射到类里面去@Table(name = &quot;user&quot;)public class User &#123;// 表明Id是主键 @Id// 策略,表明主键是递增的 @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; private String name; private String sex; private int age; private String password; private String phone; //构造方法 public User(String id,String name,String sex,String age,String password,String phone )&#123; this.id= Integer.parseInt(id); this.name=name; this.sex=sex; this.age= Integer.parseInt(age); this.password=password; this.phone=phone; &#125;// mybatis需要 public User() &#123; // 无参构造方法 &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getSex()&#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125;&#125; UserService 12345678910111213141516171819202122package com.example.springboot.service;import com.example.springboot.dao.UserDao;import com.example.springboot.entity.User;import jakarta.annotation.Resource;import org.springframework.stereotype.Service;import java.util.List;//表明是service层@Servicepublic class UserService &#123;// service调用dao @Resource private UserDao userDao; public List&lt;User&gt; getUser() &#123; return (List&lt;User&gt;) userDao.getUser(); &#125;&#125; SpringbootApplication 123456789101112131415161718package com.example.springboot;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication//扫描@MapperScan(&quot;com.example.springboot.dao&quot;) // 替换为你的实际 DAO 包路径public class SpringbootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootApplication.class, args); &#125;&#125; UserMapper.xml 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;.//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace =&quot;com.example.springboot.dao.UserDao&quot;&gt;&lt;/mapper&gt; application.yml 12345678910111213141516171819server: port: 8080#application: #name: myapp#数据库配置spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver username: root #你本地的数据库用户名 password: cjm2003 #你本地的数据库密码 url: jdbc:mysql://localhost:3306/springboot?useSSL=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=Asia/Shanghai#配置mybatis实体配置mybatis: mapper-locations: classpath:mapper/*.xml #映射到resources/mapper/User.xml里 type-aliases-package: com.example.springboot.entity# configuration:# map-underscore-to-camel-case: true # 自动转换下划线命名到驼峰命名 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.5.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;springboot&lt;/description&gt; &lt;url/&gt; &lt;licenses&gt; &lt;license/&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer/&gt; &lt;/developers&gt; &lt;scm&gt; &lt;connection/&gt; &lt;developerConnection/&gt; &lt;tag/&gt; &lt;url/&gt; &lt;/scm&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 替换旧依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;!-- 支持 Spring Boot 3.x --&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","categories":[],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"}],"author":"m0_75167025"},{"title":"如何快速删除Word文档中的英文内容","slug":"Other/如何快速删除Word文档中的英文内容","date":"2025-08-20T03:06:13.000Z","updated":"2025-08-20T03:13:45.768Z","comments":true,"path":"2025/08/20/Other/如何快速删除Word文档中的英文内容/","link":"","permalink":"http://www.formeasy.cc/2025/08/20/Other/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4Word%E6%96%87%E6%A1%A3%E4%B8%AD%E7%9A%84%E8%8B%B1%E6%96%87%E5%86%85%E5%AE%B9/","excerpt":"","text":"如何快速删除Word文档中的英文内容 ◉ 打开Word文档 首先，在电脑中 启动Word办公软件 ，新建一个空白文档，并在其中输入包含中英文的文本段落。 ◉ 使用替换功能 接着，在 工具栏的“开始”选项 下，我们可以在文档的右上角找到并点击 “替换” 功能。这一操作将触发 “查找和替换”对话框 的弹出。 ◉ 选择特殊格式 在对话框的左下角，我们点击 “更多” 以展开更多选项。随后，会出现一个下拉窗口，在其中我们选择 “特殊格式” 。在右侧弹出的特殊格式选项中，我们进一步选择 “任意字母” 。选定后，查找内容栏中会出现一个 “^$” 符号。最后，我们点击 “全部替换” 按钮，并返回到文档。此时，原先的英文内容已全部消失。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":null},{"title":"【redis】centos7下安装redis7_centos7安装redis7","slug":"Redis/【redis】centos7下安装redis7_centos7安装redis7","date":"2025-08-20T01:33:14.000Z","updated":"2025-08-20T01:52:15.828Z","comments":true,"path":"2025/08/20/Redis/【redis】centos7下安装redis7_centos7安装redis7/","link":"","permalink":"http://www.formeasy.cc/2025/08/20/Redis/%E3%80%90redis%E3%80%91centos7%E4%B8%8B%E5%AE%89%E8%A3%85redis7_centos7%E5%AE%89%E8%A3%85redis7/","excerpt":"","text":"在CentOS 7下安装Redis7可以通过以下两种方法实现：手动编译安装和使用YUM进行安装。 CentOS 7系统的环境和版本： 12$ cat /etc/centos-releaseCentOS Linux release 7.9.2009 (Core) 手动编译安装 参考官方文档：https://redis.io/docs/latest/operate/oss\\_and\\_stack/install/install-redis/install-redis-from-source/ 下载Redis7安装包： 从Redis的官方网站下载Redis7的源代码包。例如，下载Redis7.2.0： 12$ cd /opt/soft$ sudo wget https://download.redis.io/releases/redis-7.2.0.tar.gz 编译并安装Redis7： 下载完成后，解压缩源代码包，并进入解压后的目录进行编译和安装： 1234$ sudo tar -zxvf redis-7.2.0.tar.gz$ cd redis-7.2.0$ sudo make$ sudo make install 如果编译过程中报错，很有可能是操作系统没有安装如下依赖，Redis的编译依赖于GCC和一些其他开发工具。可以通过以下命令安装这些依赖： 12$ sudo yum update -y$ sudo yum install -y gcc tcl make 在解压缩源代码包下有一个README.md文件，介绍了如何源码安装redis。 配置Redis： 编译安装完成后，Redis的可执行文件（如redis-server、redis-cli）会被放置在/usr/local/bin/目录下。 Redis的配置文件默认位于源代码目录下的redis.conf。可以将此文件复制到/etc/或其他你喜欢的位置，并对其进行编辑以满足需求。 12$ sudo cp redis.conf /etc/redis.conf$ sudo vim /etc/redis.conf 根据需要修改配置文件，例如： 将bind 127.0.0.1改为bind 0.0.0.0，允许远程连接（如果需要的话）。 将daemonize no改为daemonize yes，让Redis在后台运行。 设置密码（可选），取消requirepass的注释并设置密码。 设置日志文件路径和数据库持久化方式等（可选）。 启动Redis服务： 配置完成后，可以使用以下命令启动Redis服务： 1$ redis-server /etc/redis.conf 验证Redis服务： 12345$ redis-cli127.0.0.1:6379&gt; auth redispassOK127.0.0.1:6379&gt; pingPONG 设置Redis开机自启： 如果想让Redis在系统启动时自动启动，需要创建一个systemd服务单元文件： 1$ sudo vim /etc/systemd/system/redis.service 在文件中添加以下内容（注意修改ExecStart的路径以匹配Redis配置文件位置）： 12345678910111213[Unit]Description=Redis In-Memory Data StoreAfter=network.target[Service]User=redisGroup=redisExecStart=/usr/local/bin/redis-server /etc/redis.confExecStop=/usr/local/bin/redis-cli shutdownRestart=always[Install]WantedBy=multi-user.target 创建一个redis用户和组（如果它们不存在的话），并将/etc/redis.conf文件的权限设置给这个用户。 12$ sudo groupadd redis$ sudo useradd -g redis redis 重新加载systemd配置，启动Redis服务，并设置开机自启： 123$ sudo systemctl daemon-reload$ sudo systemctl start redis$ sudo systemctl enable redis 使用YUM进行安装 更新YUM源： 由于CentOS 7官方镜像已经被下单，官方的镜像地址mirrorlist.centos.org无法找到所需的文件，这里使用阿里云的镜像地址： 1$ sudo wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 在进行任何安装之前，首先要确保YUM源是最新的。运行以下命令来更新YUM源： 1$ sudo yum update -y 如果不更改镜像地址，执行上面的命令会抛出如下错误： 12Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=7&amp;arch=x86_64&amp;repo=os&amp;infra=stock error was14: curl#6 - &quot;Could not resolve host: mirrorlist.centos.org; Unknown error&quot; 添加EPEL和Remi Repository： Redis7不在CentOS 7的默认仓库中，因此需要添加EPEL（Extra Packages for Enterprise Linux）和Remi Repository。 安装EPEL： 1$ sudo yum install epel-release -y 安装Remi repository： 1$ sudo yum install -y https://mirrors.tuna.tsinghua.edu.cn/remi/enterprise/remi-release-7.rpm 启用Remi仓库： 1$ sudo yum-config-manager --enable remi 安装Redis 7： 使用YUM命令从Remi仓库中下载并安装Redis 7： 1$ sudo yum install redis -y 配置文件默认位置在/etc/redis.conf。 启动Redis服务： 安装完成后，启动Redis服务： 1$ sudo systemctl start redis 设置Redis服务为开机启动： 使用以下命令确保Redis在系统重启时自动启动： 1$ sudo systemctl enable redis 验证Redis安装： 使用以下命令检查Redis服务的状态： 1$ sudo systemctl status redis 如果Redis服务正在运行，应能看到“active (running)”的状态。 redis.conf常用配置 开启守护进程模式： 1daemonize yes daemonize设置yes或者no区别： yes：代表开启守护进程模式，redis会在后台运行，并将进程pid号写入至redis.conf选项pidfile设置的文件中。 no：启动将进入redis的命令行界面，exit或者关闭连接工具(putty，xshell等)都会导致redis进程退出。 bind配置项用于指定Redis服务器监听的IP地址，默认是使用的本地回环地址，也就是本地才能连接，可以注释掉这一行或者改为bind 0.0.0.0放开所有的外部网络访问。 12#bind 127.0.0.1bind 0.0.0.0 protected-mode用来限制对Redis服务器的访问。 1protected-mode yes 外部想要访问redis服务，除了需要修改bind的IP地址，还需要满足以下两个条件之一： protected-mode设置为no，将允许Redis接受来自任何网络接口的连接请求，只要这些接口被Redis监听。 protected-mode设置为yes，同时设置密码（requirepass）","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.formeasy.cc/tags/Redis/"}],"author":"u022812849"},{"title":"Redis深度解析：特性、缓存策略、持久化与集群实战","slug":"Redis/Redis深度解析：特性、缓存策略、持久化与集群实战","date":"2025-08-20T01:22:19.000Z","updated":"2025-08-20T01:51:48.183Z","comments":true,"path":"2025/08/20/Redis/Redis深度解析：特性、缓存策略、持久化与集群实战/","link":"","permalink":"http://www.formeasy.cc/2025/08/20/Redis/Redis%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E7%89%B9%E6%80%A7%E3%80%81%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E3%80%81%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%8E%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98/","excerpt":"","text":"一、Redis 是什么 Redis 是Remote Dictionary Server(Redis) 的缩写，是一个使用 C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型的Key-Value数据库，并提供多种语言的API。 它是一种 NoSQL（not-only sql，泛指非关系型数据库）的数据库，可以用作数据库、缓存、消息中间件、分布式锁等。 二、Redis 的特点和功能 性能优秀，数据在内存中，读写速度非常快，支持并发 10W QPS（每秒查询量）。 单进程单线程，是线程安全的，采用 IO 多路复用机制。 丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等。 支持数据持久化。 可以将内存中数据保存在磁盘中，重启时加载。 主从复制，哨兵，高可用。 可以用作分布式锁。 可以作为消息中间件使用，支持发布订阅 三、缓存和数据库数据一致性问题 分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是强一致性的，那么就不要使用缓存。 我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。 四、缓存选型（Redis 和 Memcached 的区别） Redis 和 Memcached 的区别 **存储方式上：**Memcache 会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis 有部分数据存在硬盘上，这样能保证数据的持久性。 **数据支持类型上：**Memcache 对数据类型的支持简单，只支持简单的 key-value，，而 Redis 支持五种数据类型。 **使用底层模型不同：**它们之间底层实现方式以及与客户端之间通信的应用协议不一样。Redis 直接自己构建了 VM 机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 **Value 的大小：**Redis 可以达到 1GB，而 Memcache 只有 1MB 五、Redis 为什么能这么快 官方提供的数据可以达到 100000+ 的 QPS（每秒内的查询次数），这个数据不比 Memcached 差。 Redis 完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度是 O(1)。 数据结构简单，对数据操作也简单。 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的 CPU 切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。 使用多路复用 IO 模型，非阻塞 IO。 六、Redis 缓存的淘汰策略 Redis 有六种淘汰策略，如下图： Redis 4.0 加入了 LFU（least frequency use）淘汰策略，包括 volatile-lfu 和 allkeys-lfu，通过统计访问频率，将访问频率最少，即最不经常使用的 KV 淘汰 七、Redis 持久化 1.为什么需要持久化 比如redis里有10gb数据，突然停电或者意外宕机了，再启动的时候10gb都没了！所以需要持久化，宕机后再通过持久化文件将数据恢复。 2.Redis 的持久化策略的两种方式 **RDB（默认）：**快照形式是直接把内存中的数据保存到 dump.rdb 文件中，定时全量保存，保存的是数据。 **AOF：**把所有的对 Redis 的服务器进行修改的命令都保存到 appendonly.aof 文件中，定时向文件中追加，保存的是命令。 3.RDB的特点 RDB性能高，速率快，全量持久化，但数据可靠性低。 (1)rdb文件 RDB(Redis DataBase)：基于时间的快照，Redis默认是会以快照&quot;RDB&quot;的形式将数据持久化到磁盘的一个二进制文件 dump.rdb中，其默认只保留当前最新的一次快照，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前时间点之间未做快照的数据。 但是我们可以通过配置文件配置多个时间点的备份,这样就可以保留多个备份,当出现问题时候方便恢复到不同时间节点,很适合备份,并且此文件格式支持不少第三方工具可以进行后续的数据分析。比如:可以在最近24小时内,每小时进行一次备份RDB文件，并且在每个月的每一天，也备份一个RDB文件，这样的话，即便遇上问题，也可以随时将数据集还原到不同的版本，所以RDB 非常适合灾难恢复。 (2)优点 由于rdb文件都是二进制文件，所以很小，在灾难恢复的时候会快些。 他的效率（宕机恢复的效率，而不是持久化的效率）相对于aof要高（bgsave而不是save），因为每来个请求他都不会处理任何事，只是bgsave的时候他会fork()子进程且可能copyonwrite，但copyonwrite只是一个寻址的过程，纳秒级别的。而aof每次都是写盘操作，毫秒级别。没法比。 注：fork()子进程以及copyonwrite（写时复制）的详解可见文末的参考“RDB原理” (3)缺点 数据可靠性比aof低，也就是会丢失的多。因为aof可以配置每秒都持久化或者每个命令处理完就持久化一次这种高频率的操作，而rdb的话虽然也是靠配置进行bgsave，但是没有aof配置那么灵活，也没aof持久化快，因为rdb每次全量，aof每次只追加。 4.AOF的特点 AOF数据可靠性高，增量持久化，但宕机恢复的效率相比于RDB还是略低。 (1)aof文件 AOF(Append Only File)：只追加文件，使用 AOF 做持久化，每一个写命令都通过 write 函数追加到 appendonly.aof 中。而RDB是压缩成二进制等时机开子进程去干这件事。 (2)优点 ①持久化的速度快，因为每次都只是追加，rdb每次都全量持久化。 ②全程持久化，只需要在配置中开启 appendonly yes。这样 Redis 每执行一个修改数据的命令，都会把它添加到 AOF 文件中，当 Redis 重启时，将会读取 AOF 文件进行重放，恢复到 Redis 关闭前的最后时刻。 ③数据相对更可靠，丢失少，使用 AOF 的优点是会让 Redis 变得非常耐久。可以设置不同的 Fsync 策略，AOF的默认策略是每秒钟 Fsync 一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 (3)缺点 灾难性恢复的时候过慢，因为aof每次都只追加原命令，导致aof文件过大，但是后面会rewrite，但是相对于rdb也是慢的。 5.项目中如何选择这两种方式 如果你追求性能，同时仍然可以承受数分钟内的数据丢失的话，那么可以使用 RDB 持久化。 如果你非常关心你的数据，并且性能对性能要求不是那么高的话，那么可以使用 AOF 持久化。 注：Redis 支持同时开启 RDB 和 AOF，系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。 八、Redis 集群模式选择 redis集群有三种模式 1.主从复制 2.哨兵模式 3.Cluster集群模式 主从复制：选取有三台（奇数）服务器，一主两从，主节点负责写入，从节点负责读取，达到读写分离，此时三台集群上的数据一致，但是有个不好的点在于 当主节点挂了的话，就需要人为操作，来重启主节点。 哨兵模式：哨兵模式在原有主从复制的基础上加了哨兵机制，简单理解就是监测各个节点活性，假如主节点挂了，还可以自动重启主节点。 Cluster集群模式：将数据均分到所有主节点上。与主从复制不同，集群中的节点不存储全量数据，而是分片存储。这种方式适合数据量较大的场景，可以均摊服务器压力 九、Redis 哨兵的基本原理 如图，是 Redis Sentinel（哨兵）的架构图。Redis Sentinel（哨兵）主要功能包括主节点存活检测、主从运行情况检测、自动故障转移、主从切换。 Redis Sentinel 最小配置是一主一从。Redis 的 Sentinel 系统可以用来管理多个 Redis 服务器。 该系统可以执行以下四个任务： **监控：**不断检查主服务器和从服务器是否正常运行。 **通知：**当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本向管理员或者其他应用程序发出通知。 **自动故障转移：**当主节点不能正常工作时，Sentinel 会开始一次自动的故障转移操作，它会将与失效主节点是主从关系的其中一个从节点升级为新的主节点，并且将其他的从节点指向新的主节点，这样人工干预就可以免了。 **配置提供者：**在 Redis Sentinel 模式下，客户端应用在初始化时连接的是 Sentinel 节点集合，从中获取主节点的信息。 哨兵的工作原理： ①每个 Sentinel 节点都需要定期执行以下任务：每个 Sentinel 以每秒一次的频率，向它所知的主服务器、从服务器以及其他的 Sentinel 实例发送一个 PING 命令。（如上图） ②如果一个实例距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 所指定的值，那么这个实例会被 Sentinel 标记为主观下线。（如上图） ③如果一个主服务器被标记为主观下线，那么正在监视这个服务器的所有 Sentinel 节点，要以每秒一次的频率确认主服务器的确进入了主观下线状态。 ④如果一个主服务器被标记为主观下线，并且有足够数量的 Sentinel（至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断，那么这个主服务器被标记为客观下线。 ⑤一般情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令。 当一个主服务器被标记为客观下线时，Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率，会从 10 秒一次改为每秒一次。 ⑥Sentinel 和其他 Sentinel 协商客观下线的主节点的状态，如果处于 SDOWN 状态，则投票自动选出新的主节点，将剩余从节点指向新的主节点进行数据复制。 ⑦当没有足够数量的 Sentinel 同意主服务器下线时，主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING 命令返回有效回复时，主服务器的主观下线状态就会被移除。 十、Redis缓存雪崩、穿透、击穿概念及解决办法 雪崩场景： 如果首页所有 Key 的失效时间都是 12 小时，中午 12 点刷新的，我零点有个大促活动大量用户涌入，假设每秒 6000 个请求，本来缓存可以抗住每秒 5000 个请求，但是缓存中所有 Key 都失效了，此时 6000 个/秒的请求全部落在了数据库上，数据库必然扛不住，真实情况可能 数据库都没反应过来直接挂了，此时，如果没什么特别的方案来处理，DBA 很着急，重启数据库，但是数据库立马又被新流量给打死了。这就是我理解的缓存雪崩。 雪崩解决方案： 在批量往 Redis 存数据的时候，把每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效，或者设置热点数据永不过期。 穿透场景： 缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求，这样的不断攻击导致数据库压力很大，严重会击垮数据库 穿透解决方案： 缓存穿透我会在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接 return，或者 使用高级用法布隆过滤器（Bloom Filter）这个也能很好的预防缓存穿透的发生。 击穿场景： 缓存击穿，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了 DB。而缓存击穿不同的是缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。 击穿解决方案： 使用互斥锁或者分布式锁来对并发请求进行控制，避免对同一资源的并发读写竞争，另外也可以使用热点数据预加载等机制来提前将热点数据加入缓存，在其失效时快速刷新缓存 参考：2W 字图解 Redis，面试必过必杀技！！ JAVA架构 | Redis分布式缓存原理分析 十三、Redis持久化之RDB原理_会飞的IT蜗牛的博客-CSDN博客_rdb","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.formeasy.cc/tags/Redis/"}],"author":null},{"title":"Redis的哨兵模式原理详解","slug":"Redis/Redis的哨兵模式原理详解","date":"2025-08-20T00:59:32.000Z","updated":"2025-08-20T01:52:03.940Z","comments":true,"path":"2025/08/20/Redis/Redis的哨兵模式原理详解/","link":"","permalink":"http://www.formeasy.cc/2025/08/20/Redis/Redis%E7%9A%84%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Redis的哨兵模式原理详解 开篇：哨兵模式就像城市的应急指挥中心 想象一下，一个繁忙的城市交通系统。当主要交通枢纽出现故障时，如果没有应急机制，整个城市的交通就会陷入瘫痪。这时，城市的应急指挥中心就会启动，自动检测故障、协调备用路线、通知相关部门，确保城市交通能够继续运行。 Redis的哨兵(Sentinel)模式就是这样一个&quot;应急指挥中心&quot;。在Redis主从架构中，如果主节点(master)出现故障，哨兵系统会自动检测到问题，然后从从节点(slave)中选举出新的主节点，并通知所有客户端连接到新的主节点，确保Redis服务的高可用性。 今天，我们就来深入探讨Redis哨兵模式的原理、工作机制和实现细节。通过这篇文章，大家将了解到哨兵模式如何保障Redis的高可用性，以及在实际项目中如何配置和使用哨兵模式。 一、Redis哨兵模式的基本概念 理解了哨兵模式的生活比喻后，我们来看它的技术定义。Redis哨兵是一个分布式系统，用于监控Redis主从服务器的状态，并在主服务器出现故障时自动进行故障转移(failover)。 上图展示了Redis哨兵模式的基本架构。多个哨兵节点监控着主节点和从节点，哨兵之间也会互相通信。 1.1 哨兵模式的主要功能 监控(Monitoring)：哨兵会定期检查主从节点是否正常工作 通知(Notification)：当被监控的Redis实例出现问题时，哨兵可以通过API通知系统管理员 自动故障转移(Automatic failover)：如果主节点不可用，哨兵可以启动故障转移过程，将一个从节点升级为新的主节点 配置提供者(Configuration provider)：客户端可以查询哨兵获取当前Redis主节点的地址 1.2 哨兵模式的特点 哨兵模式具有以下几个重要特点： 分布式特性：哨兵本身也是一个分布式系统，通常由多个哨兵节点组成，避免单点故障 自动故障检测：哨兵使用心跳机制和投票协议来检测节点故障 自动故障恢复：检测到主节点故障后，哨兵会自动选举新的主节点并重新配置系统 客户端透明：客户端可以通过哨兵自动发现当前的主节点，无需手动修改配置 二、哨兵模式的工作流程 了解了哨兵的基本概念后，我们来看它的具体工作流程。哨兵的工作可以分为几个关键阶段：监控阶段、故障检测阶段、故障转移阶段和配置更新阶段。 上述序列图展示了哨兵模式的完整工作流程，包括监控、故障检测、故障转移和配置更新四个主要阶段。 2.1 监控阶段 哨兵会定期向所有被监控的主从节点发送PING命令，根据返回结果判断节点状态： 如果节点在down-after-milliseconds时间内没有正确响应PING命令，哨兵会将该节点标记为&quot;主观下线&quot;(subjectively down) 哨兵会通过发布/订阅频道与其他哨兵交流，确认节点状态 当足够数量的哨兵(由quorum参数决定)都认为主节点不可达时，主节点被标记为&quot;客观下线&quot;(objectively down) 2.2 故障转移阶段 一旦主节点被确认为客观下线，哨兵会开始故障转移过程： 哨兵会从存活的从节点中选举一个作为新的主节点 选举标准包括：从节点的优先级、复制偏移量、运行ID等 哨兵会向选定的从节点发送SLAVEOF NO ONE命令，将其提升为主节点 哨兵会向其他从节点发送SLAVEOF命令，让它们复制新的主节点 哨兵会更新自己的配置，将故障的主节点标记为从节点(当它恢复时) 三、哨兵模式的配置与实现 理解了哨兵的工作原理后，我们来看如何在实际项目中使用哨兵模式。Redis哨兵的配置相对简单，但有一些关键参数需要注意。 3.1 哨兵配置文件示例 下面是一个典型的哨兵配置文件sentinel.conf： 1234567891011port 26379daemonize yespidfile /var/run/redis-sentinel.pidlogfile &quot;/var/log/redis/sentinel.log&quot;sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1sentinel auth-pass mymaster MySecurePassword 上述配置文件中： - sentinel monitor指定要监控的主节点 - down-after-milliseconds定义多久无响应视为下线 - failover-timeout定义故障转移超时时间 - parallel-syncs控制同时同步的从节点数量 - auth-pass设置Redis认证密码 3.2 启动哨兵进程 配置完成后，可以使用以下命令启动哨兵： 1redis-server /path/to/sentinel.conf --sentinel 通常建议至少部署3个哨兵节点，以确保高可用性。哨兵节点数量应该是奇数，以便在投票时能达成多数共识。 哨兵部署的思维导图，总结了哨兵部署的关键考虑因素。 3.3 Java客户端连接哨兵 在Java应用中，我们可以使用Jedis或Lettuce等客户端库连接Redis哨兵。以下是使用Jedis连接哨兵的示例代码： 12345678910111213141516171819202122232425import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisSentinelPool;public class SentinelExample &#123; private static final String MASTER_NAME = &quot;mymaster&quot;; private static final Set&lt;String&gt; SENTINELS = new HashSet&lt;&gt;(Arrays.asList( &quot;sentinel1:26379&quot;, &quot;sentinel2:26379&quot;, &quot;sentinel3:26379&quot; )); public static void main(String[] args) &#123; // 创建哨兵连接池 JedisSentinelPool pool = new JedisSentinelPool(MASTER_NAME, SENTINELS); try (Jedis jedis = pool.getResource()) &#123; // 执行Redis命令 jedis.set(&quot;key&quot;, &quot;value&quot;); String value = jedis.get(&quot;key&quot;); System.out.println(&quot;Got value: &quot; + value); &#125; pool.close(); &#125;&#125; 上述Java代码展示了如何使用Jedis连接Redis哨兵。JedisSentinelPool会自动从哨兵获取当前主节点地址，并在故障转移后自动切换到新的主节点。 四、哨兵模式的内部原理详解 现在我们已经了解了哨兵的基本使用，让我们深入探讨哨兵模式的内部工作原理。哨兵系统的核心在于其分布式共识算法和故障检测机制。 4.1 哨兵之间的通信 哨兵节点之间通过Redis的发布/订阅功能进行通信。每个哨兵会向__sentinel__:hello频道发布消息，内容包括： 哨兵的运行ID 哨兵的配置纪元(configuration epoch) 哨兵监控的主节点信息 哨兵的IP和端口 通过这种方式，哨兵可以发现其他哨兵并建立通信。 哨兵状态图展示了哨兵从启动到完成故障转移的完整状态变化过程。 4.2 故障检测算法 哨兵的故障检测分为两个阶段： 主观下线(SDOWN)：单个哨兵认为节点不可用 客观下线(ODOWN)：足够数量的哨兵认为节点不可用 客观下线的判定需要满足以下条件： 1quorum &lt;= number of sentinels agreeing the master is down 其中quorum是在配置中指定的值，通常设置为哨兵数量的一半加一。 4.3 领导者选举 当主节点被确认为客观下线后，哨兵会通过Raft-like算法选举一个领导者哨兵来执行故障转移： 每个哨兵都可以发起选举，向其他哨兵发送SENTINEL is-master-down-by-addr命令请求投票 哨兵会投票给第一个请求的哨兵，并在一个配置纪元内不再投票给其他哨兵 获得多数票的哨兵成为领导者，负责执行故障转移 如果选举超时(由failover-timeout控制)且没有选出领导者，会重新开始选举 4.4 从节点选举 领导者哨兵会从符合条件的从节点中选举新的主节点，选举标准包括： 从节点与主节点的断开时间 从节点的优先级(slave-priority) 从节点的复制偏移量 从节点的运行ID(作为最后的比较标准) 选举过程会优先选择数据最新的从节点，确保最小化数据丢失。 五、哨兵模式的最佳实践与注意事项 了解了哨兵模式的内部原理后，我们来看一些实际使用中的最佳实践和常见问题。 5.1 哨兵部署建议 哨兵数量：至少部署3个哨兵节点，最好部署5个以提供更高的容错能力 部署位置：将哨兵部署在不同的物理机或可用区，避免单点故障 监控间隔：合理设置down-after-milliseconds，通常设置为5-30秒 网络要求：确保哨兵节点之间的网络延迟低且稳定 5.2 常见问题与解决方案 常见问题及其解决方案的流程图。合理配置可以避免大多数问题。 5.3 哨兵模式的局限性 虽然哨兵模式提供了高可用性，但也有其局限性： 写操作不分区：哨兵模式不解决数据分区问题，所有写操作仍然集中在主节点 故障转移期间数据可能丢失：在主节点故障时，未同步到从节点的数据会丢失 配置复杂性：需要正确配置多个参数才能确保系统稳定 网络分区敏感：在网络分区情况下可能出现脑裂问题 六、总结 通过今天的讨论，我们深入了解了Redis哨兵模式的原理和实现。让我们总结一下本文的主要内容： 基本概念：哨兵模式是Redis的高可用解决方案，用于自动故障检测和转移 工作流程：包括监控、故障检测、故障转移和配置更新四个阶段 配置实现：哨兵的配置方法和Java客户端连接方式 内部原理：哨兵之间的通信、故障检测算法、领导者选举和从节点选举 最佳实践：哨兵部署建议和常见问题解决方案 Redis哨兵模式是构建高可用Redis系统的关键组件。虽然它有一些局限性，但在大多数场景下都能提供可靠的服务保障。希望这篇文章能帮助大家更好地理解和使用Redis哨兵模式。 在实际项目中，建议结合监控系统对哨兵和Redis实例进行监控，并定期测试故障转移过程，确保系统在真正故障时能够正常工作。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.formeasy.cc/tags/Redis/"}],"author":"qq_39032307"},{"title":"Redis入门与背景详解：构建高并发、高可用系统的关键基石","slug":"Redis/Redis入门与背景详解：构建高并发、高可用系统的关键基石","date":"2025-08-20T00:51:48.000Z","updated":"2025-08-20T01:51:55.298Z","comments":true,"path":"2025/08/20/Redis/Redis入门与背景详解：构建高并发、高可用系统的关键基石/","link":"","permalink":"http://www.formeasy.cc/2025/08/20/Redis/Redis%E5%85%A5%E9%97%A8%E4%B8%8E%E8%83%8C%E6%99%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%9E%84%E5%BB%BA%E9%AB%98%E5%B9%B6%E5%8F%91%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%85%B3%E9%94%AE%E5%9F%BA%E7%9F%B3/","excerpt":"","text":"前言 在当今这个数据驱动的时代，应用的性能和可扩展性已成为衡量其成功的关键指标。当传统的单机架构面对日益增长的用户量和数据洪流而显得力不从心时，分布式系统便应运而生。然而，系统的分布式演进也带来了新的挑战：如何在多台服务器之间高效、快速地共享和访问数据？ 这篇文章将带您认识一个在分布式世界中扮演着至关重要角色的技术——Redis。我们将从最基础的单机架构出发，一步步探索系统如何演进为复杂的分布式集群，并在这个过程中揭示Redis作为高性能内存数据库和缓存中间件的核心价值。无论您是刚入门的开发者，还是希望深化对系统架构理解的工程师，本文都将为您提供一个清晰的路线图，帮助您理解Redis为何能成为现代高性能应用不可或缺的基石。 认识Redis 在内存中进行数据存储 但是我们定义变量不是在内存中进行存储么，那么我们使用redis不是饶了个圈么？ redis是在分布式系统中，才能发挥作用 如果只是单机程序，直接通过变量存储数据的方法是比使用redis更优的选择 在分布式系统中定义变量肯定是不行的，因为进程是具有隔离性的，如果是分布式系统的话肯定是涉及到多个进程的，甚至说这多个进程是分布在不同的主机上，而你想共享别的进程的变量肯定是不行的 所以Redis是基于网络，将自己内存中的变量分享给别的进程，甚至给别的主机中的进程进行使用 mysql现在最大的问题在于，访问速度比较慢，数据在硬盘上 redis也可以作为数据库，在内存上的，速度快 计算机访问内存的速度比访问硬盘的速度快 定性的角度，可以知道redis快很多，但是很难定量衡量，因为mysql和redis具体功能和使用场景都不同 redis和mysql相比，最大的劣势，存储空间是有限的，内存比较小 从功能和存储空间的角度来说，还是mysql更胜一筹的 那么是否存在一个机制，让存储速度快，存储空间大呢 典型的方案就是将mysql和redis结合起来进行使用 用redis作为mysql的cache，将我们经常访问的数据使用redis进行存储，全量数据还是放在mysql中进行存储 代价就是系统的复杂程度大大提升了，如果数据发生成修改的话，还涉及到mysql和redis之间的同步问题 redis的初心，最初就是用来作为一个&quot;消息中间件&quot;的(消息队列) 分布式系统下的生产消费模型 但是当前很少会使用redis作为消息中间件，因为界内有更多专业的消息中间件 单机架构 单机架构，只有一台服务器，这个服务器负责所偶的工作 这里使用的服务器可以是mysql mysql是一个客户端服务器结构的陈旭 本体是mysql服务器（存储和组织数据的部分） 绝大部分公司的产品都是这种单机架构 如果业务进一步增长了，用户量和数据量都水涨船高了，一台主机难以应付的时候，就需要引入更多的主机，引入更多的硬件资源 浅谈分布式系统 分布式是什么 一台主机的硬件资源是有上限的 硬件资源包括不限于下面几种：CPU、内存、硬盘、网络 服务器每次收到一个请求，都是需要消耗上述的一些资源的 如果同一时刻，处理的请求多了，此时就可能会导致某个硬件资源不够用了 无论是哪个方面不够用了，都可能会导致服务器处理请求的时间变长了，甚至于处理出错 如果我们真的遇到这样的服务器不够的情况，如何进行处理呢 1、开源 增加更多的硬件资源（但是一个主机上能增加的硬件资源也是有限的） 2、节流（软件上的优化） 一台主机扩展到极限了，但是还是不够，就只能引入多态主机了 一但引入多台主机，咱们的系统就可以成为是“分布式系统” 引入分布式，这是万不得已 系统的复杂程度会大大提高的 数据库分离和负载均衡 应用服务器，里面可能会包含很多的业务逻辑，可能会吃CPU和内存 数据库服务器，需要更大的硬盘空间，更快的访问速度，可以配置更大硬盘的服务器 引入更多的应用服务器节点，应用服务器可能比较吃CPU和内存，如果把CPU和内存吃没了，此时应用服务器就顶不住了，引入更多的应用服务器，就可以有效解决上述问题了 用户的请求先到达负载均衡器/网关服务器 假设有1w个用户请求，有2个应用服务器的话，此时按照负载均衡的方式，就可以让每个应用服务器承担5k的访问量 这个就和多线程其实很相似的 负载均衡器，对于请求量的承担能力，要远超过于应用服务器的 负载均衡器是领导，分配工作 应用服务器，是组员，执行任务 也可能请求量大道负载均衡器也扛不住了 那么我们就得引入更多的负载均衡器 增加应用服务器，确实能够处理更高的请求量 但是随之存储服务器，要承担的请求量也就更多了 实际的应用场景中，读的频率比写更高的 引入更多的从服务器 主服务器只有一个 同时从数据库通过负载均衡的方式，让应用服务器进行访问 通过这样降低单台服务器的压力 引入缓存 数据库天然问题，相应速度是更慢的！！ 把数据区分&quot;冷热&quot;，热点数据放到缓存中~缓存的访问速度往往比数据库快很多了 在数据库读写分离的基础上，这里引入了缓存服务器，存放一小部分热点数据（会频繁被访问的数据） 所以冷数据就是不会被频繁访问的数据 缓存要想快，就得付出代价 redis就是要作为缓存服务器 对应用服务器来说，绝大多数的请求都能从缓存服务器中找到答案，这就是我们的数据库服务器承担的压力变小了，并且我们的缓存服务器读取速度还快 缓存服务器帮助数据库服务器负重前行了 要想得到一个效果，就要付出一定的代价 数据库分库分表 引入分布式系统不光要应对更高的请求量（并发量），同时能应对更大的数据量 可能会出现，一台服务器已经存不下数据了，虽然一个服务器的存储量可以到几十个TB，即使如此也可能会存不下 一台主机存不下，就得需要多台主机了 针对数据库进行进一步的拆分 分库分表 本来是一个数据库服务器，这个数据库服务器上有多个数据库（指的是逻辑上的数据集合，create database创建的那个东西) 现在就可以引入多个数据库服务器，每个数据库服务器存储一个或者一部分数据库 如果某个表特别大，大到一台主机存不下，也可以针对表进行拆分 具体分库分表如何时间，还是要结合实际的业务场景来展开 业务至关重要 引入微服务 微服务架构 之前的应用服务器，一个服务器程序里面做了很多的业务，这就可能会导致这一个服务器的代码越来越复杂了，为了更方便于代码的维护，就可以把这样的一个复杂的服务器，拆分成更多的，功能更单一，更下的服务器，我们将这样小的服务器成为微服务 服务器的种类和数量就增加了 最开始引入负载均衡解决的问题是请求量更高的问题 后面引入的分库分表解决的是存储空间不足的问题 那么微服务本质上解决的是“人”的问题 当应用服务器变复杂了，那么势必就需要更多的人来维护了 当人多了，就需要配套的管理，把这些人组织好 因此就得划分组织结构，分成多个组，每个组配备领导进行管理 分成多个组之后，就需要进行分工了 按照功能，拆分成多组微服务，这样就有利于上述人员组织的结构的分配了 如果是小公司，就几个开发，那么就没必要搞微服务了 引入微服务，解决了人的问题，会有什么代价呢？ 1、性能会下降（想保证性能不下降，只能引入更多的机器，更多的硬件资源） 拆出来更多的服务，多个功能之间更要依赖网络通信， 网络通信的速度很可能是比硬盘还慢的 2、系统复杂程度提高，可用性受到影响 服务器更多了，出现问题的概率更大了 这就需要一些列的手段保证系统的可用性 微服务的优势： 1、解决了人的问题 2、使用微服务，可以更方便于功能的复用 3、可以给不同的服务去进行不同的部署 念补充 分布式，引入多个主机/服务器，协同配合完成一系列的工作 主从是分布式系统中一种比较经典的结构 多个服务器节点，一个是主，另一个是从，从节点的数据主要从主节点这里同步过来~~ 中间件和业务无关的服务（功能更通用的服务） 数据库 缓存 消息队列 吞吐和并发是衡量系统的处理请求的能力，衡量性能的一种方式 小结 1、单机架构（应用程序+数据库服务器） 2、数据库和应用分离 应用程序和数据库服务器分别放到不同主机上部署了 3、引入负载均衡：应用服务器=&gt;集群 通过负载均衡器，把请求比较君均匀的分发给集群中的每个应用服务器 当整个系统中的某个主机挂了，其他主机仍然可以承担服务，提高了整个系统的可用性 4、引入读写分离，数据库主从结构 一个数据库节点作为主节点，其他n个数据库节点作为从节点 主节点负责写数据，从节点负责读数据 主节点需要把爱修改过的数据同步到从节点 5、引入缓存，冷热数据分离 进一步提升了服务器针对请求的处理能力 二八原则 6、引入分库分表，数据库能够进一步扩展存储空间 7、引入微服务，从业务上进一步拆分应用服务器 从后业务功能的角度，把应用服务器，拆分成更多的功能单一，更简单，更小的服务器 所谓的分布式系统，就是想办法引入更多的硬件资源 Redis特性介绍 Redis是一个在内存中存储数据的中间件，用于作为数据库，用于作为数据缓存 在分布式系统中能够大展拳脚 Redis的一些特定（优点） Redis在内存中存储数据 mysql主要是通过&quot;表&quot;的方式来存储组织数据的“关系型数据库” Redis主要是通过“键值对”的方式来存储数据的 非关系型数据库 针对Redis的操作，可以直接通过简单的交互式命令进行操作 也可以通过一些脚本的方式，批量执行一些操作 持久化 Redis 持久化 内存中的数据是易失的 Redis会把数据存储在硬盘上 内存为主，硬盘为辅 硬盘相当于对内存的数据备份一下 如果Redis重启了，就会在重启时加载硬盘中的备份数据，使Redis的内存恢复到重启前的状态 支持集群 Redis 作为一个分布式系统的中间件，能够支持集群是很关键的 这个水平拓展的意思即是“分库分表” 一个Redis 能存储的数据是有限的（内存空间有限） 引入多个主机，部署多个Redis 引入多个主机，部署多个Redis 节点，每个存储数据的一部分 高可用 高可用=&gt;冗余/备份 Redis自身也是支持主从结构的 从节点就相当于主节点的备份了 快 1、Redis数据存在内存中，就比访问硬盘的数据库，要快很多 2、Redis的核心功能都是比较简单的逻辑—核心功能都是比较简单的操作内存的数据结构 3、网络角度上，Redis使用了IO多路复用的方式（epoll）—使用一个线程，管理很多个socket 4、Redis使用的是单线程模型，这样的单线程模型，减少了不必要的线程之间的竞争开销 多线程提高效率的前提是，CPU密集型的任务，使用多个线程可以充分的利用CPU多核资源 但是Redis得核心任务，主要就是操作内存的数据结构，不会吃很多的CPU Redis的应用场景 实时的数据存储，将Redis当做数据库（通过键值对进行数据存储） 大多数情况下，考虑到数据存储，有限考虑的是“大” 但是仍然有一些场景，考虑的是“快” 作为缓存 2、将会话数据单独拎出来，放到一组独立的机器上存储（Redis） 分布式系统来说，服务器和服务器之间，有时候也需要使用到生产者消费者模型的 解耦合 削峰填谷 Redis也是已提供了消息队列的功能的 如果当前场景中，对于消息队列的功能依赖的不是很多 并且又不想引入额外的依赖了，Redis可以作为一个选择 Redis不能存储大规模数据 总结 本文深入探讨了Redis的背景、核心特性及其在现代分布式系统中的关键作用。核心要点总结如下： Redis的核心定位：Redis是一个开源的、基于内存存储的键值对（Key-Value）非关系型数据库。它通过网络为分布式系统中的多个进程提供高速的数据共享服务，其访问速度远超于基于硬盘的传统数据库（如MySQL）。 分布式系统的演进与Redis的价值：随着业务量的增长，系统架构从简单的单机模式，逐步演进为应用与数据库分离、引入负载均衡、实现数据库读写分离的复杂结构。在这一过程中，为了解决数据库的访问瓶颈，引入Redis作为缓存层成为关键一步。通过将频繁访问的“热数据”放入Redis，可以极大减轻数据库的压力，并显著提升应用的响应速度。 Redis的核心特性： 速度快：数据存储在内存中，同时采用I/O多路复用和单线程模型，减少了不必要的上下文切换开销。 持久化：支持将内存数据异步写入硬盘，确保了数据在服务重启后不会丢失。 高可用与可扩展：通过主从复制（Master-Slave）架构保障高可用性，并通过集群模式实现水平扩展，以应对海量数据的存储需求。 丰富的数据结构：支持字符串、哈希、列表、集合、有序集合等多种数据类型，能灵活应对各种业务场景。 主要应用场景： 数据缓存：最核心的应用，作为MySQL等主数据库的缓存，分离冷热数据。 会话共享（Session Store）：在分布式Web服务中，集中存储用户会话信息，解决负载均衡下的会话一致性问题。 实时数据存储：适用于对速度要求极高的场景，如排行榜、计数器等。 消息队列：可用于实现简单的生产者-消费者模型，进行服务间的解耦和流量削峰。 总而言之，Redis凭借其卓越的性能和灵活性，已成为构建高性能、高并发和高可用性分布式系统的关键中间件。理解Redis不仅是掌握一个工具，更是深入理解现代应用架构演进思想的重要一环。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.formeasy.cc/tags/Redis/"}],"author":230180863610},{"title":"通信中间件 Fast DDS：编译、安装和测试","slug":"DDS/通信中间件 Fast DDS ：编译、安装和测试","date":"2025-08-15T07:11:47.000Z","updated":"2025-08-15T07:34:27.708Z","comments":true,"path":"2025/08/15/DDS/通信中间件 Fast DDS ：编译、安装和测试/","link":"","permalink":"http://www.formeasy.cc/2025/08/15/DDS/%E9%80%9A%E4%BF%A1%E4%B8%AD%E9%97%B4%E4%BB%B6%20Fast%20DDS%20%EF%BC%9A%E7%BC%96%E8%AF%91%E3%80%81%E5%AE%89%E8%A3%85%E5%92%8C%E6%B5%8B%E8%AF%95/","excerpt":"","text":"1.简介 DDS是 OMG 组织发布的一种中间件协议和 API 标准，它将系统的组件集成在一起，提供业务和任务关键型物联网(IoT) 应用程序所需的低延迟数据连接、极高的可靠性和可扩展架构。 DDS(Data Distribution Service,数据分发服务) 是一种以数据为中心的通信协议，用于分布式软件应用程序通信。 它描述了支持 数据提供者(Data Providers) 和 数据消费者(Data Consumers) 之间通信的通信应用程序编程接口 (API) 和通信语义。 要学习 DDS 就不能忽略它的模型：DCPS(以数据为中心的发布订阅模型)。 DCPS 有 3 个关键实体： publication entities: 定义消息生成对象及相关属性 subscription entities：定义消息消费对象及相关属性 configuration entities:定义传输相关的属性如 Topic 类型，通信的 QoS(服务质量)。 QoS 是一个非常重要的概念，DDS 使用 QoS 来定义 DDS 实体的行为特征。 QoS 由单独的 QoS 策略（源自 QoSPolicy 的类型的对象）组成。 FastDDS（原名 Fast RTPS）是 eProsima 公司开发的开源 DDS（Data Distribution Service）实现，基于 RTPS 协议，适用于实时通信场景。 2.Windows编译、安装和测试 2.1.编译环境准备 安装 Visual Studio 2019/2022（需勾选 “Desktop development with C++” 组件）。 安装 CMake（3.16+，添加到系统 PATH）。 安装 Git（添加到系统 PATH）。 依赖库（如 OpenSSL、asio）可通过 vcpkg 安装： 123456# 安装vcpkggit clone https://github.com/microsoft/vcpkg.\\vcpkg\\bootstrap-vcpkg.bat # 安装依赖.\\vcpkg\\vcpkg install openssl asio tinyxml2 --triplet x64-windows 由于我的电脑通过cmd命令命令行目录是C:\\Users\\Administrator，所以vcpkg是安装在C:\\Users\\Administrator这里： 下载vcpkg源码： 安装 openssl asio tinyxml2： 2.2.编译安装 2.2.1.安装FastCDR FastDDS 依赖 FastCDR（序列化库），需要获取源码，在cmd命令行直接操作： 1234567# 克隆FastCDR（必须先编译）git clone https://github.com/eProsima/Fast-CDR.gitcd Fast-CDRmkdir build &amp;&amp; cd build cmake .. -G &quot;Visual Studio 17 2022&quot; -A x64 -DCMAKE_INSTALL_PREFIX=C:\\fastdds_installcmake --build . --config Release --target install 安装完成后，在C:\\fastdds_install目录有FastCDR的头文件，库文件等信息： 2.2.2.安装Foonathan Memory FastDDS 依赖 Foonathan Memory（内存管理库），需要获取源码，在cmd命令行直接操作： 1234567# 克隆FastCDR（必须先编译）git clone https://github.com/eProsima/foonathan_memory_vendor.gitcd foonathan_memory_vendormkdir build &amp;&amp; cd build cmake .. -G &quot;Visual Studio 17 2022&quot; -A x64 -DCMAKE_INSTALL_PREFIX=C:\\fastdds_installcmake --build . --config Release --target install 在执行cmake --build . --config Release --target install的时候报错： 于是在网上各种搜索问题原因，始终没有找到解决的办法，于是我到Foonathan Memory的网站去看了一下： https://github.com/foonathan/memory 找到资料原来Foonathan Memory可以通过vcpkg安装，由于之前安装vcpkg，于是直接进入vcpkg目录，执行下面命令就行： 12./vcpkg integrate install./vcpkg install foonathan-memory 安装完之后，FastDDS的所以依赖就安装完毕，在vcpkg的安装目录下可以看到所有的依赖项： 2.2.3.安装FastDDS 跟安装FastCDR的步骤差不多，不过需要各种依赖库的路径，如下： 1234567git clone https://github.com/eProsima/Fast-DDS.gitcd Fast-DDSmkdir build &amp;&amp; cd build cmake .. -G &quot;Visual Studio 17 2022&quot; -A x64 -DCMAKE_INSTALL_PREFIX=C:\\fastdds -Dfastcdr_ROOT=C:\\fastdds_install -DAsio_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\asio_x64-windows\\include -DTinyXML2_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\tinyxml2_x64-windows -Dfoonathan_memory_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\foonathan-memory_x64-windows -DOpenSSL_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\openssl_x64-windows cmake --build . --config Release --target install 编译安装后，在C:\\fastdds目录下有FastDDS的头文件，库文件等信息： 2.3.验证安装 编译完成后，可通过运行 FastDDS 的示例程序验证： 编译： 12345mkdir build &amp;&amp; cd build cmake .. -Dfastcdr_ROOT=C:\\fastdds_install -Dfastdds_ROOT=C:\\fastdds -DTinyXML2_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\tinyxml2_x64-windows -Dfoonathan_memory_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\foonathan-memory_x64-windows -DOpenSSL_ROOT=C:\\Users\\Administrator\\vcpkg\\packages\\openssl_x64-windows cmake --build . --config Release 完成后在Relese目录下有测试程序hello_world.exe, 把hello_world.exe的一些依赖dll拷贝到这个目录下： 在命令行运行hello_world.exe，显示如下： 分别启动两个终端，运行： 12345# 启动发布者（终端1）.\\Hello_World.exe publisher # 启动订阅者（终端2）.\\Hello_World.exe subscriber 最终运行的效果（1对1）： 1对多，一个发布者，多个订阅者： 若订阅者能收到发布者的消息，说明编译和安装成功。 3.Linux编译、安装和测试 3.1.编译环境准备 以麒麟系统为例讲解，FastDDS 依赖多个工具和库，需先安装编译环境和依赖项。 123456789# 更新系统包sudo apt update &amp;&amp; sudo apt upgrade -y # 安装基础编译工具sudo apt install -y build-essential cmake git pkg-config # 安装依赖库sudo apt install -y libssl-dev libasio-dev libtinyxml2-devsudo apt install -y openjdk-11-jdk # 用于代码生成工具（可选，部分功能需要） 3.2.编译安装 3.2.1.安装FastCDR 1234567891011121314git clone https://github.com/eProsima/Fast-CDR.gitcd Fast-CDR mkdir build &amp;&amp; cd build # CMake配置（默认安装到/usr/local）cmake .. -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release # 编译（-j后接CPU核心数，加速编译）make -j$(nproc) # 安装（需要管理员权限）sudo make installcd ../.. # 返回工作目录 3.2.2.安装Foonathan Memory 1234567891011121314git clone https://github.com/eProsima/foonathan_memory_vendor.gitcd foonathan_memory_vendor mkdir build &amp;&amp; cd build # CMake配置（默认安装到/usr/local）cmake .. -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release # 编译（-j后接CPU核心数，加速编译）make -j$(nproc) # 安装（需要管理员权限）sudo make installcd ../.. # 返回工作目录 3.2.3.安装FastDDS 1234567891011121314git clone https://github.com/eProsima/Fast-DDS.gitcd Fast-DDS mkdir build &amp;&amp; cd build # CMake配置（默认安装到/usr/local）cmake .. -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release # 编译（-j后接CPU核心数，加速编译）make -j$(nproc) # 安装（需要管理员权限）sudo make installcd ../.. # 返回工作目录 编译到最后的时候，出错了： 从报错的提示说是无法找到make_strand，第一直觉应该是asio的库版本低了，FastDDS要求的asio版本是： 而我的麒麟系统是1.12.2，所以报错了。因此必须升级asio库，于是直接从地址： https://think-async.com/Asio/Download.html 下载了最新版本，直接安装： 123./configure make -j8 make -j8 install asio库相对来说更简单，由于这个库其实并不需要编译，是一个header-only的库，所以根据命令进行安装就可以了。 然后再用同样的方法安装FastDDS即可。安装完在/usr/local目录下有FastDDS的相关信息： 3.3.验证安装 编译完成后，可通过运行 FastDDS 的示例程序验证。 先编译测试程序: 12345# 进入示例目录（以HelloWorld为例）cd ~/Fast-DDS/examples/cpp/dds/HelloWorldExample/build # 编译示例（若未自动编译）cmake .. &amp;&amp; make -j$(nproc) 分别启两个终端运行测试程序： 12345# 启动发布者（终端1）./Hello_World publisher # 启动订阅者（终端2）./Hello_World subscriber 若订阅者能收到发布者的消息，说明编译和安装成功。 4.常见问题 1.依赖缺失：CMake 报错 “Could NOT find XXX” 时，检查对应依赖是否安装，或通过-DCMAKE_PREFIX_PATH指定依赖路径。 2.版本不兼容：确保 FastDDS 与 FastCDR 版本匹配（参考官方版本矩阵）。 3.权限问题：安装时若提示 “Permission denied”，添加sudo或修改安装路径（如 -DCMAKE_INSTALL_PREFIX=$HOME/fastdds）。 通过以上步骤，可在 Linux、Windows 或 macOS 系统上完成 FastDDS 的编译与安装，为后续开发 DDS 应用奠定基础。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"DDS","slug":"DDS","permalink":"http://www.formeasy.cc/tags/DDS/"}],"author":"haokan123456789"},{"title":"vscode+qt+qmake开发环境搭建(最全最详细)","slug":"Qt/vscode+qt+qmake开发环境搭建(最全最详细)","date":"2025-08-14T08:10:32.000Z","updated":"2025-08-14T08:18:43.268Z","comments":true,"path":"2025/08/14/Qt/vscode+qt+qmake开发环境搭建(最全最详细)/","link":"","permalink":"http://www.formeasy.cc/2025/08/14/Qt/vscode+qt+qmake%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E6%9C%80%E5%85%A8%E6%9C%80%E8%AF%A6%E7%BB%86)/","excerpt":"","text":"本文主要介绍了vscode+qt+qmake开发环境搭建,文中通过图文示例介绍的非常详细,对大家的学习或者工作具有一定的参考学习价值,需要的朋友们下面随着小编来一起学习学习吧 00. 前言 鉴于Qt官方IDE太过难用，VSCode＋各种插件功能强大，遂采用VSCode来写Qt项目。 01. 环境搭建 1. 需要安装的软件： VSCode，官方最新版就行 Qt，版本随意，本文主要针对较老版本使用Qmake构建系统的项目 2. 环境变量： Qt环境变量，需要配置Qt库跟MinGW，尽量使用Qt安装时自带的MinGW VSCode插件，下面C/C++插件是必需的没意见吧 02. 开始配置 1. 创建项目项目 先用Qt Creator创建个Qmake项目，最简单的空白窗口，项目结构如下 2. 使用VSCode打开项目 3. 配置C/C++插件 VSCode快捷键ctrl+shift+p打开命令面板，输入c++，选择编辑配置 4. 编辑C/C++设置 编译器路径:下拉有得选就选你配置环境变量的Qt版本，没有就自己复制路径过来 IntelliSense 模式：选择安装的gcc的架构，我安装的是64位Qt，上面自带的gcc编译器也是64位，就选择windows-gcc-x64 头文件路径：这个主要是实现头文件识别，要不然Qt的头文件一直飘红，也没法自动跳转头文件，第一行是当前像目录下所有，第二行是安装的Qt库的头文件路径 剩下的配置按需配置，不配置也不影响。选择编辑json可以查看C/C++插件json版本的配置 刚才配置的都在这里面了，现在引用Qt头文件已经不报错了 c_cpp_properties.json 12345678910111213141516171819&#123; &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;Win32&quot;, &quot;includePath&quot;: [ &quot;$&#123;workspaceFolder&#125;/**&quot;, &quot;C:/Qt/5.15.2/mingw81_64/include/**&quot; ], &quot;defines&quot;: [ &quot;_DEBUG&quot;, &quot;UNICODE&quot;, &quot;_UNICODE&quot; ], &quot;intelliSenseMode&quot;: &quot;windows-gcc-x64&quot;, &quot;compilerPath&quot;: &quot;C:/Qt/Tools/mingw810_64/bin/g++.exe&quot; &#125; ], &quot;version&quot;: 4&#125; 5. 配置task.json 选择终端-运行任务-配置任务-使用模板创建task.json文件-Others；这一步无所谓，就是搞个模板，用我下面贴的一样 配置编译Qt项目的task，这一步其实是跟Qt Creator相同的，我们打开Qt Creator，选择项目，查看刚才的项目的项目构建配置 Qt Creator构建步骤分析如下： 设置构建目录，也就是编译出来的中间文件目录 qmake，这一步其实是用qmake将.pro配置文件编译成makefile，并且将其中涉及的.ui、.qrc等编译成cpp，都在构建目录中，下面是切换Debug/Release时不同的qmake编译命令 12345#DebugC:/Qt/5.15.2/mingw81_64/bin/qmake.exe D:\\Code\\Other\\untitled\\untitled.pro -spec win32-g++ &quot;CONFIG+=debug&quot; &quot;CONFIG+=qml_debug&quot; &amp;&amp; C:/Qt/Tools/mingw810_64/bin/mingw32-make.exe qmake_all#ReleaseC:/Qt/5.15.2/mingw81_64/bin/qmake.exe D:\\Code\\Other\\untitled\\untitled.pro -spec win32-g++ &quot;CONFIG+=qml_debug&quot; &amp;&amp; C:/Qt/Tools/mingw810_64/bin/mingw32-make.exe qmake_all make，真正的编译cpp，MinGW使用的式mingw32-make.exe 1mingw32-make.exe -j22 in D:\\Code\\Other\\untitled\\build clean，这里使用还是mingw32-make.exe 1mingw32-make.exe clean -j20 in D:\\Code\\Other\\untitled\\build 将上面Qt Creator构建步骤转换为task.json就行了，我把debug、relese全流程都加上了，非常简单！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121&#123; // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; //在当前项目目录创建build文件夹 &quot;label&quot;: &quot;mkdir&quot;, //任务名称 &quot;type&quot;: &quot;shell&quot;, //任务类型，定义任务是被作为进程运行还是在 shell 中作为命令运行。 &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot; //已执行程序或脚本的当前工作目录，设置当前项目文件夹 &#125;, &quot;command&quot;: &quot;mkdir&quot;, //命令 &quot;args&quot;: [ //命令后面跟的参数 &quot;-Force&quot;, &quot;build&quot; ] &#125;, &#123; &quot;label&quot;: &quot;qmake-debug&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build&quot; //进入build目录 &#125;, &quot;command&quot;: &quot;qmake&quot;, //qmake命令，这里没用完整路径，是因为配置到环境变量了 C:/Qt/5.15.2/mingw81_64/bin/qmake.exe &quot;args&quot;: [ //跟的参数是不是很熟悉，就是上面分析出来的Qt Creator执行流程 &quot;../$&#123;workspaceFolderBasename&#125;.pro&quot;, //在build目录上一级哦 &quot;-spec&quot;, &quot;win32-g++&quot;, &quot;\\&quot;CONFIG+=debug\\&quot;&quot;, &quot;\\&quot;CONFIG+=console\\&quot;&quot; ], &quot;dependsOn&quot;: [ //这是本条命令依赖的前置条件，就是上面创建build文件夹的task，直接执行本task会自动先调用依赖的task &quot;mkdir&quot; //其实可以手动执行一次，后面不用每次都执行创建目录的操作 ] &#125;, &#123; &quot;label&quot;: &quot;make-debug&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build&quot; &#125;, &quot;command&quot;: &quot;mingw32-make&quot;, //MinGW这个也配置在环境变量了，不用写完整路径了 C:/Qt/Tools/mingw810_64/bin/mingw32-make.exe &quot;args&quot;: [ &quot;-f&quot;, &quot;Makefile.Debug&quot;, //-f 选择makefile，这是qmake编译出来的 &quot;-j7&quot; //这个参数都知道吧，编译用的线程数量 ], &quot;dependsOn&quot;: [ &quot;qmake-debug&quot; ] &#125;, &#123; &quot;label&quot;: &quot;run-debug&quot;, &quot;type&quot;: &quot;process&quot;, //运行就不能选择shell执行了，要选择process &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build/debug&quot; //没在.pro配置DESTDIR,会生成到build目录下面对应目录 &#125;, &quot;command&quot;: &quot;$&#123;workspaceFolderBasename&#125;.exe&quot;, //执行的exe名字，一般当前项目文件夹的名称，自定义可以写其他的 &quot;dependsOn&quot;: [ &quot;make-debug&quot; ] &#125;, / &#123; &quot;label&quot;: &quot;qmake-release&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build&quot; &#125;, &quot;command&quot;: &quot;qmake&quot;, &quot;args&quot;: [ //注意release跟debug参数的差异 &quot;../$&#123;workspaceFolderBasename&#125;.pro&quot;, &quot;-spec&quot;, &quot;win32-g++&quot;, &quot;\\&quot;CONFIG+=qtquickcompiler\\&quot;&quot; ], &quot;dependsOn&quot;: [ // &quot;mkdir&quot; //不用每次都创建吧 ] &#125;, &#123; &quot;label&quot;: &quot;make-release&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build&quot; &#125;, &quot;command&quot;: &quot;mingw32-make&quot;, &quot;args&quot;: [ &quot;-f&quot;, &quot;Makefile.Release&quot;, //注意release跟debug参数的差异 &quot;-j7&quot; ], &quot;dependsOn&quot;: [ &quot;qmake-release&quot; ] &#125;, &#123; &quot;label&quot;: &quot;run-release&quot;, &quot;type&quot;: &quot;process&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build/release&quot; &#125;, &quot;command&quot;: &quot;$&#123;workspaceFolderBasename&#125;.exe&quot;, &quot;dependsOn&quot;: [ &quot;make-release&quot; ] &#125;, &#123; &quot;label&quot;: &quot;clean&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;/build&quot; &#125;, &quot;command&quot;: &quot;mingw32-make&quot;, &quot;args&quot;: [ &quot;clean&quot; ] &#125; ]&#125; 既然配置好了，那就可以开心的运行代码，有两种方式 终端-运行任务-选择任务，我们配置的task都在里面了，选择run-debug/run-release就行，因为配置过depend[]，前面qmake、make都被一条龙调用 既然是VSCode，不用快捷键怎么可以，超级强大的ctrl+shift+p，输入run，和手点流程一样，回车，方向键选择run-debug/run-release回车执行就好了 一条龙调用的命令在控制台就会有输出了，exe启动后log也会在这输出 03. 配置断点调试 上面配置的是以debug/release方式运行程序，那么要打断点调试怎么办呢？ 1.配置launch.json 侧边栏选择调试，点击创建launch.json文件 选择c++就行，第一个第二个没关系，反正生成的几乎空白的模板 选择创建配置，选择gdb启动作为基础模板，来在上面修改 修改内容如下，我放了自动生成的模板跟修改后的，可以对比看下修改了那些地方，实际使用记得删除哈 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&#123; // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) 启动&quot;, //模板，实际使用记得删除 &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;输入程序名称，例如 $&#123;workspaceFolder&#125;/a.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;miDebuggerPath&quot;: &quot;/path/to/gdb&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;为 gdb 启用整齐打印&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125;, &#123; &quot;description&quot;: &quot;将反汇编风格设置为 Intel&quot;, &quot;text&quot;: &quot;-gdb-set disassembly-flavor intel&quot;, &quot;ignoreFailures&quot;: true &#125; ] &#125;, &#123; &quot;name&quot;: &quot;debug&quot;, //修改后 &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/build/debug/$&#123;workspaceFolderBasename&#125;.exe&quot;, //写完整路径 &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;, //工作目录，项目根目录 &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;miDebuggerPath&quot;: &quot;C:/Qt/Tools/mingw810_64/bin/gdb.exe&quot;, //选择MinGW中的gdb &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;为 gdb 启用整齐打印&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125; ], &quot;preLaunchTask&quot;: &quot;make-debug&quot;, //这跟depend[]很像啊，make就行了，用make编译出exe &#125; ]&#125; 2. 运行调试 重新打开调试，刚才配置的调试配置已经存在了 打个断点，点击绿色三角，运行下看看效果 04. 运行效果 run-debug及自动生成的目录结构、控制台log，ctrl+c结束程序 run-release debug断点调试 到此这篇关于vscode+qt+qmake开发环境搭建(最全最详细)的文章就介绍到这了!","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":null},{"title":"从零开始配置Qt+VsCode环境","slug":"Qt/从零开始配置Qt+VsCode环境","date":"2025-08-14T08:01:59.000Z","updated":"2025-08-14T08:08:41.528Z","comments":true,"path":"2025/08/14/Qt/从零开始配置Qt+VsCode环境/","link":"","permalink":"http://www.formeasy.cc/2025/08/14/Qt/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E9%85%8D%E7%BD%AEQt+VsCode%E7%8E%AF%E5%A2%83/","excerpt":"","text":"写在前面 测试环境（20241120）：Win11 + VsCode1.93.0 + Qt5.15.2 + CMake3.28.0-rc3 本文章适用于有一定Qt使用基础，并且想转到VsCode的同学。 扩展安装及配置 Qt Configure(@vector-wlc) 必须 Qt Extension Pack(@Qt Group)，不是必要但可提升使用体验，Qt UI具有点击.ui文件启动Qt Widgets Designer。 Qt C++ Extension Pack(@Qt Group),该扩展包包含了Qt Extension Pack(@Qt Group)，同时增加了C/C++(@Microsoft),CMake(@twxs),CMake Tools(@Microsoft)，对于不想手动一个一个安装的可以推荐。若想使用CMake这个三个都是必须的。 对于C/C++推荐装一个C/C++ Extension Pack(@Microsoft) Qt Configure配置 Qt Configure: Mingw Path，请设置MinGw的bin之前那个路径，请根据自身环境实际情况进行配置 D:\\Programs\\Qt\\5.15.2\\mingw81_64 Qt Configure: Qt Dir，请根据自身环境实际情况设置Qt的安装路径 D:\\Programs\\Qt Qt Configure: Vcvarsall Path，设置VS环境变量脚本路径，在使用Msvc编译器时会用到，同样请根据自身环境实际情况进行配置 D:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat 这里主要了就是配置Qt Configure扩展其它扩展记不太清楚了，若有不懂的可评论或者私信沟通。 还有就是我的CMake是设置了系统环境变量的，有可能会对项目操作有一些影响。 VsCode创建Qt工程 Ctrl + Shift + P 通过QtConfigure插件新建工程 输入项目名称并确认 选择Qt的构建套件，这些都是Qt的构建套件包含MinGw和Msvc，不同的Qt版本略有不同，请结合自身实际情况进行选择 选择构建工具 选择是否带UI文件 选择完成过后将自动创建项目工程 自动创建的工程如下， 其中.pro文件是Qt的项目文件， src是自动生成的源文件 .vscode中是VsCode工程工作时必要的配置信息， scripts中是项目构建生成时的脚本， 其实VsCode编译器工程本质上是通过命令行执行这些脚本调用qmake进行工程编译和生成的。 若想要编译运行 第一种可通过先单击一个.cpp文件，后会在右上角出现运行符号，可直接点击也可下拉选择 第二种 Ctrl + Shift + P 输入run，选择运行生成任务 选择 debug或者release VsCode+QMake+MinGw 若是创建工程时选择MinGw作为构建套件，QMake作为构建工具则需要做一些修改 修改构建脚本 ./scripts/build_debug.bat 在创建脚本的时候自动生成的mingw32-make的路径是在D:\\Programs\\Qt\\5.15.2\\mingw81_64 下面，这可能是由于我这里是Qt5.15.2，它不在这个路径下而是D:\\Programs\\Qt\\Tools\\mingw810_64,读者请根据自身实际情况进行修改。 @echo off title qmake and nmake build prompt @REM 修改mingw32-make的路径 @REM set MINGW_PATH=D:\\Programs\\Qt\\5.15.2\\mingw81_64 set MINGW_PATH=D:\\Programs\\Qt\\Tools\\mingw810_64 set QT_DIR=D:\\Programs\\Qt\\5.15.2\\mingw81_64 set BUILD_DIR=%cd%\\build set PRO_DIR=%cd% set PATH=%MINGW_PATH%\\bin;%QT_DIR%\\bin;%PATH% if not exist %BUILD_DIR% ( md %BUILD_DIR% ) cd build qmake.exe %PRO_DIR%\\VsCodeQMakeMinGw.pro -spec win32-g++ “CONFIG+=debug” “CONFIG+=console” if exist %BUILD_DIR%\\debug\\VsCodeQMakeMinGw.exe del %BUILD_DIR%\\debug\\VsCodeQMakeMinGw.exe @REM D:\\Programs\\Qt\\Tools\\QtCreator\\bin\\jom.exe -j4 %MINGW_PATH%\\bin\\mingw32-make -f Makefile.Debug cd debug if not exist %BUILD_DIR%\\debug\\Qt5Core.dll ( windeployqt VsCodeQMakeMinGw.exe ) 修改运行配置文件./.vscode/launch.json 同样因为Qt不同版本的gbd.exe的调试器路径可能不同这样也需要做出一定修改否则会报错 修改gdb.exe路径即miDebuggerPath参数 { “version”: “0.2.0”, “configurations”: [ { “name”: “debug”, “type”: “cppdbg”, “request”: “launch”, “program”: “workspaceRoot/build/debug/VsCodeQMakeMinGw.exe&quot;,&quot;args&quot;:[],&quot;stopAtEntry&quot;:false,&quot;cwd&quot;:&quot;{workspaceRoot}/build/debug/VsCodeQMakeMinGw.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;workspaceRoot/build/debug/VsCodeQMakeMinGw.exe&quot;,&quot;args&quot;:[],&quot;stopAtEntry&quot;:false,&quot;cwd&quot;:&quot;{workspaceRoot}”, “environment”: [], “externalConsole”: false, “MIMode”: “gdb”, // 修改gdb路径 // “miDebuggerPath”: “D:/Programs/Qt/5.15.2/mingw81_64/bin/gdb.exe”, “miDebuggerPath”: “D:/Programs/Qt/Tools/mingw810_64/bin/gdb.exe”, “setupCommands”: [ { “description”: “Enable pretty-printing for gdb”, “text”: “-enable-pretty-printing”, “ignoreFailures”: true } ], “preLaunchTask”: “debug” } ] } 这时候编译运行应该能直接弹出Qt窗口了 VsCode+QMake+Msvc VsCode1.93.0 + Qt5.15.2 + Msvc2015 创建工程时选择Msvc作为构建套件，QMake作为构建工具时唯一需要注意的就是设置好 Qt Configure: Vcvarsall Path路径，在扩展配置中有说明。 若是配置没有问题直接编译运行应该就能看到弹出的Qt窗口了。 VsCode+CMake+MinGw VsCode1.93.0 + Qt5.15.2 + CMake3.28.0-rc3 + mingw81_64 在创建工程时选择MinGw作为构建套件，选择CMake作为构建工具。 构建生成运行 第一次运行时需要选择构建器 这里请选择QtBuild 同时需要修改 ./.vscode/launch.json文件，这样也是修改dgb的路径，请读者根据自身情况就行修改。 &#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;QtBuild&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;command:cmake.launchTargetPath&#125;&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot;, &quot;environment&quot;: [ &#123; &quot;name&quot;: &quot;PATH&quot;, &quot;value&quot;: &quot;D:/Programs/Qt/5.15.2/mingw81_64/bin&quot; &#125; ], &quot;externalConsole&quot;: false, // &quot;miDebuggerPath&quot;: &quot;D:/Programs/Qt/5.15.2/mingw81_64/bin/gdb.exe&quot; &quot;miDebuggerPath&quot;: &quot;D:/Programs/Qt/Tools/mingw810_64/bin/gdb.exe&quot; &#125; ] &#125; 对于CMake工程这里还有一种构建运行方式，且好像不用修改 launch.json文件。 项目运行效果 VsCode+CMake+Msvc VsCode1.93.0 + Qt5.15.2 + CMake3.28.0-rc3 + Msvc2015 在创建工程时选择Msvc作为构建套件，选择CMake作为构建工具。 只有第一次运行时需要选择对应的编译构建器，其它都与VsCode+CMake+MinGw一样。 构建生成运行 第一次运行时需要选择构建器 这里请选择QtBuild 运行效果如下 QtCreator+QMake+MinGw-&gt;VsCode Qt5.15.2 + QtCreator12.0.1 + VsCode1.93.0 + mingw81_64 特别说明：QtCreator和VsCode扩展（Qt Configure）自动创建的工程有些不同，但是都会依赖于pro文件，QMake是基于进行编译生成的 使用QtCreator创建一个以MinGw为构建套件，QMake为构建工具的工程，并将其转换为VsCode工程，并在VsCode中进行编辑编译并运行。（这里不再赘述QtCreator工程的创建） 这里进行说明一下，Qt工程文件是.pro文件，但VsCode并没有明确的工程文件只有工程的配置文件，通过我们前面的VsCode+QMake+MinGw可以知道其实VsCode只是将工程编译整合到脚本命令中了，编译时依然会使用.pro工程。 所以我们直接将VsCode+QMake+MinGw创建的.vscode和scripts 文件夹拷贝到QtCreator创建的工程，并用VsCode打开。 先修改./scripts/build_debug.bat脚本 这里是VsCode+QMake+MinGw工程创建的脚本进行修改的，可以对比着看。 最好不要使用中文，bat脚本有时候会因为编码问题导致运行不正常，可将其转换为ASCII编码，VsCode默认保存为UTF-8。 @echo off title qmake and nmake build prompt @REM set MINGW_PATH=D:\\Programs\\Qt\\5.15.2\\mingw81_64 set MINGW_PATH=D:\\Programs\\Qt\\Tools\\mingw810_64 set QT_DIR=D:\\Programs\\Qt\\5.15.2\\mingw81_64 @REM set BUILD_DIR=%cd%\\build set BUILD_DIR=%cd%..\\build-QtCreatorQMakeMinGw-Desktop_Qt_5_15_2_MinGW_64_bit set PRO_DIR=%cd% set PATH=%MINGW_PATH%\\bin;%QT_DIR%\\bin;%PATH% if not exist %BUILD_DIR% ( md %BUILD_DIR% ) cd %BUILD_DIR% qmake.exe %PRO_DIR%\\QtCreatorQMakeMinGw.pro -spec win32-g++ “CONFIG+=debug” “CONFIG+=console” if exist %BUILD_DIR%\\debug\\QtCreatorQMakeMinGw.exe del %BUILD_DIR%\\debug\\QtCreatorQMakeMinGw.exe @REM D:\\Programs\\Qt\\Tools\\QtCreator\\bin\\jom.exe -j4 %MINGW_PATH%\\bin\\mingw32-make -f Makefile.Debug cd debug if not exist %BUILD_DIR%\\debug\\Qt5Core.dll ( windeployqt %BUILD_DIR%\\debug\\QtCreatorQMakeMinGw.exe ) 再修改 ./.vscode/launch.json文件，设置运行文件路径 &#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;debug&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, // &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/build/debug/VsCodeQMakeMinGw.exe&quot;, &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/../build-QtCreatorQMakeMinGw-Desktop_Qt_5_15_2_MinGW_64_bit/debug/QtCreatorQMakeMinGw.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, // 修改gdb路径 // &quot;miDebuggerPath&quot;: &quot;D:/Programs/Qt/5.15.2/mingw81_64/bin/gdb.exe&quot;, &quot;miDebuggerPath&quot;: &quot;D:/Programs/Qt/Tools/mingw810_64/bin/gdb.exe&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125; ], &quot;preLaunchTask&quot;: &quot;debug&quot; &#125; ] &#125; 特别说明：Qt的.pro工程使用的是影子构建，所以这里是build-QtCreatorQMakeMinGw-Desktop_Qt_5_15_2_MinGW_64_bit，若是自定义构建输出路径，以及中间生成参数请，根据实际路径做修改。 项目构建编译运行参考，运行效果如下 QtCreator+QMake+Msvc-&gt;VsCode Qt5.15.2 + QtCreator12.0.1 + VsCode1.93.0 + msvc2015 使用QtCreator创建一个以Msvc为构建套件，QMake为构建工具的工程，并将其转换为VsCode工程，并在VsCode中进行编辑编译并运行。（这里不再赘述QtCreator工程的创建） 在QtCreator+QMake+MinGw-&gt;VsCode我们已经说明QtCreator到VsCode操作的基本原理，就不在进行说明了。 同样我们拷贝VsCode+QMake+Msvc工程创建的.vscode和scripts文件夹到QtCreator项目中。 修改./scripts/build_debug.bat脚本 这里是VsCode+QMake+Msvc工程创建的脚本进行修改的，可以对比着看。 @echo off set QT_DIR=D:\\Programs\\Qt\\5.15.2\\msvc2015_64 set SRC_DIR=%cd% @REM set BUILD_DIR=%cd%\\build set BUILD_DIR=%cd%..\\build-QtCreatorQMakeMsvc-Desktop_Qt_5_15_2_MSVC2015_64bit if not exist %QT_DIR% exit if not exist %SRC_DIR% exit if not exist %BUILD_DIR% md %BUILD_DIR% cd %BUILD_DIR% call “D:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat” x64 %QT_DIR%\\bin\\qmake.exe %SRC_DIR%\\QtCreatorQMakeMsvc.pro -spec win32-msvc “CONFIG+=debug” “CONFIG+=console” if exist %BUILD_DIR%\\debug\\QtCreatorQMakeMsvc.exe del %BUILD_DIR%\\debug\\QtCreatorQMakeMsvc.exe nmake Debug if not exist %BUILD_DIR%\\debug\\Qt5Cored.dll ( %QT_DIR%\\bin\\windeployqt.exe %BUILD_DIR%\\debug\\QtCreatorQMakeMsvc.exe ) 修改 ./.vscode/launch.json文件，设置运行文件路径 &#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;Launch&quot;, &quot;type&quot;: &quot;cppvsdbg&quot;, &quot;request&quot;: &quot;launch&quot;, // &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/build/debug/VsCodeQMakeMsvc.exe&quot;, &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/../build-QtCreatorQMakeMsvc-Desktop_Qt_5_15_2_MSVC2015_64bit/debug/QtCreatorQMakeMsvc.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot;, &quot;environment&quot;: [], &quot;console&quot;: &quot;integratedTerminal&quot;, &quot;preLaunchTask&quot;: &quot;debug&quot; &#125; ] &#125; 项目构建编译运行参考，运行效果 QtCreator+CMake+MinGw-&gt;VsCode Qt5.15.2 + QtCreator12.0.1 + VsCode1.93.0 + CMake3.28.0-rc3 + mingw81_64 使用QtCreator创建以MinGw为构建套件，CMake为构建工具的项目，并使用VsCode打开 运行 选择对应编译器（第一次时选择），会自动编译生成项目。 再次点击运行，会选择启动目标，一般是第一个。（这里没有截到图可参考QtCreator+CMake+Msvc-&gt;VsCode） 运行效果 QtCreator+CMake+Msvc-&gt;VsCode Qt5.15.2 + QtCreator12.0.1 + VsCode1.93.0 + CMake3.28.0-rc3 + msvc2015 使用QtCreator创建以Msvc为构建套件，CMake为构建工具的项目，并使用VsCode打开 点击运行，选择对应编译器（第一次时选择），会自动编译生成项目。 再次点击运行，会选择启动目标，一般是第一个。 运行效果 脚本和配置的通用化 VsCode+QMake 优化脚本，适配从QtCtrator创建的工程，适合使用Qt影子构建生成的构建路径。 只需要设置编译器路径，编译debug还是release，工程名称TARGET_NAME，以及当前编译器是否是Msvc @echo off title qmake and nmake build prompt set TARGET_NAME=VsCodeQMake set BUILD_NAME=debug set IS_MSVC=1 if %IS_MSVC%==1 ( set QT_DIR=D:\\Programs\\Qt\\5.15.2\\msvc2015_64 ) else ( set QT_DIR=D:\\Programs\\Qt\\5.15.2\\mingw81_64 ) set PRO_DIR=%cd% for %%A in (“%QT_DIR%”) do (set “QT_KIT_NAME=%%~nxA”) for %%A in (“%QT_DIR%..”) do (set “QT_VERSION=%%~nxA”) set “QT_VERSION=%QT_VERSION:.=_%” echo %QT_KIT_NAME%| findstr /i “msvc”&gt;nul if errorlevel 1 ( set QT_KIT_STR=MinGW set IS_MSVC=0 ) else ( set QT_KIT_STR=%QT_KIT_NAME:~0,-3% set IS_MSVC=1 for %%i in (A B C D E F G H I J K L M N O P Q R S T U V W X Y Z) do call set QT_KIT_STR=%%QT_KIT_STR:%%i=%%i%% ) echo %QT_KIT_NAME%| findstr /i “64” &gt;nul if errorlevel 1 ( set BIT_STR=32bit) else ( set BIT_STR=64bit) set QT_KIT_STR=Desktop_Qt_%QT_VERSION%%QT_KIT_STR%%BIT_STR% set BUILD_DIR=%PRO_DIR%/…/build-%TARGET_NAME%-%QT_KIT_STR% set FIRST_CHAR=%BUILD_NAME:~0,1% for %%i in (A B C D E F G H I J K L M N O P Q R S T U V W X Y Z) do call set FIRST_CHAR=%%FIRST_CHAR:%%i=%%i%% set BUILD_NAME_U=%FIRST_CHAR%%BUILD_NAME:~1% if not exist “%QT_DIR%” exit if not exist “%PRO_DIR%” exit if not exist “%BUILD_DIR%” ( md “%BUILD_DIR%” ) if %BUILD_NAME%==“debug”( set CONFIG_STR=“CONFIG+=%BUILD_NAME%” “CONFIG+=console”) else(set CONFIG_STR=“CONFIG+=%BUILD_NAME%”) cd “%BUILD_DIR%” if %IS_MSVC%==1 ( goto build_msvc) else ( goto build_mingw) :build_msvc call “D:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat” x64 %QT_DIR%\\bin\\qmake.exe %PRO_DIR%%TARGET_NAME%.pro -spec win32-msvc %CONFIG_STR% set TARGET_NAME_ALL=%BUILD_DIR%%BUILD_NAME%%TARGET_NAME%.exe if exist “%TARGET_NAME_ALL%” del “%TARGET_NAME_ALL%” nmake %BUILD_NAME_U% goto end :build_mingw set MINGW_PATH=%QT_DIR%....\\Tools%QT_KIT_NAME:0,7%0%QT_KIT_NAME:-3% set PATH=%MINGW_PATH%\\bin;%QT_DIR%\\bin;%PATH% %QT_DIR%\\bin\\qmake.exe %PRO_DIR%%TARGET_NAME%.pro -spec win32-g++ %CONFIG_STR% set TARGET_NAME_ALL=%BUILD_DIR%%BUILD_NAME%%TARGET_NAME%.exe if exist “%TARGET_NAME_ALL%” del “%TARGET_NAME_ALL%” @REM D:\\Programs\\Qt\\Tools\\QtCreator\\bin\\jom.exe -j4 %MINGW_PATH%\\bin\\mingw32-make -f Makefile.%BUILD_NAME_U% goto end :end if not exist %BUILD_DIR%%BUILD_NAME%\\Qt5Cored.dll ( %QT_DIR%\\bin\\windeployqt.exe “%TARGET_NAME_ALL%” )","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"weixin_49500446"},{"title":"python包管理神器【uv】详解","slug":"Python/python包管理神器【uv】详解","date":"2025-08-13T08:37:10.000Z","updated":"2025-08-13T09:20:44.544Z","comments":true,"path":"2025/08/13/Python/python包管理神器【uv】详解/","link":"","permalink":"http://www.formeasy.cc/2025/08/13/Python/python%E5%8C%85%E7%AE%A1%E7%90%86%E7%A5%9E%E5%99%A8%E3%80%90uv%E3%80%91%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"1 uv简介与安装 1.1 uv作用 由Rust编写。作用：管理python版本、管理项目、管理包等作用。 原话：🚀 A single tool to replace pip, pip-tools, pipx, poetry, pyenv, twine, virtualenv, and more. 特点：快。 官网文档：https://docs.astral.sh/uv/ ！！注：uv工具.zip包含: uv.exe, uvx.exe, uvw.exe 1.2 安装 方式一：github/release页下载。 https://github.com/astral-sh/uv/releases选择符合系统的版本下载并解压。 添加下载路径到环境变量（win+q后输入环境变量，环境变量） 该方式后续更新，下载新版本，解压覆盖。 方式二：命令行安装(win) 1powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot; 该方式后续更新，终端运行： 1uv self update 方式三：pypi安装 pipx install uv或pip install uv。建议用pipx 更新：pip install --upgrade uv 确认安装成功 输入uv self version，显示版本信息即完成。 1.3 卸载 清缓存uv cache clean 删除%localappdata%/uv、%appdata%/uv、%userprofile%/.local 1.4 相关环境变量 #1.2安装中仅设置了uv的环境变量。 而通过uv安装的工具/python时，可能会生成一个.exe文件供uv使用。为了让uv能找到他自己下载工具时生成的.exe文件，需要将%userprofile%/.local/bin加入环境变量。 ！可选(推荐): 设置环境变量UV_PYTHON_INSTALL_BIN=false：用uv安装python时不生成额外的python.exe。 不使用uv tool install安装工具，而是用uvx 工具 工具参数，这会将工具安装到缓存位置，默认为%localappdata%/uv/cache。可通过UV_CACHE_DIR修改位置。 (uvx为uv tool run别名) 遵循以上两点，可以不设置%userprofile%/.local/bin环境变量 2 命令帮助 1234uvuv helpuv 命令 --helpuv help 命令 均可，遇到不会的命令可随时使用以上来查看提示信息。 3 uv管理python版本 ！！注： 默认安装&amp;管理路径%appdata%/uv/python 可通过环境变量UV_PYTHON_INSTALL_DIR修改python安装的位置 可通过命令uv python dir查看python安装目录。输出结果等于以上变量UV_PYTHON_INSTALL_DIR 3.1 uv python list列出版本 列出当前的python版本。 12345# 列出当前【已安装】的python版本uv python list --only-installed# 列出【可安装】的python版本uv python list --only-downloads 3.2 uv python install安装python 123456789101112#安装最新版python，如果已安装有python(无论是否最新)，则不运行。uv python install# 安装3.13版本python(默认CPython)uv python install 3.13# 安装3.10版本pypyuv python install pypy@3.10# 同时安装多个版本python, 用空格分隔uv python install 3.11 pypy@3.10 cpython@3.7# 会同时安装cpython3.11 pypy3.10 cpython3.7三个版本。 卸载就是把install换成uninstall，略。 3.3 全局参数:uv python --参数 所有uv python [命令]都接受的参数： 1234# 仅显示uv管理的python版本，不显示系统安装的python版本。uv python [命令] --managed-python# 和上一个相反。仅显示系统安装版本。uv python [命令] --no-managed-python 4 uv运行单个脚本 4.1 uv run .py文件 以指定版本python运行.py文件 123456789# 以默认python运行start.pyuv run start.py# 以指定版本python运行.py文件uv run -p 3.12 start.py#如果py文件包含自带标准库以外的库，则需额外添加参数#以requests（第三方包）为例：uv run --with requests app.py uv会先下载flask库，然后运行app.py。库会下载到uv cache dir位置，默认为%localappdata%/uv/cache 4.2 uv init --script 创建example.py脚本 12345# 创建以py3.12运行的脚本example.pyuv init --script example.py --python 3.12# 如果脚本中需要引入第三方库&#x27;requests&#x27; 和 &#x27;rich&#x27;：uv add --script example.py &#x27;requests&lt;3&#x27; &#x27;rich&#x27; example.py开头会自动包含以下： 4.3 uv lock --script 锁定依赖 12# 锁定脚本example.py的依赖uv lock --script example.py 运行后，会创建同名.lock文件。锁定之后，如果再次运行uv add --script``uv remove --script等命令，.lock文件可能会同样跟新。 5 uv管理项目 通过pycharm可简化5.1, 5.2两步 5.1 初始化项目 12345# 创建名为`auto`的文件夹并初始化uv init auto# 初始化当前目录uv init uv init audo = 创建auto文件夹 + 进入auto文件夹 + 在auto内运行uv init 初始化后包含文件： 12345·├── .python-version├── README.md├── main.py└── pyproject.toml 5.2 添加虚拟环境 在项目内，运行uv run、uv lock、uv sync等命令时，会自动创建uv.lock、.venv文件 12345678910.├── .venv│ ├── bin│ ├── lib│ └── pyvenv.cfg├── .python-version├── README.md├── main.py├── pyproject.toml└── uv.lock pycharm新建项目时选择uv，自动创建.venv和pyproject.toml 5.3 项目文件 pyproject.toml 官方文档：https://packaging.python.org/en/latest/guides/writing-pyproject-toml/ 包含项目相关配置数据。 .python-version .python-version文件包含项目的默认Python版本。该文件告诉uv在创建项目虚拟环境时使用哪个Python版本。 .venv 虚拟环境，项目安装依赖所在目录 uv.lock uv.lock是一个跨平台的锁定文件，它包含关于您项目依赖关系的精确信息。与用于指定项目广泛需求的pyproject.toml不同，锁定文件包含在项目环境中安装的确切解析版本。此文件应提交到版本控制中，以便在不同机器上实现一致且可重现的安装。由uv管理，不应手动编辑。 该文件仅由uv使用，其他工具无法使用。 pylock.toml 在PEP 751(点击跳转)中，Python标准化了一种新的解析文件格式，即pylock.toml。 pylock.toml是一种旨在替代requirements.txt（例如，在uv pip compile的上下文中，从一组输入要求生成一个锁定的requirements.txt文件）的解析输出格式。pylock.toml是标准化的且与工具无关，因此在未来，由uv生成的pylock.toml文件可以被其他工具安装，反之亦然。 uv的一些功能无法以pylock.toml格式表达；因此，uv将继续在项目接口内使用uv.lock格式。 然而，uv支持将pylock.toml作为导出目标以及在uv pip CLI中使用。例如： 要将uv.lock导出为pylock.toml格式，运行：uv export -o pylock.toml 要从一组要求生成pylock.toml文件，运行：uv pip compile -o pylock.toml -r requirements.in 要从pylock.toml文件安装，运行：uv pip sync pylock.toml或uv pip install -r pylock.toml 5.4 安装依赖 uv add 安装包 12345678910111213141516uv add 库名# 使用指定版本的库uv add &#x27;requests==2.31.0&#x27;# 从git仓库导入库uv add git+https://github.com/psf/requests# 指定链接导入。支持后缀：&#x27;.tar.gz&#x27; 、 &#x27;.whl&#x27; 、 &#x27;.zip&#x27;等uv add &quot;https://files.pythonhosted.org/packages/5c/2d/3da5bdf4408b8b2800061c339f240c1802f2e82d55e50bd39c5a881f47f0/httpx-0.27.0.tar.gz&quot;# 本地其他路径导入库。支持后缀同上。绝对路径和相对路径均可。uv add /myPagePath/good-0.1.0.whl# 以requirments.txt文件批量下载uv add -r requirments.txt 作用：下载依赖项、同时更新uv.lock、pyproject.toml。 强烈不建议使用uv pip install！！！ uv add=uv pip install + 编辑pyproject.toml + 编辑uv.lock uv pip list 列举已安装的包 uv tree 树状图显示项目依赖关系 uv remove 作用：删除依赖项、同时更新uv.lock、pyproject.toml。 uv lock --upgrade更新包 12345678# 更新指定包到兼容的最新版本，同时不影响其他包uv lock --upgrade-package requests# 更新多个包uv lock --upgrade-package 包1 --upgrade-package 包2# 更新全部uv lock --upgrade 尝试将指定的包更新到最新兼容版本，同时保留锁定文件的其余部分不变。 uv sync 根据当前项目的依赖配置（如 pyproject.toml 和 uv.lock 文件）同步更新虚拟环境.venv 激活虚拟环境 要在项目中运行脚本和命令而不使用uv run，必须激活虚拟环境。虚拟环境的激活因shell和平台而异。 bash: 12source .venv\\Scripts\\activateflask --app main run -p 3000 powershell: 12./.venv/scripts/activate.ps1flask --app main run -p 3000 cmd 12.venv\\Scripts\\activate.batflask --app main run -p 3000 5.5 利用虚拟环境中python运行脚本 uv run python 某某.py 前提：存在目录.venv 123456789101112131415# 运行指定命令uv run python -c &#x27;import sys;print(sys.executable)&#x27;# 输出：D:\\Python\\Project\\auto\\.venv\\Scripts\\python.exe。# ！可见确实用的虚拟环境中的解释器# 运行指定脚本uv run python main.py# 如果临时运行一个脚本，脚本中有还包含【未安装的包】uv run --with httpx==0.26.0 python -c &quot;import httpx,sys; print(httpx.__version__);print(sys.executable)&quot;# 输出：0.26.0# 输出：C:\\Users\\myuer\\AppData\\Local\\uv\\cache\\archive-v0\\AvKaefqT2QIDzAksSYIBH\\Scripts\\python.exe# ！--with参数会临时创建一个【额外】的隔离环境。不在.venv中 uv.lock 锁文件 运行uv run时，uv会自动更新uv.lock文件并更新环境(即自动运行uv lock+uv sync) 如果uv.lock文件不是最新的(即pyproject.toml中手动添加了一个依赖，但uv.lock未添加)，则会返回错误，而不是自动更新uv.lock 1uv lock --check 检查锁文件是否最新(是否与pyproject.toml同步) 1uv lock 更新锁文件uv.lock。 uv sync 虚拟环境会自动更新。也可以手动运行命令uv sync来更新环境。 锁文件是非常精确地：如果环境中存在uv.lock文件中列表以外的包，将会被删除。如果要保留多余的软件包，添加参数--inexact 12# 更新环境，但保留已存在的多余的包(不在uv.lock描述中的包)uv sync --inexact 导出依赖为通用格式 12345678910# 将uv.lock导出为requirements.txt格式，并保存到re.txt文件uv export --format requirements.txt -o re.txt# 如果存在-o保存到文件选项，可简写uv export -o re.txt# 将uv.lock导出为pylock.toml格式，并保存到pylock.toml文件uv export --format pylock.toml -o pylock.toml# 如果存在-o保存到文件选项，可简写uv export -o pylock.toml 官方文档引用(点击跳转)：生成的requirements.txt文件可以通过uv pip install安装，也可以使用其他工具如pip来安装。 一般来说，我们不建议同时使用uv.lock和requirements.txt文件。如果您发现自己正在导出uv.lock文件，请考虑开一个issue来讨论您的用例。 6 构建 1uv build uv构建可用于为您的项目构建源分发和二进制分发（wheel）。 默认情况下，uv构建将在当前目录中构建项目，并将构建的工件放置在dist/子目录中。 略。 在发布软件包时，我们建议运行 uv build --no-sources 以确保在禁用 tool.uv.sources（例如使用其他构建工具，如 pypa/build）的情况下软件包能够正确地构建。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":"qq_63365915"},{"title":"Python 环境管理新标杆：UV核心命令完全指南","slug":"Python/Python 环境管理新标杆：UV核心命令完全指南","date":"2025-08-13T08:30:15.000Z","updated":"2025-08-13T09:26:09.026Z","comments":true,"path":"2025/08/13/Python/Python 环境管理新标杆：UV核心命令完全指南/","link":"","permalink":"http://www.formeasy.cc/2025/08/13/Python/Python%20%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E6%96%B0%E6%A0%87%E6%9D%86%EF%BC%9AUV%E6%A0%B8%E5%BF%83%E5%91%BD%E4%BB%A4%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"UV工具定位：极速Python环境管理 UV是Astral团队开发的下一代Python环境管理工具，其核心优势在于： ⚡ 速度革命：依赖解析比pip快10-100倍 🪶 轻量设计：环境创建仅需0.05秒 🔒 安全可靠：内置依赖锁定机制 🔄 无缝迁移：兼容现有pip工作流 安装命令：pipx install uv（推荐）或 pip install uv 核心命令详解手册 1. uv venv：闪电环境创建 功能：创建轻量级虚拟环境 1234567891011# 基础用法（默认创建.venv）uv venv# 指定Python版本uv venv --python 3.11# 包含系统包（类似--system-site-packages）uv venv --system# 自定义路径uv venv --path ~/envs/project-env 环境结构： 12345678.venv/├── bin # Unix可执行文件│ ├── python│ ├── pip├── Scripts # Windows可执行文件│ ├── python.exe│ ├── pip.exe└── pyvenv.cfg # 环境配置文件 2. uv pip：极速依赖管理 功能：高性能依赖安装与解析 1234567891011121314151617# 安装单个包uv pip install numpy# 批量安装uv pip install pandas matplotlib seaborn# 安装指定版本uv pip install &quot;django&gt;=4.0,&lt;5.0&quot;# 从requirements安装uv pip install -r requirements.txt# 生成锁定文件uv pip compile pyproject.toml -o requirements.lock# 哈希验证安装（安全部署）uv pip install -r requirements.lock --generate-hashes 性能对比： 1传统pip: 23.5秒 | UV pip: 1.8秒 (相同依赖集) 3. uv run：智能脚本执行 功能：在UV环境中无缝运行命令 1234567891011121314# 运行Python脚本uv run app.py# 传递参数uv run train_model.py --epochs 50 --batch-size 32# 执行模块uv run -m pytest tests/# 临时环境运行（自动清理）uv run --temp &quot;import sys; print(sys.executable)&quot;# 指定环境运行uv run --venv dev-env manage.py migrate 4. uv python：解析器管理 功能：Python解释器版本管理 1234567891011121314# 列出所有可用Pythonuv python list# 输出示例：Available Pythons:* /usr/bin/python3.12 (default) /opt/homebrew/bin/python3.11 ~/.pyenv/versions/3.10.9/bin/python# 设置默认Python版本uv use 3.11# 验证版本uv python --version 5. uv cache：缓存优化 功能：管理依赖缓存加速安装 1234567891011# 查看缓存信息uv cache info# 清理所有缓存uv cache clean --all# 保留最近3个版本的缓存uv cache clean --keep-latest 3# 指定缓存目录uv cache dir ~/custom_uv_cache 6. uv use：版本切换 功能：动态切换Python版本 123456789101112# 查看当前版本uv use current# 切换到3.10uv use 3.10# 全局设置默认版本uv use --global 3.11# 项目级版本配置（pyproject.toml）[tool.uv]python = &quot;3.11&quot; # 固定版本 7. uv init：项目初始化 功能：一站式项目初始化 1234567891011# 交互式创建项目uv init# 指定Python版本uv init --python 3.11# 创建并安装依赖uv init --install# 完整初始化流程uv init --python 3.11 --name my-project --install 自动生成： 虚拟环境 .venv 基础 requirements.txt 项目结构模板 综合应用示例 场景：创建Django项目 1234567891011# 1. 初始化项目uv init --python 3.11 --name django-project --install# 2. 安装依赖uv pip install django gunicorn psycopg2# 3. 创建Django项目uv run django-admin startproject core .# 4. 启动开发服务器uv run python manage.py runserver 提示：需要通过uv run创建.venv虚拟目录环境后才能使用uv pip install 场景：CI/CD流水线 .gitlab-ci.yml配置： 12345678910test: script: - pipx install uv # 安装UV - uv venv - uv pip install -r requirements.txt - uv run pytest tests/ cache: paths: - .venv/ - ~/.cache/uv/ 命令速查表 命令 功能 高频参数 uv venv 创建环境 --name --python --system uv pip 包管理 install compile --generate-hashes uv run 执行命令 --temp --venv -m uv python 解释器管理 list --version uv cache 缓存管理 info clean dir uv use 版本切换 current 3.11 --global uv init 项目初始化 --python --install --name 提示：所有命令支持 --help 查看详细帮助，如 uv venv --help 命项目实战 1234567891011121314151617181920# 项目初始化uv init# 创建虚拟环境uv venv# 指定 Python 版本uv venv --python 3.12# 激活环境.venv\\Scripts\\activate# 添加依赖（会更新 pyproject.toml）uv add flask# 可选：添加开发依赖（如调试工具）uv add --dev flask-debugtoolbar # 开发环境用的调试工具栏# 同步项目依赖uv sync 在项目根目录修改 main.py 文件，写入基础代码 1234567891011from flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;)def hello(): return &quot;Hello, Flask with uv!&quot;if __name__ == &#x27;__main__&#x27;: app.run(debug=True) # 调试模式，代码修改后自动重启 运行 Flask 项目 方法 1：直接通过 Python 执行 12# 运行 Flask 应用python main.py 方法 2：使用 uv run 直接运行（无需手动激活环境） 1uv run main.py 方法 3：使用flask命令运行 1flask --app main run -p 5000 最佳实践总结 环境创建：项目根目录使用默认 .venv 依赖安装：优先 uv pip compile 生成锁定文件 版本控制：项目内配置 pyproject.toml 固定版本 CI/CD优化：复用UV缓存目录加速构建 多项目管理：--name 参数区分不同环境 通过掌握这7大核心命令，您将彻底掌控Python环境管理，实现开发效率的指数级提升！访问官方文档获取最新功能。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":"weixin_63779518"},{"title":"QtCreator使用Qode插件接入外部AI大模型","slug":"Qt/QtCreator使用Qode插件接入外部AI大模型","date":"2025-07-30T06:05:37.000Z","updated":"2025-07-30T06:18:04.887Z","comments":true,"path":"2025/07/30/Qt/QtCreator使用Qode插件接入外部AI大模型/","link":"","permalink":"http://www.formeasy.cc/2025/07/30/Qt/QtCreator%E4%BD%BF%E7%94%A8Qode%E6%8F%92%E4%BB%B6%E6%8E%A5%E5%85%A5%E5%A4%96%E9%83%A8AI%E5%A4%A7%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"QodeAssist：AI智能编码助手，提升Qt Creator开发效率QodeAssist 是一款针对 Qt Creator 的 AI 智能编码助手插件，它通过集成大型语言模型，如 Ollama，提供智能代码补全和提示功能，帮助开发者提升编码效率。以下是关于 QodeAssist 项目的详细介绍。项目介绍QodeAssist 是一款为 Qt Creator 开发环境设计的 AI 编码助手插…_qtcreator ai代码助手 QodeAssist介绍：AI智能编码助手，提升Qt Creator开发效率 QodeAssist 是一款针对 Qt Creator 的 AI 智能编码助手插件，它通过集成大型语言模型，如 Ollama，提供智能代码补全和提示功能，帮助开发者提升编码效率。以下是关于 QodeAssist 项目的详细介绍。 插件介绍 QodeAssist 是一款为 Qt Creator 开发环境设计的 AI 编码助手插件。它通过利用本地提供的大型语言模型，如 Ollama，为 C++ 和 QML 提供智能代码补全和建议。这款插件能够直接在 Qt 开发环境中提供上下文感知的 AI 辅助，从而极大地提升开发者的编码效率。 插件技术分析 QodeAssist 插件的核心技术包括： 智能代码补全：利用大型语言模型，如 Ollama，提供智能的代码补全和代码建议。 聊天功能：支持在侧边栏和底部面板中与语言模型进行对话，实现代码分析和问题解决。 多模型支持：插件支持多种语言模型提供商，包括 Ollama、llama.cpp、OpenAI、Anthropic Claude、LM Studio、Mistral AI、Google AI 以及其他 OpenAI 兼容服务。 插件及技术应用场景 QodeAssist 适用于以下场景： Qt Creator 开发环境：插件专为 Qt Creator 设计，能够无缝集成到开发环境中，为开发者提供实时的代码辅助。 代码效率提升：通过智能代码补全和建议，开发者可以减少编码时间，提高开发效率。 代码质量优化：插件提供的代码建议可以帮助开发者写出更高质量、更易于维护的代码。 插件特点 QodeAssist 项目的特点包括： 智能代码补全：提供实时的代码补全和代码建议，减少编码错误。 多模型支持：支持多种语言模型提供商，为开发者提供灵活的选择。 易于配置：插件提供了简单的配置界面，开发者可以根据自己的需求选择模型和设置参数。 高度集成：与 Qt Creator 环境无缝集成，无需额外设置。 丰富的功能：包括聊天功能、代码分析、自动同步编辑器文件等丰富功能。 以下是关于 QodeAssist 项目的详细说明： 智能代码补全 QodeAssist 通过集成大型语言模型，提供智能的代码补全和代码建议，帮助开发者减少编码错误，提升编码速度。插件支持多行代码补全，使开发者能够更加高效地编写代码。 聊天功能 插件支持在 Qt Creator 的侧边栏和底部面板中与语言模型进行聊天，实现代码分析和问题解决。开发者可以通过聊天界面获取代码建议、解决问题，并支持聊天历史的自动保存和恢复。 多模型支持 QodeAssist 支持多种语言模型提供商，包括 Ollama、llama.cpp、OpenAI、Anthropic Claude、LM Studio、Mistral AI、Google AI 以及其他 OpenAI 兼容服务。开发者可以根据自己的需求和偏好选择合适的模型。 易于配置 插件提供了简单的配置界面，开发者可以在 Qt Creator 的设置中轻松配置模型提供商和参数。例如，以下是配置 Ollama 的步骤： 安装 Ollama 并运行指定的语言模型。 在 Qt Creator 的 QodeAssist 设置中，选择 Ollama 作为 LLM 提供商，并设置对应的 URL 和模型。 高度集成 QodeAssist 与 Qt Creator 环境无缝集成，开发者无需进行复杂的设置即可使用插件。 丰富的功能 除了智能代码补全和聊天功能，QodeAssist 还提供了自动同步编辑器文件、代码上下文分析等丰富功能，进一步优化开发者的编码体验。 总结而言，QodeAssist 是一款强大的 AI 编码助手插件，能够显著提升 Qt Creator 开发者的编码效率。通过集成多种语言模型和提供丰富的功能，QodeAssist 成为 Qt 开发者的必备工具。 一、概要 本篇文章主要通过让QtCreator接入外部AI插件，实现在QtCretor里调用AI模型完成代码自动补全（Code Completion）和聊天助手（Chat Assistant）的目的。下面是需要操作的工具列表。 Qt版本：Qt5.14.2（自带QtCreator4.11.1，但是这里不用它） QtCreator版本：QtCreator17.0.0（独立安装程序 AI插件：QodeAssist项目 二、安装Qt5.14.2，配置高版本QtCreator 访问： Qt5.14.2使用高版本QtCreator 三、下载AI插件 访问：QodeAssist Releases 可以直接下载最新版本的插件，记的选择和自己安装的QtCreator一致的版本，这里选择QodeAssist-v0.6.0-QtC17.0.0-Windows-x64.7z。 下载解压后，里面会有按照QtCreator插件路径创建的lib文件夹，把它放到安装QtCreator17时所选择的文件夹下，一般是C:\\Qt\\qtcreator-17.0.0。 四、配置插件 4.1、AI大模型设置 前面几步操作完成后，打开QtCreator17.0.0=&gt;编辑=&gt;Preferences，找到QodeAssist，如下图配置。配置后在Provider Settings一栏中填上对应模型的API Key即可，非常简单。大家可以根据自己的需求和模型自定义。 4.2、自动补全配置 打开Code Completion选项，如下图： QodeAssist的自动补全配置分为以下几个主要类别（按界面布局排布），附上个人建议供参考： 自动补全基础设置 Enable Auto Complete (autoCompletion): 启用或禁用自动补全功能的主开关 Enable Multiline Completion (multiLineCompletion): 允许生成跨多行的代码补全建议【建议】 Enable stream option (stream): 启用流式响应，让补全结果逐步显示【建议】 Enable smart process text from instruct model (smartProcessInstuctText): 智能处理指令模型的文本输出，如果不设置返回结果大概率会以注释开头。【建议】 AI suggestion triggers after typing (autoCompletionCharThreshold): 设置触发AI建议所需的字符数量（0-10个字符） character(s) within(ms) (autoCompletionTypingInterval): 设置字符阈值必须在多长时间窗口内满足（500-5000毫秒） with delay(ms) (startSuggestionTimer): 设置建议显示的延迟时间（10-10000毫秒） Show progress indicator during code completion: 在代码补全过程中显示进度指示器 Include context from open files: 在补全时包含打开文件的上下文【不建议】 模型参数设置 基础参数： Temperature: 控制生成文本的随机性（0.0-2.0，默认0.2） Max Tokens: 设置生成的最大token数量（-1到900000，默认100） 高级参数： Top P: 核采样参数，控制候选词汇的累积概率（0.0-1.0） Top K: 限制候选词汇数量（1-1000） Presence Penalty: 存在惩罚，减少重复内容（-2.0到2.0） Frequency Penalty: 频率惩罚，进一步控制重复（-2.0到2.0） 上下文设置 Read Full File: 读取完整文件内容作为上下文【不建议】 Read Strings Before Cursor: 设置光标前读取的行数（0-10000行，默认50行） Read Strings After Cursor: 设置光标后读取的行数（0-10000行，默认30行） 提示词设置 这项设置取决你使用的模型是否为FIM模型。 Use System Prompt: 启用系统提示词 System Prompt: 为FIM模型配置的系统提示词 Use special system prompt and user message for non FIM models: 为非FIM模型使用特殊的提示词模板 Max Changes Cache Size: 项目变更缓存的最大大小（2-1000，默认10）【不建议】 Additional Programming Languages: 添加自定义编程语言支持 Quick Refactor Settings（快速重构设置） Quick Refactor Settings是专门为快速重构功能配置的设置组，包含以下选项： Include context from open files in quick refactor (useOpenFilesInQuickRefactor): 在快速重构时包含打开文件的上下文信息 Quick Refactor System Prompt (quickRefactorSystemPrompt): 专门为快速重构功能配置的系统提示词，默认内容为专业的C++、Qt和QML代码补全助手提示 Ollama Settings（Ollama设置） Ollama Settings是专门为Ollama提供商配置的设置组，包含以下选项： Livetime (ollamaLivetime): 控制Ollama在完成请求后保持活跃的时间（以分钟为单位），设置为-1可禁用此功能，默认值为&quot;5m&quot; Context Window (contextWindow): 设置Ollama的上下文窗口大小，范围为-1到10000，默认值为2048 4.3、聊天助手配置 打开Chat Assistant设置页面，如下图： QodeAssist的聊天助手配置分为以下几个主要类别（按界面布局排布）： Chat Settings（聊天设置） Chat history token limit (chatTokensThreshold): 聊天历史记录的token限制，当超过此限制时会移除最旧的消息，范围1-99999999，默认值20000 Sync open files with assistant by default (linkOpenFiles): 默认情况下与助手同步所有打开的文件，默认值false【不建议】 Enable stream option (stream): 启用流式响应选项，让回复逐步显示，默认值true Enable autosave when message received (autosave): 收到消息时启用自动保存功能，默认值true General Parameters（基础参数） Temperature: 控制生成文本的随机性和创造性，范围0.0-2.0，默认值0.5 Max Tokens: 设置生成响应的最大token数量，范围-1到10000，默认值2000 Advanced Parameters（高级参数） Top P: 核采样参数，控制候选词汇的累积概率，范围0.0-1.0，默认值0.9，需要先启用才能使用 Top K: 限制候选词汇数量，范围1-1000，默认值50，需要先启用才能使用 Presence Penalty: 存在惩罚参数，减少重复内容的生成，范围-2.0到2.0，默认值0.0 Frequency Penalty: 频率惩罚参数，进一步控制重复内容，范围-2.0到2.0，默认值0.0 Context Settings（上下文设置） Use System Prompt: 启用系统提示词功能，默认值true System Prompt: 配置聊天助手的系统提示词，默认为专业的C++、Qt和QML开发AI助手提示 Ollama Settings（Ollama设置） Livetime: 控制Ollama在完成请求后保持活跃的时间（分钟），设置为-1可禁用，默认值&quot;5m&quot; Context Window: 设置Ollama的上下文窗口大小，范围-1到10000，默认值2048 Chat Settings（聊天设置） Text Font: 设置聊天界面文本的字体家族，从系统可用字体中选择，默认为系统字体 Text Font Size: 设置文本字体大小，默认为系统字体大小 Code Font: 设置代码块的字体家族，默认为等宽字体 Code Font Size: 设置代码字体大小，默认为系统字体大小 Text Format: 设置文本格式显示方式，可选择Markdown、HTML或纯文本，默认为Markdown 结尾 根据上述提示设置后即可使用，如果有开启日志选项，可以在QtCreator底部概要信息内查看；如果想使用自动补全，又没有开启自动补全设置，可以通过快捷键Ctrl Alt Q或者右键菜单开启；如果想使用聊天助手，在底部QodeAssist Chat查看，如下图。 结束。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"fjunchao"},{"title":"Qt5.14.2使用高版本QtCreator","slug":"Qt/Qt5.14.2使用高版本QtCreator","date":"2025-07-30T03:02:56.000Z","updated":"2025-07-30T03:13:42.170Z","comments":true,"path":"2025/07/30/Qt/Qt5.14.2使用高版本QtCreator/","link":"","permalink":"http://www.formeasy.cc/2025/07/30/Qt/Qt5.14.2%E4%BD%BF%E7%94%A8%E9%AB%98%E7%89%88%E6%9C%ACQtCreator/","excerpt":"","text":"1、安装Qt5.14.2 5.14.2是提供离线安装包的最后一个版本，它安装时是默认配上Qt Creator 4.11.1版本的。这个版本的QtCreator无法取消，不过占用空间不大，后续也不会用到它。按下面选项安装 2、安装QtCreator 1、获取最新版QtCreator 访问Qt官方网站， 下载对应环境版本，本人用的是Windows10 x64环境。另外，在线安装需要登录个人账号，这个要在Qt官网上提前注册。安装器下载成功后，启动并登录个人账号，快速进入安装选项。安装过程中，除了自定义那一步，其他时候能勾上的选项尽量都勾上。 2、安装选项 安装选项里，Qt会提供默认的安装配置，选择你想要的模式进行安装，然后一直下一步即可。本人只需要安装QtCreator，所以没有选择安装器推荐的开发工具选项，而是自定义。先选择顶部的无把所有选中取消，然后单独选择Qt Creator中的Qt Creator 16.0.2安装。 如果在出现了类似 主机XX没有找到 的报错，先是在安装器的设置处选择清除缓存。 清除缓存后重试仍然报错：“https://mirrors.sau.edu.cn/qt/online/qtsdkrepository/all_os/unified_patching/2023-11-21-1039_meta.7z”时出现网络错误：主机 mirrors.sau.edu.cn 没有找到。 此时需要第二种方案，换源重新安装，推荐使用清华大学的源：https://mirrors.tuna.tsinghua.edu.cn/qt/，具体操作方案： 1、打开安装程序所在文件夹，shift+鼠标右键可以打开windows终端 2、在windows终端中输入命令 .\\qt-online-installer-windows-x64-4.9.0.exe --mirror https://mirrors.tuna.tsinghua.edu.cn/qt/ 如果清华的源访问失败，也可以换个源 .\\qt-online-installer-windows-x64-4.9.0.exe --mirror https://mirrors.ustc.edu.cn/qtproject 前面的exe换成你自己的安装器版本，回车正常安装即可 3、使用独立QtCreator离线安装包（2025.7.1更新） 访问：官方QtCreator独立安装包 根据个人环境选择独立安装包进行下载，如下图。下载完成后一路傻瓜式安装即可。 上面自定义安装选项中，最后一项勾上可以添加自定义插件，对于使用AI插件很方便。 3、给最新QtCreator配置Qt5.14.2 1、打开构建套件Kit 老版本的设置在顶部菜单的工具一栏的最下方，新版本要从顶层菜单的编辑一栏最下方进入。进入设置后找到构建套件（Kit）。 2、手动添加Qt版本、编译器、调试器 在添加套件之前，要知道一个套件是包括Qt版本（找到对应Qt版本的qmake.exe）、编译器和调试器的。我们一步步添加，先在Qt版本一栏手动添加Qt5.14.2的mingw64对应的qmake.exe，需要注意的地方已经在图上标出了。 同理，手动添加编译器，总共需要给个名称，然后找到对应版本的gcc.exe作为C compiler path，一般同路径下会有个g++.exe，会在选中gcc.exe后自动配置为C++ compiler path。注意，本人的编译器已经在自动检测一栏识别到了，所以这里操作会报重复添加，仅作演示。 然后是调试器，一般都能自动检测出来，如果检测不出来就要自行排查。如果是MinGW，看前面安装Qt时是否有选择同时安装调试工具；如果是MSVC，要单独下载对应的调试工具，再重新检测。 3、手动添加构建套件 完成第二步后，只需要在构建套件（Kit）一栏把它们集成到一起即可。 所有操作完成后，应用即可。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"fjunchao"},{"title":"理解模型微调（Fine-tuning） 和 模型蒸馏（Distillation）","slug":"LLM/理解模型微调（Fine-tuning） 和 模型蒸馏（Distillation）","date":"2025-07-29T07:00:32.000Z","updated":"2025-07-29T07:09:32.313Z","comments":true,"path":"2025/07/29/LLM/理解模型微调（Fine-tuning） 和 模型蒸馏（Distillation）/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/LLM/%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%EF%BC%88Fine-tuning%EF%BC%89%20%E5%92%8C%20%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%EF%BC%88Distillation%EF%BC%89/","excerpt":"","text":"大模型蒸馏与大模型微调是当前人工智能领域中两种重要的技术手段，它们在模型优化、性能提升和资源利用方面各有特点。以下将从定义、技术原理、应用场景及优缺点等方面对这两种技术进行深入对比。 一、定义与基本概念 大模型蒸馏（Knowledge Distillation） 蒸馏是一种将大型复杂模型（教师模型）的知识迁移到小型模型（学生模型）的技术。通过训练学生模型模仿教师模型的行为，实现模型压缩和性能保留的目标。蒸馏过程通常包括两个阶段：预训练阶段（教师模型训练）和知识传递阶段（学生模型训练）。 大模型微调（Fine-tuning） 微调是指在预训练的大模型基础上，通过少量标注数据的再训练，使模型适应特定任务的需求。微调可以分为全量微调和参数高效微调（如PEFT）。全量微调适用于需要高精度输出的任务，而参数高效微调则通过优化超参数和调整策略，减少计算资源消耗。 二、技术原理与实现方式 大模型蒸馏的技术原理 知识传递：通过教师模型生成高质量的软标签（概率分布），学生模型通过学习这些标签来模仿教师的行为。 逐步蒸馏法：逐步蒸馏是一种分步方法，通过逐步增加蒸馏过程中的复杂性，提升学生模型的性能。 剪枝与量化：蒸馏过程中常结合模型剪枝和量化技术，进一步压缩模型大小并降低计算成本。 大模型微调的技术原理 增量学习：在预训练模型的基础上，通过少量标注数据进行再训练，使模型更好地适应特定任务。 参数高效微调（PEFT） ：包括Prefix Tuning、Prompt Tuning等方法，通过少量参数调整实现高效的微调效果。 自适应微调：根据任务需求动态调整学习率、正则化策略等超参数，以提高模型的泛化能力。 三、模型微调：像“专业进修” 它是什么？ 你有一个 **“什么都懂一点” 的通才**（预训练大模型，比如 ChatGPT），但不懂某个专业领域（比如法律、医疗）。 微调就是送它去“专业培训班”：用 **少量专业资料**（法律文书/医学病例）教它，让它变成该领域的专家。 ⚙️ 怎么做？ 不从头学：保留它原本的通用知识（比如语言能力）。 小范围调整：只修改模型 **一小部分参数**（就像医生进修只更新“诊断知识”，不重学解剖学）。 成果：它成了 “法律版ChatGPT” 或 **“医疗助手”**，专业问题答得更准。 ✅ **比喻**： 通才医生 → 送去心内科进修 → 变成心脏病专家 （还是同一个人，但某些能力更强了） 四、模型蒸馏：像“师徒传承” 它是什么？ 你有个 **超级博学的老教授**（大模型），但ta太贵/太慢（需要顶级算力）。 蒸馏就是让老教授教出一个“少年天才”（小模型）：把老教授的知识 压缩传授 给学生，让学生用更少资源达到接近老师的水平。 ⚙️ 怎么做？ 老师示范：让大模型对同一问题生成 **详细答案+解题思路**（不仅给答案，还教“为什么选A不选B”）。 学生模仿：小模型学习老师的 **思考逻辑**（而不只是死记硬背答案）。 成果：小模型变得 **又快又小又聪明**，能在手机、手表上运行。 ✅ **比喻**： 老教授（GPT-4）→ 把毕生心得教给天才少年（TinyLLM）→ 少年能独立看病开药，但只带个小药箱 五、对比总结：核心区别一眼懂 特点模型微调模型蒸馏目标让大模型 更专业让大模型 变小变快操作对象原模型自己进修大模型教小模型（两个模型！）资源需求中等（需专业数据）较高（需老师生成教学材料）典型结果领域专家模型（如医疗GPT）轻量小模型（手机可运行）类比医生进修专科教授培养天才学生 六、什么场景用哪个？ 选微调当你的模型需要： 回答 **专业领域问题**（法律、金融、医疗） 理解 **企业私有术语**（比如公司内部黑话） 适配 **特殊任务格式**（自动生成SQL语句） 选蒸馏当你的模型需要： 塞进 **手机/智能硬件**（离线运行） 响应速度 **极快**（&lt;100ms） 成本 **极低**（1%的算力消耗） 终极技巧：强强联合 实际开发中常 组合使用 微调和蒸馏： 先微调：让大模型变成“心脏科专家” 再蒸馏：把专家知识教给小模型，做成“便携心电图仪” 例如： 医院用 **微调后的GPT-4**（会诊专家）→ 蒸馏出 **手机App版小模型**（患者居家自测） 既专业，又普惠！ 下次听到这两个词，记住： 微调 = 专家进修班 蒸馏 = 师徒速成班","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"}],"author":"关于作者JeffreyArchAI解决方案架构师｜专注 AI 工程化应用回答0文章5关注者2关注发私信"},{"title":"kafka单机和集群部署","slug":"kafka/kafka单机和集群部署","date":"2025-07-29T02:47:14.000Z","updated":"2025-07-29T02:55:49.414Z","comments":true,"path":"2025/07/29/kafka/kafka单机和集群部署/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/kafka/kafka%E5%8D%95%E6%9C%BA%E5%92%8C%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"","text":"一、kafka简介 1.1、概述 kafka 是由 linkedin 公司开发，是一个分布式、分区、多副本、多生产者、多消费者，基于 zookeeper 的分布式 日志系统（也可以作为MQ 系统），常见可以用于 web/nginx 日志、访问日志、消息服务等， Linkedin2010 年将项目贡献给了Apache 基金会并成为顶级开源项目。 主要应用场景是：日志收集系统和消息详细。 设计目标如下： 1. 一时间复杂度为 O(1) 的方式提供消息持久能力，即使对 TB 级以上的数据也能保证常数时间的访问性能。 2. 高吞吐率：即使在非常廉价的商用机器上也能做到单机支持每秒 100k 条消息的传输。 3. 支持 Kafka Server 间的消息分布，以及分布式消费，同时保证每个 partition 内的消息顺序传输。 4. 同时支持离线数据和实时数据处理。 5. Scale out ：支持在线水平扩展。 1.2、消息系统介绍 一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需要关注数据，无需要关系数据再两个或者 多个应用间是如何传递的。分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消 息，有两种主要的消息传递模式：点对点传递模式、发布-订阅模式。大部分的消息系统选用发布 - 订阅模式。 kafka 无疑也是一种消息订阅模式的系统。 1.3、点对点消息传递模式 在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费队列中的数据。但是一条消息只 能被消费一次，当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式及时有多 个消费者同时消费数据，也能保证数据处理的顺序，架构示意图如下 1.4、发布-订阅消息传递模式 在该模式中，消息呗持久化到一个 topic 中。与点对点消息系统不同的是，消费者可以订阅一个或者多个 topic，消费者可以消费 topic 中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在该模式下，消息的生产者称为发布者，消费者称为订阅这，架构示意图如下： 二、kafka术语解释 2.1、结构概述 上图中一个 topic 配置了 3 个 partition 。 Partition1 有两个 oﬀset ： 0 和 1 。 Partition2 有 4 个 oﬀset 。 Partition3 有 1个oﬀset 。副本的 id 和副本所在的机器的 id 恰好相同。 如果一个 topic 的副本数为 3 ，那么 Kafka 将在集群中为每个 partition 创建 3 个相同的副本。集群中的每个 broker存储一个或多个partition 。多个 producer 和 consumer 可同时生产和消费数据。 2.2、broker 一台 Kafka 服务器就是一个 Broker ，一个集群由多个 Broker 组成，一个 Broker 可以容纳多个 Topic ， Broker 和Broker之间没有 Master 和 Standy 的概念，他们之间的地位基本是平等的。 Kafka 集群包含一个或者多个服务器，服务器节点成为 broker 。 broker 存储 topic 的数据，如果某 topic 有 N 个 partion, 集群有 N 个 broker 。 broker 存储 topic 的数据。如果某 topic 有 N 个 partition ，集群有 N 个 broker ，那么每个 broker 存储该 topic 的一个partition 。 如果某 topic 有 N 个 partition ，集群有 (N+M) 个 broker ，那么其中有 N 个 broker 存储该 topic 的一个 partition ，剩下的M 个 broker 不存储该 topic 的 partition 数据。 如果某 topic 有 N 个 partition ，集群中 broker 数目少于 N 个，那么一个 broker 存储该 topic 的一个或多个 partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致 Kafka 集群数据不均衡。 2.3、topic 每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic 。（物理上不同 Topic 的消息分开存储，逻辑上一个Topic 的消息虽然保存于一个或多个 broker 上但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处） 类似于数据库的表名。 2.4、producer topic 中的数据分割为一个或多个 partition 。每个 topic 至少有一个 partition 。每个 partition 中的数据使用多个 segment文件存储。 partition 中的数据是有序的，不同 partition 间的数据丢失了数据的顺序。如果 topic 有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将 partition 数目设为1 。 2.5、consumer 消费者可以从 broker 中读取数据。消费者可以消费多个 topic 中的数据。 2.6、consumer group 每个 Consumer 属于一个特定的 Consumer Group （可为每个 Consumer 指定 group name ，若不指定 groupname则属于默认的 group ）。 2.7、leader 每个 partition 有多个副本，其中有且仅有一个作为 Leader ， Leader 是当前负责数据的读写的 partition 。 2.8、follower Follower 跟随 Leader ，所有写请求都通过 Leader 路由，数据变更会广播给所有 Follower ， Follower 与 Leader 保持数据同步。如果Leader 失效，则从 Follower 中选举出一个新的 Leader 。当 Follower 与 Leader 挂掉、卡住或者同步太慢，leader 会把这个 follower 从 “in sync replicas” （ ISR ）列表中删除，重新创建一个 Follower 。 2.9、partition 为了实现可扩展性，一个非常大的 Topic 可以被分为多个 Partion, 从而分布到多台 Broker 上。 Partion 中的每条消息都会被分配一个自增Id(Oﬀset) 。 Kafka 只保证按一个 Partion 中的顺序将消息发送给消费者，但是不保证单个Topic 中的多个 Partion 之间的顺序。 2.10、offset 消息在 Topic 的 Partion 中的位置，同一个 Partion 中的消息随着消息的写入，其对应的 Oﬀset 也自增，结构图如下： 2.11、replica 副本。 Topic 的 Partion 含有 N 个 replica,N 为副本因子。其中一个 Replica 为 Leader, 其他都为 Follower,Leader 处理Partition 的所有读写请求，与此同时， Follower 会定期去同步 Leader 上的数据。 2.12、message 通讯的基本单位，消息 2.13、zookeeper 存放 Kafka 集群相关元数据的组件。在 ZK 集群中会保存 Topic 的状态消息，例如分区的个数，分区的组成，分区的分布情况等；保存Broker 的状态消息；报错消费者的消息等。通过这些消息， Kafka 很好的将消息生产，消息存储，消息消费的过程结合起来。 三、kafka架构 在 Kafka 集群中生产者将消息发送给以 Topic 命名的消息队列 Queue 中，消费者订阅发往以某个 Topic 命名的消息队列Queue 中的消息。其中 Kafka 集群由若干个 Broker 组成， Topic 由若干个 Partition 组成，每个 Partition 里面的消息通过Oﬀset 来获取。 一个典型的 Kafka 集群中包含若干个 Producer( 可以是某个模块下发的 Command, 或者是 Web 前端产生的 PageView，或者是服务器日志，系统 CPU,Memor 等 ) ，若干个 Broker （ Kafka 集群支持水平扩展，一般 Broker数量越多，整个Kafka 集群的吞吐率也就越高），若干个 ConsumerGroup, 以及一个 Zookeeper 集群。 Kafka 通过zookeeper 管理集群配置。 Producer 使用 Push 模式将消息发不到 Broker 上， consumer 使用 Pull 模式从Broker上订阅并消费消息。 四、kafka的部署 4.1、软件下载 无论单机部署还是集群，这一步都不能省 4.1.1、jdk的安装 由于带GUI界面的安装，是自带jdk版本的，我们可以选择使用默认jdk 自带JDK，这种JDK可以使用java -version检查，如果使用javac就不行了，所以进行安装: 1sudo yum install java-1.8.0-openjdk-devel -y 4.1.2、zookeeper安装 Apache ZooKeeper 选择3.5.7版本 上传服务器，安装 12345678910111213141516171819202122232425262728293031323334353637解压tar -zxvf apache-zookeeper-3.5.7-bin.tar.gzmv apache-zookeeper-3.5.7-bin zookeeper3.5.7mv zookeeper3.5.7/ /opt 创建软链接ln -s /opt/zookeeper3.5.7/ /opt/zookeeper 配置环境变量vim /etc/profile 添加export ZK_HOME=/opt/zookeeperexport PATH=$PATH:$ZK_HOME/bin source /etc/profile 将Zookeeper提供的配置文件复制一份，复制成Zookeeper默认寻找的文件cd /opt/zookeeper/conflscp zoo_sample.cfg zoo.cfgcd .. 创建数据存放目录mkdir datachmod 755 /opt/zookeeper/data 修改数据存放位置cd conf/vim zoo.cfg ##修改以下配置dataDir=/opt/zookeeper/data 启动 Zookeeper，Zookeeper的bin目录下cd .../bin/zkServer.sh start zoo.cfg 检测zookeeper是否正常 123jps # 看到控制台成功输出 QuorumPeerMain，表示启动成功 ./bin/zkServer.sh status zoo.cfg ## Mode: standalone表示ok 4.1.3、kafka的安装 https://kafka.apache.org/downloads 选择 kafka_2.12-3.8.0.tgz 进行下载，Scala 2.12 和 Scala 2.13 主要是使用Scala编译的版本不同，两者皆可 上传服务器，安装 1234567891011121314151617解压tar -zxvf kafka_2.12-2.7.0.tgzmv kafka_2.12-2.7.0 /optcd /opt 创建软链接ln -s /opt/kafka_2.12-2.7.0/ /opt/kafkals 配置环境变量vim /etc/profile 添加export KAFKA_HOME=/opt/kafkaexport PATH=:$PATH:$&#123;KAFKA_HOME&#125; source /etc/profile 4.2、单机模式 123456789101112131415161718192021在Kafka的config目录下存在相关的配置信息——本次我们只想让Kafka快速启动起来只关注server.properties文件即可 cd $&#123;KAFKA_HOME&#125;/configls#connect-console-sink.properties connect-file-source.properties consumer.properties server.properties#connect-console-source.properties connect-log4j.properties kraft tools-log4j.properties#connect-distributed.properties connect-mirror-maker.properties log4j.properties trogdor.conf#connect-file-sink.properties connect-standalone.properties producer.properties zookeeper.properties 打开配置文件，并主要注意以下几个配置vim server.properties broker.id=0 #kafka服务节点的唯一标识，这里是单机不用修改# listeners = PLAINTEXT://host1:9092 别忘了设置成自己的主机名listeners=PLAINTEXT://host1:9092 #kafka底层监听的服务地址，注意是使用主机名，不是ip。# log.dirs 指定的目录 kafka启动时可以自动创建，因此不要忘了让kafka可以有读写这个目录的权限。log.dirs=/opt/kafka/data ##kafka的分区以日志的形式存储在集群中（其实就是broker数据存储的目录） log.retention.hours=168 #日志的留存策略，默认168小时也就是一周# zookeeper 的连接地址 ，别忘了设置成自己的主机名，单机情况下可以使用 localhostzookeeper.connect=host1:2181 启动kafka 1234567./bin/kafka-server-start.sh -daemon config/server.properties #后台启动kafka 使用 jps 查看是否成功启动kafkajps34843 QuorumPeerMain21756 Jps116076 Kafka 4.3、集群部署 4.3.1、针对每一个节点的hosts文件添加节点的ip映射信息 1234vim /etc/hosts192.168.157.80 host1192.168.157.81 host2192.168.157.82 host3 4.3.2、时间同步 12yum install ntp -yntpdate cn.pool.ntp.org | ntp[1-7].aliyun.com #两个时钟同步地址选择一个就行 4.3.3、zookeeper配置 12345vim /opt/zookeeper/conf/zoo.cfg##额外添加以下配置server.1=host1:2888:3888 #数据同步端口:领导选举时服务器监听的端口server.2=host2:2888:3888server.3=host3:2888:3888 4.3.4、创建对应的服务id 123456# host1echo 1 &gt; /opt/zookeeper/data/myid #在这个文件中写入自己服务的id号# host2echo 2 &gt; /opt/zookeeper/data/myid# host3echo 3 &gt; /opt/zookeeper/data/myid 4.3.5、zoo.cfg参数解析 1234567891011tickTime=2000: 通信心跳数，用于设置Zookeeper服务器与客户端之间的心跳时间间隔，单位是毫秒。这个时间间隔是Zookeeper使用的基本时间单位，用于服务器之间或客户端与服务器之间维持心跳的时间间隔。 initLimit=10: LF初始通信时限，用于设置集群中的Follower跟随者服务器与Leader领导者服务器之间启动时能容忍的最多心跳数。如果在这个时限内（10个心跳时间）领导和根随者没有发出心跳通信，就视为失效的连接，领导和根随者彻底断开。 syncLimit=5: LF同步通信时限，用于设置集群启动后，Leader与Follower之间的最大响应时间单位。假如响应超过这个时间（syncLimit * tick Time -&gt; 10秒），Leader就认为Follower已经死掉，会将Follower从服务器列表中删除。 dataDir: 数据文件目录+数据持久化路径，主要用于保存Zookeeper中的数据。 dataLogDir: 日志文件目录，用于存储Zookeeper的日志文件。 clientPort=2181: 客户端连接端口，用于监听客户端连接的端口 4.3.6、集群kafka配置 server.properties配置文件 123456789101112cd $&#123;KAFKA_HOME&#125;/configvim server.properties broker.id=0 #kafka服务节点的唯一标识# listeners = PLAINTEXT://your.host.name:9092 别忘了设置成自己的主机名listeners=PLAINTEXT://host1:9092 #集群中需要设置成每个节点自己的# log.dirs 指定的目录 kafka启动时可以自动创建，因此不要忘了让kafka可以有读写这个目录的权限。log.dirs=/opt/kafka/data ##kafka的分区以日志的形式存储在集群中（其实就是broker数据存储的目录）# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=168 #日志的留存策略，默认168小时也就是一周# zookeeper 集群的连接地址 zookeeper.connect=host1:2181,host2:2181，host3:2181 其余配置： 12345678910##修改差异配置cd $&#123;KAFKA_HOME&#125;/configvim server.properties # host2节点broker.id=1listeners=PLAINTEXT://host2:9092# host3节点broker.id=2listeners=PLAINTEXT://host3:9092 kafka集群即可正常启动 1234567891011121314kafka其余命令 ./bin/kafka-server-stop.sh #关闭kafkakafka-console-consumer.sh #消费命令kafka-console-producer.sh #生产命令kafka-consumer-groups.sh #查看消费者组，重置消费位点等kafka-topics.sh #查询topic状态，新建，删除，扩容kafka-acls.sh #配置，查看kafka集群鉴权信息kafka-configs.sh #查看，修改kafka配置kafka-mirror-maker.sh #kafka集群间同步命令kafka-preferred-replica-election.sh #重新选举topic分区leaderkafka-producer-perf-test.sh #kafka自带生产性能测试命令kafka-reassign-partitions.sh #kafka数据重平衡命令kafka-run-class.sh #kafka执行脚本","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"}],"author":220175865964},{"title":"手把手教你玩转 kafka-python：从安装到消费者实战全攻略","slug":"kafka/手把手教你玩转 kafka-python：从安装到消费者实战全攻略","date":"2025-07-29T02:33:59.000Z","updated":"2025-07-29T02:43:55.233Z","comments":true,"path":"2025/07/29/kafka/手把手教你玩转 kafka-python：从安装到消费者实战全攻略/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/kafka/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%8E%A9%E8%BD%AC%20kafka-python%EF%BC%9A%E4%BB%8E%E5%AE%89%E8%A3%85%E5%88%B0%E6%B6%88%E8%B4%B9%E8%80%85%E5%AE%9E%E6%88%98%E5%85%A8%E6%94%BB%E7%95%A5/","excerpt":"","text":"在分布式系统开发中，我们经常会遇到消息队列的需求，而 Kafka 作为高性能的消息中间件，自然成为首选。但如何在 Python 中高效使用 Kafka 呢？今天我们就来深入探讨 kafka-python 的安装与消费者实战，带你从零开始掌握这个强大的工具。 一、kafka-python 安装指南 1. 最新稳定版安装 我们可以使用最常用的 Pip 包管理器来安装 kafka-python 的最新稳定版本，只需一行命令即可完成基础安装： 1pip install kafka-python 2. 开发版安装（获取最新特性） 如果我们想体验最新的功能特性，可以通过 Git 克隆仓库并手动安装： 123git clone https://github.com/dpkp/kafka-pythoncd kafka-pythonpip install . 3. 性能优化相关的可选安装 （1）crc32c 安装（Kafka 11 + 强烈推荐） 当我们使用 Kafka 11 + 版本的 broker 时，新的消息协议需要计算 crc32c，而默认的纯 Python 实现性能较差。安装 crc32c 包可以显著提升性能： 1pip install &#x27;kafka-python[crc32c]&#x27; （2）ZSTD 压缩支持 如果我们需要使用 ZSTD 压缩格式，需要安装对应的依赖： 1pip install &#x27;kafka-python[zstd]&#x27; （3）LZ4 压缩支持 同理，启用 LZ4 压缩功能需要安装： 1pip install &#x27;kafka-python[lz4]&#x27; （4）Snappy 压缩支持 Snappy 的安装稍显复杂，需要先安装开发库： Ubuntu 系统： 1apt-get install libsnappy-dev OSX 系统： 1brew install snappy 从源代码安装： 123456wget https://github.com/google/snappy/releases/download/1.1.3/snappy-1.1.3.tar.gztar xzvf snappy-1.1.3.tar.gzcd snappy-1.1.3./configuremakesudo make install 安装完开发库后，再安装 Python 模块： 1pip install &#x27;kafka-python[snappy]&#x27; 二、KafkaConsumer 核心功能解析 1. 初始化 KafkaConsumer KafkaConsumer 类是我们与 Kafka 集群交互的核心组件，它可以透明处理集群服务器故障，并适应主题分区的创建或迁移。下面是初始化 Consumer 的关键参数说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124from kafka import KafkaConsumer consumer = KafkaConsumer( # 订阅的主题列表，可选，未设置时需调用subscribe或assign *topics, # 引导服务器列表，至少一个可用broker bootstrap_servers=&#x27;localhost:9092&#x27;, # 客户端标识，用于服务器日志标识 client_id=&#x27;my-consumer&#x27;, # 消费者组ID，None时禁用自动分区分配和偏移量提交 group_id=&#x27;my-group&#x27;, # 键的反序列化函数 key_deserializer=lambda m: m.decode(&#x27;utf-8&#x27;), # 值的反序列化函数 value_deserializer=lambda m: m.decode(&#x27;utf-8&#x27;), # 启用增量fetch会话，提升性能 enable_incremental_fetch_sessions=True, # 每次fetch最小数据量(字节) fetch_min_bytes=1, # fetch最大等待时间(毫秒) fetch_max_wait_ms=500, # 每次fetch最大数据量(字节) fetch_max_bytes=52428800, # 50MB # 每个分区最大fetch数据量(字节) max_partition_fetch_bytes=1048576, # 请求超时时间(毫秒) request_timeout_ms=305000, # 错误重试间隔(毫秒) retry_backoff_ms=100, # 重连间隔(毫秒) reconnect_backoff_ms=50, # 最大重连间隔(毫秒)，指数退避上限 reconnect_backoff_max_ms=30000, # 每个连接最大未完成请求数 max_in_flight_requests_per_connection=5, # 偏移量越界时的重置策略 auto_offset_reset=&#x27;latest&#x27;, # 是否自动提交偏移量 enable_auto_commit=True, # 自动提交间隔(毫秒) auto_commit_interval_ms=5000, # 偏移量提交回调函数 default_offset_commit_callback=None, # 是否自动检查CRC32 check_crcs=True, # 隔离级别，处理事务性消息 isolation_level=&#x27;read_uncommitted&#x27;, # 是否允许自动创建主题 allow_auto_create_topics=True, # 元数据刷新间隔(毫秒) metadata_max_age_ms=300000, # 分区分配策略 partition_assignment_strategy=None, # 每次poll最大记录数 max_poll_records=500, # 两次poll最大间隔(毫秒)，超时会触发重平衡 max_poll_interval_ms=300000, # 会话超时时间(毫秒)，用于检测消费者故障 session_timeout_ms=10000, # 心跳间隔(毫秒)，维持会话活性 heartbeat_interval_ms=3000, # TCP接收缓冲区大小 receive_buffer_bytes=None, # TCP发送缓冲区大小 send_buffer_bytes=None, # 套接字选项 socket_options=[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)], # 消费者迭代超时时间(毫秒) consumer_timeout_ms=float(&#x27;inf&#x27;), # 安全协议 security_protocol=&#x27;PLAINTEXT&#x27;, # SSL上下文 ssl_context=None, # 是否验证主机名 ssl_check_hostname=True, # CA证书文件 ssl_cafile=None, # 客户端证书文件 ssl_certfile=None, # 客户端私钥文件 ssl_keyfile=None, # 证书密码 ssl_password=None, # CRL文件 ssl_crlfile=None, # SSL密码套件 ssl_ciphers=None, # 指定Kafka API版本 api_version=None, # API版本自动检测超时时间(毫秒) api_version_auto_timeout_ms=2000, # 连接最大空闲时间(毫秒) connections_max_idle_ms=540000, # 指标报告器 metric_reporters=None, # 是否启用指标收集 metrics_enabled=True, # 指标采样数 metrics_num_samples=2, # 指标采样窗口(毫秒) metrics_sample_window_ms=30000, # I/O选择器 selector=None, # 是否排除内部主题 exclude_internal_topics=True, # SASL认证机制 sasl_mechanism=None, # SASL用户名 sasl_plain_username=None, # SASL密码 sasl_plain_password=None, # Kerberos名称 sasl_kerberos_name=None, # Kerberos服务名称 sasl_kerberos_service_name=&#x27;kafka&#x27;, # Kerberos域名 sasl_kerberos_domain_name=None, # OAuth令牌提供器 sasl_oauth_token_provider=None, # Socks5代理 socks5_proxy=None, # 自定义KafkaClient创建函数 kafka_client=None) 2. 核心方法详解 （1）分区分配与订阅 手动分配分区（assign） 1234567from kafka import TopicPartition # 手动分配特定分区consumer.assign([TopicPartition(&#x27;my_topic&#x27;, 0), TopicPartition(&#x27;my_topic&#x27;, 1)]) # 获取当前分配的分区assigned_partitions = consumer.assignment() 自动订阅主题（subscribe） 1234567891011# 订阅单个或多个主题consumer.subscribe([&#x27;topic1&#x27;, &#x27;topic2&#x27;]) # 通过正则表达式订阅匹配的主题consumer.subscribe(pattern=&#x27;^topic-&#x27;) # 获取当前订阅的主题subscribed_topics = consumer.subscription() # 取消所有订阅consumer.unsubscribe() （2）偏移量操作 提交偏移量 1234567891011121314151617181920# 同步提交偏移量consumer.commit() # 提交指定偏移量consumer.commit(&#123; TopicPartition(&#x27;topic1&#x27;, 0): offset_and_metadata, TopicPartition(&#x27;topic2&#x27;, 1): offset_and_metadata&#125;) # 异步提交偏移量consumer.commit_async() # 异步提交带回调def on_commit(errors, offsets): if errors: print(f&quot;Commit failed: &#123;errors&#125;&quot;) else: print(f&quot;Commit successful: &#123;offsets&#125;&quot;) consumer.commit_async(callback=on_commit) 获取已提交偏移量 123456# 获取指定分区的已提交偏移量committed_offset = consumer.committed(TopicPartition(&#x27;topic1&#x27;, 0)) # 获取多个分区的已提交偏移量partitions = [TopicPartition(&#x27;topic1&#x27;, 0), TopicPartition(&#x27;topic1&#x27;, 1)]offsets = consumer.committed(partitions, metadata=True) （3）消息获取与定位 轮询获取消息 1234567# 轮询获取消息，超时时间100毫秒messages = consumer.poll(timeout_ms=100, max_records=100) # 处理获取的消息for topic_partition, records in messages.items(): for record in records: print(f&quot;Received message: &#123;record.value&#125; at offset &#123;record.offset&#125;&quot;) 手动定位偏移量 12345678# 定位到指定偏移量consumer.seek(TopicPartition(&#x27;topic1&#x27;, 0), 100) # 定位到分区起始位置consumer.seek_to_beginning(TopicPartition(&#x27;topic1&#x27;, 0)) # 定位到分区末尾位置consumer.seek_to_end(TopicPartition(&#x27;topic1&#x27;, 0)) （4）偏移量与元数据查询 查询分区偏移量范围 123456789# 获取分区最早偏移量begin_offsets = consumer.beginning_offsets([TopicPartition(&#x27;topic1&#x27;, 0)]) # 获取分区末尾偏移量（下一条消息的偏移量）end_offsets = consumer.end_offsets([TopicPartition(&#x27;topic1&#x27;, 0)]) # 通过时间戳查询偏移量timestamps = &#123;TopicPartition(&#x27;topic1&#x27;, 0): 1678901234000&#125;offsets = consumer.offsets_for_times(timestamps) 查询分区元数据 12345# 获取主题的所有分区partitions = consumer.partitions_for_topic(&#x27;my_topic&#x27;) # 获取分区的高水位偏移量highwater = consumer.highwater(TopicPartition(&#x27;topic1&#x27;, 0)) （5）分区控制 暂停与恢复分区 12345678# 暂停分区 fetchconsumer.pause(TopicPartition(&#x27;topic1&#x27;, 0)) # 获取暂停的分区paused_partitions = consumer.paused() # 恢复分区 fetchconsumer.resume(TopicPartition(&#x27;topic1&#x27;, 0)) 三、实战案例：构建一个可靠的 Kafka 消费者 下面我们通过一个完整的案例来展示如何使用 KafkaConsumer 构建一个可靠的消息消费者： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import jsonimport timefrom kafka import KafkaConsumerfrom kafka.errors import KafkaError # 配置消费者consumer = KafkaConsumer( &#x27;my-topic&#x27;, bootstrap_servers=[&#x27;localhost:9092&#x27;], group_id=&#x27;my-consumer-group&#x27;, auto_offset_reset=&#x27;latest&#x27;, enable_auto_commit=False, key_deserializer=lambda k: k.decode(&#x27;utf-8&#x27;), value_deserializer=lambda v: json.loads(v.decode(&#x27;utf-8&#x27;))) try: print(&quot;Consumer started, waiting for messages...&quot;) # 循环获取消息 while True: # 轮询获取消息，超时时间100ms messages = consumer.poll(timeout_ms=100) if not messages: continue # 处理消息 for topic_partition, records in messages.items(): print(f&quot;Received &#123;len(records)&#125; messages from &#123;topic_partition&#125;&quot;) # 批量处理消息 for record in records: try: # 处理消息内容 print(f&quot;Processing message: &#123;record.value&#125; at offset &#123;record.offset&#125;&quot;) # 模拟业务处理 time.sleep(0.1) except Exception as e: print(f&quot;Error processing message: &#123;e&#125;&quot;) # 手动提交偏移量 try: consumer.commit() print(f&quot;Offsets committed successfully for &#123;topic_partition&#125;&quot;) except KafkaError as e: print(f&quot;Offset commit failed: &#123;e&#125;&quot;) except KeyboardInterrupt: print(&quot;Consumer stopped by user&quot;)finally: # 关闭消费者 consumer.close() print(&quot;Consumer closed&quot;) 这个案例展示了一个基本的消费者流程，包括： 配置消费者参数（手动提交偏移量、JSON 反序列化） 循环轮询获取消息 批量处理消息 手动提交偏移量确保消息不丢失 异常处理和资源清理 总结 通过本文，我们详细介绍了 kafka-python 的安装方法和 KafkaConsumer 的核心功能，从基础安装到高级特性，再到实战案例，希望能帮助你在项目中熟练运用 Kafka。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"}],"author":"The_Thieves"},{"title":"Kafka简介和Ubuntu20.04安装kafka","slug":"kafka/Kafka简介和Ubuntu20.04安装kafka","date":"2025-07-29T02:19:26.000Z","updated":"2025-07-29T02:33:28.393Z","comments":true,"path":"2025/07/29/kafka/Kafka简介和Ubuntu20.04安装kafka/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/kafka/Kafka%E7%AE%80%E4%BB%8B%E5%92%8CUbuntu20.04%E5%AE%89%E8%A3%85kafka/","excerpt":"","text":"简介 Kafka是一个实时数据处理系统，可以横向扩展、高可靠，而且还变态快，已经被很多公司使用。 那么什么是实时数据处理系统呢？顾名思义，实时数据处理系统就是数据一旦产生，就要能快速进行处理的系统。 对于实时数据处理，我们最常见的，就是消息中间件了，也叫MQ（Message Queue，消息队列），也有叫Message Broker的。 为什么需要消息中间件 消息中间件的作用主要有两点： 1. 解耦消息的生产和消费。 2. 缓冲。 想象一个场景，你的一个创建订单的操作，在订单创建完成之后，需要触发一系列其他的操作，比如进行用户订单数据的统计、给用户发送短信、给用户发送邮件等等，就像这样： 123456createOrder(...)&#123; ... statOrderData(...); sendSMS(); sendEmail();&#125; 代码这样写似乎没什么问题，可是过了一段时间，你给系统引进了一个用户行为分析服务，它也需要在订单创建完成之后，进行一个分析用户行为的操作，而且随着系统的逐渐壮大，创建订单之后要触发的操作也就越来越多，代码也渐渐膨胀成这样： 123456789101112createOrder(...)&#123; ... statOrderData(...); sendSMS(); sendEmail(); // new operation statUserBehavior(...); doXXX(...); doYYY(...); // more and more operations ...&#125; 导致代码越来越膨胀的症结在于，消息的生产和消费耦合在一起了。createOrder方法不仅仅要负责生产“订单已创建”这条消息，还要负责处理这条消息。 这就好比BBC的记者，在知道皇马拿到欧冠冠军之后，拿起手机，翻开皇马球迷通讯录，给球迷一个一个打电话，告诉他们，皇马夺冠了。 事实上，BBC的记者只需要在他们官网发布这条消息，然后球迷自行访问BBC，去上面获取这条新闻；又或者球迷订阅了BBC，那么订阅系统会主动把发布在官网的消息推送给球迷。 同样，createOrder也需要一个像BBC官网那样的载体，也就是消息中间件，在订单创建完成之后，把一条主题为“orderCreated”的消息，放到消息中间件去就ok了，不必关心需要把这条消息发给谁。这就完成了消息的生产。 至于需要在订单创建完成之后触发操作的服务，则只需要订阅主题为“orderCreated”的消息，在消息中间件出现新的“orderCreated”消息时，就会收到这条消息，然后进行相应的处理。 因此，通过使用消息中间件，上面的代码也就简化成了： 1234createOrder(...)&#123; ... sendOrderCreatedMessage(...);&#125; 以后如果在订单创建之后有新的操作需要执行，这串代码也不需要修改，只需要给对消息进行订阅即可。 另外，通过这样的解耦，消费者在消费数据时更加的灵活，不必每次消息一产生就要马上去处理（虽然通常消费者侧也会有线程池等缓冲机制），可以等自己有空了的时候，再过来消息中间件这里取数据进行处理。这就是消息中间件带来的缓冲作用。 Kafka一代 - 消息队列 从上面的描述，我们可以看出，消息中间件之所以可以解耦消息的生产和消费，主要是它提供了一个存放消息的地方——生产者把消息放进来，消费者在从中取出消息进行处理。 那么这个存放消息的地方，应该采用什么数据结构呢？ 在绝大多数情况下，我们都希望先发送进来的消息，可以先被处理（FIFO），这符合大多数的业务逻辑，少数情况下我们会给消息设置优先级。不管怎样，对于消息中间件来说，一个先进先出的队列，是非常合适的数据结构： 那么要怎样保证消息可以被顺序消费呢？ 消费者过来获取消息时，每次都把index=0的数据返回过去，然后再删除index=0的那条数据？ 很明显不行，因为订阅了这条消息的消费者数量，可能是0，也可能是1，还可能大于1。如果每次消费完就删除了，那么其他订阅了这条消息的消费者就获取不到这条消息了。 事实上，Kafka会对数据进行持久化存储（至于存放多长时间，这是可以配置的），消费者端会记录一个offset，表明该消费者当前消费到哪条数据，所以下次消费者想继续消费，只需从offset+1的位置继续消费就好了。 消费者甚至可以通过调整offset的值，重新消费以前的数据。 那么这就是Kafka了吗？不，这只是一条非常普通的消息队列，我们姑且叫它为Kafka一代吧。 这个Kafka一代用一条消息队列实现了消息中间件，这样的简单实现存在不少问题： · Topic鱼龙混杂。想象一下，一个只订阅了topic为“A”的消费者，却要在一条有ABCDEFG…等各种各样topic的队列里头去寻找topic为A的消息，这样性能岂不是很慢？ · 吞吐量低。我们把全部消息都放在一条队列了，请求一多，它肯定应付不过来。 由此就引申出了Kafka二代。 Kafka二代 - Partition 要解决Kafka一代的那两个问题，很简单——分布存储。 二代Kafka引入了Partition的概念，也就是采用多条队列， 每条队列里面的消息都是相同的topic： Partition的设计解决了上面提到的两个问题： 纯Topic队列。一个队列只有一种topic，消费者再也不用担心会碰到不是自己想要的topic的消息了。 提高吞吐量。不同topic的消息交给不同队列去存储，再也不用以一敌十了。 一个队列只有一种topic，但是一种topic的消息却可以根据自定义的key值，分散到多条队列中。也就是说，上图的p1和p2，可以都是同一种topic的队列。不过这是属于比较高级的应用了，以后有机会再和大家讨论。 Kafka二代足够完美了吗？当然不是，我们虽然通过Partition提升了性能，但是我们忽略了一个很重要的问题——高可用。 万一机器挂掉了怎么办？单点系统总是不可靠的。我们必须考虑备用节点和数据备份的问题。 Kafka三代 - Broker集群 很明显，为了解决高可用问题，我们需要集群。 Kafka对集群的支持也是非常友好的。在Kafka中，集群里的每个实例叫做Broker，就像这样： 每个partition不再只有一个，而是有一个leader(红色)和多个replica(蓝色)，生产者根据消息的topic和key值，确定了消息要发往哪个partition之后（假设是p1），会找到partition对应的leader(也就是broker2里的p1)，然后将消息发给leader，leader负责消息的写入，并与其余的replica进行同步。 一旦某一个partition的leader挂掉了，那么只需提拔一个replica出来，让它成为leader就ok了，系统依旧可以正常运行。 通过Broker集群的设计，我们不仅解决了系统高可用的问题，还进一步提升了系统的吞吐量，因为replica同样可以为消费者提供数据查找的功能。 Kafka没那么简单 1. kafka的消息结构 我们只知道Kafka内部是一个消息队列，但是队列里的元素长什么样，包含了哪些消息呢？ 参考：Kafka - messageformat 2. zookeeper和kafka的关系 如果玩过Kafka的Quick Start教程，就会发现，我们在使用Kafka时，需要先启动一个ZK，那么这个ZK的作用到底是什么呢？ 参考：What-is-the-actual-role-of-Zookeeper-in-Kafka 3. 数据可靠性和重复消费 生产者把消息发给Kafka，发送过程中挂掉、或者Kafka保存消息时发送异常怎么办？ 同理，消费者获取消费时发生异常怎么办？ 甚至，如果消费者已经消费了数据，但是修改offset时失败了，导致重复消费怎么办？ 等等这些异常场景，都是Kafka需要考虑的。 参考：Kafka - Message Delivery Semantics 4. pull or push 消费者侧在获取消息时，是通过主动去pull消息呢？还是由Kafka给消费者push消息？ 这两种方式各自有什么优劣？ 参考：Kafka - push vs pull 5. 如何提高消费者处理性能 还是之前的订单创建的例子，订单创建后，你要给用户发送短信，现在你发现由于你只有一个消费者在发送短信，忙不过来，怎么办？这就有了Kafka里头的消费者组（Consumer Group）的设计。 参考：Understanding-kafka-consumer-groups-and-consumer 6.终极问题：一条消息从生产，到被消费，完整流程是怎样的？ 如果能详尽透彻地回答这个问题，那你对Kafka的理解也就非常深入了。 7. 参考文献&amp;学习资源 官网： Apache Kafka Kafka简介 Kafka官网文档 一些不错的博客： Kafka-in-a-nutshell（入门绝佳读物） What every software engineer should know about real-time data’s unifying abstraction（从这篇文章可以知道LinkedIn为何要开发Kafka） How to choose the number of topics/partitions in a Kafka cluster?（对Kafka Partition的深入讲解和性能优化指导） 书籍（没看过，但是感觉不错的书）： Kafka权威指南 Apache Kafka源码剖析（可以自己先看看源码，再看看这本书） 安装JAVA（jdk） 下载安装包 （官网）链接： 还可以直接通过wget命令直接把JDK安装包下载下来，具体执行命令请度娘。 解压安装包 可自定义一个目录存（/home/temp）放并进行解压,执行命令行如下： 123# mkdir /home/temp# cd /home/temp# tar -zxvf jdk-8u181-linux-x64.tar.gz 将解压后的【jdk1.8.0_181】里面的所有数据移动到指定的文件夹下（如/usr/local/java） 1# mkdir /usr/local/java 将【jdk1.8.0_181】里的数据拷贝至java目录下 1# mv /home/temp/jdk1.8.0_181 /usr/local/java 修改环境变量 修改环境变量，通过命令 1# vim /etc/profile 在文件末尾添加一下内容： 12345export JAVA_HOME=/usr/local/javaexport JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125; 然后，保存并退出(按：wq!) 保存完之后，通过命令source /etc/profile让profile文件立即生效 第四步、测试是否安装成功 ①、使用javac命令，不会出现command not found错误 ②、使用java -version，出现版本为java version “1.8.0_181” ③、echo $PATH，看看自己刚刚设置的的环境变量配置是否都正确 测试没问题即安装成功 安装Zookeeper 下载 到官网去下载你想要的版本 官网下载地址 解压 1#tar -zxvf zookeeper-3.4.10.tar.gz 将解压后的文件复制到/usr/local目录下，并重命名为zookeeper： 12[root@localhost tmp]# cp zookeeper-3.4.10 /usr/local/zookeeper -r //复制所有文件到zookeeper 文件夹下[root@localhost tmp]# cd /usr/local/zookeeper //切换到/usr/local/zookeeper目录下 配置 but 这里需要更改一下 .cfg 文件名 zookeeper 启动脚本默认是寻找 zoo.cfg 文件。。。。之所以 得修改文件名 切换到zookeeper目录下的conf目录下，重新复制一份zoo_sample.cfg文件并命名为zoo.cfg： 1234567891011121314[root@localhost zookeeper]# cd conf //切换到目录下[root@localhost conf]# ll//显示目录下的信息总用量 12-rw-r--r--. 1 root root 535 5月 8 18:17 configuration.xsl-rw-r--r--. 1 root root 2161 5月 8 18:17 log4j.properties-rw-r--r--. 1 root root 922 5月 8 18:17 zoo_sample.cfg[root@localhost conf]# cp zoo_sample.cfg zoo.cfg//copy一份到当前目录下，并命名为zoo.cfg[root@localhost conf]# ll总用量 16-rw-r--r--. 1 root root 535 5月 8 18:17 configuration.xsl-rw-r--r--. 1 root root 2161 5月 8 18:17 log4j.properties-rw-r--r--. 1 root root 922 5月 8 18:29 zoo.cfg-rw-r--r--. 1 root root 922 5月 8 18:17 zoo_sample.cfg[root@localhost conf]# 修改zoo.cfg文件如下： 12345678910111213141516171819202122232425262728293031323334[root@localhost conf]# vi zoo.cfg# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=D:\\\\zookeeper-3.5.4-beta\\\\datadataLogDir=D:\\\\zookeeper-3.5.4-beta\\\\log# the port at which the clients will connectadmin.serverPort=8082clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.0=192.168.2.3:9092:113 修改内容： 增加了：admin.serverPort=8082 #不然会出现端口被占用的情况，因为默认是和Apache.Tomcat使用的8080端口 修改了：dataDir=D:\\zookeeper-3.5.4-beta\\data #保存数据的目录 dataLogDir=D:\\zookeeper-3.5.4-beta\\log #保存日志的目录 tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。 dataLogDir：顾名思义就是 Zookeeper 保存日志文件的目录 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 server.A = B:C:D A表示这个是第几号服务器 B 是这个服务器的 ip 地址 C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口 D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader 最后一步配置环境变量： 打开/etc/profile 1[root@localhost zookeeper]# vi /etc/profile//编辑文件 添加如下内容： 12export ZOOKEEPER=/usr/local/zookeeperexport PATH=$PATH:$ZOOKEEPER/bin 重启配置文件 1[root@localhost zookeeper]# source /etc/profile //使生效 启动Zookeeper 因为配置了环境变量，所以在任意目录下都可以运行以下启动命令启动Zookeeper。 12[root@localhost ~]# zkServer.sh start //启动[root@localhost ~]# zkServer.sh status //查看运行状态 启动客户端： 1[root@localhost ~]# zkCli.sh //启动客户端 配置开机启动zookeeper 在/etc/init.d目录下新建zookeeper文件 vi /etc/init.d/zookeeper//vi 编辑zookeeper文件，不存在时就创建该文件 输入以下内容： 12345678910#!/bin/bashZK_PATH=/usr/local/zookeeperexport JAVA_HOME=/usr/local/java/jdk1.8.0_171case $1 in start) sh $ZK_PATH/bin/zkServer.sh start;; stop) sh $ZK_PATH/bin/zkServer.sh stop;; status) sh $ZK_PATH/bin/zkServer.sh status;; restart) sh $ZK_PATH/bin/zkServer.sh restart;; *) echo &quot;require start|stop|status|restart&quot; ;;esac 保存并退出后，执行以下chkconfig --add 指令把脚本注册为Service： 1chkconfig --add zookeeper 你可以使用chkconfig --list查看你的注册操作时否成功 注意： 1. Ubuntu 16.04 下安装 Nginx 服务器，在添加 nginx 服务时出现如下信息 12# chkconfig --add nginxchkconfig: command not found 问题原因 Ubuntu 中 chkconfig 已经被 sysv-rc-conf 所替代，chkconfig 命令如下： 12# chkconfig --add nginx # chkconfig nginx on 问题解决 123# apt-get update# apt-get install sysv-rc-conf# sysv-rc-conf nginx on 2.Ubuntu下安装sysv-rc-conf报错：ubuntuE: Unable to locate package sysv-rc-conf 当我安装sysv-rc-conf时，报了如下的错： E: Unable to locate package sysv-rc-conf（无法定位sysv-rc-conf包） 提供一个解决办法，如下： 在软件源列表sources.list（该文本的位置在/etc/apt/sources.list）文件中的末尾添加如下内容： deb http://archive.ubuntu.com/ubuntu/ trusty main universe restricted multiverse 第一步：终端输入：sudo gedit /etc/apt/sources.list（这里我使用的是gedit，你可以使用自己喜欢的工具，如vi、vim等），打开该文件 1sudo gedit /etc/apt/sources.list 第二步：在软件源sources.list文件中添加如下一列文本： deb http://archive.ubuntu.com/ubuntu/ trusty main universe restricted multiverse 第三步：更新apt-get，在终端输入sudo apt-get update 1sudo apt-get update 注意，此处更新可能会出错，重复执行更新就好了 第四步：完成更新后，重新安装sysv-rc-conf，在终端输入sudo apt-get install sysv-rc-conf，即可成功安装。 安装 kafka 下载代码 下载地址：https://kafka.apache.org/downloads，ubuntu下可以用wget直接下载，我是下载到了/home/kafka目录 1wget http://mirrors.shuosc.org/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz 解压 1tar -zxvf kafka_2.11-1.0.0.tgz 在kafka解压目录下创建日志存储目录 修改kafka-server 的配置文件 1vim config/server.properties 修改配置文件中21、31、36和60行 1234**broker.id=1** //--使用单机模式可以不修改**listeners=PLAINTEXT://:9092** //--使用单机模式可以不修改**advertised.listeners=PLAINTEXT://host_ip:9092** //--使用单机模式可以不修改**log.dirs=/home/yzy/kafka/kafka_2.12-2.6.0/kafka_logs** 启动服务器 Kafka 使用 ZooKeeper 如果你还没有ZooKeeper服务器，你需要先启动一个ZooKeeper服务器。 您可以通过与kafka打包在一起的便捷脚本来快速简单地创建一个单节点ZooKeeper实例。 1bin/zookeeper-server-start.sh config/zookeeper.properties //--该启动脚本在kafka文件夹bin下面，不是在zookeeper里面 现在启动Kafka服务器： 1bin/kafka-server-start.sh config/server.properties 创建一个topic 让我们创建一个名为“test”的topic，它有一个分区和一个副本： 1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 现在我们可以运行list（列表）命令来查看这个topic： 12bin/kafka-topics.sh --list --zookeeper localhost:2181test 或者，您也可将代理配置为：在发布的topic不存在时，自动创建topic，而不是手动创建。 发送消息 Kafka自带一个命令行客户端，它从文件或标准输入中获取输入，并将其作为message（消息）发送到Kafka集群。默认情况下，每行将作为单独的message发送。 运行 producer，然后在控制台输入一些消息以发送到服务器。 123bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&gt;This is a message&gt;This is another message 启动一个consumer Kafka 还有一个命令行consumer（消费者），将消息转储到标准输出。 123bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningThis is a messageThis is another message 如果您将上述命令在不同的终端中运行，那么现在就可以将消息输入到生产者终端中，并将它们在消费终端中显示出来。 所有的命令行工具都有其他选项；运行不带任何参数的命令将显示更加详细的使用信息。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"}],"author":null},{"title":"kafka入门安装教程_ubuntu安装kafka","slug":"kafka/kafka入门安装教程_ubuntu安装kafka","date":"2025-07-29T02:01:53.000Z","updated":"2025-07-29T02:11:41.732Z","comments":true,"path":"2025/07/29/kafka/kafka入门安装教程_ubuntu安装kafka/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/kafka/kafka%E5%85%A5%E9%97%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B_ubuntu%E5%AE%89%E8%A3%85kafka/","excerpt":"","text":"一、安装前准备 安装Java环境 Kafka依赖Java运行，推荐安装OpenJDK 8或11： 12sudo apt updatesudo apt install openjdk-11-jdk # 或 openjdk-8-jdk 验证安装： 1java -version 配置环境变量（如未自动配置）： 12echo &#x27;export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64&#x27; &gt;&gt; ~/.bashrc # 根据实际路径调整source ~/.bashrc 创建专用用户（可选） 为安全起见，建议创建独立用户运行Kafka： 1234sudo useradd -m kafkasudo passwd kafkasudo adduser kafka sudosu - kafka # 切换到kafka用户 二、下载与安装Kafka 下载Kafka二进制包 访问Apache Kafka官网选择版本（推荐3.5.1或稳定版），下载并解压： 123wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgztar -xzf kafka_2.13-3.5.1.tgzmv kafka_2.13-3.5.1 ~/kafka 配置环境变量（可选） 将Kafka路径加入系统环境： 123echo &#x27;export KAFKA_HOME=~/kafka&#x27; &gt;&gt; ~/.bashrcecho &#x27;export PATH=$PATH:$KAFKA_HOME/bin&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc 三、配置与启动ZooKeeper 使用Kafka内置ZooKeeper Kafka自带ZooKeeper，适合单机测试： 12cd ~/kafkabin/zookeeper-server-start.sh -daemon config/zookeeper.properties # 后台启动 验证ZooKeeper是否运行： 1jps # 应显示QuorumPeerMain进程 独立安装ZooKeeper（可选） 若需独立部署，参考以下步骤： 下载并解压ZooKeeper 配置zoo.cfg文件（如数据目录和端口） 启动服务：bin/zkServer.sh start 四、配置与启动Kafka 修改Kafka配置文件 编辑~/kafka/config/server.properties： 12345broker.id=0 # 集群中唯一IDlisteners=PLAINTEXT://0.0.0.0:9092 # 允许外部访问log.dirs=/tmp/kafka-logs # 日志目录，建议修改为持久化路径zookeeper.connect=localhost:2181 # ZooKeeper地址delete.topic.enable=true # 允许删除主题 启动Kafka服务 1bin/kafka-server-start.sh -daemon config/server.properties # 后台启动 验证端口是否监听： 1netstat -tunlp | grep 9092 五、测试Kafka功能 创建测试主题 1bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic test-topic --partitions 1 --replication-factor 1 启动生产者与消费者 生产者： 1bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test-topic 消费者： 1bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning 输入消息后，消费者应能实时接收。 六、服务管理（Systemd集成） 创建Systemd服务文件 为ZooKeeper和Kafka分别创建服务： 1234567891011121314151617181920212223242526272829# ZooKeeper服务（/etc/systemd/system/zookeeper.service）[Unit]Requires=network.targetAfter=network.target[Service]Type=simpleUser=kafkaExecStart=~/kafka/bin/zookeeper-server-start.sh ~/kafka/config/zookeeper.propertiesExecStop=~/kafka/bin/zookeeper-server-stop.shRestart=on-failure[Install]WantedBy=multi-user.target# Kafka服务（/etc/systemd/system/kafka.service）[Unit]Requires=zookeeper.serviceAfter=zookeeper.service[Service]Type=simpleUser=kafkaExecStart=~/kafka/bin/kafka-server-start.sh ~/kafka/config/server.propertiesExecStop=~/kafka/bin/kafka-server-stop.shRestart=on-failure[Install]WantedBy=multi-user.target 启用服务： 123sudo systemctl daemon-reloadsudo systemctl start kafkasudo systemctl enable kafka 七、常见问题与优化 内存不足错误 修改bin/kafka-server-start.sh中的堆内存参数： 1export KAFKA_HEAP_OPTS=&quot;-Xmx256M -Xms128M&quot; # 根据机器配置调整 防火墙配置 开放ZooKeeper（2181）和Kafka（9092）端口： 12sudo ufw allow 2181/tcpsudo ufw allow 9092/tcp 集群部署（可选） 修改server.properties中的broker.id、listeners和advertised.listeners，确保各节点ZooKeeper连接一致。 八、扩展工具（可选） KafkaT：通过Ruby Gem安装，用于集群管理： 12sudo apt install ruby ruby-devsudo gem install kafkat 通过以上步骤，您可以在Ubuntu系统上完成Kafka的安装与基础配置。如需更详细配置（如SSL加密、监控工具），请参考Kafka官方文档或相关来源。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"}],"author":"yyeare"},{"title":"Windows 下 Kafka 安装教程","slug":"kafka/Windows下Kafka安装教程","date":"2025-07-29T01:29:11.000Z","updated":"2025-07-29T02:01:29.123Z","comments":true,"path":"2025/07/29/kafka/Windows下Kafka安装教程/","link":"","permalink":"http://www.formeasy.cc/2025/07/29/kafka/Windows%E4%B8%8BKafka%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、准备工作 ✅ 1. 安装 Java JDK（Kafka 依赖 Java 运行环境） Kafka 是基于 Java 的，必须先安装 JDK。一般学到kafka的同学肯定已经安装好了JDK了，这一步我就不写了，具体可以参考其他文章。 ⚠️ 注意：Kafka 3.9.0 要求本地必须安装 JDK 17 或以上版本。JDK 8 和 11 已不再被官方支持。 步骤： 访问官网下载 OpenJDK 或 Oracle JDK。 推荐版本：JDK 8 ~ JDK 17（Kafka 3.x 支持到 JDK 17） Kafka需要的JDK版本！ 安装完成后设置环境变量： JAVA_HOME：指向 JDK 安装目录，例如 C:\\Program Files\\Java\\jdk-17.0.1 Path 中添加 %JAVA_HOME%\\bin 验证是否安装成功： 12java -versionjavac -version 二、下载 Kafka 访问 Apache Kafka 官网下载页面： 🔗 https://kafka.apache.org/downloads 选择最新的稳定版本，例如： 1Latest release: kafka_2.13-3.9.0.tgz Windows 用户选择 kafka_2.13-3.9.0.tgz 即可，Scala 版本不影响你在 Windows 上运行 Kafka。除非你自己用 Scala 编写客户端程序，否则任意版本都可以。社区推荐使用 2.13，因此建议你就选这个版本。 ✅ 注意：Windows 上使用的是 Kafka 自带的 windows 脚本，不需要 Linux 工具支持。 三、解压 Kafka 虽然 Kafka 是为 Linux 设计的，但官方提供了部分 Windows 兼容脚本（位于 bin/windows/ 目录下），所以你可以放心地： 使用 zookeeper-server-start.bat 使用 kafka-server-start.bat 创建 Topic、发送和消费消息等操作都正常运行 只是要注意以下几点： 注意事项 说明 路径不要有空格或中文 推荐安装路径如 F:\\kafka_2.13-3.9.0 日志文件位置 默认在 logs/ 目录下 性能略差于 Linux 本地开发没问题，生产建议用 Linux 不支持某些高级功能 如 log.dirs 中使用多个磁盘路径（Windows 下可能出错） Kafka配置（kafka-logs的新建必要！！） 这个文件主要是存放分区的offerset，元文件，记录消费到哪里等等。 类型 存放内容 Topic 数据 每个 Topic 的分区数据都存在这里 Offset 信息 记录消费者组消费到的位置 元数据 分区状态、ISR（In-Sync Replicas）等 日志文件 controller.log、kafka-request.log 等 第一步：一定要需要建立一个空文件夹kafka-logs在bin、config同级！！ 12345F:\\kafka_2.13-3.9.0\\├── bin/├── config/├── logs/└── kafka-logs/ ← 新建这个文件夹 第二步：编辑\\kafka_2.13-3.9.0\\config下的server.properties文件 1log.dirs=/kafka-logs 除了 log.dirs，还有几个常用配置项也建议了解一下，其他改不改不影响基本使用： 配置项 默认值 说明 broker.id 0 Kafka 实例的唯一 ID，单机版保持默认即可 listeners PLAINTEXT://:9092 Kafka 监听地址，默认本地访问 num.partitions 1 默认每个 topic 创建的分区数 log.retention.hours 168 (7天) 消息保留时间 log.segment.bytes 1GB 单个日志文件大小上限 message.max.bytes 1MB 最大消息体大小（生产环境可调大） 完整配置样例（适合 Windows 单节点开发，不必要，默认也可） 123456789101112broker.id=0listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://localhost:9092log.dirs=F:/kafka_2.13-3.9.0/kafka-logsnum.partitions=1log.retention.hours=168log.segment.bytes=1073741824message.max.bytes=10485880replica.lag.time.ms=10000offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1 四、启动 Kafka与关闭Kafka（比较麻烦，需要打开多窗口执行） ✅ 1. 启动 ZooKeeper Kafka 依赖 ZooKeeper 存储元数据信息。 打开 CMD，进入 Kafka 目录： 1cd F:\\kafka_2.13-3.9.0 执行以下命令启动 ZooKeeper： 1.\\bin\\windows\\zookeeper-server-start.bat .\\config\\zookeeper.properties ✅ 成功标志：看到类似 INFO ... Starting zookeeper version... 的日志输出。 问题描述 有时zooKeeper报错:ZooKeeper audit is disabled. [2023-02-18 12:17:27,368] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider) 原因分析： zookeeper设置参数问题 解决方案： 修改kafka安装目录下config文件中的zookeeper.properties文件 在文件中将false改为true，没有的话就添加下面语句 1audit.enable=true [2023-02-18 12:17:27,368] INFO ZooKeeper audit is enabled.(org.apache.zookeeper.audit.ZKAuditProvider) ✅ 2. 启动 Kafka 保持上一个窗口不要关闭，再打开一个新的 CMD 窗口，同样进入 Kafka 目录： 执行： 1.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties ✅ 成功标志：看到 INFO [KafkaServer id=0] started (kafka.server.KafkaServer) 成功启动kafka图 ✅ 步骤 3：关闭 Kafka 进入 Kafka 目录： 1.\\bin\\windows\\kafka-server-stop.bat 你会看到 Kafka 开始安全退出，等待几秒后自动结束。 ✅ 步骤 4：关闭 ZooKeeper 继续在当前 CMD 窗口中执行： 1.\\bin\\windows\\zookeeper-server-stop.bat ZooKeeper 也会优雅退出。 五、创建 Topic 新打开一个 CMD 窗口，创建一个测试用的 Topic： 1.\\bin\\windows\\kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 参数说明： --topic：Topic 名称 --partitions：分区数 --replication-factor：副本数（本地开发设为 1 即可） 查看已创建的 Topic： 1.\\bin\\windows\\kafka-topics.bat --list --bootstrap-server localhost:9092 六、发送消息（Producer） 打开一个新 CMD 窗口，运行生产者控制台： 1.\\bin\\windows\\kafka-console-producer.bat --topic test-topic --bootstrap-server localhost:9092 输入任意文字后按回车即可发送消息，比如： 12&gt;Hello Kafka!&gt;This is a test message. 七、消费消息（Consumer） 再新开一个 CMD 窗口，运行消费者控制台： 1.\\bin\\windows\\kafka-console-consumer.bat --topic test-topic --from-beginning --bootstrap-server localhost:9092 你会看到刚刚发送的消息被打印出来！ 八、Windows 下如何正确启动和关闭 Kafka？ ⚠️ 不要直接关闭 CMD 窗口也不要ctrl + c，都是强制关机！再次启动可能会有很多bug！ 一定要使用官方的启动和关闭脚本！！！bug血泪！ 因为： Ctrl + C 是发送 SIGINT 信号，Kafka 和 ZooKeeper 会尝试优雅关闭，但不一定能完成全部清理工作 如果用户误操作、窗口被意外关闭、或脚本中断，会导致： .lock 文件残留 controller.log 重命名失败 ZooKeeper 节点未清除 Kafka Broker 状态未更新 九、推荐脚本（自动化启停） 为了方便你以后快速操作，我为你写好了两个批处理脚本： 放在同级目录下即可！ ✅ 启动脚本：start-kafka.bat 123456789101112131415161718192021222324252627282930313233@echo offchcp 65001 &gt; nulTITLE Kafka 启动器 - kafka_2.13-3.9.0​SETLOCAL​set KAFKA_HOME=F:\\kafka_2.13-3.9.0​if not exist &quot;%KAFKA_HOME%&quot; ( echo ❌ 错误：KAFKA_HOME 路径不存在: %KAFKA_HOME% pause exit /b 1)​cd /d %KAFKA_HOME%​:: 清理锁文件（防止上次异常退出导致冲突）if exist &quot;logs\\*.lock&quot; del /Q &quot;logs\\*.lock&quot;if exist &quot;logs\\*.pid&quot; del /Q &quot;logs\\*.pid&quot;​:: 启动 ZooKeeperecho ▶️ 正在启动 ZooKeeper...start &quot;ZooKeeper&quot; /D &quot;%KAFKA_HOME%&quot; call bin\\windows\\zookeeper-server-start.bat config\\zookeeper.properties​:: 等待初始化完成timeout /t 7 &gt; NUL​:: 启动 Kafkaecho ▶️ 正在启动 Kafka Server...call bin\\windows\\kafka-server-start.bat config\\server.properties​echo ✅ Kafka 已成功启动！pause ✅ 关闭脚本：stop-kafka.bat 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@echo offchcp 65001 &gt; nulTITLE Kafka 关闭器 - kafka_2.13-3.9.0​SETLOCAL​set KAFKA_HOME=F:\\kafka_2.13-3.9.0​if not exist &quot;%KAFKA_HOME%&quot; ( echo ❌ 错误：KAFKA_HOME 路径不存在: %KAFKA_HOME% pause exit /b 1)​cd /d %KAFKA_HOME%​:: 停止 Kafkaecho ⏹️ 正在尝试优雅地停止 Kafka...call &quot;%KAFKA_HOME%\\bin\\windows\\kafka-server-stop.bat&quot;​:: 等待 Kafka 进程结束call :wait_for_process_exit &quot;kafka&quot; 30if errorlevel 1 ( echo ⚠️ Kafka 进程未能在指定时间内退出，请检查日志或手动终止。)​:: 停止 ZooKeeperecho ⏹️ 正在尝试优雅地停止 ZooKeeper...call &quot;%KAFKA_HOME%\\bin\\windows\\zookeeper-server-stop.bat&quot;​:: 等待 ZooKeeper 进程结束call :wait_for_process_exit &quot;zookeeper&quot; 30if errorlevel 1 ( echo ⚠️ ZooKeeper 进程未能在指定时间内退出，请检查日志或手动终止。)​echo ✅ Kafka 和 ZooKeeper 已尝试优雅关闭。pauseexit /b 0​​:: ============ 函数区 ============​:: 等待指定关键字的 Java 进程退出:wait_for_process_exitsetlocalset keyword=%~1set timeout=%~2set count=0​echo 🔍 正在等待 [%keyword%] 进程退出，最多等待 %timeout% 秒...​:looptasklist | findstr /i java &gt;nul &amp;&amp; ( tasklist | findstr /i %keyword% &gt;nul &amp;&amp; ( if %count% lss %timeout% ( timeout /t 1 &gt;nul set /a count+=1 goto loop ) else ( endlocal exit /b 1 ) ))​endlocalexit /b 0 优雅地关闭Kafka 十、常见问题与解决方案 问题 可能原因 解决方案 Address already in use 上次未正常关闭 Kafka 或 ZooKeeper 使用 stop-kafka.bat 关闭服务，或重启电脑 Node does not exist ZooKeeper 没有正确启动 确保 ZooKeeper 启动后再启动 Kafka Class 'kafka.Kafka' could not be found 路径错误或 JDK 版本不对 检查 JAVA_HOME 是否设置正确 找不到或无法加载主类 Kafka 路径包含中文或空格 将 Kafka 安装到英文路径下","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"}],"author":"KeyandL"},{"title":"使用Python操作Neo4j","slug":"Neo4j/使用Python操作Neo4j","date":"2025-07-28T08:31:11.000Z","updated":"2025-07-28T08:45:34.712Z","comments":true,"path":"2025/07/28/Neo4j/使用Python操作Neo4j/","link":"","permalink":"http://www.formeasy.cc/2025/07/28/Neo4j/%E4%BD%BF%E7%94%A8Python%E6%93%8D%E4%BD%9CNeo4j/","excerpt":"","text":"一、基础环境准备 1.1 创建 Conda 虚拟环境 打开终端/命令行，输入： 1conda create -n neo4j_env python=3.11 -y -n neo4j_env：环境名称（可自定义，如 my_neo4j_env）。 python=3.11.0：指定 Python 版本（本次采用3.11.0）。 -y：自动确认安装依赖。 激活环境 1conda activate neo4j_env # Windows/macOS/Linux 通用命令 1.2 安装 Py2neo 库 安装最新py2neo版本的命令： 12# 或安装最新版（适合 Neo4j 5.x）pip install py2neo 1.3 验证安装 在 Python 交互环境中测试： 123456from py2neo import __version__print(&quot;Py2neo 版本:&quot;, __version__) # 应显示安装版本号# 连接 Neo4j 测试（确保本地 Neo4j 服务已启动）from py2neo import Graphgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;你的密码&quot;))print(graph.run(&quot;RETURN &#x27;连接成功&#x27;&quot;).data()) 可以看到，已经成功连接neo4j数据库。 二、neo4j的基础语法 2.1 创建节点与关系 2.1.1 创建节点 创建一个Person的节点，名字是Alice。相当于Alice被划分为Person这个类别。 对于Person节点，有name和age两个属性。 12345678910from py2neo import Graph, Node# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 创建节点node = Node(&quot;Person&quot;, name=&quot;Alice&quot;, age=30)graph.create(node) 在neo4j内，每一个点称作一个实体(节点)，Alice就是一个实体，拥有age和name两个属性。 2.1.2 创建关系 在此之前，我们先清空neo4j内的所有数据，使用以下CQL语句： 12MATCH (n)DETACH DELETE n 清除之后，数据库内再无任何实体。 然后，我们开始创建Alice与Bob的关系，设定他们是朋友关系，指向关系为：alice-&gt;bob；since表示朋友关系的开始时间。 创建代码如下： 123456789101112from py2neo import Graph, Node, NodeMatcher,Relationship# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 创建节点间关系alice = Node(&quot;Person&quot;, name=&quot;Alice&quot;)bob = Node(&quot;Person&quot;, name=&quot;Bob&quot;)relation = Relationship(alice, &quot;FRIEND&quot;, bob, since=2025)graph.create(relation) # 提交关系 2.1.3 注意事项 重复执行创建关系，并不会覆盖，而是会新建节点与关系。 我们再次执行2.1.2的代码，可以看到Alice和Bob再次形成新的实体，且id是不一样的。 2.2 merge的使用 2.2.1 注意事项graph.create()的缺点 在通过graph.create()进行节点、关系创建时，多次执行后，我们会重复创建相同的节点与关系。 实际上，多数情况下，这并不是我们想要的结果，我们想要的是即使多次执行，仍然只创建一组实体。 对于此，我们可以采用merge函数来解决这个问题。 2.2.2 merge的效果 存在则匹配：若指定模式已存在，则直接匹配并返回结果。 不存在则创建：若模式不存在，则创建该模式的所有元素（节点、关系及属性）。 在py2neo中，merge 会检查实体的 is_bound 状态（是否已绑定到数据库）。若实体未绑定（即未预先提交），则会自动创建并绑定实体，再创建关系。 简单来说，若实体存在，就不再次创建实体，直接创建关系；如果不存在，就先创建实体再创建关系。 2.2.3 merge的python代码 1234567891011121314from py2neo import Graph, Node, NodeMatcher,Relationship# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 创建节点间关系alice = Node(&quot;Person&quot;, name=&quot;Alice&quot;)bob = Node(&quot;Person&quot;, name=&quot;Bob&quot;)relation = Relationship(alice, &quot;FRIEND&quot;, bob, since=2026)graph.merge(alice,&quot;Person&quot;,&quot;name&quot;) # 提交节点graph.merge(bob,&quot;Person&quot;,&quot;name&quot;) # 提交节点graph.merge(relation,&quot;Person&quot;,&quot;name&quot;) # 提交关系 即使我们多次执行此代码，也仅形成一个实体关系对。 2.3 实体的查询 2.3.1 查询节点 通过NodeMatcher去匹配节点。 1234567891011121314from py2neo import Graph, Node, NodeMatcher,Relationship,RelationshipMatcher# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 使用NodeMatchermatcher = NodeMatcher(graph)# 匹配name=Alice的节点result = matcher.match(&quot;Person&quot;).where(&quot;_.name = &#x27;Alice&#x27;&quot;).all()print(result) 2.3.2 查询关系 通过RelationshipMatcher去匹配关系。 12345678910111213from py2neo import Graph, Node, NodeMatcher,Relationship,RelationshipMatcher# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 使用RelationshipMatcherrel_matcher = RelationshipMatcher(graph)relations = rel_matcher.match(r_type=&quot;FRIEND&quot;).all()print(relations) 2.4 删除实体与关系 2.4.1 删除实体 通过graph.delete()删除指定实体，当实体被删除后，其关系将自动被删除。 本质：匹配到指定节点，然后用delete删除。 12345678910111213from py2neo import Graph, Node, NodeMatcher,Relationship# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 按条件删除节点matcher = NodeMatcher(graph)# 匹配第一个Alice的Person节点node = matcher.match(&quot;Person&quot;, name=&quot;Alice&quot;).first()if node: graph.delete(node) # 自动删除关联关系 在删除Alice实体后，Alice实体的关系也被删除，仅保留Bob实体。 2.4.2 删除关系 通过graph.delete()删除指定关系，实体会被保留。 本质：匹配到指定关系，然后用delete删除。 123456789101112131415from py2neo import Graph, Node, NodeMatcher,Relationship,RelationshipMatcher# 连接 Docker 内的 Neo4jgraph = Graph(&quot;bolt://localhost:7687&quot;, auth=(&quot;neo4j&quot;, &quot;neo4j1234&quot;))# 删除特定关系rel_matcher = RelationshipMatcher(graph)# 匹配FRIEND的关系relation = rel_matcher.match(r_type=&quot;FRIEND&quot;).first()if relation: graph.separate(relation) # 仅删除关系，保留节点 可以看到，实体间关系被删除，但是实体得以保留。 2.4.3 删除所有数据 graph.delete_all()可以删除数据库内所有数据，一定要慎用。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"http://www.formeasy.cc/tags/Neo4j/"}],"author":"作者：Python伊甸园"},{"title":"Neo4j 入门级使用_neo4j使用教程","slug":"Neo4j/Neo4j 入门级使用_neo4j使用教程","date":"2025-07-28T08:22:02.000Z","updated":"2025-07-28T08:45:16.780Z","comments":true,"path":"2025/07/28/Neo4j/Neo4j 入门级使用_neo4j使用教程/","link":"","permalink":"http://www.formeasy.cc/2025/07/28/Neo4j/Neo4j%20%E5%85%A5%E9%97%A8%E7%BA%A7%E4%BD%BF%E7%94%A8_neo4j%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、集成步骤 （一）创建 Spring Boot 项目 使用 Spring Initializr 创建项目时，选择 Maven 或 Gradle 作为项目构建工具，选择合适的 Spring Boot 版本，并添加 “Spring Data Neo4j” 依赖。 （二）添加依赖 若使用 Maven，在 pom.xml 文件中添加以下代码： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-neo4j&lt;/artifactId&gt;&lt;/dependency&gt; （三）配置 Neo4j 连接信息 在 application.properties 或 application.yml 文件中配置 Neo4j 数据库的连接信息。如使用 application.properties 文件，可按以下格式配置： 123spring.data.neo4j.uri=bolt://localhost:7687spring.data.neo4j.username=neo4jspring.data.neo4j.password=123456 二、实体类定义 （一）节点实体类 使用 @Node 注解定义节点实体类。例如： 1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.springframework.data.neo4j.core.schema.GeneratedValue;import org.springframework.data.neo4j.core.schema.Id;import org.springframework.data.neo4j.core.schema.Node; @Nodepublic class Person &#123; @Id @GeneratedValue private Long id; private String name; private int age; // 空构造方法、带参数构造方法、getter 和 setter 方法 public Person() &#123;&#125; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; // getter 和 setter 方法 public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; （二）关系实体类 使用 @Relationship 注解定义关系实体类。例如： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import org.springframework.data.neo4j.core.schema.GeneratedValue;import org.springframework.data.neo4j.core.schema.Id;import org.springframework.data.neo4j.core.schema.Node;import org.springframework.data.neo4j.core.schema.Relationship; @Nodepublic class Movie &#123; @Id @GeneratedValue private Long id; private String title; private String genre; // 空构造方法、带参数构造方法、getter 和 setter 方法 public Movie() &#123;&#125; public Movie(String title, String genre) &#123; this.title = title; this.genre = genre; &#125; // getter 和 setter 方法 public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getGenre() &#123; return genre; &#125; public void setGenre(String genre) &#123; this.genre = genre; &#125; // 定义从 Movie 到 Person 的关系（演员参演） @Relationship(type = &quot;ACTED_IN&quot;, direction = Relationship.Direction.INCOMING) private Person actor; public Person getActor() &#123; return actor; &#125; public void setActor(Person actor) &#123; this.actor = actor; &#125;&#125; 三、仓库接口 创建一个仓库接口来操作节点实体类。例如： 123456import org.springframework.data.neo4j.repository.Neo4jRepository; public interface PersonRepository extends Neo4jRepository&lt;Person, Long&gt; &#123; // 自定义查询方法示例：根据姓名查询 Person findByName(String name);&#125; 四、服务层 创建一个服务类来调用仓库接口的方法。例如： 1234567891011121314151617181920212223import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service; @Servicepublic class PersonService &#123; @Autowired private PersonRepository personRepository; // 保存 Person public Person savePerson(Person person) &#123; return personRepository.save(person); &#125; // 根据姓名查询 Person public Person findPersonByName(String name) &#123; return personRepository.findByName(name); &#125; // 删除所有 Person public void deleteAllPersons() &#123; personRepository.deleteAll(); &#125;&#125; 五、控制器 创建一个控制器类来处理 HTTP 请求，并调用服务层的方法。例如： 123456789101112131415161718192021222324252627import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*; @RestController@RequestMapping(&quot;/persons&quot;)public class PersonController &#123; @Autowired private PersonService personService; // 添加 Person @PostMapping public Person addPerson(@RequestBody Person person) &#123; return personService.savePerson(person); &#125; // 根据姓名查询 Person @GetMapping(&quot;/&#123;name&#125;&quot;) public Person getPersonByName(@PathVariable String name) &#123; return personService.findPersonByName(name); &#125; // 删除所有 Person @DeleteMapping public void deleteAllPersons() &#123; personService.deleteAllPersons(); &#125;&#125; 六、运行项目 启动 Spring Boot 应用程序后，可以通过 RESTful API 来操作 Neo4j 数据库。 七、Neo4j 的详细使用 （一）基本操作 1. 创建节点 在 Neo4j Browser 中，可以使用 Cypher 查询语言创建节点。例如： 12CREATE (p:Person &#123;name: &quot;John Doe&quot;, age: 30&#125;)CREATE (m:Movie &#123;title: &quot;The Matrix&quot;, genre: &quot;Science Fiction&quot;&#125;) 2. 查询节点 查询所有 Person 节点： 1MATCH (p:Person) RETURN p 查询特定条件的节点： 1MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;) RETURN p 3. 更新节点 更新节点的属性： 123MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;)SET p.age = 31RETURN p 4. 删除节点 删除节点： 12MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;)DETACH DELETE p （二）关系操作 1. 创建关系 创建两个节点之间的关系： 123MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;), (m:Movie &#123;title: &quot;The Matrix&quot;&#125;)CREATE (p)-[r:ACTED_IN]-&gt;(m)RETURN r 2. 查询关系 查询特定的关系： 123MATCH (p:Person)-[r:ACTED_IN]-&gt;(m:Movie)WHERE p.name = &quot;John Doe&quot; AND m.title = &quot;The Matrix&quot;RETURN r 3. 更新关系 更新关系的属性： 123MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;)-[r:ACTED_IN]-&gt;(m:Movie &#123;title: &quot;The Matrix&quot;&#125;)SET r.role = &quot;Lead Actor&quot;RETURN r 4. 删除关系 删除关系： 12MATCH (p:Person &#123;name: &quot;John Doe&quot;&#125;)-[r:ACTED_IN]-&gt;(m:Movie &#123;title: &quot;The Matrix&quot;&#125;)DELETE r （三）其他操作 1. 图查询 查询路径： 12MATCH path = (p:Person)-[*]-(m:Movie)RETURN path 查询最短路径： 1234MATCH (start:Person &#123;name: &quot;John Doe&quot;&#125;), (end:Movie &#123;title: &quot;The Matrix&quot;&#125;)CALL algo.shortestPath.stream(start, end, &quot;ACTED_IN&quot;)YIELD nodeIdsRETURN nodeIds 2. 图分析 计算节点的度数中心性： 1234MATCH (p:Person)-[r:ACTED_IN]-&gt;(m:Movie)WITH p, COUNT(r) AS degreeRETURN p, degreeORDER BY degree DESC 计算节点的 PageRank： 1234CALL gds.pageRank.stream(&#x27;person-movie-graph&#x27;)YIELD nodeId, scoreRETURN gds.util.asNode(nodeId).name AS name, scoreORDER BY score DESC 以上是 Spring Boot 集成 Neo4j 以及 Neo4j 的详细使用方法，通过这些步骤和操作，你可以方便地在 Spring Boot 项目中使用 Neo4j 数据库来存储和查询图数据。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"http://www.formeasy.cc/tags/Neo4j/"}],"author":"weixin_45737215"},{"title":"图数据库Neo4j和JDK安装与配置教程（超详细）","slug":"Neo4j/图数据库Neo4j和JDK安装与配置教程（超详细）","date":"2025-07-28T08:15:33.000Z","updated":"2025-07-28T08:45:57.273Z","comments":true,"path":"2025/07/28/Neo4j/图数据库Neo4j和JDK安装与配置教程（超详细）/","link":"","permalink":"http://www.formeasy.cc/2025/07/28/Neo4j/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93Neo4j%E5%92%8CJDK%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B%EF%BC%88%E8%B6%85%E8%AF%A6%E7%BB%86%EF%BC%89/","excerpt":"","text":"前言 Neo4j作为目前比较流行的图数据库，在知识图谱等领域有较多应用。本文将详细介绍Windows系统下Neo4j图数据库的安装与配置。 Neo4j 是基于Java的图数据库，其运行时需要 Java 运行时环境（JRE）来启动 JVM 进程，而 JDK 包含了 JRE 以及开发工具，因此安装 JDK 是必要的。 一、Java环境配置 （一）JDK的下载与安装 首先，访问Oracle官方JDK下载页面，根据要安装的Neo4j版本选择匹配的JDK版本。 Windows环境下Neo4j与JDK版本的对应关系Neo4j版本JDK版本3.584.0114.1114.2114.3114.411517 下载地址：Java Downloads | Oracle，因为我接下来要使用的版本是neo4j-community-5.18.1，所以选择下载JDK17。 下载完成后，双击运行安装程序 。 1.点击下一步。 2.更改自己的安装位置（注意：不要把安装包和安装程序放在同一个文件夹里面）点击下一步。 3.安装完成。 （二）JDK环境配置 右击此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量。 新建环境变量 变量名 ：JAVA_HOME 变量值：你刚才安装JDK的地址 双击Path，进入Path内部添加环境变量 由于JDK17在我们安装的时候可能会自动进行环境变量配置，我们需要在环境变量配置PATH中删除如下信息： （三）检测JDK17是否配置成功 快捷键win+R，然后输入cmd，点击确定。 输入java -version 看看是不是出现以下信息，如果出现以下信息即表示安装成功。 二、Neo4j的安装与配置 （一）Neo4j的下载与安装 下载地址：Index of /doc/neo4j/ 下载所需版本的neo4j的zip文件之后，将该文件移动到想要安装的位置后直接解压即可。 （二）Neo4j环境变量配置 同样右击此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量。 和JDK环境配置一样，双击Path。 将neo4j的bin目录复制进来。 （三）检查Neo4j是否配置完成 快捷键win+R，然后输入cmd，点击确定。 输入：neo4j console，当末行出现Started，即说明配置成功。 在浏览器中访问：http://localhost:7474/， 会出现登录页，默认的账号和密码都是 neo4j，登陆后需要修改密码。 Neo4j的使用 一、在前台运行 在终端中输入：neo4j console，接着访问： http://localhost:7474/ 即可。 所谓【前台运行】是指：当终端关闭后，neo4j服务也会随之停止。 二、在后台运行 想要让neo4j在关闭终端后仍然保持运行，需要先将neo4j注册为一个Windows服务，然后使用neo4j start 启动服务。想要关闭neo4j服务，只需在终端中输入 neo4j stop 命令即可。 以下是常用命令，均在cmd终端中输入。 首先进入neo4j的bin目录。 cd E:\\APP\\neo4j\\neo4j-community-5.18.1\\bin 输入neo4j windows-service install，会出现一个弹窗，点击是就可以了。 输入neo4j start，会出现弹窗点击是即可，然后访问http://localhost:7474。 现在无需在终端输入neo4j console即可访问 http://localhost:7474/了。 要想关闭服务，输入neo4j stop即可。 查看服务状态：输入neo4j status。 大功告成！加油 ~","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"http://www.formeasy.cc/tags/Neo4j/"}],"author":"m0_62975468"},{"title":"用Python爬取百度图片：手把手教你写一个图片爬虫","slug":"Python/用Python爬取百度图片：手把手教你写一个图片爬虫","date":"2025-07-28T01:44:49.000Z","updated":"2025-07-28T03:19:41.553Z","comments":true,"path":"2025/07/28/Python/用Python爬取百度图片：手把手教你写一个图片爬虫/","link":"","permalink":"http://www.formeasy.cc/2025/07/28/Python/%E7%94%A8Python%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E5%9B%BE%E7%89%87%EF%BC%9A%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E4%B8%80%E4%B8%AA%E5%9B%BE%E7%89%87%E7%88%AC%E8%99%AB/","excerpt":"","text":"前言 最近想收集一些特定主题的图片素材，手动一张张下载实在太费时间了。作为一个懒人程序员，我决定写个爬虫来自动完成这个任务。今天就跟大家分享这个实用的百度图片爬虫，它能自动搜索并下载你想要的任何图片。 这个爬虫虽然只有100多行代码，但包含了请求处理、JSON解析、文件操作等实用技巧。我会详细解释每个部分的实现思路，让你不仅能使用这个爬虫，还能真正理解它的工作原理。 爬虫整体设计 我们先来看看这个爬虫的总体结构： 123456789101112131415class BaiduImageSpider(object): def __init__(self): # 初始化代码 def create_directory(self, name): # 创建保存图片的文件夹 def get_image_link(self, url): # 获取图片链接 def save_image(self, img_link, filename): # 下载并保存图片 def run(self): # 主运行逻辑 这个类包含了爬虫的所有功能，结构清晰，每个方法负责一个具体的任务。接下来我会详细讲解每个部分的实现。 初始化设置 12345678910def __init__(self): self.json_count = 0 self.url = &#x27;https://image.baidu.com/search/acjson?tn=resultjson_com&amp;ipn=rj&amp;queryWord=&#123;&#125;&amp;word=&#123;&#125;&amp;pn=&#123;&#125;&amp;rn=30&#x27; self.directory = r&quot;C:\\价值一个亿\\python-mini-projects\\projects\\baidutupian\\&#123;&#125;&quot; self.header = &#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;, &#x27;Accept-Language&#x27;: &#x27;en-US,en;q=0.5&#x27;, &#x27;Referer&#x27;: &#x27;https://image.baidu.com&#x27; &#125; self.image_counter = 0 # 新增全局图片计数器 初始化方法中，我们设置了几个重要的变量： json_count：控制要下载多少组图片（每组30张） url：百度图片的API接口地址，使用格式化字符串方便后续替换关键词 directory：图片保存路径，使用&#123;&#125;作为占位符方便后续替换 header：请求头，模拟浏览器访问，避免被反爬 image_counter：图片计数器，用于生成唯一的文件名 创建保存目录 1234def create_directory(self, name): self.directory = self.directory.format(name) os.makedirs(self.directory, exist_ok=True) self.directory += r&#x27;\\&#123;&#125;&#x27; 这个方法负责创建保存图片的文件夹： 使用format方法将搜索关键词插入到路径中 os.makedirs创建目录，exist_ok=True表示如果目录已存在也不报错 最后在路径后添加\\&#123;&#125;，方便后续格式化文件名 获取图片链接 12345678910111213def get_image_link(self, url): try: response = requests.get( url, headers=self.header, proxies=&#123;&quot;http&quot;: None, &quot;https&quot;: None&#125;, timeout=10 ) response.raise_for_status() return [item[&#x27;thumbURL&#x27;] for item in response.json().get(&#x27;data&#x27;, []) if &#x27;thumbURL&#x27; in item] except Exception as e: print(f&quot;获取图片链接失败: &#123;e&#125;&quot;) return [] 这是爬虫的核心方法之一，负责从百度API获取图片链接： 使用requests.get发送HTTP请求 设置了请求头和代理（这里禁用了代理） 添加了10秒超时设置 raise_for_status()会在请求失败时抛出异常 使用列表推导式从返回的JSON中提取所有thumbURL字段 添加了异常处理，失败时打印错误信息并返回空列表 下载并保存图片 123456789101112131415def save_image(self, img_link, filename): try: res = requests.get( img_link, headers=self.header, proxies=&#123;&quot;http&quot;: None, &quot;https&quot;: None&#125;, timeout=10 ) res.raise_for_status() with open(filename, &quot;wb&quot;) as f: f.write(res.content) print(f&quot;成功保存: &#123;filename&#125;&quot;) except Exception as e: print(f&quot;下载图片失败: &#123;e&#125;&quot;) 这个方法负责下载并保存图片： 同样使用requests.get获取图片内容 以二进制写入模式(wb)打开文件 直接将响应内容写入文件 添加了异常处理，下载失败时打印错误信息 主运行逻辑 12345678910111213141516def run(self): searchName = input(&quot;查询内容：&quot;) searchName_parse = parse.quote(searchName) self.create_directory(searchName) self.image_counter = 0 # 重置计数器 for index in range(self.json_count): pn = index * 30 request_url = self.url.format(searchName_parse, searchName_parse, str(pn)) links = self.get_image_link(request_url) for link in links: filename = os.path.join(self.directory.format(f&quot;&#123;self.image_counter&#125;.jpg&quot;)) # 使用全局计数器 self.save_image(link, filename) self.image_counter += 1 # 计数器递增 time.sleep(1) print(f&quot;&#123;searchName&#125;----图像下载完成---------&gt;&quot;) 这是爬虫的主控制流程： 获取用户输入的搜索关键词 对关键词进行URL编码 创建保存目录 重置图片计数器 循环获取多组图片（每组30张） 构建请求URL，pn参数控制分页 获取图片链接列表 逐个下载图片，文件名使用递增的数字 每次下载后暂停1秒，避免请求过于频繁 完成后打印提示信息 扩展思路 这个基础爬虫还可以进一步扩展： 支持更多搜索引擎：除了百度，还可以添加谷歌、必应等图片搜索的支持 图片筛选：根据大小、格式、颜色等条件筛选图片 去重功能：使用哈希值检查避免下载重复图片 断点续传：记录已下载的图片，程序中断后可以从中断处继续 GUI界面：使用PyQt或Tkinter添加图形界面，更方便非技术人员使用 完整代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import requestsimport jsonfrom urllib import parseimport osimport timeclass BaiduImageSpider(object): def __init__(self): self.json_count = 0 self.url = &#x27;https://image.baidu.com/search/acjson?tn=resultjson_com&amp;ipn=rj&amp;queryWord=&#123;&#125;&amp;word=&#123;&#125;&amp;pn=&#123;&#125;&amp;rn=30&#x27; self.directory = r&quot;C:\\价值一个亿\\python-mini-projects\\projects\\baidutupian\\&#123;&#125;&quot; self.header = &#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;, &#x27;Accept-Language&#x27;: &#x27;en-US,en;q=0.5&#x27;, &#x27;Referer&#x27;: &#x27;https://image.baidu.com&#x27; &#125; self.image_counter = 0 # 新增全局图片计数器 def create_directory(self, name): self.directory = self.directory.format(name) os.makedirs(self.directory, exist_ok=True) self.directory += r&#x27;\\&#123;&#125;&#x27; def get_image_link(self, url): try: response = requests.get( url, headers=self.header, proxies=&#123;&quot;http&quot;: None, &quot;https&quot;: None&#125;, timeout=10 ) response.raise_for_status() return [item[&#x27;thumbURL&#x27;] for item in response.json().get(&#x27;data&#x27;, []) if &#x27;thumbURL&#x27; in item] except Exception as e: print(f&quot;获取图片链接失败: &#123;e&#125;&quot;) return [] def save_image(self, img_link, filename): try: res = requests.get( img_link, headers=self.header, proxies=&#123;&quot;http&quot;: None, &quot;https&quot;: None&#125;, timeout=10 ) res.raise_for_status() with open(filename, &quot;wb&quot;) as f: f.write(res.content) print(f&quot;成功保存: &#123;filename&#125;&quot;) except Exception as e: print(f&quot;下载图片失败: &#123;e&#125;&quot;) def run(self): searchName = input(&quot;查询内容：&quot;) searchName_parse = parse.quote(searchName) self.create_directory(searchName) self.image_counter = 0 # 重置计数器 for index in range(self.json_count): pn = index * 30 request_url = self.url.format(searchName_parse, searchName_parse, str(pn)) links = self.get_image_link(request_url) for link in links: filename = os.path.join(self.directory.format(f&quot;&#123;self.image_counter&#125;.jpg&quot;)) # 使用全局计数器 self.save_image(link, filename) self.image_counter += 1 # 计数器递增 time.sleep(1) print(f&quot;&#123;searchName&#125;----图像下载完成---------&gt;&quot;)if __name__ == &#x27;__main__&#x27;: spider = BaiduImageSpider() spider.json_count = 10 # 下载10组图片 spider.run() 使用说明 安装依赖： 1pip install requests 运行方式： 直接运行：tupian.py 或者导入使用： if name == ‘main’: spider = BaiduImageSpider() spider.json_count = 10 # 下载10组图片 spider.run() 创建爬虫实例 设置json_count决定下载多少组图片（每组30张） 调用run()方法开始爬取 运行后会提示输入搜索关键词，然后就会自动下载图片到指定目录。 高级技巧 代理设置：如果需要使用代理，可以修改请求方法： 12345proxies = &#123; &#x27;http&#x27;: &#x27;http://your.proxy:port&#x27;, &#x27;https&#x27;: &#x27;http://your.proxy:port&#x27;&#125;response = requests.get(url, headers=self.header, proxies=proxies) 多线程下载：可以使用concurrent.futures实现： 1234from concurrent.futures import ThreadPoolExecutorwith ThreadPoolExecutor(max_workers=5) as executor: executor.map(self.save_image, links) 断点续传：记录已下载的URL，程序重启后跳过已下载的图片。 注意事项 请遵守百度的robots.txt协议，合理控制请求频率 不要用于商业用途，尊重图片版权 建议设置合理的json_count值，避免请求过多被封IP 下载失败时，程序会自动重试，但大量失败可能是触发了反爬机制 这个改进版的百度图片爬虫具有更好的稳定性、更详细的日志输出和更友好的使用体验。你可以根据自己的需求进一步扩展功能，比如添加图片去重、自动分类等功能。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":"qq_53544522"},{"title":"MySQL8.0.43保姆级安装教程","slug":"MySQL/MySQL8.0.43保姆级安装教程","date":"2025-07-28T01:40:12.000Z","updated":"2025-07-28T01:44:01.846Z","comments":true,"path":"2025/07/28/MySQL/MySQL8.0.43保姆级安装教程/","link":"","permalink":"http://www.formeasy.cc/2025/07/28/MySQL/MySQL8.0.43%E4%BF%9D%E5%A7%86%E7%BA%A7%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、下载 MySQL Installer 首先访问 MySQL 官方下载页面：点击链接 在页面中找到 MySQL Installer 8.0.43 部分。 二、安装包版本选择 页面中提供了两个安装包选项： 版本 大小 说明 mysql-installer-web-community-8.0.43.0.msi 2.1M 🌐 在线安装包 • 需要网络连接 • 安装时实时下载组件 • 文件小，下载快 mysql-installer-community-8.0.43.0.msi 354.3M 💿 离线安装包 • 无需网络连接 • 包含所有必要组件 • 文件大，但安装稳定 我们选择下载 354.3M 的离线版本，原因：安装过程更稳定,不依赖网络状况,包含完整组件,适合学习和开发环境 点击354.3M版本对应的Download按钮 跳转到登录页面后,点击No thanks,just start my download. 开始下载mysql-installer-community-8.0.43.0.msi文件 三、开始安装 3.1 运行安装程序 找到下载的 mysql-installer-community-8.0.43.0.msi 文件,双击运行,之后等待安装程序启动 3.2 选择安装类型 在安装向导中：选择 “Custom”（自定义） 安装类型,点击 【Next】 按钮（💡为什么选择自定义安装？可以选择具体安装的组件，可以自定义安装路径，避免安装不需要的组件） 3.3 选择 MySQL 组件 在左侧组件列表中，展开 “MySQL Servers”，找到 “MySQL Server 8.0.43 - X64”，点击右箭头 “&gt;” 将其添加到右侧安装列表 3.4 配置安装路径 在右侧列表中选中 MySQL Server 8.0.43 - X64 点击 Advanced Options按钮，修改安装路径： 点击 【OK】 确认 点击 【Next】 继续 3.5 处理依赖项 如果系统缺少 Microsoft Visual C++ Redistributable：在 “Check Requirements” 页面会显示缺少的组件，选中缺少的 Visual C++ Redistributable 项目，点击 【Execute】 开始安装 弹出安装对话框后，勾选 我同意许可条款和条件，点击 【安装】 按钮，等待安装完成，点击 【关闭】 按钮 注意：如果系统已安装 Visual C++ 组件，则不会出现此步骤 返回 MySQL 安装向导，点击 【Next】 继续 3.6 MySQL 服务配置 在 Installation 页面，点击 【Execute】 开始安装 MySQL，等待安装进度完成 点击 【Next】 继续 在 Product Configuration 页面，直接点击 【Next】 继续 在 Type and Networking 页面，保持默认设置： Config Type: Development Computer Port: 3306 X Protocol Port: 33060 点击 【Next】 继续 3.7 设置 Root 密码 在 Authentication Method 页面，选择 Use Strong Password Encryption for Authentication（RECOMMENDED），点击 【Next】 继续 在 Accounts and Roles 页面，设置 MySQL Root Password（根密码） 建议密码：root（仅用于学习环境） 生产环境请使用复杂密码 点击 【Next】 继续 在 Windows Service 页面，保持其他默认设置： ✅ Start the MySQL Server at System Startup ✅ Run Windows Service as Standard System Account 点击 【Next】 继续 在 Server File Permissions 页面，点击 【Next】 继续 在 Apply Configuration 页面，点击 【Execute】 应用所有配置，等待配置完成 点击 【Finish】 完成安装 四、环境变量配置 打开设置，搜索环境变量，点击编辑系统环境变量 点击环境变量按钮 在系统变量 中找到 Path 点击 编辑 添加 MySQL 路径，点击 新建，添加路径：C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin（根据你的实际安装路径），点击 【确定】 保存 关闭所有窗口，依次点击 【确定】 关闭所有对话框 五、安装验证 打开命令提示符：按 Win + R 键，输入 cmd 并按回车 测试 MySQL 命令： mysql --version 如果显示版本信息，说明环境变量配置成功。 连接 MySQL 服务器： mysql -u root -p 输入之前设置的密码（如：root） 测试数据库操作： SHOW DATABASES; EXIT;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"}],"author":"weixin_66401877"},{"title":"c++和python的互相调用","slug":"Python/c++和python的互相调用","date":"2025-07-22T07:01:02.000Z","updated":"2025-07-22T07:12:25.130Z","comments":true,"path":"2025/07/22/Python/c++和python的互相调用/","link":"","permalink":"http://www.formeasy.cc/2025/07/22/Python/c++%E5%92%8Cpython%E7%9A%84%E4%BA%92%E7%9B%B8%E8%B0%83%E7%94%A8/","excerpt":"","text":"前提 因项目需求，需要在C++中调用python，对这方面的一些工具做个简单的介绍。 ctypes ctypes 是 Python 的外部函数库。它提供了与 C 兼容的数据类型，并允许调用 DLL 或共享库中的函数。可使用该模块以纯 Python 形式对这些库进行封装。 上面是ctypes官方文档给出的介绍，通俗理解来说：ctypes可以加载动态链接库，然后以此调用动态链接库中的函数。也就是说，如果我们有一个.c文件，我们可以将它编译成库，然后在python代码里面使用ctypes加载调用它。 相关代码如下： 创建一个main.c文件，包括三个函数，等会我们要通过调用动态链接库的方式在python中调用这三个函数。 123456789101112131415// main.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int add(int a, int b) &#123; return a + b;&#125;int sum(int *a, int num)&#123; int sum = 0; for(int i=0; i&lt;num; i++)&#123; sum += a[i]; &#125; return sum;&#125; 将main.c编译为动态链接库mainlib.dll 1gcc -shared -o mainlib.dll main.c 现在我们的文件夹下便会多出一个mainlib.dll库文件，接下来我们在python中调用并且使用它。 12345678910111213# demo.pyimport ctypesfrom ctypes import *mainlib = ctypes.CDLL(&#x27;test/mainlib.dll&#x27;)a = ctypes.c_int(1)b = ctypes.c_int(2) print(mainlib.add(a,b))# 要想传入int类型的数组，就必须按照下面的方式先进行定义int_array = (c_int * 3)(1, 2, 3)num = ctypes.c_int(3)print(mainlib.sum(int_array, 3)) 总结: ctypes可以应用到在python中调用c函数，也就是python调用C，也就是扩展python。 pybind11 pybind11之前我使用过，当时的场景是：有一个深度学习算子是用c和cuda写的，要把它接入到pytorch中，**相当于是python中调用c**。当时的解决方案是：使用pybind11这个工具将这个算子封装成动态库文件，然后在python端进行加载运行。 在这里，我可以很明确的告诉大家：pybind11可以使我们在python中调用C++(这是pybind11的主要目的和应用)，也可以使我们在C++中调用python。 下面给出两个示例。 在python中调用C++ 安装pybind11 这里我建议使用conda install 的方式安装pybind11，否在后面在C++中会找不到pybind的头文件等。 1conda install pybind11 创建main.cpp 12345678910111213#include &lt;pybind11/pybind11.h&gt;namespace py = pybind11;int add(int i, int j)&#123; return i+j;&#125;PYBIND11_MODULE(example, m) &#123; m.doc() = &quot;pybind11 example plugin&quot;; // optional module docstring m.def(&quot;add&quot;, &amp;add, &quot;A function that adds two numbers&quot;);&#125; 可以看到，在main.c中定义了一个add函数。后面几行添加了pybind接口的代码。 生成动态链接库 生成动态链接库这一部分，很多教程中使用的都是一个setup.py，这里我使用从官网得到的命令行生成.so文件。 1c++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) main.cpp -o example$(python3-config --extension-suffix) 运行完这条指令后，可以看到文件夹中多了一个以example开头的.so文件。 在python中调用该动态链接库 1import example 以上就是使用pybind11在python中调用c++的全流程。 在C++中调用python 这一部分互联网上资源很少，我没有找到一个完整的demo，最后从pybind11的官网 找到了一些demo，这里进行展示。 准备c++环境 因为我是使用cmake编译代码，所以第一步要找到pybind11的头文件，也就是确保CmakeLists.txt文件正确。下面是我的cmake文件。 1234567cmake_minimum_required(VERSION 3.16)project(main)find_package(pybind11 REQUIRED) # 寻找pybind11add_executable(main main.cpp)target_link_libraries(main pybind11::embed) demo 123456789101112131415161718192021222324252627282930313233343536#include &lt;pybind11/embed.h&gt; // 注意，这里的头文件和上一个不一样#include &lt;iostream&gt;namespace py = pybind11;int main()&#123; py::scoped_interpreter guard&#123;&#125;; // 激活python解释器 py::print(&quot;hello, world!&quot;); // 使用python api py::exec(R&quot;( kwargs = dict(name=&quot;World&quot;, number=42) message = &quot;Hello, &#123;name&#125;! The answer is &#123;number&#125;&quot;.format(**kwargs) print(message) )&quot;); // 使用exec在c++中运行python代码 // 在c++中导入python的模块 py::module_ sys = py::module_::import(&quot;sys&quot;); py::print(sys.attr(&quot;path&quot;)); // 为了简单起见，现在的工作目录已经被添加到了`sys.path`里面。 /* 1. 创建calc.py * *&quot;&quot;&quot;calc.py located in the working directory&quot;&quot;&quot; * def add(i, j): * return i + j */ // 2. import calc module py::module_ calc = py::module_::import(&quot;calc&quot;); // 3. call calc module&#x27;s method py::object result = calc.attr(&quot;add&quot;)(1,2); int n = result.cast&lt;int&gt;(); std::cout&lt;&lt;&quot;n = &quot;&lt;&lt;n&lt;&lt;std::endl; return 0;&#125; Cython 这里先强调一点：Cython和CPython是完全不同的两个东西以及这篇文章。 Cython是一门结合了C和Python的编程语言(Cython是python的超集)，接下来我们给出Cython几种不同的作用，但是无论如何，在linux下Cython最后都会生成一个.so文件。 加快python速度 我们有一个python写的斐波那契数列，但是运行速度太慢，因为Cython中有C语言的特性，所以我们可以使用Cython语言重写斐波那契数列，然后编译为动态链接库，然后在python代码中使用。 代码如下： 1.斐波那契数列原始的python代码： 123456## fib.pydef fib(n): a, b = 0.0, 1.0 for i in range(n): a, b = a + b, a return a 用Cython重写的斐波那契数列，文件后缀名为.pyx: 1234567## fib.pyxdef fib(int n): cdef int i cdef double a = 0.0, b = 1.0 for i in range(n): a, b = a + b, a return a 编译fib.pyx文件为动态链接库.so 这里有两种编译方式，一种是使用setup.py自动进行编译，一种是手动进行编译。 setup.py文件 12345from distutils.core import setupfrom Cython.Build import cythonizesetup(ext_modules = cythonize(&quot;fib.pyx&quot;)) 然后在命令行运行`python setup.py build_ext --inplace` 便会在同级目录下生成一个以`fib`开头的动态链接库以及一个`fib.c`文件，这个`fib.c`文件就是`fib.pyx`完全转为`c`代码后结果。 - 手动编译 - 第一步：在命令行运行`cython fib.pyx`，会生成`fib.c` - 使用gcc对`fib.c`编译生成动态链接库： `gcc -fPIC -shared -I ~/miniconda3/include/python3.11/ fib.c -o fib.so`。注意这里python include的路径需要你自己更换为自己环境的路径。 这样在第2步，我们就生成了动态链接库.so文件。 在python代码中使用这个动态链接库 123import fibprint(fib.fib(100)) 以上就是Cython工作的大体流程。这里要注意的是：我的介绍只是一点点入门知识，Cython还是很博大精深的。 在C中调用python代码 上面我们已经说过，Cython是python的超集，所以如果我们有一个python脚本或者模块，想要在C语言环境中调用它，那么可以使用cython对这个py文件进行编译生成动态链接库，然后在C语言中调用它即可。 注：这一种方式博主没有亲自测试过 调用Python的原生C API 这是最暴力的一种方法，我们知道，python这个语言也有C的API，所以我们可以直接在C语言代码中使用这些API来调用python模块，下面是一个简单的示例。 我们拥有的my_modules.py文件 1234567891011121314151617# # my_modules.pydef add(a, b): print(a + b) return a + bdef helloworld(s): print(&quot;hello &quot; + s)class A: def __init__(self, a, b) -&gt; None: self.first = a self.second = b def add(self): print(self.first+self.second) return &quot;hello world&quot; 可以看到，有两个函数(一个做求和，一个输出&quot;hello world&quot;)和一个类。 构建C++的环境 我是使用cmake进行编译程序的，所以要配置好CMakeLists.txt，配置如下： 123456789101112131415cmake_minimum_required(VERSION 3.16)project(CallPython)find_package (Python COMPONENTS Interpreter Development) # 找到python解释器message(STATUS &quot;Python_VERSION: $&#123;Python_INCLUDE_DIRS&#125;&quot;)message(STATUS &quot;python_LIBRARIES: $&#123;Python_LIBRARIES&#125;&quot;)# message(STATUS &quot;python_Interpreter: $&#123;ython_LIBRARIES&#125;&quot;)# message(STATUS &quot;python_LIBRARIES: $&#123;ython_LIBRARIES&#125;&quot;)include_directories( $&#123;Python_INCLUDE_DIRS&#125; )# 生成目标文件add_executable(call_python call_python.cpp)# 链接库target_link_libraries(call_python $&#123;Python_LIBRARIES&#125;) 创建call_python.cpp文件，文件内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;Python.h&gt; // 必须要有这个头文件，在cmake中进行配置也是为了找到这个头文件int main(int argc, char** argv)&#123; // 运行Python解释器 Py_Initialize(); // 添加.py的路径 PyRun_SimpleString(&quot;import sys&quot;); PyRun_SimpleString(&quot;sys.path.append(&#x27;/home/wjq/workspace/test1&#x27;)&quot;); // py文件的父目录 /************************** ********* add函数 ********** **************************/ // 导入模块 PyObject* pModule = PyImport_ImportModule(&quot;my_modules&quot;); // 导入要运行的函数 PyObject* pFunc = PyObject_GetAttrString(pModule, &quot;add&quot;); // 构造传入参数 PyObject* args = PyTuple_New(2); PyTuple_SetItem(args, 0, Py_BuildValue(&quot;i&quot;, 1)); PyTuple_SetItem(args, 1, Py_BuildValue(&quot;i&quot;, 10)); // 运行函数，并获取返回值 PyObject* pRet = PyObject_CallObject(pFunc, args); if (pRet) &#123; long result = PyLong_AsLong(pRet); // 将返回值转换成long型 std::cout &lt;&lt; &quot;result:&quot; &lt;&lt; result &lt;&lt; std::endl ; &#125; /************************** ****** helloworld函数 ***** **************************/ // 导入函数 pFunc = PyObject_GetAttrString(pModule, &quot;helloworld&quot;); // 构造传入参数 PyObject* str = Py_BuildValue(&quot;(s)&quot;, &quot;python&quot;); // 执行函数 PyObject_CallObject(pFunc, str); /************************** * ******class A测试***** **************************/ PyObject* pDict = PyModule_GetDict(pModule); // 类 PyObject* pClassA = PyDict_GetItemString(pDict, &quot;A&quot;); // 类的构造对象 PyObject* pConstruct = PyInstanceMethod_New(pClassA); // 类的对象 PyObject * pInsA = PyObject_CallObject(pConstruct, args); // 调用类的方法 PyObject* result = PyObject_CallMethod(pInsA, &quot;add&quot;, nullptr); // 对结果进行解读 if(result != nullptr)&#123; char * str_result; PyArg_Parse(result, &quot;s&quot;, &amp;str_result); printf(&quot;Result: %s\\n&quot;, str_result); Py_DECREF(result); &#125; // 终止Python解释器 Py_Finalize(); &#125; 结果如下所示： 1234511result:11hello python11Result: hello world Python的C API有很多，这里我们只是用了几个，关于更多的API，请参考官网。 参考链接 https://www.52txr.cn/2023/CPytonCython.html https://www.cnblogs.com/traditional/p/13196509.html https://chend0316.github.io/backend/cython/#第1章-cython的安装和使用 https://blog.csdn.net/u011722929/article/details/114871365 https://www.hbblog.cn/python%26C%2B%2B/python和C的交互/#31-pythonapi https://zhuanlan.zhihu.com/p/79896193 https://blog.csdn.net/qq\\_42688495/article/details/120563844","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":"qq_41596730"},{"title":"AI图像和视频换脸大师Facefusion详解教程","slug":"Other/AI图像和视频换脸大师Facefusion详解教程","date":"2025-07-22T05:51:55.000Z","updated":"2025-07-22T06:05:09.270Z","comments":true,"path":"2025/07/22/Other/AI图像和视频换脸大师Facefusion详解教程/","link":"","permalink":"http://www.formeasy.cc/2025/07/22/Other/AI%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%A2%E8%84%B8%E5%A4%A7%E5%B8%88Facefusion%E8%AF%A6%E8%A7%A3%E6%95%99%E7%A8%8B/","excerpt":"","text":"Facefusion是一款首屈一指的AI换脸工具，可以对图像换脸，也可以对视频换脸。本教程将详细讲解Facefusion中各个参数的用法。 截止目前（2025年6月7日），官方推出的Facefusion最新版本号是3.3.0，网上有网友自行改变版本号发布，出现了4.0甚至其他的版本，都不是官方版本号，下面我用的是官方标准版3.2的一键整合包，按钮颜色显示为红色。如果你使用的Facefusion的按钮是紫色或绿色等，都是被网友改过后的版本，这些改进后的版本里面通常添加了一些额外的信息和号码，大家在使用时要注意分辨。 一、一键整合包的使用方法 下载下来的Facefusion整合包要解压到没有任何中文的目录下运行，建议N卡显存6G以上，显存越大越好，如果显存低，则可以使用CPU运行，只是出图很慢，也就是说，Facefusion可以在绝大多数电脑上运行，无论显卡。 注意：导入到Facefusion的图像、音频、视频文件所在的目录位置以及文件名称最好也全都是字母构成，使用中文可能带来不稳定。 二、启动界面 启动后的Facefusion界面如下图所示。 三、执行模式参数 执行模式参数如下图所示。 这些执行模式共包含10个，我首先把每个执行模式的作用大体概述一下，然后再详细说明。 （1）face_swapper（换脸器）：核心换脸功能，能把一个人的脸部特征替换到另一个人面部 。比如制作创意视频，将演员 A 的脸替换到演员 B 表演画面里，实现 “换脸演出” 。 （2）face_enhancer（脸部增强器 ）：提升转换后视频中人物面部清晰度，让面部细节更突出。处理低画质素材换脸时，开启它可让换脸后的脸更清晰、真实 。 （3）deep_swapper（深度换脸器 ）：可能是更深度、精细的换脸模式，在复杂场景（如多人换脸、高分辨率画面）下，提升换脸精准度与自然度，让换脸效果更逼真 。 （4）age_modifier（年龄修改器 ）：用于调整面部呈现的年龄，可让脸变年轻或变老。比如把年轻人的脸模拟出老年状态，用于影视角色年龄跨度表现 。 （5）face_debugger（人脸调试器）：开启遮罩处理时的调试模式，方便查看预览区域红线、点等，辅助精准调整换脸区域。像处理有遮挡（如头发遮脸）的换脸场景，可借它调试遮罩范围，确保换脸贴合 。 （6）expression_restorer（表情恢复器 ）：可恢复、调整面部表情，让换脸后的表情更自然。比如原视频人物表情僵硬，用它优化，使换脸后表情生动，像让面无表情的脸呈现微笑表情 。 （7）face_editor（人脸编辑器 ）：对脸部五官进行细致调整，比如放大眼睛、调整眉毛形状等。例如想制作卡通风格换脸，用它把人脸五官改成卡通化比例 。 （8）frame_colorizer（帧着色器 ）：能为照片、视频上色，给黑白素材或想改变色调的内容重新着色。比如给老电影黑白片段换脸后，用它上色成彩色，还原复古色彩风格 。 （9）frame_enhancer（帧增强器 ）：提升转换后视频整体清晰度，优化画面质量。换脸后的视频画面模糊，开启它可让整个视频画面更清晰锐利 。 （10）lip_syncer（嘴唇同步器 ）：用音频驱动视频中人物嘴型，让嘴型与音频匹配。比如给换脸后的人物配音，开启它可让人物嘴型随配音自然变动，像制作虚拟主播说话视频 。 （1）Face_swapper 换脸器，这是换脸必须要选择的选项，右侧源文件添加换脸图像，下面目标文件添加被换脸的图像，也就是说，源文件的脸换到目标文件的脸上，当添加源文件图像和目标文件图像后，程序会自动完成换脸，但是，此时你会发现，换脸后，脸部不清楚。如何让换脸后的图像更清楚，你接着往下看就行。 选择换脸选项后，下面还有两个换脸参数，一个是换脸模型，一个是换脸像素分辨率，如下图所示。 换脸模型包含10个，默认使用inswapper_128_fp16，如下图所示， 以下是FaceFusion中这十个换脸模型的用途简要说明： a. blendswap_256：采用融合交换算法，以256×256分辨率处理，在融合面部特征时注重自然过渡，适合追求柔和换脸效果的场景，像日常创意短视频换脸，让换脸后的面部与原画面融合更和谐 。 b. ghost_1_256、ghost_2_256、ghost_3_256：属于GHOST系列模型，256×256分辨率，在肤色匹配、光影处理上表现好，能让换脸效果更逼真，在影视制作、创意设计等专业领域，用于复杂场景换脸，提升视觉真实性 。 c. hififace_unofficial_256：256×256分辨率，强调换脸的高清质感，在处理一些对脸部细节要求高的内容，比如精致肖像换脸时，能较好保留面部纹理、毛孔等细节，让换脸更细腻 。 d. inswapper_128：以128×128分辨率运行，计算量相对小、处理速度快，适合对画质要求不极致，追求高效处理的场景，像简单的社交娱乐换脸，快速出效果 。 e. inswapper_128_fp16：基于inswapper_128，用16位浮点数计算，进一步优化速度，减少资源占用，在实时性要求高的场景，如直播换脸预览，能让换脸过程更流畅，是常用的高效模型 。 f. simswap_256：256×256分辨率，运用相似性交换算法，在保持原面部动作、表情相似性上有优势，适合处理动态视频换脸，让换脸后的人物表情、动作与原视频适配度更高 。 g. simswap_unofficial_512：512×512高分辨率，在simswap基础上提升画质，能处理对清晰度要求高的内容，比如专业影视片段换脸，让面部细节更丰富，换脸效果更逼真 。 h. uniface_256：256×256分辨率，注重面部统一融合效果，在多人脸换脸或面部特征差异大的换脸场景中，能更好协调面部与整体画面的融合，让换脸后的画面更自然统一 。 以上模型如无特殊情况，使用模型模型即可。 换脸像素分辨率：包含六种分辨率，分辨率越高，脸部保留的细节越多，但换脸时间也就越长。 如下图所示是采用128×128分辨率换脸效果。 如下图所示是采用512×512分辨率换脸效果。 （2）Face_enhancer 脸部增强器，前面说过，默认状态下，换脸后的图像一般很不清楚，解决方法来了，选择该选项就可以让换脸后的图像更清楚了。如下图所示。 选择人脸增强后，会显示两个参数，一个是人脸增强模型，一个是人脸增强混合，如下图所示。 人脸增强模型：这里提供了9个增强模型，默认使用的是gfpgan_1.4，如下图所示。 a. codeformer：专注修复人脸图像质量问题，像模糊、噪点、压缩伪影等情况，能恢复丢失面部特征，提升人脸清晰度与完整性 。 b. gfpgan_1.2、gfpgan_1.3、gfpgan_1.4：属于 GFP-GAN 不同迭代版本，通过预训练 GAN 模型，修复老照片人脸或优化 AI 生成图像的面部，是换脸场合常用标配模型，版本越高通常算法优化越好、效果可能更优 。 c. gpen_bfr_256、gpen_bfr_512、gpen_bfr_1024、gpen_bfr_2048：GPEN 面部增强网络的不同版本，数字代表支持的图像分辨率（如 256×256 像素等 ），用于提升人脸分辨率和图像清晰度，分辨率越高对硬件要求也越高，可按需选对应分辨率来增强人脸细节 。 d. restoreformer_plus_plus：致力于用深度学习和复原转换技术，修复增强人像图像，尤其针对因压缩等导致失真的人脸图像效果较好 。 模型多，很容易让人眼花缭乱，摸不着头脑，实际上，我们通常使用默认的模型即可。 人脸增强混合：主要用于控制人脸增强效果的融合程度、强度等，一般情况下保持默认值80即可。 简单说，人脸增强模型是 “工具”，提供具体增强能力；人脸增强混合参数是 “调节器”，决定这些工具怎么配合、用多大力度，共同让换脸后的面部更好看、更自然。 （3）deep_swapper 深度换脸，主要针对直播实时换脸，基于神经网络，换脸细节更多更自然，但我感觉效果不怎么好。如下图所示，就是使用了深度换脸之后的效果，细节看起来多了，但是面部先得脏兮兮的，而且换脸后，长相发生很大的变化。 （4）age_modifier 年龄修改器：可以编辑人像年龄大小。此选项可以单独对目标图像进行修改，也可以对换脸后的图像进行修改。这里我只对目标图像进行年龄修改，如下图所示为减小年龄后的样子。 下图则是增大年龄后的样子。 （5）face_debugger 脸部调试器：face_debugger 是 Facefusion 的调试模式，作用和使用场景如下： 核心作用：开启遮罩调试，帮你在换脸时，根据目标图像 / 视频效果，调整参数让融合更好 。 举例说明： 遮挡场景：处理 “面部被眼镜、手、帽子遮挡” 的素材（如人物戴墨镜的视频 ），开启 face_debugger，搭配 face - mask 里的 occlusion 遮罩类型，能精准识别遮挡区域，让换脸时避开遮挡、融合更自然，调试时看预览效果，调整遮罩参数 。 效果优化：做高精度换脸（如电影级角色替换 ），开启后可通过 face_debugger_items 里的 bounding - box（看人脸边界准不准 ）、landmark - 68（检查五官关键点定位细不细 ），发现问题就调模型 / 参数，让换脸更逼真 。 【注意】正式执行换脸前，要关闭 face_debugger，否则可能让人脸出现曲线遮挡等异常，影响最终效果 。 简单说，就是换脸遇到复杂情况（遮挡、追求高精度 ）时，用它调试优化，调好就关～ 当选择面部调试选项后，下面会列出面部调试的选项，默认状态下，选择的是，face_landmark-5/68和face-mask选项，如下图所示。 此时右侧的换脸结果显示如下图所示。 外侧的绿色线框是是face-mask（面部遮罩），内部的五个绿点就是face-landmark-5/58标注的关键点。在使用面部调试时，先从人脸调试项目选择相应的选项，然后在右侧修改参数，例如，选择人脸蒙版类型为occlusion（阻挡），如下图所示。 此时，换脸结果处显示的绿色矩形框会变成如下图所示的形状。 在脸部调试时，我们可以修改下面的参数，如下图所示。 参数修改后，换脸结果处相应的标志和标记也会随之变化，如下图所示。 这就是脸部调试选项的作用，也就是说，如果在换脸时，遇到换脸出现问题，可以激活脸部调试对换脸进行调试，调试结束后，关闭脸部调试选项。所以，这个脸部调试可以看做是一个辅助换脸工具。 对于这些人脸调试项目的作用及场景我概述如下： bounding-box（人脸边界框）： 作用：定位人脸在画面里的矩形范围，标记人脸所处位置和大小 。 场景：比如视频换脸时，先快速框出人脸区域，方便后续处理；或者检测画面中有无人脸，像安防监控里初步筛选含有人脸的画面片段 。 选择该选项后，换脸结果显示处会显示一个红色矩形框，如下图所示。 face-landmark-5（5 个人脸关键点）： 作用：识别人脸 5 个关键点位，一般是双眼中心、鼻尖、左右嘴角 ，做基础人脸特征定位。 场景：简单人脸对齐场景，如简易美颜 APP 里，快速根据 5 个点调整人脸基础位置，适配滤镜模板；或者人脸快速检测场景，辅助判断人脸朝向等基础信息 。 选择该选项会用5个红点基础关键点标记左右眼睛、鼻尖以及左右嘴角位置，如下图所示。 face-landmark-5/68（5 和 68 个人脸关键点）： 作用：同时识别 5 个基础关键点和 68 个更细致关键点，兼顾快速定位与精细特征捕捉 。 场景：换脸精度要求适中的场景，既想快速完成初步对齐，又需要一定细节（如面部轮廓大致精细度 ）来优化效果，像短视频平台的换脸特效，平衡处理速度和效果 。 face-landmark-68（68 个人脸关键点）： 作用：识别 68 个细致人脸关键点，涵盖面部轮廓、五官精细位置（如眼睫毛、眼角、嘴唇轮廓等 ），精准刻画人脸特征 。 场景：对换脸细节要求高的场景，比如电影级换脸、高精度人脸美颜（要精细调整五官形状、位置 ）；艺术创作中精准操控人脸表情、形态，像数字人制作时，依据 68 个点塑造逼真面部神态 。 选择该选项会在面部显示68个绿色点，如下图所示。 face-landmark-68/5（68 和 5 个人脸关键点）： 作用：同时识别 68 个精细点和 5 个基础点，适配不同精度需求，可灵活切换或结合使用 。 场景：处理复杂人脸素材库，既有需要快速筛选的低精度场景（用 5 个点 ），又有深度加工的高精度场景（用 68 个点 ）；或者调试换脸算法时，对比不同关键点数量对效果的影响 。 选择该选项后，会在面部显示68个青色的点，如下图所示。 face-mask（人脸遮罩）： 作用：检测、生成人脸遮罩，可标记人脸区域，也能用于处理人脸与背景融合、添加特效限制范围 。 场景：换脸时让新脸与原背景自然融合，遮罩界定人脸范围，避免特效影响背景；制作人脸特效（如虚拟面具 ），限定特效仅作用在人脸区域；还能处理戴口罩场景，精准识别口罩覆盖部分与人脸的关系 。 默认状态下，人脸遮罩使用的是box盒子（矩形），如下图所示。 换脸结果显示如下图所示。 如果选择occlusion阻挡选项，如下图所示。 则换脸结果处显示的遮罩形状就不是规则的举行，而是围绕脸部变化的曲线了，如下图所示。 face-detector-score（人脸检测置信度）： 作用：评估人脸检测结果的可信度、精准度，数值越高，检测出的人脸越可靠 。 场景：大规模人脸数据筛选，过滤检测置信度低的无效人脸（如模糊、误识别的 ），像人脸数据库构建时，保证入库数据质量；自动换脸流程里，优先处理高置信度人脸，提升整体效果稳定性 。 选择该选项会在换脸面部显示置信度参数，如下图显示的是0.8，这表示检测处的人脸可靠性较高。 face-landmarker-score（人脸关键点识别置信度）： 作用：评估人脸关键点识别结果的可靠性，判断关键点定位准不准 。 场景：高精度换脸、人脸重建等对关键点精度要求高的场景，比如医学模拟人脸手术效果，需高置信度关键点确保模拟准确；艺术创作中精细调整人脸，依据分数判断关键点数据能不能用 。 选择该选项后，换脸结果显示绿色的数字表示置信度参数，如下图所示。 age（年龄预测）： 作用：基于人脸特征预测年龄信息 。 场景：影视创作中，根据角色年龄需求，筛选适配人脸素材（如找 “看起来 20 - 30 岁” 的人脸换脸 ）；用户画像分析，结合人脸年龄数据做统计（如 APP 分析用户年龄分布 ）；特效制作，给人脸添加符合年龄变化的特效（如模拟变老、变年轻 ） 。 选择该选项后，换脸结果处显示红色数字表示年龄，如下图所示。 gender（性别识别）： 作用：识别人脸对应的性别类别（男、女等 ） 。 场景：性别特定的换脸、美颜需求，比如给男性、女性分别设计不同风格特效（男性硬朗风格、女性柔美风格 ）；数据分类统计，像统计平台用户性别占比，辅助内容推荐；影视角色替换，快速筛选同性别人脸素材换脸 。 选择该选项后，换脸结果显示处会显示性别提示，如下图所示。 race（种族识别）： 作用：识别人脸所属种族（如亚洲、欧洲、非洲等 ） 。 场景：跨种族人脸研究、创作，比如模拟不同种族人脸特征融合；文化相关艺术创作，精准呈现特定种族面部风格；还有一些涉及种族特征分析的学术、应用场景，辅助做数据分类处理 。 选择该选项后，换脸结果显示处会以红色文字显示种族提示，例如，白人显示为“white”，如下图所示。 (6)expression_restorer 表情恢复器：主要针对视频换脸，主要作用是 修复、还原或优化换脸后人物的面部表情，让换脸结果在表情呈现上更自然、更贴合原始素材的情绪氛围，避免因换脸流程导致表情僵硬、失真、不协调等问题。简单说，它是给换脸后的表情 “做微调医美”，让表情从 “凑合能看” 变 “自然丝滑”，尤其对追求极致换脸效果的场景（比如影视级换脸、逼真短视频创作 ），是个很实用的细节优化开关 。 选择该选项后，下面会显示表情恢复的参数，如下图所示。 举个具体场景理解：假设你用一段 “人物开心大笑” 的视频做换脸，把 A 的脸换到视频里人物 B 脸上： 若没开 expression_restorer ，换脸后可能出现 表情断层：比如人物本该大笑时，脸部肌肉牵拉、嘴角上扬幅度，和原始 B 的表情动态不匹配，看起来 “笑容很假”“脸部僵住”，甚至像 “皮笑肉不笑” 。 开启 expression_restorer 后，它会 分析原始素材里的表情运动规律（比如面部肌肉走向、嘴角 / 眼部的动态变化），然后 调整换脸后的面部表情细节，让 A 的脸能自然复刻 “大笑” 的神态，让换脸结果从表情上更难看出破绽，和原素材情绪、动态更贴合。 （7）face_editor 人脸编辑器，这是一个非常棒的功能，可以对目标人像单独调整，也可以对换脸后的图像调整，有了这个功能，我们可以对照片或视频中的人脸及无关进行调整，例如抬头和低头、矫正歪头、转头等，非常有趣，也非常有用。 选择该选项后，下面列出了面部编辑器的众多参数，如下图所示。 这些参数很容易理解，只要调整某个参数，右侧上方就会显示调整的结果，如下图是原图（目标图像）。 下图是抬头和低头效果。 下图是左右歪头效果。 下图是左右转头效果。 其他的面部编辑参数请你自行尝试，非常有趣，也非常有用的。 （8）frame_colorizer 帧着色器 ：这个是针对整个画面，而不是单独针对人脸的上色，它能为照片、视频上色，给黑白素材或想改变色调的内容重新着色。比如给老电影黑白片段换脸后，用它上色成彩色，还原复古色彩风格 。 选择该选项后，下方显示它的参数，如下图所示。 下图是使用该功能对黑白人像照片上色的效果。 下图则是对黑白风景照片上色的效果。 帧上色模型包含DDColor和DeOldify两大类，如下图所示。 它们各自的优缺点参考下面： DDColor 优点： 色彩准确性高：采用双解码器技术，能同时考虑色彩分布和像素级详细信息，可准确识别图像中的物体和场景，为其添加逼真颜色，减少颜色错误涂抹问题，实现高度真实的图像上色效果。无论是给历史黑白照片上色，还是为动漫或游戏中的风景进行真实风格的上色，都有出色表现。 细节处理好：利用多尺度图像特征学习颜色查询，能减轻颜色溢出，并显著改善小物体的着色，使图像细节处的色彩过渡自然，不会出现色彩断层或不自然的边界。 色彩丰富度高：引入了色彩损失函数，进一步提高生成结果的色彩丰富度，让上色后的图像色彩更加鲜艳、生动，接近真实世界的色彩表现。 缺点： 相对来说，可能对复杂场景中一些特殊光影效果或艺术化的色彩需求处理不够灵活，更侧重于写实风格的色彩还原，如果想要实现一些独特的艺术化色彩风格，可能不如专门的艺术化模型表现出色。 DeOldify 优点： 修复功能强大：不仅能为黑白或褪色的图像上色，还能在一定程度上修复图像的损坏部分，对于有破损、划痕等问题的老照片或视频片段，能在恢复色彩的同时进行修复，提升图像质量。 艺术化效果好：提供多种模型，如艺术模型可满足追求高图像质量、丰富色彩和细节的用户需求，能生成具有独特艺术风格的色彩效果，适合对图像有艺术化处理需求的场景；稳定模型在风景和肖像处理上表现佳，输出稳定；视频模型专为视频处理设计，能提供流畅且无闪烁的视频上色体验。 皮肤渲染自然：在皮肤渲染方面有显著进步，减少了僵尸般的效果，使人物肤色看起来更加自然，对于人像照片或视频的上色处理有优势。 缺点 虽然 DeOldify 在不断优化，但在某些复杂场景下，可能上色的准确性不如 DDColor，例如对于一些具有特殊光影条件或罕见色彩组合的场景，可能无法准确还原出符合现实逻辑的颜色。而且不同模型适用于不同场景，需要用户根据具体需求进行选择，这对用户的操作经验和对模型的了解程度有一定要求。 着色模型带artistic（艺术）主要侧重对非写实类图像着色。 ddcolor_artistic：在 ddcolor 基础上，融入艺术化色彩倾向，为画面增添油画、复古等艺术风格色彩 ；deoldify_artistic：侧重以艺术化方式给老旧内容上色，强化复古、创意色彩表现，让黑白画面呈现独特艺术氛围 。 帧上色大小包含四个尺寸，如下图所示。 小尺寸（如 256×256 ）：处理速度快、占用电脑资源（显存 / 内存 ）少，适合配置一般设备或对细节要求不高、追求快速出结果的场景，但可能损失画面细节，让上色效果粗糙 。 大尺寸（如 512×512 ）：能捕捉更多画面细节，上色后色彩过渡、纹理还原更细腻，适合高性能设备处理对细节要求高的内容（如老电影修复 ），但会增加资源消耗、延长处理时间 。 帧上色混合：控制上色程度大小，数值高，新上色效果突出，原始信息残留少，适合想彻底覆盖旧色彩的场景；数值低，保留更多原始质感（如灰度 ），让上色过渡自然，适合追求柔和融合效果的场景 ，用于调节新旧色彩在最终画面里的呈现比例。 （9） frame_enhancer 帧增强器 ：主要针对整个画面，而不是单独针对人脸的增强，提升转换后视频整体清晰度，优化画面质量。换脸后的视频画面模糊，开启它可让整个视频画面更清晰锐利 。 选择该选项后，下面显示帧增强模型和帧增强混合参数，如下图所示。 帧增强模型包含17个，如下图所示。 对于这些模型的特点和作用，我大体叙述如下： （一）RealESRGAN系列（以RealESRGAN为基础的衍生模型 ） real_esrgan_x2 / real_esrgan_x2_fp16 特点：主打 2倍超分辨率 ，用较小计算成本实现基础画质提升。`fp16` 版本是半精度计算优化，能在保持效果的同时，加快处理速度、降低显存占用，适合对分辨率要求没那么极致，但想快速提升清晰度的场景（比如短视频片段、低清素材初步修复 ）。 real_esrgan_x4 / real_esrgan_x4_fp16 特点：4倍超分辨率是核心，在画质提升幅度和计算效率间找平衡。对低分辨率视频帧（如老旧监控、低清动画 ），能有效增强细节、锐化边缘，让画面更清晰。`fp16` 版本同样是加速优化，适合中端配置设备处理常规视频增强需求。 real_esrgan_x8 / real_esrgan_x8_fp16 特点：8倍超分辨率 ，追求极致细节还原，但对硬件要求高（需要更强算力、显存 ）。适合处理极低成本素材（如早期手机拍摄的模糊低清视频 ），能最大程度挖掘画面细节，但处理速度慢、资源消耗大，更适合追求画质极限的场景（如老电影修复、珍贵影像抢救 ）。 （二）其他特色增强模型 clear_reality_x4 特点：侧重 “真实感还原” ，在超分辨率同时，会优化色彩自然度、抑制过度锐化。适合处理风景、写实类视频帧，让增强后的画面既清晰又贴近真实视觉（比如旅行vlog修复，避免画面过锐显得假 ）。 lsdir_x4 特点：可能偏向 “轻量快速” ，针对小尺寸、低复杂度画面优化。适合批量处理简单素材（如表情包、小尺寸短视频 ），用较低资源消耗快速提升清晰度，主打一个“高效简洁”。 nomos8k_sc_x4 特点：对 8K及超高清适配性强 ，处理高分辨率原始素材时，能精准增强细节、保持画面一致性。适合专业影视后期、高端视频创作，给8K拍摄的素材做精细画质优化，避免放大后细节崩坏。 real_hatgan_x4 特点：结合 GAN（生成对抗网络 ） 技术，在增强分辨率同时，强化画面“真实纹理生成”。对人脸、物体纹理修复效果突出（比如老照片人脸修复 ），让增强后的细节更自然、有真实质感，不像传统算法容易“假糊”。 real_web_photo_x4 特点：针对 网络照片/网页视频 优化，这类素材常因压缩、传输损失画质。模型会重点修复色块、模糊、压缩噪声，让从网页/社交平台下载的低质素材（如截图、转发多次的视频 ）恢复清晰度，适配二次创作场景。 realistic_rescaler_x4 特点：强调 “写实风格缩放” ，超分辨率时严格遵循真实物理规律（光影、纹理比例 ）。适合建筑、工业类视频帧处理（如工程监控、建筑设计视频 ），保证增强后画面比例、细节符合现实逻辑，不出現艺术化失真。 remacri_x4 特点：可能偏向 “艺术化增强” ，在提升清晰度同时，给画面加轻微艺术滤镜（如胶片感、复古色调 ）。适合想让视频帧有独特风格的创作（如复古风短视频、艺术短片 ），增强画质+风格化一步到位。 siaux_x4 特点：主打 “智能细节补全” ，对画面缺失细节（如老照片划痕、低清画面模糊轮廓 ），能通过算法“脑补”合理内容。适合破损素材修复（如带划痕的老影像 ），在提升清晰度同时修复画面瑕疵。 span_kendata_x4 特点：对 人物/肖像优化 有侧重，超分辨率时强化皮肤纹理、五官细节，让人脸更清晰自然。适合短视频换脸、人物vlog处理，让增强后的人物面部细节更真实（比如美妆、颜值类视频修复 ）。 swin2_sr_x4 特点：基于 Swin Transformer架构 ，擅长捕捉长距离画面依赖关系（比如复杂场景中不同物体关联 ）。对大场景、多元素视频帧（如电影场景、城市全景 ），能更精准增强细节、还原整体氛围，适合专业影视级画质提升。 ultra_sharp_x4 特点：极端追求 “锐利清晰” ，超分辨率时最大化锐化边缘、强化细节。适合需要强视觉冲击力的场景（如游戏CG、广告片 ），让画面线条硬朗、细节突出，但要注意过度锐化可能导致画面“假”“生硬”，需配合其他参数调整。 追求“效率优先” → 选带 `fp16` 后缀（加速 ）、`x2`/`x4` 小倍数模型（如 `real_esrgan_x2_fp16` ）； 追求“极致画质” → 选 `x8` 大倍数、`swin2_sr_x4` 这类架构复杂的模型；针对“特定场景”（人脸、风景、8K ）→ 对应专项优化模型（`span_kendata_x4` 、`nomos8k_sc_x4` ）。 简单说，每个模型都是在 “分辨率提升幅度”“计算效率”“场景适配性” 三者间做取舍，根据素材质量、设备性能、创作需求选就行~ （10）lip_syncer 嘴唇同步器 ：也就是对口型功能，用音频驱动视频中人物嘴型，让嘴型与音频匹配。比如给换脸后的人物配音，开启它可让人物嘴型随配音自然变动，像制作虚拟主播说话视频 。 选择lip_syncer（嘴唇同步器 ）后，下方显示它的参数，如下图所示。 唇形同步模型包含两个，如下图所示。 wav2lip_96：基础唇形同步模型，通过提取嘴形、音频特征并计算相似度，实现唇形与音频匹配，重点保障唇形同步精度 ，专注让唇部动作严格贴合声音节奏。 wav2lip_gan_96：引入 生成对抗网络（GAN） ，在同步唇形基础上，增加对 “视觉质量” 的优化，通过生成器和判别器对抗，让结果更自然、细节更丰富 。 唇形同步要求一段音频和与音频时长对应的人像视频。 视频换脸和唇形同步设置完参数之后，都要点击一下下方的“开始”按钮。 注意：UI工作流程下拉列表中要选择instant_runner，此时下方的“应用”按钮变成“开始/停止”按钮，并多了一个“清除”按钮，如下图所示。 四、运行模式 运行模式包括三种，如果你的电脑不是英伟达显卡，则只能选择CPU模式，如果是英伟达显卡且安装了cuda或tensorrt，则可以选择之，可以加速渲染速度。 具体而言，cuda的特点如下： 依赖与优势：依托 NVIDIA 显卡的 CUDA 技术，能调用 GPU 算力加速。适合有 N 卡（NVIDIA 显卡 ）的设备，大幅提升人脸处理速度，像视频换脸时，利用 GPU 并行计算，快速处理每一帧画面 。 适用场景：对硬件有一定要求，需 N 卡且装好对应 CUDA 工具包，适合追求高效处理、电脑配置（有适配 N 卡）较好，处理大规模人脸数据（如长视频换脸、批量换脸任务 ）的场景。 tensorrt的特点如下： 依赖与优势：是 NVIDIA 的高性能推理优化器，需适配的 GPU 硬件（通常 N 卡 ）。能进一步优化模型推理，在 cuda 基础上，通过模型优化、精度调整等，降低延迟、提高吞吐量，让人脸处理更高效，比如复杂人脸融合任务，能更快出结果 。 适用场景：要求硬件支持（适配 TensorRT 的 N 卡等 ）、软件环境配置对应库，适合对处理速度极致追求，且有专业硬件基础（如 AI 开发、高性能计算场景 ），处理高复杂度人脸操作（如超高清视频换脸、多模型融合换脸 ）的情况。 cpu的特点如下： 依赖与优势：依靠计算机 CPU 运算，无需特殊显卡，兼容性强，任何电脑基本都能用。不过受限于 CPU 本身运算能力，处理速度相对慢，尤其大数据量时更明显，但胜在普适性，低配置 “渣机” 也能运行基础人脸处理任务 。 适用场景：无特殊硬件要求，适合电脑无独立显卡（或显卡不满足 cuda/tensorrt 条件 ）、处理简单人脸任务（如单张图片换脸、低分辨率短视频换脸 ），或临时应急使用，不追求极致速度的场景。 执行线程数： 可简单理解为程序同时 “动手干活” 的 “工人数量” 。比如设为 4，就是同时有 4 个线程（可看作 4 个 “工人” ）并行处理任务，像对人脸图像的不同区域、不同视频帧，分配给不同线程运算，利用多线程并行提升处理速度。 但线程数不是越多越好，受 CPU 核心数、任务类型（CPU 密集型 / IO 密集型 ）限制，太多线程会因切换频繁、资源竞争，反而拖慢整体速度。 **CPU 密集型任务（如人脸模型推理计算 ）**若电脑是多核 CPU，线程数建议接近或不超过 CPU 核心数（比如 4 核 CPU，设 3 - 4 ）。因这类任务主要靠 CPU 运算，线程多了切换成本高，会降低效率。像 FaceFusion 对高清人脸图像深度处理时，线程数匹配 CPU 核心，能让运算资源充分利用又不浪费。 IO 密集型任务（如加载人脸素材、读写临时文件 ） 线程数可适当调高（比如 8 - 12 ，甚至更多，依实际测试 ）。因为任务多数时间在等 IO（像等文件读取 ），CPU 空闲，多开线程能在等待时让 CPU 处理其他任务，提升整体吞吐量。比如批量换脸时加载大量人脸图片素材，多线程并行加载可减少等待时间。 执行队列数：是等待执行任务的 “排队区容量” 。当任务产生速度快于线程处理速度，没被立即处理的任务会进入队列排队，设为 1 就是队列最多缓存 1 个待处理任务（超过可能触发拒绝策略或影响程序稳定性 ）。它用于协调任务生产和消费节奏，避免任务 “拥堵” 导致内存溢出等问题。 任务量稳定、少波动场景：队列数设小些（如 1 - 3 ）。若任务生产和处理速度匹配好，队列只是临时 “缓冲”，小队列可避免内存存太多待处理任务，减轻内存压力。比如日常单视频换脸，任务数少且稳定，队列数 1 或 2 就够。 任务突发、生产快场景：适当增大队列数（如 5 - 10 ，需结合内存情况 ）。当短时间有大量换脸任务（像批量处理几十条短视频 ），队列能暂存任务，等线程有空再处理，避免任务直接被拒绝。但要注意监控内存，队列太满存大量任务，可能引发内存溢出，导致程序崩溃。 简单说，使用时要结合自身硬件（CPU 核心数、内存大小 ）和实际任务类型（人脸处理是算得多还是等得多 ），先小范围调整线程数和队列数，测试程序处理速度、资源占用（任务管理器看 CPU、内存 ），找到既高效又稳定的组合，让 FaceFusion 换脸又快又稳 。 五、模型下载方式 在 FaceFusion（以及很多涉及模型加载、使用的 AI 应用场景里 ）中，“github” 和 “huggingface” 这两种模型下载方式，作用是为程序提供获取人脸相关模型文件（比如用于换脸的算法模型、权重参数等 ）的不同来源渠道。 若你想深度定制模型（比如改 FaceFusion 里模型的推理逻辑 ）、追踪模型版本更新（开发者频繁提交代码变动时，能通过 Git 拉取最新版 ），选 GitHub 下载更方便，能获取完整项目上下文，辅助调试、优化。 如果你是快速想用模型跑通 FaceFusion 流程，不想折腾代码仓库细节，选 Hugging Face 更省心，直接调库下载即用；而且想对比不同模型效果（平台上模型多、评价全 ），或用社区热门的 “开箱即用” 模型，它是高效渠道。 简单说，两种方式给你选 “从哪拿模型” 的自由：想折腾代码、深度开发，用 GitHub；想快速用、依赖社区成熟模型，选 Hugging Face 。FaceFusion 里同时勾选，程序会按逻辑（可能优先 / 同时从两个渠道找 ）去拉取模型，保证能拿到文件，也让你灵活应对不同网络环境（比如有时 GitHub 访问慢，Hugging Face 能兜底 ） 。 六、视频内存策略和限制 在 FaceFusion 这类视频处理（尤其是涉及人脸融合等 AI 操作 ）的工具里，视频内存策略用于控制程序处理视频时如何分配、使用计算机内存，影响视频处理的流畅度、稳定性，以及对硬件资源的占用效率。 简单说，就是平衡 “视频处理质量 / 速度” 和 “内存占用” 。视频处理（比如人脸替换、帧渲染 ）很吃内存，尤其高清、长视频，内存不够易卡顿、崩溃。内存策略决定程序在 “用尽量少的内存保证处理效果” 和 “多占用内存提升速度 / 质量” 之间怎么选，让工具适配不同硬件（低配电脑少卡、高配电脑高效利用 ）。 strict（严格策略 ） 特点：对内存使用限制最严格，尽可能少占内存。程序会精细管控内存分配，比如严格限制缓存的视频帧数量、压缩临时数据，甚至牺牲一点处理速度，优先保证内存不超阈值，避免因内存不足导致程序崩溃。 用途：适合低配电脑（内存小，比如 8G/16G ） ，或处理短、低分辨率视频时用。比如旧笔记本内存只有 8G，处理短视频换脸，选 strict 能降低内存爆掉的风险，代价可能是处理时间稍长（因为要频繁 “省内存” ）。 moderate（适中策略 ） 特点：内存控制和处理效率找平衡。既不会像 strict 那样极端压缩内存，也不会无节制占用。会合理缓存必要的视频数据、中间结果，保证处理速度的同时，让内存占用维持在多数电脑（比如 16G/32G 内存 ）能承受的范围。 用途：日常通用场景首选，大部分电脑（内存不算特别小 / 特别大 ）、处理普通长度 / 分辨率视频（如 1080P 短视频 ）时，选 moderate 既能保证处理流畅（速度还不错 ），又不容易因内存占用太高触发系统预警、卡顿。 tolerant（宽松策略 ） 特点：优先保证处理速度、质量，对内存占用限制宽松。程序会大胆缓存视频帧、中间模型结果，甚至尽可能多开并行任务，充分利用大内存优势加速处理。但内存占用会更高，对硬件要求也高。 用途：适合高配电脑（内存大，比如 32G 及以上 ） ，处理长视频、高分辨率（4K 等 ）视频。比如用 64G 内存的工作站做电影级人脸替换，选 tolerant 能让 GPU/CPU 少等 “内存搬运数据”，更快完成复杂计算，代价是内存会被大量占用（但高配电脑扛得住 ）。 综上所述，到底怎么用这三个选项可以参考下面的总结： 看硬件：内存小（≤16G ）选 strict；内存中等（16G - 32G ）选 moderate；内存大（≥32G ）、追求速度选 tolerant。 看任务：处理短、小视频，strict/moderate 足够；处理长、高清、复杂视频（要快 ），用 tolerant 更爽。 实际测试：同一视频、同一模型，换不同策略跑一遍，看电脑内存占用（任务管理器看 ）、处理时间、是否卡顿崩溃，找到自己硬件 + 任务下最稳的组合～ 简单说，这三策略就是给你 “用内存换速度 / 质量” 的选择，根据电脑配置和处理需求挑，让 FaceFusion 不崩、跑得顺～ 再看系统内存限制，如下图所示。 系统内存限制：就是防止程序 “吃内存吃到撑爆系统” 。视频处理（尤其是高清、长视频，叠加人脸模型运算 ）非常消耗内存，一旦程序无节制占用内存，可能导致： 电脑整体卡顿（其他程序被挤没内存跑 ）； 触发系统 “内存不足” 警告，甚至直接崩溃； 极端情况损坏硬件（虽概率低，但持续高内存压力对设备有影响 ）。通过设置 “系统内存限制”，你能主动给 FaceFusion 划一道 “内存红线”，让它在处理视频（人脸融合 ）时，不管任务多复杂，最多只用这么多内存，保障电脑整体稳定。 比如你电脑总内存是 16G，日常还要开浏览器、办公软件。如果给 FaceFusion 设 “系统内存限制 = 8G”，那么不管处理多夸张的视频，它最多用 8G 内存，剩下的 8G 留给系统和其他程序，避免电脑因内存被占满而死机、强制重启。 我再说具体点， 低配电脑（总内存小，如 8G ）可以把限制调低（比如设 2G - 4G ），保证 FaceFusion 能跑起来，同时给系统留喘气空间（不然开个软件直接内存爆炸 ）。代价是处理速度可能变慢（内存不够，程序得频繁 “挤内存、换数据” ），但至少能完成任务。 高配电脑（总内存大，如 32G/64G ）：可以适当调高限制（比如设 16G - 24G ），让 FaceFusion 充分利用大内存加速处理（缓存更多视频帧、模型数据，减少等待时间 ），兼顾速度和稳定性。 注意： “视频内存策略”（strict/moderate/tolerant ），它和 “系统内存限制” 是配合工作的： “视频内存策略” 是程序内部的内存分配逻辑（比如 strict 更抠内存，tolerant 更放开 ）； “系统内存限制” 是给程序套的 “外部枷锁” ，不管内部策略多激进，总内存 usage 不能超过你设的限制。举个栗子： 你选了 “tolerant（宽松 ）” 视频策略（程序想多占内存加速 ），但设了 “系统内存限制 = 4G”，那 FaceFusion 再怎么 “放飞自我”，最多也只能用 4G 内存，避免把系统搞崩～ 那么实际中怎么调呢？ 先看总内存：比如总内存 16G，想留 4G 给系统，就设 “≤12G”；总内存 8G，设 “≤4G” 更稳。 测试任务：处理同一个视频，从低到高调限制，看：内存占用是否触发警告 / 崩溃； 处理速度是否能接受（内存给太少，速度会巨慢 ）。 日常使用：找到 “能稳定跑完任务，又不影响电脑其他操作” 的阈值，固定下来就好～ 七、源文件和目标文件 当目标文件为视频文件时，界面左侧会增加与视频相关的选项，如下图所示。 临时帧格式：设置处理过程中，视频临时存储的图像格式，默认是PNG格式，还可以设置其他的格式，如下图所示。 bmp：无压缩，画质真，文件大，保留完整像素信息，常见于 Windows 。 jpeg：有损压缩，高压缩比，文件小，适合照片分享，会损失部分细节 。 png：无损压缩，支持透明，画质好，网页等场景常用，文件比 bmp 小 。 tiff：无损 / 有损可选，画质优，文件大，多用于专业图像存储、印刷 。 输出音频编码器：决定输出音频采用的编码算法，影响音频压缩、质量和兼容性，默认是flac编码，还可以设置其他的编码，如下图所示。 flac：无损压缩，音质无损，文件相对大，保留完整音频信息。 aac：有损压缩，高效编码，音质较好，常用于流媒体 。 libmp3lame：即 MP3 编码，有损，压缩比高，兼容性极强，普及度高 。 libopus：有损，低延时，适合实时通讯，音质与效率兼顾 。 libvorbis：有损，开源，高音质，在压缩效率上有优势 。 pcm_s16le：无压缩，音质原始精准，文件大，常用于专业音频编辑 。 pcm_s32le：无压缩，高精度采样，音质更优，文件体积更大 。 输出视频编码器：选择将视频原始数据编码为最终视频文件的编码工具，输出视频编码器包含如下图所示。 libx264：H.264 编码，兼容性强、画质好，编码速度与质量平衡，应用广泛。 libx265：H.265 编码，高效压缩，同等画质体积更小，需设备解码支持 。 libvpx - vp9：VP9 编码，开源高效，适合网络视频，压缩优于 H.264，编码稍慢。 h264_amf：AMD 显卡加速的 H.264 编码，利用 AMD 硬件，加快编码，适合 AMD 用户。 h264_nvenc：NVIDIA 显卡加速的 H.264 编码，借 NVIDIA GPU，编码快，适配 N 卡。 hevc_nvenc：NVIDIA 加速的 H.265 编码，依托 N 卡硬件，高效编码 H.265 格式。 h264_qsv：Intel Quick Sync Video 加速的 H.264 编码，用 Intel 核显，编码高效。 hevc_amf：AMD 加速的 H.265 编码，借助 AMD 硬件，实现 H.265 快速编码。 hevc_qsv：Intel 加速的 H.265 编码，依托 Intel 核显，加速 H.265 编码流程。 rawvideo：无压缩，保留原始视频数据，画质无损但文件极大，少用于最终输出 。 输出视频预设：是编码器内置的一组参数组合，影响编码速度和输出视频质量、体积，如下图所示。 ultrafast：极速编码，画质损失大，赶时间出片选它 。 superfast：编码快，画质一般，追求速度可尝试 。 veryfast：速度较快，画质尚可，日常常用的平衡选项 。 faster：编码速度不错，画质比 veryfast 好点，折中选择 。 fast：速度与画质更平衡，编码稍慢，效果有提升 。 medium：中速编码，画质较好，时间和质量的中间态 。 slow：编码慢，画质优，细节保留多，适合精品需求 。 slower：更慢编码，画质更细腻，对硬件和时间要求高 。 veryslow：极慢编码，极致画质，追求完美且不计耗时用 。 输出视频质量：控制视频输出的画质水平，数值越高理论画质越好 。默认数值80，属于中高画质。 输出视频分辨率：设定输出视频的画面尺寸，长和宽的像素数量，分辨率高画面细节承载多、清晰，但文件体积大、编码处理量大；1080x1920 适合竖屏展示场景（如手机端短视频等 ），适配对应播放终端的显示需求。 输出视频帧率：决定视频每秒呈现的帧数，影响画面流畅度 。30帧/秒是常见帧率，能保证基本流畅度，相比 24 帧更流畅，比 60 帧在编码压力、文件体积上小，平衡了流畅度和资源占用，适合一般视频创作输出 ，让动作、画面切换等呈现自然不卡顿。 注意：当目标文件为视频时，界面右侧也会显示一些与视频相关的选项。如下图所示。 预览帧：控制上面显示的帧画面，也就是让我们看到的画面。默认看到的是第一帧。 修剪帧：控制输出视频帧的范围，默认是全部输出。 注意：视频中的第一帧一般用0帧表示。 八、源文件和目标文件 源文件可以是图像和音频，目标文件可以是图像和视频。当图像换脸时，二者都导入图像，如下图所示。 当视频换脸时，源文件是人像图像，目标文件是视频，如下图所示。 当使用唇形同步时，则源文件是音频，目标文件是视频。如下图所示。 九、输出路径和输出 输出路径：指定输出的换脸图像或视频默认存放的位置，是位于facefusion目录下的output文件夹。 我们可以在facefusion目录下找到这个文件夹。如下图所示。 输出：该区域主要显示换脸视频或唇形同步视频，生成视频后，可以点击下方的播放按钮预览视频效果。如下图所示。 十、日志级别和终端 日志级别： 控制用于调整终端显示消息的严重性，控制输出日志详细程度，包含四个日志级别，如下图所示。 error：仅显示严重错误，助快速定位关键故障。 warn：提示潜在风险，不影响运行但需留意 。 info：输出常规流程信息，展现正常运行状态 。 debug：记录详细调试内容，用于深度排查问题 。 终端：是展示运行过程信息的交互窗口，如下图所示。 根据日志级别设置的不同，终端可以 ： 输出日志，像换脸进度、参数加载、错误提示，帮你了解工具运行状态； 显示报错，遇到换脸失败、依赖缺失等问题，能通过终端信息排查解决； 调试时，高级用户可借助终端输入命令、查看底层执行细节，优化换脸效果 。 十一、UI工作流程 UI工作流程：包含三个选项，如下图所示。 instant_runner：快速执行模式，简化流程，追求 “即点即出” 的高效换脸，适合简单场景。视频换脸常用该选项，选择该选项后，界面变成如下图所示。 job_runner：按标准任务流程运行，一步步处理换脸作业，注重过程完整性。选择该选项后，界面变成如下图所示。 任务操作：提供不同指令，用于按需执行、重试单个或全部换脸任务，管控任务处理流程 。包含四个任务操作，如下图所示， job-run：执行单个指定换脸任务，启动单次作业流程。 job-run-all：批量运行所有待处理换脸任务，一次性执行队列。 job-retry：重试单个失败 / 中断的换脸任务，重新尝试执行。 job-retry-all：批量重试所有失败 / 中断任务，统一重新执行 。 任务ID：用于精准标识、区分不同换脸任务的唯一标识，如下图所示。 任务ID的作用是： 执行任务时，指定具体要处理的任务，让操作精准对应到单个 / 特定任务； 任务运行中，通过 ID 追踪进度、状态（如是否完成、失败原因 ）； 任务结束后，依据 ID 查询结果、复盘流程，方便管理多任务场景下的复杂作业 。 job_manager：带任务管理能力，可排队、监控多个换脸任务，适合批量或复杂场景 。这也是默认的换脸工作流程，选择该选项后，界面变成如下图所示。 任务操作包含如下图所示的内容。 job-create：创建新换脸任务，初始化任务流程与基础配置。 job-submit：提交已创建任务，正式启动换脸处理流程。 job-delete：删除指定任务，清理无需保留的任务数据。 job-add-step：给任务添加新处理步骤，扩展流程内容。 job-remix-step：重新编排任务步骤顺序，调整流程逻辑。 job-insert-step：在任务指定位置插入步骤，灵活补全流程。 job-remove-step：移除任务中某步骤，简化或修正流程 。 十二、预览 用于预览换脸或唇形同步，如果是视频换脸，则显示预览帧和修剪帧，这两个参数前面已讲过，如下图所示。 如果是图像换脸，则不会显示这两个参数，如下图所示。 十三、人脸选择器模式 人脸选择器模式控制人脸选择的不通过策略，包含三个选项，默认采用reference参考选项，如下图所示。 many：识别并选取画面中多张人脸，用于多脸换脸场景。有多少脸，就换「多少张」 one：只选单个人脸，聚焦单一目标，简化换脸对象。不管多少脸，只换「最明显的 1 张」 reference：依据参考图匹配选取人脸，精准定位特定面容 。只换「和参考图最像的 1 张（或指定张）」，再说明白一点，就是我们可以用鼠标点击参考列表中要换的哪张脸，如下图所示，我在参考列表中点击了美女的脸，则美女的脸就被换掉了。 如下图所示，我点击了帅哥的脸，则帅哥的脸就被换掉了。 如下图所示，我点击了参考列表中间美女的脸，则三个美女的脸同时被换掉了，这是为什么？因为两边的美女和中间的美女长相几乎一样，facefusion认为三个人是一个人了，_ 十四、人脸选择器及其他 这些参数包括如下图所示。 这一部分内容比较多，我们分开来学习。 人脸选择器顺序是 Facefusion 中人脸选择后，对人脸应用或处理的顺序规则，包含八个选项，如下图所示。 每个选项的作用是： left-right：按检测到的人脸，从左到右依次处理。 right-left：按检测到的人脸，从右到左依次处理 。如下图所示，采用右-左方式后，则最右侧的人像被换脸。 top-bottom：按检测到的人脸，从上到下依次处理 。 bottom-top：按检测到的人脸，从下到上依次处理 。 small-large：按人脸检测尺寸，从小到大排序处理 。 large-small：按人脸检测尺寸，从大到小排序处理 。如下图所示，采用大-小方式后，图像中最大的头部是最左侧的男人，所以他的头像被换掉了。 best-worst：按人脸质量（清晰、完整度），从优到差处理 。 worst-best：按人脸质量（清晰、完整度），从差到优处理 。 2、人脸选择器性别 可以根据男女性别有针对性换脸。默认状态是none，也就是不分性别。 如下图所示，选择male男性后，则图像中的女性就不会被换脸，只有右侧的男性的脸被换掉了。 3、人脸选择器种族 按选择的种族进行换脸，例如，可以只替换图像中的亚洲人脸，也就是黄种人，种族包含六种，如下图所示。 none：无；无特定种族 white：白色人种；高加索人种 black：黑色人种；非洲人种 latino：拉丁裔（美洲裔拉丁人，涵盖多种族混合背景 ） asian：亚洲人种；亚裔 indian：印度人种（也用于指代美洲印第安人，需结合场景，这里侧重南亚印度 ） arabic：阿拉伯人种；阿拉伯裔 如下图所示，选择了黑种人换脸，则图像中只有黑种人脸被换掉。 说明：上图中，由于没有限制性别，所以，图像中不分男女，只要是黑种人都会被换脸。 4、人脸选择器年龄 可以限定年龄范围，从而只替换这个年龄段的人脸，如下图所示。年龄限定在0-14岁，则只有最前面孩子的脸被替换了。 注意： （1）上面讲的四个人脸选择器是交集的关系，而不是并集关系，也就是说，换脸的人像要同时满足这四个条件，如果有的人脸选择器设置为none，则会忽略该条件。如下图所示。设定的条件是目标图像中按从左往右的顺序只对年龄在18-40岁的亚洲女性进行换脸。 （2）这些限定条件有时会判断失误，例如，有时会把女性判定为男性，把男性判定为女性，也有时候会误判年龄大小，如下图所示，我把年龄限定在50-100岁，则检测结果是目标图像中没有人超过50岁，这是不对的。根据前面孩子的年龄，我们可以大体推断右侧的两位老人的年龄应该超过50岁了。 如果把年龄限制在30-40，则检测出奶奶的年龄在这个范围，所以，这里的年龄限制只作为一个参数使用就行，没必要一定等同于多少岁。 5、人脸遮挡模型 在替换人脸时，经常会遇到人脸被遮挡的情况，例如，话筒遮挡了人脸，如下图所示。 手指遮挡了人脸，如下图所示。 甚至戴的口罩更严重地遮挡了人脸。 这些遮挡人脸的情况都会严重影响替换人脸效果，为了更好地解决人脸遮挡的问题，于是人脸遮挡模型就出现了。 这些是 Facefusion 中用于人脸遮挡处理的模型，作用是辅助识别、分割人脸区域与遮挡部分，包含三个模型。 xseg_1：基础版人脸遮挡分割模型，识别并处理人脸遮挡，初步区分人脸与遮挡物 。 xseg_2：进阶版，在遮挡分割精度、复杂场景适配（如多遮挡）上优化，效果更细 。 xseg_3：高阶版，对细微遮挡、复杂环境（如半透明遮挡）处理更精准，提升换脸融合度 。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"青砚墨痕 关注"},{"title":"最新换脸软件facefusion汉化版整合包分享及使用教程","slug":"Other/最新换脸软件facefusion汉化版整合包分享及使用教程","date":"2025-07-22T05:46:55.000Z","updated":"2025-07-22T05:51:27.473Z","comments":true,"path":"2025/07/22/Other/最新换脸软件facefusion汉化版整合包分享及使用教程/","link":"","permalink":"http://www.formeasy.cc/2025/07/22/Other/%E6%9C%80%E6%96%B0%E6%8D%A2%E8%84%B8%E8%BD%AF%E4%BB%B6facefusion%E6%B1%89%E5%8C%96%E7%89%88%E6%95%B4%E5%90%88%E5%8C%85%E5%88%86%E4%BA%AB%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"最新换脸软件facefusion汉化版整合包分享及使用教程 Facefusion是一款最新的开源AI视频/图片换脸项目。项目官方介绍只有一句话，下一代换脸器和增强器。采用了全新的界面设计，可以像Stable Diffuison一样，在网页打开操作页面，更加方便。 下载安装 学术Fun将上述工具制作成一键启动包，点击即可使用，避免大家配置Python环境出现各种问题，下载地址： https://xueshu.fun/2947/ 获取软件并解压，请注意要解压到一个英文路径下，最好是放非C盘的根目录，比如D盘下面。 解压之后只需要点击启动.exe 启动会非常快，启动之后会出现一个网址http://127.0.0.1:7860 复制到浏览器，打开就可以看到界面了。 完整的界面如下： 使用教程 这次的软件使用gradio构建了WebUI，界面上有很多选项。 可以设置很多参数，比如： 设置人脸替换 设置人脸增强 设置画面增强 设置GPU和CPU 设置线程数量 设置缓存文件格式 设置缓存帧的质量 设置保持帧率不变 设置保持缓存文件 设置音频还原 设置视频编码和视频质量 设置参考人脸替换和全部替换 通过相似度选择人脸 通过方位选择人脸 通过年龄选择人脸 通过性别选择人脸 支持换脸和预览 支持图片和视频换脸。 核心操作其实非常简单，根据下图来就好了。 ① 设置人脸（Source） 只要点击这个框框就会跳出文件管理器，选择一张带清晰完整人脸图片就可以了。注意图片名字用英文和数字。 ② 设置目标（Target） 方法同上，目标可以是图片，也可以是视频。 ③ 效果预览 （Preview） 一定选中目标之后，软件里面就开始运行，运行之后会把合成预览显示在这个区域。换的是图片，其实预览区域就是换脸后的结果了。 换的是视频的话，会截取某一帧作为预览效果。 ④ 开始换脸（Start） 一切就绪之后，就可以点击按钮开始换了。 ⑤ 查看结果（OUTPUT） 换脸成功之后，会把结果显示在这里。点击右上角的下载图标，就可以把结果保存下来了。 上面就是核心步骤，整体来说已经非常简单了。 下面说一下左侧的参数设置。 ①处理器 处理器，包含了换脸，人脸增强，帧增强。 换脸是最基本的，肯定要勾选。 人脸增强可选，不选会比较模糊，相似度高。勾选后会更清楚，相似度有所下降，消耗更多的硬件资源。 帧增强这是新加入的一个增加方式，会对整个画面进行修复。这个看情况来，个人感觉如果同时启动人脸增强和帧增强，会有点假。 ②执行器 执行器就是运行设备，可以选择Tensor，Cuda，cpu。 启动之后默认只勾选了CPU，一般来说大家都是用显卡跑，只要勾选一下CUDA就可以了。 ③缓存帧 缓存帧主要是针对视频，在视频换脸过程中，会先把视频的每一帧都转换成图片。这个时候就会涉及到图片质量和图片格式的问题了。 PNG是无损转换，但是硬盘代价很高，时间会慢。 JPG可以保证质量损失不大，但是效率超高，文件大小减少巨多。 ④开关参数 开关参数，主要就是保持帧率，保留缓存数据，音轨。 保持帧率最好开启，否则可能会声音和画面不同步。 缓存数据不需要勾选。 音轨，不勾选，代表保留音轨。 下面再说一下右下方的参数。 ① 人脸识别方式选择 这里主要是两种方式，一种是制定人脸，一种是全部替换。 指定人脸，默认使用人脸相似度来指定。 ② 通过方向选择 通过人脸在图片中的位置和大小选择要替换的人脸。 ③通过年龄选择 通过不同年龄段来选择要选好的人脸。 ④通过性别选择 通过性别来选择要替换的人脸。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"学术Fun 关注"},{"title":"内存管理基础：数据结构的存储方式","slug":"C/内存管理基础：数据结构的存储方式","date":"2025-07-21T09:19:49.000Z","updated":"2025-07-21T09:23:48.200Z","comments":true,"path":"2025/07/21/C/内存管理基础：数据结构的存储方式/","link":"","permalink":"http://www.formeasy.cc/2025/07/21/C/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%9F%BA%E7%A1%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F/","excerpt":"","text":"内存管理基础：数据结构的存储方式 想象一下你正在整理你的衣柜。有些衣服你会折叠整齐地放在抽屉里（连续存储），有些则挂在衣架上分散在衣柜各处（链式存储。计算机内存管理数据的方式其实和这个场景非常相似。今天，我们就来探讨一下数据结构在内存中的不同存储方式，以及它们各自的优缺点。 1. 连续存储结构 理解了衣柜的比喻后，我们来看看计算机中最基础的存储方式——连续存储。这种存储方式就像把衣服一件件紧密地叠放在抽屉里，每件衣服占据固定大小的空间，并且按照顺序排列。 1.1 数组的存储方式 数组是最典型的连续存储结构。让我们通过一个简单的例子来看看数组在内存中是如何存储的： 1int arr[5] = &#123;10, 20, 30, 40, 50&#125;; 上述代码定义了一个包含5个整数的数组。在内存中，这些元素会被连续地存储在一起。 以上流程图说明了数组在内存中的连续存储方式，每个元素占据4字节空间 1.2 连续存储的优缺点 连续存储结构的主要优点包括： 访问速度快：可以通过索引直接计算出元素的内存地址 缓存友好：相邻元素很可能被一起加载到CPU缓存中 空间利用率高：没有额外的存储开销 但连续存储也有明显的缺点： 大小固定：一旦分配，大小难以改变 插入/删除成本高：需要移动大量元素 专业提示： 在C++中，std::vector虽然看起来可以动态扩展，但实际上它内部仍然是连续存储的，当容量不足时会重新分配更大的连续空间。 2. 链式存储结构 了解了连续存储的限制后，我们来看看另一种完全不同的存储方式——链式存储。这种结构就像衣柜中的衣架，每个衣架（节点）可以放在任何位置，只需要记住下一个衣架在哪里。 2.1 链表的存储方式 链表是链式存储的典型代表。下面是一个简单的链表节点定义： 1234struct Node &#123; int data; Node* next;&#125;; 上述代码定义了一个链表节点，包含数据部分和指向下一个节点的指针。 以上流程图展示了链表在内存中的存储方式，节点可以分散在内存各处 2.2 链式存储的优缺点 链式存储的主要优点包括： 动态大小：可以随时添加或删除节点 插入/删除高效：只需要修改指针，不需要移动数据 但链式存储也有其缺点： 访问速度慢：必须从头开始遍历 空间开销大：需要额外空间存储指针 缓存不友好：节点分散在内存各处 注意： 在实际应用中，现代CPU的缓存机制使得链表的性能往往比理论预期要差，因为频繁的指针跳转会引发大量的缓存未命中。 3. 索引存储结构 理解了基本的连续和链式存储后，我们来看一种结合了两者优点的存储方式——索引存储。这就像在衣柜中建立一个目录，告诉你每类衣服放在哪个抽屉里。 3.1 索引存储的实现 索引存储通常由一个索引表和数据区组成。下面是一个简单的索引结构示例： 1234567struct IndexEntry &#123; int key; void* data_ptr;&#125;;IndexEntry index_table[100];char data_pool[1024]; // 数据存储池 以上流程图展示了索引存储结构，索引表和数据区分离 3.2 索引存储的应用 索引存储结合了连续和链式存储的优点： 快速查找：可以通过索引快速定位 动态扩展：数据区可以动态增长 灵活组织：可以按需重组索引而不移动数据 数据库系统中的B+树索引就是索引存储的典型应用。 4. 散列存储结构 了解了索引存储后，我们来看另一种高效的存储方式——散列存储。这就像给每件衣服一个唯一的编号，然后根据编号直接找到存放的位置。 4.1 哈希表的实现 哈希表是散列存储的典型代表。下面是一个简单的哈希表实现： 12345678910111213#define TABLE_SIZE 10struct HashNode &#123; int key; int value; HashNode* next;&#125;;HashNode* hashTable[TABLE_SIZE];int hashFunction(int key) &#123; return key % TABLE_SIZE;&#125; 以上流程图展示了哈希表的基本结构，使用哈希函数确定存储位置 4.2 散列存储的特点 散列存储的主要特点包括： 快速访问：理想情况下O(1)时间复杂度 空间换时间：需要预留足够空间减少冲突 冲突处理：需要处理哈希冲突（链地址法/开放寻址法） 专业提示： 现代编程语言中的字典/映射类型（如Python的dict、C++的unordered_map）通常都采用散列存储实现。 5. 存储方式的选择策略 了解了各种存储方式后，我们来看看在实际应用中如何选择合适的存储结构。 以上流程图提供了一个简单的存储结构选择策略 5.1 实际应用案例 让我们看一个实际案例：实现一个学生成绩管理系统。我们需要考虑以下需求： 按学号快速查找学生 支持动态添加/删除学生 支持按成绩排序 考虑到这些需求，我们可以采用组合存储方式： 12345678// 使用哈希表快速查找unordered_map&lt;int, Student*&gt; student_map;// 使用链表维护插入顺序list&lt;Student&gt; student_list;// 使用有序数组支持排序vector&lt;Student*&gt; sorted_by_score; 上述代码展示了如何结合多种存储方式来满足不同的需求。 总结 通过今天的讨论，我们了解了数据结构在内存中的四种主要存储方式： 连续存储：如数组，适合随机访问但大小固定 链式存储：如链表，适合频繁插入删除但访问慢 索引存储：结合连续和链式优点，如数据库索引 散列存储：如哈希表，提供快速查找但可能冲突 在实际应用中，我们经常需要根据具体需求选择合适的存储方式，有时甚至需要组合多种存储方式来达到最佳效果。 最后建议： 理解这些基础存储方式不仅对编写高效代码很重要，也是学习更高级数据结构和算法的基础。建议大家在实际编程中多思考数据是如何存储和访问的，这将帮助你做出更好的设计决策。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":"qq_39032307"},{"title":"多 Git 账号管理解决方案，SSH 密钥配置实战技巧（附详细图文教程）_git 多账号配置","slug":"Other/多 Git 账号管理解决方案，SSH 密钥配置实战技巧（附详细图文教程）_git 多账号配置","date":"2025-07-21T09:11:25.000Z","updated":"2025-07-21T09:18:31.645Z","comments":true,"path":"2025/07/21/Other/多 Git 账号管理解决方案，SSH 密钥配置实战技巧（附详细图文教程）_git 多账号配置/","link":"","permalink":"http://www.formeasy.cc/2025/07/21/Other/%E5%A4%9A%20Git%20%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%8CSSH%20%E5%AF%86%E9%92%A5%E9%85%8D%E7%BD%AE%E5%AE%9E%E6%88%98%E6%8A%80%E5%B7%A7%EF%BC%88%E9%99%84%E8%AF%A6%E7%BB%86%E5%9B%BE%E6%96%87%E6%95%99%E7%A8%8B%EF%BC%89_git%20%E5%A4%9A%E8%B4%A6%E5%8F%B7%E9%85%8D%E7%BD%AE/","excerpt":"","text":"🚀 为什么需要多 Git 账号管理？ 作为一名开发者，我们常常在 Git 平台上托管个人项目。例如，我在 GitHub 上维护着一些开源项目，同时也会在 GitCode 上参与一些开源社区的协作。由于这些平台不同，我需要在本地管理多个 Git 平台的 SSH 密钥。起初，我直接使用默认的平台 SSH 密钥，但因为不同平台的密钥会频繁覆盖，每次推送代码时总是遇到权限错误。为了应对这种问题，我只能手动频繁切换账号。 经过一段时间的摸索，我总结出了一种通过配置多个 SSH 密钥来管理不同账号的方法，解决了每次切换账号的麻烦。下面就把这些实战技巧分享给大家。 本文以 GitHub + GitCode 场景演示：通过不同 SSH 密钥区分两个账号，实现免密推送远程 Git 仓库。 🔑 二、生成多 Git 平台 SSH 密钥 2.1 配置 GitCode 平台 SSH 密钥 2.1.1 生成 SSH 密钥 打开命令行终端，输入以下命令在指定目录生成密钥文件： 123456789101112 ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; -f ~/.ssh/&lt;平台名称&gt;_id_rsa``` - **`-t rsa`**：指定密钥使用 RSA 算法 - **`-b 4096`**：表示生成 4096 位的密钥 - **`-C &quot;your_email@example.com&quot;`**：添加注释，用于标识密钥，通常使用邮箱地址 - **`-f ~/.ssh/&lt;平台名称&gt;_id_rsa`**：自定义密钥保存路径和文件名，用于 Git 通过文件名区分不同平台的密钥，例如 `~/.ssh/gitcode_id_rsa`2. 接下来，系统会提示设置密钥密码（可选但推荐）：```bash Enter passphrase for &quot;/c/Users/Jie/.ssh/gitcode_id_rsa&quot; (empty for no passphrase): Enter same passphrase again: - 设置密码后，每次使用 SSH 密钥时都需要输入该密码，可以防止私钥被未经授权的人使用。 - 如果不需要密码，直接按 Enter 键跳过。 操作成功后，终端将输出以下内容： 12345678910111213141516Your identification has been saved in /Users/.ssh/gitcode_id_rsaYour public key has been saved in /Users/.ssh/gitcode_id_rsa.pubThe key fingerprint is:SHA256:Ub+LOdZzqYTdq5t+mDAErdkTtzUbnB8VPXJs/cTBDPA your_email@example.comThe key&#x27;s randomart image is:+---[RSA 4096]----+| +o. || =.oo E.. ||o +o. .o. ||o* . .. . ||*+= o.+ S ||O+=o+o + ||*= o *o ||o.o . oo .. ||o o+=o.. |+----[SHA256]-----+ 在 ~/.ssh/ 目录可以看到生成的密钥文件： 私钥：gitcode_id_rsa（不公开） 公钥：gitcode_id_rsa.pub（需添加到 GitCode） 2.1.2 添加 SSH 公钥到 GitCode 执行以下命令或者手动复制 SSH 公钥文件 gitcode_id_rsa.pub 的内容： 1cat ~/.ssh/gitcode_id_rsa.pub | clip 注：如果手动复制公共 SSH 密钥，请确保复制了整个密钥，以 `ssh-rsa` 开头，并以电子邮件地址结尾。 登录 GitCode 平台，进入「个人设置」-&gt;「安全设置」-&gt;「SSH 公钥」： 点击「+ SSH 公钥」： 在「公钥名称」一栏中，为公钥添加一个描述性名称 将复制的公钥内容粘贴到「公钥」文本框中 点击「新建」完成操作 2.2 配置 GitHub 平台 SSH 密钥 2.2.1 生成 SSH 密钥 同理，在终端执行以下命令生成 GitHub 密钥： 1ssh-keygen -t rsa -b 4096 -C &quot;1500492856@qq.com&quot; -f ~/.ssh/github_id_rsa 在 ~/.ssh/ 目录可以看到生成的密钥文件： 私钥：github_id_rsa（不公开） 公钥：github_id_rsa.pub（需添加到 GitHub） 2.2.2 添加公钥到 GitHub 登录 GitHub，进入 Settings → SSH and GPG Keys: 点击「New SSH key」新建密钥，粘贴 github_id_rsa.pub 内容并保存： ⚙️ 三、关键！编写 config 配置文件（核心区分逻辑） 在 C:\\Users\\&lt;用户名&gt;\\.ssh 目录打开 config 文件（无扩展名），如果文件不存在，可以手动创建一个。 按以下格式编写 Git 平台的配置，指定对应的私钥文件： 12345# ------------------------ GitHub 配置 ------------------------Host github.com HostName github.com # 实际主机名（不变） PreferredAuthentications publickey IdentityFile ~/.ssh/github_id_rsa # 指向GitHub私钥文件 - **Host**：自定义识别符（可理解为 “别名”，用于区分不同账号），通常与平台域名一致。 - **HostName**：目标平台的真实域名（如[gitlab.com](http://gitlab.com/)/[github.com](http://gitlab.com/)/[gitcode.com](http://gitlab.com/)），用于建立 SSH 连接。 - **IdentityFile**：指定当前平台对应的私钥文件路径（与生成的密钥文件名一致），是实现多账号区分的核心配置。 将编写完成后的配置添加到 config 文件，以下是一个示例配置： 1234567891011# ------------------------ GitHub 配置 ------------------------Host github.com HostName github.com # 实际主机名（不变） PreferredAuthentications publickey IdentityFile ~/.ssh/github_id_rsa # 指向GitHub私钥# ------------------------ GitCode 配置 ------------------------Host gitcode.com HostName gitcode.com PreferredAuthentications publickey IdentityFile ~/.ssh/gitcode_id_rsa # 指向GitCode私钥 🔍 四、验证连接是否成功 4.1 测试 GitHub 连接 通过以下命令测试 SSH 连接 GitHub: 1ssh -T git@github.com 如果是第一次连接，SSH 客户端会提示你确认 GitHub 服务器的身份： 1234The authenticity of host &#x27;github.com (20.205.243.166)&#x27; can&#x27;t be established.ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.This key is not known by any other names.Are you sure you want to continue connecting (yes/no/[fingerprint])? 如果你信任 GitHub 服务器，可以输入 yes 来继续连接： 1Are you sure you want to continue connecting (yes/no/[fingerprint])? yes 在终端看到以下内容，则表示 SSH 密钥已被正确认证，成功连接到 GitHub： 1Hi ShiJieCloud! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. 接下来我们就可以正常进行克隆、推送、拉取代码等操作了。 4.2 测试 GitCode 连接 同理，使用以下命令测试连接： 1ssh -T git@gitcode.com 成功连接后会在终端看到以下内容： 123456789101112131415 remote: Welcome to GitCode, @username``` ## 💡 五、仓库级个性化配置（可选）默认情况下，Git 会使用全局的用户名和邮箱进行身份验证和提交。但是，如果希望为不同的仓库使用不同的**用户名/邮箱**，可以通过以下方法来配置每个仓库的用户名和邮箱，而不是仅依赖全局设置。### 5.1 设置全局用户名和邮箱（适用于所有仓库）通过以下命令设置全局的用户名和邮箱，这会在所有仓库中使用相同的用户名和邮箱：```bash git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;your_email@example.com&quot; 5.2 为特定仓库设置用户名和邮箱 在指定项目仓库的目录下通过以下命令来设置仓库级别的用户名和邮箱，这只会影响当前仓库，不会更改全局配置： 1234# 进入项目目录cd path/to/your/repogit config user.name &quot;Other Name&quot;git config user.email &quot;other_email@example.com&quot; 这样设置后，每个仓库将使用独立的用户名和邮箱配置，避免因全局配置导致的账号混淆问题。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"qq_20185737"},{"title":"【MySQL基础】MySQL事务详解：原理、特性与实战应用","slug":"MySQL/【MySQL基础】MySQL事务详解：原理、特性与实战应用","date":"2025-07-21T09:00:35.000Z","updated":"2025-07-21T09:09:10.837Z","comments":true,"path":"2025/07/21/MySQL/【MySQL基础】MySQL事务详解：原理、特性与实战应用/","link":"","permalink":"http://www.formeasy.cc/2025/07/21/MySQL/%E3%80%90MySQL%E5%9F%BA%E7%A1%80%E3%80%91MySQL%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3%EF%BC%9A%E5%8E%9F%E7%90%86%E3%80%81%E7%89%B9%E6%80%A7%E4%B8%8E%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/","excerpt":"","text":"一、事务的基本概念 1.1 什么是事务？ 事务(Transaction)是数据库操作的最小工作单元，是用户定义的一个操作序列，这些操作要么全部执行，要么全部不执行，是一个不可分割的工作单位。 1234START TRANSACTION; UPDATE accounts SET balance = balance - 500 WHERE user_id = 1; UPDATE accounts SET balance = balance + 500 WHERE user_id = 2;COMMIT; 1.2 为什么需要事务？ 事务主要解决以下问题： 数据一致性：确保相关数据同时更新 操作原子性：保证操作的&quot;全有或全无&quot;特性 并发控制：协调多用户同时访问数据 故障恢复：系统崩溃后能恢复到一致状态 二、事务的ACID特性 2.1 原子性(Atomicity) 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2.2 一致性(Consistency) 事务执行前后，数据库从一个一致性状态变到另一个一致性状态。 2.3 隔离性(Isolation) 多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 2.4 持久性(Durability) 一旦事务提交，其所做的修改将永久保存在数据库中。 三、MySQL事务的实现机制 3.1 事务日志 MySQL通过以下日志实现事务特性： 日志类型 作用 实现特性 redo log 物理日志，记录页的修改 持久性 undo log 逻辑日志，记录事务发生前的数据 原子性 binlog 二进制日志，用于复制和恢复 数据同步 3.2 MVCC机制 多版本并发控制(MVCC)是MySQL实现高并发的重要机制： 每行数据有隐藏的创建版本号和删除版本号 读操作只读取版本号早于当前事务的数据 写操作创建新版本 四、事务隔离级别 4.1 四种隔离级别 隔离级别 脏读 不可重复读 幻读 性能 READ UNCOMMITTED 可能 可能 可能 最高 READ COMMITTED 不可能 可能 可能 高 REPEATABLE READ 不可能 不可能 可能 中 SERIALIZABLE 不可能 不可能 不可能 低 4.2 隔离级别示例 脏读问题： 1234567-- 事务ASTART TRANSACTION;UPDATE users SET age = 21 WHERE id = 1; -- 不提交 -- 事务B (READ UNCOMMITTED)START TRANSACTION;SELECT age FROM users WHERE id = 1; -- 读到未提交的21 不可重复读问题： 12345678910-- 事务ASTART TRANSACTION;SELECT age FROM users WHERE id = 1; -- 返回20 -- 事务BUPDATE users SET age = 21 WHERE id = 1;COMMIT; -- 事务ASELECT age FROM users WHERE id = 1; -- 返回21，与之前不同 4.3 MySQL默认隔离级别 MySQL InnoDB默认使用REPEATABLE READ，但通过Next-Key Locking机制解决了幻读问题。 五、事务中的锁机制 5.1 锁的类型 锁类型 描述 粒度 共享锁(S锁) 读锁，允许多个事务同时读取 行级/表级 排他锁(X锁) 写锁，独占资源 行级/表级 意向共享锁(IS) 表示事务打算设置共享锁 表级 意向排他锁(IX) 表示事务打算设置排他锁 表级 5.2 锁的兼容性矩阵 当前锁\\请求锁 X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 5.3 行锁算法 记录锁(Record Lock)：锁定索引中的一条记录 间隙锁(Gap Lock)：锁定索引记录间的间隙 临键锁(Next-Key Lock)：记录锁+间隙锁的组合 六、事务实战应用 6.1 事务的最佳实践 短事务原则：尽量缩短事务执行时间 避免交互操作：事务中不要包含用户交互 合理设置隔离级别：根据业务需求选择最低合适的隔离级别 注意锁等待：设置合理的锁等待超时时间 12345-- 设置事务隔离级别SET TRANSACTION ISOLATION LEVEL READ COMMITTED; -- 设置锁等待超时(秒)SET innodb_lock_wait_timeout = 50; 6.2 事务与性能优化 批量操作：减少事务次数 12345678910111213-- 不好START TRANSACTION;INSERT INTO table VALUES(1);COMMIT; START TRANSACTION;INSERT INTO table VALUES(2);COMMIT; -- 更好START TRANSACTION;INSERT INTO table VALUES(1),(2);COMMIT; 合理使用保存点 1234567START TRANSACTION;INSERT INTO table1 VALUES(1);SAVEPOINT sp1;INSERT INTO table2 VALUES(1);-- 如果table2插入失败ROLLBACK TO sp1;COMMIT; 七、常见事务问题与解决方案 7.1 死锁问题 死锁示例： 123456789-- 事务1START TRANSACTION;UPDATE accounts SET balance = balance - 100 WHERE id = 1;UPDATE accounts SET balance = balance + 100 WHERE id = 2; -- 事务2START TRANSACTION;UPDATE accounts SET balance = balance - 100 WHERE id = 2;UPDATE accounts SET balance = balance + 100 WHERE id = 1; 解决方案： 保持一致的访问顺序 降低隔离级别 添加合理的索引减少锁定范围 设置死锁检测和超时机制 7.2 长事务问题 长事务会导致： 锁持有时间过长 回滚段膨胀 系统资源占用高 监控长事务： 12SELECT * FROM information_schema.INNODB_TRX WHERE TIME_TO_SEC(TIMEDIFF(NOW(), trx_started)) &gt; 60; 八、高级事务特性 8.1 分布式事务(XA) MySQL支持XA协议实现分布式事务： 123456789-- 协调者XA START &#x27;xid1&#x27;;INSERT INTO orders VALUES(1001, &#x27;2023-01-01&#x27;);XA END &#x27;xid1&#x27;;XA PREPARE &#x27;xid1&#x27;; -- 参与者XA PREPARE &#x27;xid1&#x27;;XA COMMIT &#x27;xid1&#x27;; -- 或 XA ROLLBACK &#x27;xid1&#x27; 8.2 保存点(Savepoint) 123456START TRANSACTION;INSERT INTO table1 VALUES(1);SAVEPOINT sp1;INSERT INTO table1 VALUES(2);ROLLBACK TO sp1; -- 只回滚到sp1，第一条插入仍然有效COMMIT; 九、事务监控与优化 9.1 监控事务状态 123456789-- 查看当前运行的事务SELECT * FROM information_schema.INNODB_TRX; -- 查看锁等待情况SELECT * FROM performance_schema.events_waits_current WHERE EVENT_NAME LIKE &#x27;%lock%&#x27;; -- 查看事务历史SELECT * FROM performance_schema.events_transactions_current; 9.2 事务相关系统变量 变量名 描述 默认值 autocommit 是否自动提交 ON tx_isolation 事务隔离级别 REPEATABLE-READ innodb_lock_wait_timeout 锁等待超时(秒) 50 innodb_rollback_on_timeout 超时是否回滚 OFF 十、总结 MySQL事务是保证数据一致性和完整性的核心机制，理解其工作原理对于开发高性能、高可靠的数据库应用至关重要。通过合理设置隔离级别、优化事务设计和避免常见陷阱，可以显著提升应用的并发性能和数据可靠性。 在实际应用中，应该根据业务需求选择合适的事务策略，平衡一致性和性能的关系。同时，良好的监控机制可以帮助我们及时发现和解决事务相关的问题。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"}],"author":230180220607},{"title":"k8s 命令大全","slug":"kubernetes/k8s 命令大全","date":"2025-07-11T06:17:27.000Z","updated":"2025-07-11T06:22:22.309Z","comments":true,"path":"2025/07/11/kubernetes/k8s 命令大全/","link":"","permalink":"http://www.formeasy.cc/2025/07/11/kubernetes/k8s%20%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/","excerpt":"","text":"Kubernetes (K8s) 提供了丰富的 kubectl 命令用于管理集群、Pod、服务等。以下是 K8s 常见命令大全： 📌 一、基本命令 123456789kubectl version # 查看 kubectl 和集群的版本kubectl cluster-info # 查看集群信息kubectl get nodes # 查看所有节点kubectl get pod # 查看所有 Podkubectl get svc # 查看所有服务kubectl get deployments # 查看所有 Deploymentkubectl get all # 获取所有资源（Pod、Service、Deployment 等）kubectl config view # 查看当前 kubeconfig 配置kubectl config use-context &lt;name&gt; # 切换 K8s 集群环境 📌 二、Pod 操作 12345678910kubectl get pods -o wide # 查看 Pod 详细信息kubectl describe pod &lt;pod_name&gt; # 查看 Pod 详情kubectl logs &lt;pod_name&gt; # 查看 Pod 日志kubectl logs -f &lt;pod_name&gt; # 实时查看 Pod 日志kubectl logs &lt;pod_name&gt; -c &lt;container_name&gt; # 指定容器查看日志（多容器 Pod）kubectl exec -it &lt;pod_name&gt; -- /bin/sh # 进入 Pod（alpine, busybox）kubectl exec -it &lt;pod_name&gt; -- /bin/bash # 进入 Pod（常见 Linux 发行版）kubectl delete pod &lt;pod_name&gt; # 删除 Podkubectl delete pod --all # 删除所有 Podkubectl get pod --field-selector=status.phase=Running # 查询运行中的 Pod 📌 三、Deployment 操作 1234567kubectl create deployment &lt;name&gt; --image=&lt;image&gt; # 创建 Deploymentkubectl get deployments # 查看所有 Deploymentkubectl describe deployment &lt;name&gt; # 查看 Deployment 详情kubectl scale deployment &lt;name&gt; --replicas=&lt;num&gt; # 扩缩容kubectl delete deployment &lt;name&gt; # 删除 Deploymentkubectl rollout status deployment &lt;name&gt; # 查看滚动更新状态kubectl rollout undo deployment &lt;name&gt; # 回滚 Deployment 📌 四、Service（服务）操作 1234kubectl expose deployment &lt;name&gt; --type=NodePort --port=80 # 创建 Servicekubectl get services # 查看所有 Servicekubectl describe service &lt;name&gt; # 查看 Service 详情kubectl delete service &lt;name&gt; # 删除 Service 📌 五、ConfigMap 和 Secret 123456789kubectl create configmap &lt;name&gt; --from-literal=key=value # 创建 ConfigMapkubectl get configmap # 查看 ConfigMapkubectl describe configmap &lt;name&gt; # 查看 ConfigMap 详情kubectl delete configmap &lt;name&gt; # 删除 ConfigMap kubectl create secret generic &lt;name&gt; --from-literal=key=value # 创建 Secretkubectl get secret # 查看 Secretkubectl describe secret &lt;name&gt; # 查看 Secret 详情kubectl delete secret &lt;name&gt; # 删除 Secret 📌 六、Namespace（命名空间） 12345kubectl get namespaces # 查看所有命名空间kubectl create namespace &lt;name&gt; # 创建命名空间kubectl delete namespace &lt;name&gt; # 删除命名空间kubectl get pods -n &lt;namespace&gt; # 查看指定命名空间的 Podkubectl config set-context --current --namespace=&lt;name&gt; # 切换默认命名空间 📌 七、YAML 文件管理 1234kubectl apply -f &lt;file&gt;.yaml # 通过 YAML 文件创建资源kubectl delete -f &lt;file&gt;.yaml # 通过 YAML 文件删除资源kubectl get -f &lt;file&gt;.yaml # 通过 YAML 查询资源kubectl edit -f &lt;file&gt;.yaml # 编辑 YAML 文件 📌 八、其他实用命令 12345678910kubectl top node # 查看节点资源使用情况kubectl top pod # 查看 Pod 资源使用情况kubectl cp &lt;pod&gt;:&lt;file&gt; &lt;local&gt; # 从 Pod 拷贝文件到本地kubectl cp &lt;local&gt; &lt;pod&gt;:&lt;file&gt; # 从本地拷贝文件到 Podkubectl port-forward &lt;pod&gt; 8080:80 # 端口转发（本地 8080 -&gt; Pod 80）kubectl drain &lt;node&gt; --ignore-daemonsets # 驱逐节点上的 Podkubectl cordon &lt;node&gt; # 标记节点为不可调度kubectl uncordon &lt;node&gt; # 取消不可调度kubectl taint nodes &lt;node&gt; key=value:NoSchedule # 给节点添加污点kubectl get events --sort-by=.metadata.creationTimestamp # 查看最新事件 这份 Kubernetes 命令大全涵盖了常见操作，如果你需要更详细的帮助，可以使用： 12kubectl helpkubectl &lt;command&gt; --help","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":"蒲公英PGY"},{"title":"Docker常用命令","slug":"Docker/Docker常用命令","date":"2025-07-11T06:03:12.000Z","updated":"2025-07-11T06:16:28.241Z","comments":true,"path":"2025/07/11/Docker/Docker常用命令/","link":"","permalink":"http://www.formeasy.cc/2025/07/11/Docker/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Docker 通过镜像 (Image) 和容器 (Container) 两个核心概念，极大地简化了应用的构建、分发和运行。掌握相关的命令行工具是高效使用 Docker 的关键。 思维导图 一、Docker 镜像 (Image) 常用命令 镜像是一个只读的模板，包含了运行应用程序所需的文件系统、库、依赖和代码。容器是镜像的一个可运行实例。 1. 搜索镜像 (search) 从 Docker Hub (默认的公共镜像仓库) 搜索可用的镜像。 1docker search &lt;image_name&gt; 代码案例： 搜索所有与 nginx 相关的镜像。 1docker search nginx 2. 拉取镜像 (pull) 从仓库下载一个镜像到本地。 1docker pull &lt;image_name&gt;[:tag] [:tag]: 可选。指定镜像的版本标签。如果不指定，默认拉取 latest 标签。 代码案例： 12345# 拉取最新版本的 Ubuntu 镜像docker pull ubuntu# 拉取指定版本的 Redis 镜像docker pull redis:6.2 3. 查看本地镜像 (images / image ls) 列出本地已存在的所有镜像。 123docker images# 或者docker image ls 代码案例： 4. 删除本地镜像 (rmi / image rm) 删除一个或多个本地镜像。 1docker rmi &lt;image_name&gt;[:tag] | &lt;image_id&gt; 如果有正在运行的容器是基于该镜像创建的，需要先停止并删除这些容器才能成功删除镜像。 -f 或 --force: 强制删除镜像 (即使有容器在使用它，但不推荐)。 代码案例： 12345678# 通过名称和标签删除docker rmi redis:6.2# 通过镜像ID删除 (假设ID是 edbdd97bf78b)docker rmi edbdd97bf78b# 删除多个镜像docker rmi ubuntu:latest redis:latest 5. 查看镜像详细信息 (inspect) 以 JSON 格式返回镜像的详细元数据。 1docker inspect &lt;image_name&gt;[:tag] | &lt;image_id&gt; 代码案例： 1docker inspect ubuntu:latest 6. 查看镜像历史 (history) 显示镜像的构建历史，即组成该镜像的每一层 (layer)。 1docker history &lt;image_name&gt;[:tag] | &lt;image_id&gt; 代码案例： 1docker history nginx:latest 7. 保存镜像为 tar 文件 (save) 将一个或多个本地镜像打包成一个 .tar 归档文件，方便离线传输。 1docker save -o &lt;output_filename.tar&gt; &lt;image_name&gt;[:tag] 代码案例： 1docker save -o my_nginx_image.tar nginx:latest 8. 从 tar 文件加载镜像 (load) 从一个 .tar 归档文件加载镜像到本地。 1docker load -i &lt;input_filename.tar&gt; 代码案例： 1docker load -i my_nginx_image.tar 9. 为镜像打标签 (tag) 为已存在的镜像创建一个新的标签 (相当于一个别名)。这在推送到不同仓库或重命名时非常有用。 1docker tag &lt;source_image&gt;[:tag] &lt;target_image&gt;[:tag] 代码案例： 12345# 将本地的 nginx:latest 标记为 myrepo/mynginx:1.0docker tag nginx:latest myrepo/mynginx:1.0# 删除这个打了标签的镜像[root@ivan01 ~]# docker rmi myrepo/mynginx:1.0Untagged: myrepo/mynginx:1.0 二、Docker 容器 (Container) 常用命令 容器是镜像的可运行实例。你可以创建、启动、停止、移动和删除容器。 1. 创建并运行容器 (run) 这是一个非常强大的复合命令，如果本地没有指定镜像，它会先自动 pull，然后基于该镜像创建一个新容器并启动它。 1docker run [OPTIONS] &lt;image_name&gt;[:tag] [COMMAND] [ARG...] -d 或 --detach: 后台运行容器 (守护式容器)。 -i 或 --interactive: 交互式操作 (保持 STDIN 打开)。 -t 或 --tty: 分配一个伪终端。通常 -it 一起使用。 --name &lt;container_name&gt;: 为容器指定一个名称。 -p &lt;host_port&gt;:&lt;container_port&gt;: 端口映射，将主机的端口映射到容器的端口。 -v &lt;host_path&gt;:&lt;container_path&gt;: 挂载数据卷，将主机的目录挂载到容器的目录。 --rm: 容器退出时自动删除。 -e &lt;KEY=VALUE&gt;: 设置环境变量。 代码案例： 12345# 以后台模式运行一个Nginx容器，并将主机的8080端口映射到容器的80端口docker run -d -p 8080:80 --name my-web-server nginx:latest# 交互式地进入一个Ubuntu容器的bash shelldocker run -it --rm ubuntu:latest /bin/bash 2. 查看正在运行的容器 (ps / container ls) 列出当前正在运行的容器。 123docker ps# 或者docker container ls -a 或 --all: 列出所有容器 (包括已停止的)。 代码案例： 12# 查看所有容器docker ps -a 3. 停止容器 (stop) 优雅地停止一个或多个正在运行的容器。 1docker stop &lt;container_name | container_id&gt; 代码案例： 1docker stop my-web-server 4. 启动已停止的容器 (start) 启动一个已存在但已停止的容器。 1docker start &lt;container_name | container_id&gt; 代码案例： 1docker start my-web-server 5. 重启容器 (restart) 1docker restart &lt;container_name | container_id&gt; 代码案例： 1docker restart my-web-server 6. 进入正在运行的容器 (exec / attach) exec: 在正在运行的容器中执行一个新命令 (最常用)。 attach: 直接连接到容器的主进程 (PID 1) 的输入/输出流。 exec 语法 (推荐)： 1docker exec [OPTIONS] &lt;container_name | container_id&gt; &lt;COMMAND&gt; 代码案例 (进入容器的shell)： 1docker exec -it my-web-server /bin/bash 7. 删除容器 (rm / container rm) 删除一个或多个已停止的容器。 1docker rm &lt;container_name | container_id&gt; -f 或 --force: 强制删除一个正在运行的容器。 代码案例： 1234# 首先停止容器docker stop my-web-server# 然后删除docker rm my-web-server 8. 查看容器日志 (logs) 获取容器的标准输出和标准错误日志。 1docker logs [OPTIONS] &lt;container_name | container_id&gt; -f 或 --follow: 实时跟踪日志输出。 --tail &lt;number&gt;: 只显示最后N行日志。 代码案例： 12# 实时查看my-web-server的日志docker logs -f my-web-server 9. 查看容器详细信息 (inspect) 以 JSON 格式返回容器的详细配置和状态信息。 1docker inspect &lt;container_name | container_id&gt; 代码案例： 1docker inspect my-web-server 10. 从容器复制文件到主机 (cp) 1docker cp &lt;container_name | container_id&gt;:&lt;container_path&gt; &lt;host_path&gt; 代码案例： 12# 将容器my-web-server中的/etc/nginx/nginx.conf文件复制到主机的当前目录docker cp my-web-server:/etc/nginx/nginx.conf . 11. 从主机复制文件到容器 (cp) 1docker cp &lt;host_path&gt; &lt;container_name | container_id&gt;:&lt;container_path&gt; 代码案例： 12# 将主机的index.html文件复制到容器my-web-server的/usr/share/nginx/html/目录下docker cp index.html my-web-server:/usr/share/nginx/html/ 总结： 镜像 (Image): search, pull, images, rmi, inspect, save, load, tag。 容器 (Container): run, ps, stop, start, restart, exec, rm, logs, inspect, cp。 Docker 命令行练习题 (共12道) 请为以下每个任务编写相应的Docker命令。 题目： 从 Docker Hub 搜索与 mysql 相关的官方镜像 (通常 STARS 数最高且 OFFICIAL 为 [OK])。 拉取 mysql 镜像的 8.0 版本。 查看你本地现在拥有的所有镜像。 以后台模式运行一个 MySQL 8.0 容器，为其命名为 my-mysql-db，并设置MySQL的root用户密码为 MySecretPwd123 (提示：通过环境变量 MYSQL_ROOT_PASSWORD 设置)。 列出所有正在运行的容器。 列出所有容器，包括已经停止的。 查看 my-mysql-db 容器的实时日志。 进入正在运行的 my-mysql-db 容器，并启动一个 bash shell。 将你本地的一个名为 backup.sql 的SQL文件复制到 my-mysql-db 容器的 /tmp/ 目录下。 停止名为 my-mysql-db 的容器。 删除已停止的 my-mysql-db 容器。 删除你本地的 mysql:8.0 镜像。 答案与解析： 搜索 mysql 镜像： 1docker search mysql 解析： docker search 是用于在Docker Hub上查找镜像的命令。 拉取 mysql:8.0 镜像： 1docker pull mysql:8.0 解析： docker pull 用于下载镜像，&lt;image_name&gt;:&lt;tag&gt; 格式指定了镜像名和版本标签。 查看本地镜像： 1docker images 解析： docker images 或 docker image ls 用于列出本地已下载的镜像。 运行 MySQL 容器： 1docker run -d --name my-mysql-db -e MYSQL_ROOT_PASSWORD=MySecretPwd123 mysql:8.0 解析： -d 使容器在后台运行。--name 为容器指定一个易于记忆的名称。-e 用于设置容器内的环境变量，MYSQL_ROOT_PASSWORD 是MySQL镜像官方文档中指定的用于设置root密码的环境变量。 列出运行中的容器： 1docker ps 解析： docker ps 是 docker container ls 的简写，默认只显示正在运行的容器。 列出所有容器： 1docker ps -a 解析： -a 或 --all 参数会显示所有容器，包括那些已经停止运行的。 查看实时日志： 1docker logs -f my-mysql-db 解析： docker logs 用于查看容器日志。-f 或 --follow 参数会持续输出新产生的日志，实现实时跟踪。 进入容器的 shell： 1docker exec -it my-mysql-db /bin/bash 解析： docker exec 用于在运行中的容器内执行命令。-it 组合参数提供了交互式终端，/bin/bash 是要在容器内启动的命令。 复制文件到容器： 1docker cp backup.sql my-mysql-db:/tmp/ 解析： docker cp 用于在主机和容器之间复制文件。格式为 docker cp &lt;host_source_path&gt; &lt;container&gt;:&lt;container_dest_path&gt;。 停止容器： 1docker stop my-mysql-db 解析： docker stop 用于向容器发送停止信号，使其优雅地关闭。 删除容器： 1docker rm my-mysql-db 解析： docker rm 用于删除一个或多个已停止的容器。如果容器正在运行，需要先 stop 或使用 -f 强制删除。 删除镜像： 1docker rmi mysql:8.0 解析： docker rmi 或 docker image rm 用于删除本地镜像。如果有任何容器（即使是已停止的）是基于该镜像创建的，必须先删除这些容器，才能成功删除镜像。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}],"author":240183830408},{"title":"C++11 算法详解：std::copy_if 与 std::copy_n","slug":"C/C++11 算法详解：stdcopy_if 与 stdcopy_n","date":"2025-07-11T02:12:20.000Z","updated":"2025-07-11T02:16:02.548Z","comments":true,"path":"2025/07/11/C/C++11 算法详解：stdcopy_if 与 stdcopy_n/","link":"","permalink":"http://www.formeasy.cc/2025/07/11/C/C++11%20%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%9Astdcopy_if%20%E4%B8%8E%20stdcopy_n/","excerpt":"","text":"引言 C++11 标准为算法库带来了诸多增强，其中 std::copy_if 和 std::copy_n 作为 std::copy 的补充，为元素复制操作提供了更精细的控制。这两个算法不仅简化了代码逻辑，还提升了可读性和性能。本文将深入探讨这两个算法的实现细节、使用场景及最佳实践，帮助开发者在实际项目中正确高效地应用它们。 std::copy_if：条件筛选复制 函数原型 12template&lt; class InputIt, class OutputIt, class UnaryPred &gt;OutputIt copy_if( InputIt first, InputIt last, OutputIt d_first, UnaryPred pred ); 核心功能 std::copy_if 从输入范围 [first, last) 中复制满足谓词 pred 的元素到目标范围（始于 d_first），并保持元素的相对顺序。该算法在 C++11 中引入，是对传统 std::copy 的条件化扩展。 参数解析 first/last：输入迭代器对，定义源元素范围。 d_first：输出迭代器，指向目标范围的起始位置。 pred：一元谓词函数（可调用对象），返回 bool 类型，用于判断元素是否应被复制。 注意：谓词 pred 不得修改输入元素，其参数类型通常为 const T&amp;。 返回值 返回目标范围中最后一个被复制元素的下一个位置迭代器，便于后续操作（如继续添加元素）。 实现逻辑 cppreference 提供的参考实现清晰展示了其工作原理： 12345678910template&lt;class InputIt, class OutputIt, class UnaryPred&gt;OutputIt copy_if(InputIt first, InputIt last, OutputIt d_first, UnaryPred pred) &#123; for (; first != last; ++first) &#123; if (pred(*first)) &#123; *d_first = *first; ++d_first; &#125; &#125; return d_first;&#125; 循环遍历输入范围，对每个元素应用谓词判断，满足条件则复制到目标位置并移动目标迭代器。 示例：筛选容器中的偶数 1234567891011121314151617181920#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() &#123; std::vector&lt;int&gt; src = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; std::vector&lt;int&gt; dest; // 预留空间以避免多次扩容（性能优化） dest.reserve(src.size()); // 复制所有偶数 std::copy_if(src.begin(), src.end(), std::back_inserter(dest), [](int x) &#123; return x % 2 == 0; &#125;); // 输出结果：2 4 6 8 for (int num : dest) &#123; std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; &#125;&#125; 注意事项 范围重叠：若目标范围与输入范围重叠，行为未定义。此时应考虑 std::copy_backward。 谓词副作用：谓词函数不得修改输入元素，否则可能导致未定义行为。 性能考量：对于大型容器，提前调用 reserve 为目标容器分配空间可避免多次内存分配。 std::copy_n：固定数量复制 函数原型 12template&lt; class InputIt, class Size, class OutputIt &gt;OutputIt copy_n( InputIt first, Size count, OutputIt result ); 核心功能 std::copy_n 从起始位置 first 复制恰好 count 个元素到目标范围（始于 result）。该算法同样在 C++11 中引入，填补了传统 std::copy 无法指定复制数量的空白。 参数解析 first：输入迭代器，指向源范围的起始位置。 count：要复制的元素数量（若为负数，行为未定义）。 result：输出迭代器，指向目标范围的起始位置。 返回值 返回目标范围中最后一个被复制元素的下一个位置迭代器（若 count 为 0，则返回 result）。 实现逻辑 参考实现如下： 1234567891011template&lt;class InputIt, class Size, class OutputIt&gt;constexpr OutputIt copy_n(InputIt first, Size count, OutputIt result) &#123; if (count &gt; 0) &#123; *result = *first; ++result; for (Size i = 1; i != count; ++i, (void)++result) &#123; *result = *++first; &#125; &#125; return result;&#125; 首先处理 count &gt; 0 的情况，复制首个元素后循环复制剩余 count-1 个元素。 示例：复制前 N 个元素 123456789101112131415161718#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;numeric&gt;#include &lt;iostream&gt;int main() &#123; std::vector&lt;int&gt; src(100); std::iota(src.begin(), src.end(), 1); // 填充 1~100 std::vector&lt;int&gt; dest(5); // 复制前 5 个元素（1,2,3,4,5） std::copy_n(src.begin(), 5, dest.begin()); // 输出结果：1 2 3 4 5 for (int num : dest) &#123; std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; &#125;&#125; 注意事项 目标空间不足：若目标容器容量小于 count，会导致缓冲区溢出（未定义行为）。 负数 count：标准明确规定 count 为负数时行为未定义，实际使用中应确保其非负。 迭代器类型：输入迭代器只需满足 LegacyInputIterator，但随机访问迭代器可提升性能（支持 first + i 直接访问）。 对比分析与应用场景 功能差异 特性 std::copy_if std::copy_n 核心逻辑 条件筛选复制 固定数量复制 关键参数 谓词函数 pred 元素数量 count 元素数量 取决于谓词匹配结果 严格等于 count（若源足够） 顺序保证 保持源范围中的相对顺序 按源范围顺序复制 性能对比 std::copy_if：需对每个元素执行谓词判断，时间复杂度为 O(N)（N 为输入范围大小），但实际复制次数可能小于 N。 std::copy_n：时间复杂度为 O(count)，无额外判断开销，适合已知复制数量的场景。 优化提示：当源迭代器为 LegacyContiguousIterator（如 std::vector::iterator）且元素类型为 TriviallyCopyable 时，编译器可能将 std::copy_n 优化为 memmove，大幅提升性能。 典型应用场景 std::copy_if 适用场景 数据过滤：从容器中提取满足特定条件的元素（如筛选日志中的错误信息）。 数据清洗：移除无效数据（如空字符串、负数等）。 条件转换：结合 std::back_inserter 动态构建新容器。 std::copy_n 适用场景 批量数据处理：读取固定大小的数据包（如网络通信中的报文头）。 截断/截取：获取容器的前 N 个元素（如分页显示前 10 条记录）。 定长缓冲区填充：向固定大小的数组中复制数据。 最佳实践与常见陷阱 1. 避免目标容器空间不足 问题：使用 std::copy_n 时，若目标容器大小小于 count，会导致未定义行为。 解决方案：提前确保目标容器有足够空间，或使用 std::back_inserter 自动扩容。 1234567// 错误示例：目标容器大小不足std::vector&lt;int&gt; dest(3);std::copy_n(src.begin(), 5, dest.begin()); // 缓冲区溢出！// 正确示例：使用 back_inserterstd::vector&lt;int&gt; dest;std::copy_n(src.begin(), 5, std::back_inserter(dest)); // 自动扩容 2. 谓词函数的设计 问题：谓词函数修改输入元素或有副作用。 解决方案：确保谓词为纯函数，仅依赖输入参数且无副作用。 1234567// 错误示例：谓词修改输入元素std::copy_if(src.begin(), src.end(), dest.begin(), [](int&amp; x) &#123; return x++ &gt; 5; &#125;); // 修改了 x// 正确示例：纯函数谓词std::copy_if(src.begin(), src.end(), dest.begin(), [](int x) &#123; return x &gt; 5; &#125;); // 仅读取 x 3. 处理重叠范围 问题：源范围与目标范围重叠时使用 std::copy_if 或 std::copy_n。 解决方案：若需复制到右侧重叠区域，使用 std::copy_backward；若需条件复制，手动实现安全逻辑。 4. 与其他算法的配合 结合 std::distance 和 std::copy_n 可实现动态数量复制： 123// 复制两个迭代器之间的元素（等价于 std::copy）auto n = std::distance(first, last);std::copy_n(first, n, result); 总结 std::copy_if 和 std::copy_n 作为 C++11 引入的算法，为元素复制提供了更灵活的选择。前者擅长条件筛选，后者专注固定数量复制，二者相辅相成，可大幅简化代码并提升可读性。实际使用中，需注意目标容器空间、迭代器类型及范围重叠等问题，结合具体场景选择合适的算法。 现代 C++ 倡导使用标准算法而非手动循环，这不仅能减少错误，还能让代码更具表达力。掌握这些算法的细节，将有助于写出更高效、更优雅的 C++ 代码。 参考资料 cppreference.com - std::copy_if cppreference.com - std::copy_n ISO/IEC 14882:2011 (C++11 Standard), § 25.3.1]","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":"Z_oioihoii"},{"title":"【ubuntu】查看端口占用情况，以及系统详情","slug":"Ubuntu/【ubuntu】查看端口占用情况，以及系统详情","date":"2025-07-11T02:01:30.000Z","updated":"2025-07-11T02:07:06.459Z","comments":true,"path":"2025/07/11/Ubuntu/【ubuntu】查看端口占用情况，以及系统详情/","link":"","permalink":"http://www.formeasy.cc/2025/07/11/Ubuntu/%E3%80%90ubuntu%E3%80%91%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5%EF%BC%8C%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%AF%A6%E6%83%85/","excerpt":"","text":"一、ubuntu 查看端口占用情况 在Ubuntu 系统中，你可以使用以下几种方法来查看端口占用情况以及检查指定端口是否被占用： 方法 1：使用 netstat 命令（传统方式） 12345# 查看所有端口占用情况sudo netstat -tulnp# 查看指定端口是否被占用（例如检查 80, 443, 3306 端口）sudo netstat -tulnp | grep -E &#x27;:(80|443|3306)\\s&#x27; 选项说明： -t：显示 TCP 端口 -u：显示 UDP 端口 -l：仅显示监听中的端口 -n：以数字形式显示地址和端口 -p：显示进程信息 方法 2：使用 ss 命令（更现代的替代方案） 12345# 查看所有端口占用情况sudo ss -tulnp# 检查指定端口是否被占用（例如 80, 443, 3306）sudo ss -tulnp | grep -E &#x27;:(80|443|3306)\\s&#x27; ss 命令比 netstat 更快，是推荐的现代替代方案。 方法 3：使用 lsof 命令 12345# 查看所有端口占用sudo lsof -i -P -n# 检查指定端口（例如 80, 443, 3306）sudo lsof -i :80,443,3306 方法 4：快速检查单个端口是否被占用 12345678# 检查单个端口（例如 8080）sudo lsof -i :8080# 或sudo netstat -tulnp | grep :8080# 或sudo ss -tulnp | grep :8080# 如果端口未被占用，这些命令不会有输出 方法 5：使用 telnet 或 nc 测试端口连接性 12345# 检查本地端口（例如 3306）telnet 127.0.0.1 3306# 或使用 ncnc -zv 127.0.0.1 3306 检查多个指定端口的脚本示例 如果你想一次性检查多个端口是否被占用，可以使用这个脚本： 123456789101112#!/bin/bashports=(80 443 3306 8080 8000)for port in &quot;$&#123;ports[@]&#125;&quot;; do echo -n &quot;Checking port $port... &quot; if sudo lsof -i :$port &gt; /dev/null 2&gt;&amp;1; then echo -e &quot;\\e[31m占用\\e[0m&quot; sudo lsof -i :$port | head -n 2 else echo -e &quot;\\e[32m空闲\\e[0m&quot; fidone 将上述脚本保存为 check_ports.sh，然后运行： 12chmod +x check_ports.sh./check_ports.sh 注意事项 查看端口占用通常需要 sudo 权限才能看到所有信息 如果端口被占用，命令会显示占用该端口的进程信息 没有输出通常表示端口未被占用 对于 Docker 容器使用的端口，也需要用上述方法检查 这些方法可以帮助你全面了解 Ubuntu 系统中的端口占用情况，并快速检查特定端口是否可用。 二、Ubuntu 系统信息查看命令大全 1. 查看系统版本信息 查看 Ubuntu 版本 1lsb_release -a 输出示例： 12345No LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 22.04.3 LTSRelease: 22.04Codename: jammy 查看内核版本 123uname -a# 或cat /proc/version 查看系统架构 123arch# 或uname -m 2. 查看内存信息 查看内存总量和使用情况 1free -h 输出示例： 123 total used free shared buff/cache availableMem: 15Gi 3.2Gi 8.4Gi 1.2Gi 3.4Gi 10GiSwap: 2.0Gi 0.0Ki 2.0Gi 查看详细内存信息 1cat /proc/meminfo 监控内存使用（动态） 123top# 或htop # 需要安装：sudo apt install htop 3. 查看硬盘信息 查看磁盘分区和挂载情况 1df -h 输出示例： 12Filesystem Size Used Avail Use% Mounted on/dev/nvme0n1p2 457G 123G 311G 29% / 查看所有磁盘设备 123lsblk# 或sudo fdisk -l 查看磁盘IO情况 123iostat -x 1# 或安装sudo apt install sysstat 4. 查看CPU信息 查看CPU型号和核心数 1lscpu 输出示例： 1234Architecture: x86_64CPU op-mode(s): 32-bit, 64-bitCPU(s): 16Model name: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz 查看CPU使用率 123top# 或mpstat -P ALL 1 查看CPU温度（需要安装lm-sensors） 123sudo apt install lm-sensorssudo sensors-detectsensors 5. 查看综合系统信息 使用neofetch（需要安装） 12sudo apt install neofetchneofetch 使用inxi工具（需要安装） 12sudo apt install inxiinxi -Fxz 6. 查看GPU信息 NVIDIA显卡 123nvidia-smi# 或lspci | grep -i nvidia AMD/Intel显卡 12lspci | grep -i vgaglxinfo | grep &quot;OpenGL renderer&quot; 7. 查看网络信息 查看IP地址 123ip a# 或hostname -I 查看网络接口 123ifconfig# 或ip link show 查看路由表 123ip route# 或route -n 8. 查看系统运行时间 1uptime 输出示例： 114:30:45 up 5 days, 2:15, 3 users, load average: 0.08, 0.03, 0.01 9. 查看系统日志 查看内核日志 1dmesg 查看系统服务日志 1journalctl -xe 10. 常用组合命令 一键查看主要系统信息 12345echo -e &quot;\\n===== 系统版本 =====&quot; &amp;&amp; lsb_release -a &amp;&amp; \\echo -e &quot;\\n===== 内存信息 =====&quot; &amp;&amp; free -h &amp;&amp; \\echo -e &quot;\\n===== 磁盘信息 =====&quot; &amp;&amp; df -h &amp;&amp; \\echo -e &quot;\\n===== CPU信息 =====&quot; &amp;&amp; lscpu | grep -E &quot;Model name|CPU\\(s\\)&quot; &amp;&amp; \\echo -e &quot;\\n===== 运行时间 =====&quot; &amp;&amp; uptime 以上命令可以帮助您全面了解Ubuntu系统的硬件配置和运行状态。根据您的具体需求选择适合的命令即可。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"}],"author":"ladymorgana"},{"title":"vector的详细讲解","slug":"C/vector的详细讲解","date":"2025-07-11T01:07:09.000Z","updated":"2025-07-11T01:59:17.840Z","comments":true,"path":"2025/07/11/C/vector的详细讲解/","link":"","permalink":"http://www.formeasy.cc/2025/07/11/C/vector%E7%9A%84%E8%AF%A6%E7%BB%86%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"1.vector的介绍及使用 1.1 vector的介绍 1. vector 是表示可变大小数组的序列容器。 2. 就像数组一样， vector 也采用的连续存储空间来存储元素。也就是意味着可以采用下标对 vector 的元素 进行访问，和数组一样高效。但是又不像数组，它的大小是可以动态改变的，而且它的大小会被容器自 动处理。 3. 本质讲， vector 使用动态分配数组来存储它的元素。当新元素插入时候，这个数组需要被重新分配大小 为了增加存储空间。其做法是，分配一个新的数组，然后将全部元素移到这个数组。就时间而言，这是 一个相对代价高的任务，因为每当一个新的元素加入到容器的时候，vector 并不会每次都重新分配大 小。 4. vector 分配空间策略： vector 会分配一些额外的空间以适应可能的增长，因为存储空间比实际需要的存 储空间更大。不同的库采用不同的策略权衡空间的使用和重新分配。但是无论如何，重新分配都应该是 对数增长的间隔大小，以至于在末尾插入一个元素的时候是在常数时间的复杂度完成的。 5. 因此， vector 占用了更多的存储空间，为了获得管理存储空间的能力，并且以一种有效的方式动态增 长。 6. 与其它动态序列容器相比（ deque, list and forward_list ），vector 在访问元素的时候更加高效，在末 尾添加和删除元素相对高效。对于其它不在末尾的删除和插入操作，效率更低。比起list 和 forward_list 统一的迭代器和引用更好。 使用 STL 的三个境界：能用，明理，能扩展 ，那么下面学习 vector，我们也是按照这个方法去学习 当然也可以借助文档来学习 http://www.cplusplus.com/reference/vector/vector/ 1.2 vector的使用 vector 学习时一定要学会查看文档，vector在实际中非常的重要，在实际中我们熟悉常 见的接口就可以，下面列出了 哪些接口是要重点掌握的 。 1.2.1 vector的定义 1234567891011121314151617181920212223242526272829#define _CRT_SECURE_NO_WARNINGS #include &lt;iostream&gt;using namespace std;#include &lt;vector&gt; ////////////////////////////////////////////////////////////////////// vector的构造////////////////////////////////////////////////////////////////////int TestVector1()&#123; // constructors used in the same order as described above: vector&lt;int&gt; first; // empty vector of ints vector&lt;int&gt; second(4, 100); // four ints with value 100 vector&lt;int&gt; third(second.begin(), second.end()); // iterating through second vector&lt;int&gt; fourth(third); // a copy of third // 下面涉及迭代器初始化的部分，我们学习完迭代器再来看这部分 // the iterator constructor can also be used to construct from arrays: int myints[] = &#123; 16,2,77,29 &#125;; vector&lt;int&gt; fifth(myints, myints + sizeof(myints) / sizeof(int)); cout &lt;&lt; &quot;The contents of fifth are:&quot;; for (vector&lt;int&gt;::iterator it = fifth.begin(); it != fifth.end(); ++it) cout &lt;&lt; &#x27; &#x27; &lt;&lt; *it; cout &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; 1.2.2 vector iterator的使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253////////////////////////////////////////////////////////////////////////// vector的迭代器////////////////////////////////////////////////////////////////////////void PrintVector(const vector&lt;int&gt;&amp; v)&#123; // const对象使用const迭代器进行遍历打印 vector&lt;int&gt;::const_iterator it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl;&#125; void TestVector2()&#123; // 使用push_back插入4个数据 vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); v.push_back(4); // 使用迭代器进行遍历打印 vector&lt;int&gt;::iterator it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; // 使用迭代器进行修改 it = v.begin(); while (it != v.end()) &#123; *it *= 2; ++it; &#125; // 使用反向迭代器进行遍历再打印 // vector&lt;int&gt;::reverse_iterator rit = v.rbegin(); auto rit = v.rbegin(); while (rit != v.rend()) &#123; cout &lt;&lt; *rit &lt;&lt; &quot; &quot;; ++rit; &#125; cout &lt;&lt; endl; PrintVector(v);&#125; 1.2.3 vector 空间增长问题 capacity 的代码在 vs 和 g++ 下分别运行会发现， vs 下 capacity 是按 1.5 倍增长的， g++ 是按 2 倍增长的 。 这个问题经常会考察，不要固化的认为，vector 增容都是 2 倍，具体增长多少是根据具体的需求定义 的。vs 是 PJ 版本 STL ， g++ 是 SGI 版本 STL 。 reserve 只负责开辟空间，如果确定知道需要用多少空间， reserve 可以缓解 vector 增容的代价缺陷问 题。 resize在开空间的同时还会进行初始化，影响 size 。 123456789101112131415161718192021222324252627282930313233343536373839404142// 测试vector的默认扩容机制void TestVectorExpand()&#123; size_t sz; vector&lt;int&gt; v; sz = v.capacity(); cout &lt;&lt; &quot;making v grow:\\n&quot;; for (int i = 0; i &lt; 100; ++i) &#123; v.push_back(i); if (sz != v.capacity()) &#123; sz = v.capacity(); cout &lt;&lt; &quot;capacity changed: &quot; &lt;&lt; sz &lt;&lt; &#x27;\\n&#x27;; &#125; &#125;&#125;//vs：运行结果：vs下使用的STL基本是按照1.5倍方式扩容//making foo grow ://capacity changed : 1//capacity changed : 2//capacity changed : 3//capacity changed : 4//capacity changed : 6//capacity changed : 9//capacity changed : 13//capacity changed : 19//capacity changed : 28//capacity changed : 42//capacity changed : 63//capacity changed : 94//capacity changed : 141//g++运行结果：linux下使用的STL基本是按照2倍方式扩容//making foo grow ://capacity changed : 1//capacity changed : 2//capacity changed : 4//capacity changed : 8//capacity changed : 16//capacity changed : 32//capacity changed : 64//capacity changed : 128 123456789101112131415161718// 如果已经确定vector中要存储元素大概个数，可以提前将空间设置足够// 就可以避免边插入边扩容导致效率低下的问题了void TestVectorExpandOP()&#123; vector&lt;int&gt; v; size_t sz = v.capacity(); v.reserve(100); // 提前将容量设置好，可以避免一遍插入一遍扩容 cout &lt;&lt; &quot;making bar grow:\\n&quot;; for (int i = 0; i &lt; 100; ++i) &#123; v.push_back(i); if (sz != v.capacity()) &#123; sz = v.capacity(); cout &lt;&lt; &quot;capacity changed: &quot; &lt;&lt; sz &lt;&lt; &#x27;\\n&#x27;; &#125; &#125;&#125; 接口演示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162////////////////////////////////////////////////////////////////////////// vector的resize 和 reserve////////////////////////////////////////////////////////////////////////// reisze(size_t n, const T&amp; data = T())// 将有效元素个数设置为n个，如果时增多时，增多的元素使用data进行填充// 注意：resize在增多元素个数时可能会扩容void TestVector3()&#123; vector&lt;int&gt; v; // set some initial content: for (int i = 1; i &lt; 10; i++) v.push_back(i); v.resize(5); v.resize(8, 100); v.resize(12); cout &lt;&lt; &quot;v contains:&quot;; for (size_t i = 0; i &lt; v.size(); i++) cout &lt;&lt; &#x27; &#x27; &lt;&lt; v[i]; cout &lt;&lt; &#x27;\\n&#x27;;&#125; // 测试vector的默认扩容机制// vs：按照1.5倍方式扩容// linux：按照2倍方式扩容void TestVectorExpand()&#123; size_t sz; vector&lt;int&gt; v; sz = v.capacity(); cout &lt;&lt; &quot;making v grow:\\n&quot;; for (int i = 0; i &lt; 100; ++i) &#123; v.push_back(i); if (sz != v.capacity()) &#123; sz = v.capacity(); cout &lt;&lt; &quot;capacity changed: &quot; &lt;&lt; sz &lt;&lt; &#x27;\\n&#x27;; &#125; &#125;&#125; // 往vecotr中插入元素时，如果大概已经知道要存放多少个元素// 可以通过reserve方法提前将容量设置好，避免边插入边扩容效率低void TestVectorExpandOP()&#123; vector&lt;int&gt; v; size_t sz = v.capacity(); v.reserve(100); // 提前将容量设置好，可以避免一遍插入一遍扩容 cout &lt;&lt; &quot;making bar grow:\\n&quot;; for (int i = 0; i &lt; 100; ++i) &#123; v.push_back(i); if (sz != v.capacity()) &#123; sz = v.capacity(); cout &lt;&lt; &quot;capacity changed: &quot; &lt;&lt; sz &lt;&lt; &#x27;\\n&#x27;; &#125; &#125;&#125; 1.2.4 vector 增删查改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106////////////////////////////////////////////////////////////////////////// vector的增删改查////////////////////////////////////////////////////////////////////////// 尾插和尾删：push_back/pop_backvoid TestVector4()&#123; vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); v.push_back(4); auto it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; v.pop_back(); v.pop_back(); it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl;&#125; // 任意位置插入：insert和erase，以及查找find// 注意find不是vector自身提供的方法，是STL提供的算法void TestVector5()&#123; // 使用列表方式初始化，C++11新语法 vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; // 在指定位置前插入值为val的元素，比如：3之前插入30,如果没有则不插入 // 1. 先使用find查找3所在位置 // 注意：vector没有提供find方法，如果要查找只能使用STL提供的全局find auto pos = find(v.begin(), v.end(), 3); if (pos != v.end()) &#123; // 2. 在pos位置之前插入30 v.insert(pos, 30); &#125; vector&lt;int&gt;::iterator it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; pos = find(v.begin(), v.end(), 3); // 删除pos位置的数据 v.erase(pos); it = v.begin(); while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl;&#125; // operator[]+index 和 C++11中vector的新式for+auto的遍历// vector使用这两种遍历方式是比较便捷的。void TestVector6()&#123; vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; // 通过[]读写第0个位置。 v[0] = 10; cout &lt;&lt; v[0] &lt;&lt; endl; // 1. 使用for+[]小标方式遍历 for (size_t i = 0; i &lt; v.size(); ++i) cout &lt;&lt; v[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; vector&lt;int&gt; swapv; swapv.swap(v); cout &lt;&lt; &quot;v data:&quot;; for (size_t i = 0; i &lt; v.size(); ++i) cout &lt;&lt; v[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; // 2. 使用迭代器遍历 cout &lt;&lt; &quot;swapv data:&quot;; auto it = swapv.begin(); while (it != swapv.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; // 3. 使用范围for遍历 for (auto x : v) cout &lt;&lt; x &lt;&lt; &quot; &quot;; cout &lt;&lt; endl;&#125; 1.2.5 vector 迭代器失效问题。（重点） 迭代器的主要作用就是让算法能够不用关心底层数据结构，其底层实际就是一个指针，或者是对指针进行了 封装 ，比如： vector 的迭代器就是原生态指针 T* 。因此 迭代器失效，实际就是迭代器底层对应指针所指向的 空间被销毁了，而使用一块已经被释放的空间 ，造成的后果是程序崩溃 ( 即 如果继续使用已经失效的迭代器， 程序可能会崩溃 ) 。 对于vector 可能会导致其迭代器失效的操作有： 1. 会引起其底层空间改变的操作，都有可能是迭代器失效 ，比如： resize 、 reserve 、 insert 、 assign 、 push_back等 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;#include &lt;vector&gt;int main()&#123; vector&lt;int&gt; v&#123; 1,2,3,4,5,6 &#125;; auto it = v.begin(); // 将有效元素个数增加到100个，多出的位置使用8填充，操作期间底层会扩容 // v.resize(100, 8); // reserve的作用就是改变扩容大小但不改变有效元素个数，操作期间可能会引起底层容量改变 // v.reserve(100); // 插入元素期间，可能会引起扩容，而导致原空间被释放 // v.insert(v.begin(), 0); // v.push_back(8); // 给vector重新赋值，可能会引起底层容量改变 v.assign(100, 8); /* 出错原因：以上操作，都有可能会导致vector扩容，也就是说vector底层原理旧空间被释放掉， 而在打印时，it还使用的是释放之间的旧空间，在对it迭代器操作时，实际操作的是一块已经被释放的 空间，而引起代码运行时崩溃。 解决方式：在以上操作完成之后，如果想要继续通过迭代器操作vector中的元素，只需给it重新 赋值即可。 */ while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; return 0;&#125; 2. 指定位置元素的删除操作 - -erase 1234567891011121314#include &lt;iostream&gt;using namespace std;#include &lt;vector&gt;int main()&#123; int a[] = &#123; 1, 2, 3, 4 &#125;; vector&lt;int&gt; v(a, a + sizeof(a) / sizeof(int)); // 使用find查找3所在位置的iterator vector&lt;int&gt;::iterator pos = find(v.begin(), v.end(), 3); // 删除pos位置的数据，导致pos迭代器失效。 v.erase(pos); cout &lt;&lt; *pos &lt;&lt; endl; // 此处会导致非法访问 return 0;&#125; erase 删除 pos 位置元素后， pos 位置之后的元素会往前搬移，没有导致底层空间的改变，理论上讲迭代 器不应该会失效，但是：如果pos 刚好是最后一个元素，删完之后 pos 刚好是 end 的位置，而 end 位置是 没有元素的，那么pos 就失效了。因此删除 vector 中任意位置上元素时， vs 就认为该位置迭代器失效 了。 以下代码的功能是删除 vector 中所有的偶数，请问那个代码是正确的，为什么？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;#include &lt;vector&gt;int main()&#123; int a[] = &#123; 1, 2, 3, 4 &#125;; vector&lt;int&gt; v(a, a + sizeof(a) / sizeof(int)); // 使用find查找3所在位置的iterator vector&lt;int&gt;::iterator pos = find(v.begin(), v.end(), 3); // 删除pos位置的数据，导致pos迭代器失效。 v.erase(pos); cout &lt;&lt; *pos &lt;&lt; endl; // 此处会导致非法访问 return 0;&#125; #include &lt;iostream&gt;using namespace std;#include &lt;vector&gt;int main()&#123; vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; auto it = v.begin(); while (it != v.end()) &#123; if (*it % 2 == 0) v.erase(it); ++it; &#125; return 0;&#125;int main()&#123; vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; auto it = v.begin(); while (it != v.end()) &#123; if (*it % 2 == 0) it = v.erase(it); else ++it; &#125; return 0;&#125; 3. 注意： Linux 下， g++ 编译器对迭代器失效的检测并不是非常严格，处理也没有 vs 下极端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#include &lt;iostream&gt;using namespace std;#include &lt;vector&gt;int main()&#123; vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; auto it = v.begin(); while (it != v.end()) &#123; if (*it % 2 == 0) v.erase(it); ++it; &#125; return 0;&#125;int main()&#123; vector&lt;int&gt; v&#123; 1, 2, 3, 4 &#125;; auto it = v.begin(); while (it != v.end()) &#123; if (*it % 2 == 0) it = v.erase(it); else ++it; &#125; return 0;&#125; // 1. 扩容之后，迭代器已经失效了，程序虽然可以运行，但是运行结果已经不对了int main()&#123; vector&lt;int&gt; v&#123; 1,2,3,4,5 &#125;; for (size_t i = 0; i &lt; v.size(); ++i) cout &lt;&lt; v[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; auto it = v.begin(); cout &lt;&lt; &quot;扩容之前，vector的容量为: &quot; &lt;&lt; v.capacity() &lt;&lt; endl; // 通过reserve将底层空间设置为100，目的是为了让vector的迭代器失效 v.reserve(100); cout &lt;&lt; &quot;扩容之后，vector的容量为: &quot; &lt;&lt; v.capacity() &lt;&lt; endl; // 经过上述reserve之后，it迭代器肯定会失效，在vs下程序就直接崩溃了，但是linux下不会 // 虽然可能运行，但是输出的结果是不对的 while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; return 0;&#125;程序输出：1 2 3 4 5扩容之前，vector的容量为: 5扩容之后，vector的容量为 : 1000 2 3 4 5 409 1 2 3 4 5// 2. erase删除任意位置代码后，linux下迭代器并没有失效// 因为空间还是原来的空间，后序元素往前搬移了，it的位置还是有效的#include &lt;vector&gt;#include &lt;algorithm&gt;int main()&#123; vector&lt;int&gt; v&#123; 1,2,3,4,5 &#125;; vector&lt;int&gt;::iterator it = find(v.begin(), v.end(), 3); v.erase(it) cout &lt;&lt; *it &lt;&lt; endl; while (it != v.end()) &#123; cout &lt;&lt; *it &lt;&lt; &quot; &quot;; ++it; &#125; cout &lt;&lt; endl; return 0;&#125;程序可以正常运行，并打印：44 5 // 3: erase删除的迭代器如果是最后一个元素，删除之后it已经超过end// 此时迭代器是无效的，++it导致程序崩溃int main()&#123; vector&lt;int&gt; v&#123; 1,2,3,4,5 &#125;; // vector&lt;int&gt; v&#123;1,2,3,4,5,6&#125;; auto it = v.begin(); while (it != v.end()) &#123; if (*it % 2 == 0) v.erase(it); ++it; &#125; for (auto e : v) cout &lt;&lt; e &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; return 0;&#125;========================================================// 使用第一组数据时，程序可以运行[sly@VM - 0 - 3 - centos 20220114]$ g++ testVector.cpp - std = c++11[sly@VM - 0 - 3 - centos 20220114]$ . / a.out1 3 5======================================================== =// 使用第二组数据时，程序最终会崩溃[sly@VM - 0 - 3 - centos 20220114]$ vim testVector.cpp[sly@VM - 0 - 3 - centos 20220114]$ g++ testVector.cpp - std = c++11[sly@VM - 0 - 3 - centos 20220114]$ . / a.outSegmentation fault 从上述三个例子中可以看到： SGI STL 中，迭代器失效后，代码并不一定会崩溃，但是运行结果肯定不 对，如果it 不在 begin 和 end 范围内，肯定会崩溃的。 4. 与 vector 类似， string 在插入 + 扩容操作 +erase 之后，迭代器也会失效 12345678910111213141516171819202122232425#include &lt;string&gt;void TestString()&#123; string s(&quot;hello&quot;); auto it = s.begin(); // 放开之后代码会崩溃，因为resize到20会string会进行扩容 // 扩容之后，it指向之前旧空间已经被释放了，该迭代器就失效了 // 后序打印时，再访问it指向的空间程序就会崩溃 //s.resize(20, &#x27;!&#x27;); while (it != s.end()) &#123; cout &lt;&lt; *it; ++it; &#125; cout &lt;&lt; endl; it = s.begin(); while (it != s.end()) &#123; it = s.erase(it); // 按照下面方式写，运行时程序会崩溃，因为erase(it)之后 // it位置的迭代器就失效了 // s.erase(it); ++it; &#125;&#125; 迭代器失效解决办法：在使用前，对迭代器重新赋值即可. 2.vector深度剖析及模拟实现 2.1 std::vector的核心框架接口的模拟实现xyl::vector 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426#pragma once#include &lt;assert.h&gt; namespace xyl&#123; template &lt;class T&gt; class vector &#123; public: typedef T* iterator; typedef const T* const_iterator; vector() :_start(nullptr) , _finish ( nullptr) , _endOfStorage (nullptr) &#123; &#125; vector(int n, const T&amp; value = T()) :_start(nullptr) , _finish ( nullptr) , _endOfStorage (nullptr) &#123; resize(n, value); &#125; template&lt;class InputIterator&gt; vector(InputIterator first, InputIterator last) :_start(nullptr) , _finish ( nullptr) , _endOfStorage (nullptr) &#123; size_t sz = last-first; T* tmp = new T[sz]; for (size_t i = 0;i &lt; sz;i++) &#123; tmp[i] = first[i]; &#125; //memcpy(tmp, first, sizeof(T) * (sz)); _start = tmp; _finish = _start + sz; _endOfStorage = _finish; &#125; vector( vector&lt;T&gt;&amp; v) :_start(nullptr) , _finish(nullptr) , _endOfStorage(nullptr) &#123; size_t sz= v.size(); size_t cp = v.capacity(); _start = new T[cp]; for (size_t i = 0;i &lt; sz;i++) &#123; _start[i] = v._start[i]; &#125; //memcpy(tmp, v._start, sizeof(T) * (sz)); _finish = _start + sz; _endOfStorage = _start+ cp; &#125; vector&lt;T&gt;&amp; operator= (vector&lt;T&gt; v) &#123; /*size_t sz = v.size(); size_t cp = v.capacity(); T* tmp = new T[cp]; memcpy(tmp, v._start, sizeof(T) * (sz)); _start = tmp; _finish = _start + sz; _endOfStorage = _start + cp;*/ swap(v); return *this; &#125; void reserve(size_t n) &#123; if (n &gt;= capacity()) &#123; size_t sz = size(); T* tmp = new T[n]; if (_start) &#123; for (size_t i=0;i &lt; sz;i++) &#123; tmp[i] = _start[i]; &#125; //memcpy(tmp, _start, sizeof(T)*sz); delete[]_start; &#125; _start = tmp; _finish = _start + sz; _endOfStorage = _start + n; &#125; &#125; void resize(size_t n, const T&amp; value = T()) &#123; /* for (size_t i = 0;i &lt; n;i++) &#123; push_back(value); &#125;*/ if (n &lt; size()) &#123; _finish = _start + n; &#125; else &#123; reserve(n); while (_finish != _start + n) &#123; *_finish = value; _finish++; &#125; &#125; &#125; void push_back(const T&amp; x) &#123; if (_finish == _endOfStorage) &#123; size_t newcapacity =capacity()== 0 ? 4 : capacity() * 2; reserve(newcapacity); &#125; *_finish = x; _finish++; &#125; void pop_back() &#123; assert(size()); //_finish -= 1; erase(end()-1); &#125; void swap(vector&lt;T&gt;&amp; v) &#123; std::swap(_start, v._start); std::swap(_finish, v._finish); std::swap(_endOfStorage, v._endOfStorage); &#125; iterator insert(iterator pos, const T&amp; x) &#123; assert(pos &gt;= _start &amp;&amp; pos &lt;= _finish); if (_finish==_endOfStorage) &#123; size_t len = pos-_start; size_t newcapacity = capacity() == 0 ? 4 : capacity() * 2; reserve(newcapacity); pos = _start + len; &#125; iterator end = _finish - 1; while (end &gt;= pos) &#123; *(end + 1) = *end; end--; &#125; *pos = x; ++_finish; return pos; &#125; iterator erase(iterator pos) &#123; assert(pos &gt;= _start &amp;&amp; pos &lt;= _finish); iterator p1 = pos; iterator end = _finish - 1; while (p1&lt;end ) &#123; *p1 = *(p1+1); p1++; &#125; _finish--; return pos; &#125; size_t capacity() &#123; return _endOfStorage - _start; &#125; size_t size() &#123; return _finish - _start; &#125; iterator begin() &#123; return _start; &#125; iterator end() &#123; return _finish; &#125; const_iterator begin() const &#123; return _start; &#125; const_iterator end() const &#123; return _finish; &#125; const_iterator cbegin() &#123; return _start; &#125; const_iterator cend() const &#123; return _finish; &#125; T&amp; operator[](size_t pos) &#123; return _start[pos]; &#125; const T&amp; operator[](size_t pos)const &#123; return _start[pos]; &#125; ~vector() &#123; if (_start) &#123; delete[]_start; _start = _finish = _endOfStorage = nullptr; &#125; &#125; private: iterator _start; // 指向数据块的开始 iterator _finish; // 指向有效数据的尾 iterator _endOfStorage;// 指向存储容量的尾 &#125;;&#125;``` &#123;public:typedef T* iterator;typedef const T* const_iterator;vector():_start(nullptr), _finish ( nullptr), _endOfStorage (nullptr)&#123;&#125;vector(int n, const T&amp; value = T()) :_start(nullptr) , _finish ( nullptr) , _endOfStorage (nullptr)&#123;resize(n, value);&#125;template&lt;class InputIterator&gt;vector(InputIterator first, InputIterator last) :_start(nullptr) , _finish ( nullptr) , _endOfStorage (nullptr)&#123;size_t sz = last-first;T* tmp = new T[sz];for (size_t i = 0;i &lt; sz;i++)&#123;tmp[i] = first[i];&#125;_start = tmp;_finish = _start + sz;_endOfStorage = _finish;&#125;vector( vector&lt;T&gt;&amp; v):_start(nullptr), _finish(nullptr), _endOfStorage(nullptr)&#123;size_t sz= v.size();size_t cp = v.capacity();_start = new T[cp];for (size_t i = 0;i &lt; sz;i++)&#123;_start[i] = v._start[i];&#125;_finish = _start + sz;_endOfStorage = _start+ cp;&#125;vector&lt;T&gt;&amp; operator= (vector&lt;T&gt; v)&#123;swap(v);return *this;&#125;void reserve(size_t n)&#123;if (n &gt;= capacity())&#123;size_t sz = size();T* tmp = new T[n];if (_start)&#123;for (size_t i=0;i &lt; sz;i++)&#123;tmp[i] = _start[i];&#125;delete[]_start;&#125;_start = tmp;_finish = _start + sz;_endOfStorage = _start + n;&#125;&#125;void resize(size_t n, const T&amp; value = T())&#123;if (n &lt; size())&#123;_finish = _start + n;&#125;else&#123;reserve(n);while (_finish != _start + n)&#123;*_finish = value;_finish++;&#125;&#125;&#125;void push_back(const T&amp; x)&#123;if (_finish == _endOfStorage)&#123;size_t newcapacity =capacity()== 0 ? 4 : capacity() * 2;reserve(newcapacity);&#125;*_finish = x;_finish++;&#125;void pop_back()&#123;assert(size());erase(end()-1);&#125;void swap(vector&lt;T&gt;&amp; v)&#123;std::swap(_start, v._start);std::swap(_finish, v._finish);std::swap(_endOfStorage, v._endOfStorage);&#125;iterator insert(iterator pos, const T&amp; x)&#123;assert(pos &gt;= _start &amp;&amp; pos &lt;= _finish);if (_finish==_endOfStorage)&#123;size_t len = pos-_start;size_t newcapacity = capacity() == 0 ? 4 : capacity() * 2;reserve(newcapacity);pos = _start + len;&#125;iterator end = _finish - 1;while (end &gt;= pos)&#123;*(end + 1) = *end;end--;&#125;*pos = x;++_finish;return pos;&#125;iterator erase(iterator pos)&#123;assert(pos &gt;= _start &amp;&amp; pos &lt;= _finish);iterator p1 = pos;iterator end = _finish - 1;while (p1&lt;end )&#123;*p1 = *(p1+1); p1++;&#125;_finish--;return pos;&#125;size_t capacity()&#123;return _endOfStorage - _start;&#125;size_t size()&#123;return _finish - _start;&#125;iterator begin()&#123;return _start;&#125;iterator end()&#123;return _finish;&#125;const_iterator begin() const&#123;return _start;&#125;const_iterator end() const&#123;return _finish;&#125;const_iterator cbegin()&#123;return _start;&#125;const_iterator cend() const&#123;return _finish;&#125;T&amp; operator[](size_t pos)&#123;return _start[pos];&#125;const T&amp; operator[](size_t pos)const&#123;return _start[pos];&#125;~vector()&#123;if (_start)&#123;delete[]_start;_start = _finish = _endOfStorage = nullptr;&#125;&#125;private:iterator _start; iterator _finish; iterator _endOfStorage;&#125;;&#125;测试部分```c++#include &lt;iostream&gt;//#include&lt;vector&gt;#include &quot;vector.h&quot; using namespace std;void test_vector1()&#123; xyl::vector&lt;int&gt; v1; v1.push_back(1); v1.push_back(2); v1.push_back(3); v1.push_back(4); v1.push_back(5); v1.push_back(6); v1.push_back(7); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; xyl::vector&lt;int&gt; v2(5,100); for (auto e : v2) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; xyl::vector&lt;int&gt; v3(v1.begin(), v1.end()); for (auto e : v3) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; xyl::vector&lt;int&gt; v4(v3); cout &lt;&lt; endl; for (auto e : v4) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; xyl::vector&lt;int&gt; v5; cout &lt;&lt; endl; v5 = v4; for (auto e : v5) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; for (int i = 0;i &lt; v5.size();i++) &#123; cout &lt;&lt; v5[i]&lt;&lt; &quot; &quot;; &#125;&#125;void test_vector2()&#123; xyl::vector&lt;int&gt; v1; v1.push_back(1); v1.push_back(2); v1.push_back(3); v1.push_back(4); v1.push_back(5); v1.push_back(4); v1.push_back(100); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; v1.pop_back(); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; xyl::vector&lt;int&gt; v2; v1.swap(v2); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; for (auto e : v2) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; xyl::vector&lt;int&gt; v3; v3.push_back(1); v3.push_back(4); v3.push_back(3); v3.push_back(4); v3.push_back(500); v3.push_back(4); v3.push_back(100); v3.insert(v3.begin()+2, 5); for (auto e : v3) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; v3.erase(v3.begin() + 2); for (auto e : v3) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125;&#125;void test_vector3()&#123; xyl::vector&lt;int&gt; v1; v1.push_back(1); v1.push_back(2); v1.push_back(3); v1.push_back(4); v1.push_back(5); v1.push_back(4); v1.push_back(100); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; v1.erase(v1.end()); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125;&#125;void test_vector4()&#123; xyl::vector&lt;int&gt; v1; v1.resize(10); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &quot; &quot;; &#125;&#125;void test_vector5()&#123; xyl::vector&lt;string&gt; v1; v1.push_back(&quot;1111111111&quot;); v1.push_back(&quot;2222222222&quot;); v1.push_back(&quot;3333333333&quot;); v1.push_back(&quot;4444444444&quot;); for (auto e : v1) &#123; cout &lt;&lt; e &lt;&lt; &#x27; &#x27;; &#125; cout &lt;&lt; endl; xyl::vector&lt;string&gt; v2(v1); for (auto e : v2) &#123; cout &lt;&lt; e &lt;&lt; &#x27; &#x27;; &#125; cout &lt;&lt; endl; xyl::vector&lt;string&gt; v3(v1.begin(),v1.end()); for (auto e : v3) &#123; cout &lt;&lt; e &lt;&lt; &#x27; &#x27;; &#125;&#125;int main()&#123; test_vector5(); return 0;&#125; 2.2 使用memcpy拷贝问题 假设模拟实现的 vector 中的 reserve 接口中，使用 memcpy 进行的拷贝，以下代码会发生什么问题？ 12345678int main()&#123; xyl::vector&lt;bite::string&gt; v; v.push_back(&quot;1111&quot;); v.push_back(&quot;2222&quot;); v.push_back(&quot;3333&quot;); return 0;&#125; 问题分析： 1. memcpy 是内存的二进制格式拷贝，将一段内存空间中内容原封不动的拷贝到另外一段内存空间中 2. 如果拷贝的是内置类型的元素， memcpy 既高效又不会出错，但如果拷贝的是自定义类型元素，并且自 定义类型元素中涉及到资源管理时，就会出错，因为memcpy 的拷贝实际是浅拷贝。 结论：如果对象中涉及到资源管理时，千万不能使用 memcpy 进行对象之间的拷贝，因为 memcpy 是 浅拷贝，否则可能会引起内存泄漏甚至程序崩溃。 2.3****动态二维数组理解 123456789101112131415161718// 以杨辉三角的前n行为例：假设n为5void test2vector(size_t n)&#123; // 使用vector定义二维数组vv，vv中的每个元素都是vector&lt;int&gt; bit::vector&lt;bit::vector&lt;int&gt;&gt; vv(n); // 将二维数组每一行中的vecotr&lt;int&gt;中的元素全部设置为1 for (size_t i = 0; i &lt; n; ++i) vv[i].resize(i + 1, 1); // 给杨辉三角出第一列和对角线的所有元素赋值 for (int i = 2; i &lt; n; ++i) &#123; for (int j = 1; j &lt; i; ++j) &#123; vv[i][j] = vv[i - 1][j] + vv[i - 1][j - 1]; &#125; &#125;&#125; bit::vector&lt;bit::vector&gt; vv(n) ; 构造一个 vv 动态二维数组， vv 中总共有 n 个元素，每个元素都是 vector 类 型的，每行没有包含任何元素，如果n 为 5 时如下所示： vv 中元素填充完成之后，如下图所示： 使用标准库中 vector 构建动态二维数组时与上图实际是一致的","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":"hy____123"},{"title":"【机器学习】决策树（Decision Tree）","slug":"algo/【机器学习】决策树（Decision Tree）","date":"2025-07-10T01:33:12.000Z","updated":"2025-07-10T01:38:24.844Z","comments":true,"path":"2025/07/10/algo/【机器学习】决策树（Decision Tree）/","link":"","permalink":"http://www.formeasy.cc/2025/07/10/algo/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88Decision%20Tree%EF%BC%89/","excerpt":"","text":"引入 决策树是一类预测模型，它代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。 关于分类问题 这里主要考虑决策树基于分类问题的处理算法，分类问题和回归问题有个简单的判别方式：分类的目标属性是离散的，而回归的目标属性是连续的。 分类问题的步骤 1、模型构建：通过对训练集合的归纳，利用归纳算法生成可读的规则，建立分类模型。 2、预测推论：根据规则和建立的分类模型，对测试集合进行测试，并处理新的数据。 关于归纳算法 归纳是从特殊到一般的过程，归纳过程就是在描述空间中进行搜索的过程。 归纳可分为自顶向下，自底向上和双向搜索三种方式。 自底向上法：一次处理一个输入对象，将描述逐步一般化， 直到最终的一般化描述。 自顶向下法：对一般性描述集进行搜索，寻找满足一定要求的最优的描述。 归纳算法是决策树技术发现数据模式和规则的核心。 归纳学习依赖于检验数据，因此又称为检验学习。 归纳推理试图从对象的一部分或整体的特定的观察中获得一个完备且正确的描述。即从部分事实到普遍性规律的结论。 归纳的基本假设 归纳学习存在一个基本假设：任一假设如果能够在足够大的训练样本集中很好的逼近目标函数，则它也能在测试样本中很好地逼近目标函数。 该假定是归纳学习的有效性的前提条件。 决策树模型 分类决策树是一种描述对实例进行分类的树形结构，决策树由结点和有向边构成，结点可分为内部结点和叶结点两种，内部节点表示一个特征或属性，叶节点表示一个分类，通常用圆表示内部结点，用方框表示叶结点。 决策树分类，从根结点开始，对实例某一特征进行测试，根据测试结果将实例分配到其子结点，每一个子结点对应着该特征的一个取值，如此递归直至达到叶结点。 构造决策树的核心问题是在每一步如何选择适当的属性对样本做拆分。对一个分类问题，从已知类标记的训练样本中学习并构造出决策树是一个自上而下，分而治之的过程。 决策树的if-then规则 由决策树的根结点到叶结点的每一条路径构建一条规则:路径上内部结点的特征对应规则的条件，而叶结点的类对应规则的结论。 决策树的路径与其对应的if-then规则集合具有一个重要的性质:互斥且完备。这意味着每一个实例都被一条路径或一条规则所覆盖，并且只被一条路径或一条规则所覆盖。 决策树与条件概率分布 决策树表示给定特征条件下类的条件概率分布。条件概率分布定义在特征空间的一个划分上.将特征空间划分为互不相交的单元或区域，并在每个单元定义一个类的概率分布就构成了一个条件概率分布。 决策树的一条路径对应划分中的一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。 决策树学习本质上是从训练数据集中归纳出一组分类规则，能对训练数据进行正确分类的决策树可能有多个，也可能一个也没有。我们需要的是一个与训练数据矛盾较小同时具有较优泛化能力的决策树。即条件概率模型应该不仅对训练数据有很好的拟合，而且对未知数据有很好的预测。 决策树算法 四个重要算法：CLS、ID3、C4.5、CART。ID3中使用了信息增益选择特征，增益大优先选择。C4.5中，采用信息增益率选择特征，减少因特征值多导致信息增益大的问题。CART分类树算法使用基尼系数选择特征，基尼系数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）相反。 算法历程： 1966年，CLS学习系统 1979年，简化CLS，得到ID3 1984年，CART算法 1986年，基于ID3，创建节点缓冲区，得到ID4 1988年，基于ID4，优化效率，得到ID5 1993年，改进ID3，得到C4.5 决策树CLS算法 CLS(Concept Learning System)算法是许多决策树学习算法的基础 基本思想 CLS的基本思想是从一棵空决策树开始，选择某一分类属性作为测试属性。该测试属性对应决策树中的决策结点。根据该分类属性的值的不同，可将训练样本分成相应的子集。 若该子集为空，或该子集中的样本属于同一个类，则该子集为叶结点。否则该子集对应于决策树的内部结点，即测试结点，需要选择一个新的分类属性对该子集进行划分，直到所有的子集都为空或者属于同一类。 算法步骤 1、生成一颗空决策树和一张训练样本属性集； 2、若训练样本集T中所有的样本都属于同一类,则生成结点T , 并终止学习算法;否则继续； 3、根据某种策略从训练样本属性表中选择属性A 作为测试属性, 生成测试结点A； 测试属性集的组成以及测试属性的先后对决策树的学习具有举足轻重的影响 4、若A的取值为v1,v2,…,vm, 则根据A的取值的不同,将T划分成m个子集T1,T2,…,Tm； 5、从训练样本属性表中删除属性A，转至步骤二，对每个子集递归调用CLS。 算法思考 实际应用中可以发现，测试属性集的组成以及测试属性的先后对决策树的学习具有举足轻重的影响，不同的特征和不同的选取顺序会生成不同的决策树，因此特征的选择显得尤为重要。 不同的特征和不同的选取顺序会生成不同的决策树 那么，如何选择特征？这一点会在接下来的ID3算法中得到进一步尝试。 决策树ID3算法 ID3算法主要针对属性选择问题。是决策树学习方法中最具影响和最为典型的算法。 基本思想 基于CLS的基本思想，ID3算法通过信息增益度选择特征 当获取信息时，需要将不确定的内容转为确定的内容，因此信息伴着不确定性。从某种程度上讲，小概率事件比大概率事件包含的信息量大，如果某件事情是“百年一见”则肯定比“习以为常”的事件包含的信息量大。那么如何衡量信息量的大小？这就涉及信息论中的概念。 熵的概念 熵（entropy）: 信息量大小的度量，也表示随机变量不确定性的度量。 熵的通俗解释：事件Ai的信息量可以表示为：,其中表示事件Ai发生的概率。 熵的理论解释：设X是一个取有限个值的离散随机变量，其概率分布为 则随机变量X的熵为： 其中对数以2为底或以e为底，熵的单位分别称为比特(bit)或纳特(nat)。 熵只依赖于X的分布，与X的取值无关。 熵越大，对应随机变量的不确定性也越大。 当X为0，1分布时，,, H随p的变化情况可用图表示： 条件熵: ，表示在己知随机变量X的条件下随机变量Y的不确定性，定义为X给定条件下Y的条件概率分布的熵对X的数学期. 当熵和条件熵中的概率由数据估计(特别是极大似然估计)得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵. 信息增益 信息增益(Information gain)：特征A对训练数据集D的信息增益g(D,A), 定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即 信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度，一般来说称为互信息，决策树学习中的信息增益等价于训练数据集中类与特征的互信息。 信息增益的算法 输入：训练数据集D和特征A； 1、计算数据集D得经验熵： 2、计算特征A对数据集D的经验条件熵H(D|A) 3、计算信息增益 输出：特征A对训练数据集D的信息增益。 |Ck |为属于类Ck的样本个数 特征A有n个不同的 取值{a1,a2…an}根据特征A的取值 将D划分为n个子集D1…Dn 子集Di中属于类Ck的样本集合为Dik ID3算法 1、从根节点开始，计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的划分特征； 2、由该特征的不同取值建立子节点； 3、再对子节点递归1-2步，构建决策树； 4、直到没有特征可以选择或类别完全相同为止，得到最终的决策树。 算法思考 ID3算法以信息熵为度量，用于决策树节点的属性选择，每次优先选取信息量最多的属性，亦即能使熵值变为最小的属性，以构造一颗熵值下降最快的决策树，到叶子节点处的熵值为0。此时，每个叶子节点对应的实例集中的实例属于同一类。 决策树C4.5算法 ID3中使用了信息增益选择特征，增益大优先选择。C4.5中，采用信息增益率选择特征，减少因特征值多导致信息增益大的问题。以信息增益作为划分训练数据集的特征，易偏向于选择取值较多的特征，考虑信息增益比可以矫正这一问题。 信息增益比 特征A对训练数据集D的信息增益比定义为信息增益与训练数据集D关于特征A的值的熵之比 其中，n是特征A的取值个数 决策树CART算法 ID3和C4.5算法，生成的决策树是多叉树，只能处理分类不能处理回归。而CART（classification and regression tree）分类回归树算法，既可用于分类也可用于回归。 分类树的输出是样本的类别， 回归树的输出是一个实数。 算法组成 决策树生成 决策树剪枝 CATR树 目标变量是类别的——分类树：Gini指标、Towing、order Towing 目标变量是连续的——回归树：最小平方残差、最小绝对残差 基尼系数 数据集D的纯度可用基尼值来度量 其中， p(xi) 是分类 xi 出现的概率，n是分类的数目。Gini(D)反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此，Gini(D)越小，则数据集D的纯度越高。 对于样本D，样本容量为|D|，根据特征A 是否取某一可能值a，把样本D分成两部分D1和D2 ，所以CART分类树算法建立起来的是二叉树，而不是多叉树。 在属性A的条件下，样本D的基尼系数定义为 决策树的优点 1、决策推理过程可以表示成If-Then的形式； 2、推理过程完全依赖于属性变量的取值特点； 3、可忽略对目标变量无贡献的属性变量。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"algo","slug":"algo","permalink":"http://www.formeasy.cc/tags/algo/"}],"author":"weixin_73404807"},{"title":"C++动态分配内存知识点！","slug":"C/C++动态分配内存知识点！","date":"2025-07-10T01:24:48.000Z","updated":"2025-07-10T01:30:51.007Z","comments":true,"path":"2025/07/10/C/C++动态分配内存知识点！/","link":"","permalink":"http://www.formeasy.cc/2025/07/10/C/C++%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%81/","excerpt":"","text":"1.动态分配内存的思想 动态分配内存是指在程序运行时根据需要动态地分配内存空间。这相对于静态分配内存来说，静态分配内存是在编译时固定地分配内存空间，而动态分配内存可以在程序运行期间根据实际需求进行内存的申请和释放，以提高内存的利用率和灵活性。 2.动态分配内存的概念 动态分配内存的概念包括以下几个方面： 2.1内存分配函数 动态分配内存需要使用内存分配函数，如C语言中的malloc()、calloc()、realloc()等，这些函数可以根据需要在运行时动态地分配一块连续的内存空间。 2.2动态内存的申请和释放 使用内存分配函数可以申请一块指定大小的内存空间，申请的内存空间可以在程序运行期间使用。使用完毕后，可以使用释放函数将内存空间释放，以便其他程序继续使用。 2.3内存碎片问题 动态分配内存可能会导致内存碎片问题。当频繁地进行内存分配和释放操作时，可能会在内存中留下一些未被使用的小块内存，这些小块内存无法被再次利用，导致内存的浪费。为了解决内存碎片问题，可以使用内存管理算法来进行内存的分配和释放操作。 3.动态分配内存的作用 动态分配内存在计算机编程中有很多重要的作用，包括： 3.1 灵活分配内存空间 动态分配内存可以根据程序的实际需求，在运行时动态地申请适当大小的内存空间。这使得程序可以根据具体情况来分配所需的内存，提高了程序的灵活性和适应性。 3.2 提高内存利用率 动态分配内存可以避免静态分配内存的固定大小限制，可以根据实际需要进行灵活的内存分配。这样可以更有效地利用内存资源，避免了内存的浪费。 3.3 动态数据结构的实现 动态分配内存是实现动态数据结构（如链表、树等）的基础。动态数据结构的大小可能在程序运行过程中变化，需要动态地为其分配和释放内存空间。 3.4 避免内存溢出和内存泄漏 动态分配内存可以避免程序因为内存空间不足而导致的内存溢出错误。同时，使用动态分配内存还可以确保内存的正确释放，避免造成内存泄漏问题。 3.5 提高程序的性能 动态分配内存可以减少内存碎片的问题，提高内存的利用效率。同时，动态分配内存也可以减少静态分配内存的开销，提高程序的性能。 3.6 总结 总之，动态分配内存在计算机编程中具有重要的作用，它可以提供灵活的内存分配方式，提高内存的利用率，支持动态数据结构的实现，避免内存溢出和内存泄漏问题，同时提高程序的性能。 4.动态分配内存的实现 在C++中，动态内存分配通常使用new和delete操作符来完成。下面我将分步骤和代码两部分来介绍如何进行动态内存分配。 4.1 步骤 4.1.1 确定需要分配的内存大小 首先，你需要确定要分配多少内存。这通常取决于你要存储的数据类型以及你要存储多少这样的数据。 4.1.2 使用new操作符分配内存 使用new操作符来分配内存。例如，如果你要分配一个整数数组，你可以使用new int[size]，其中size是你想要的数组大小。 4.1.3 检查分配是否成功 new操作符在无法分配所需内存时会返回nullptr。因此，你应该检查返回的指针是否为nullptr，以确保内存已成功分配。 4.1.4 使用分配的内存 一旦内存成功分配，你就可以开始使用它。例如，你可以将值存储在数组中，或者创建对象等。 释放内存：当你不再需要分配的内存时，应使用delete或delete[]操作符来释放它。忘记释放内存会导致内存泄漏，这是一个常见的编程错误。 4.2 代码示例 下面是一个简单的代码示例，演示了如何在C++中动态分配和释放内存： 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt; int main() &#123;// 步骤1：确定需要分配的内存大小const int size = 10; // 步骤2：使用new操作符分配内存int* array = new int[size]; // 检查分配是否成功if (array == nullptr) &#123;std::cerr &lt;&lt; &quot;Memory allocation failed!&quot; &lt;&lt; std::endl;return 1; // 返回错误代码&#125; // 步骤3：使用分配的内存for (int i = 0; i &lt; size; ++i) &#123;array[i] = i;&#125; // 打印数组内容for (int i = 0; i &lt; size; ++i) &#123;std::cout &lt;&lt; array[i] &lt;&lt; &quot; &quot;;&#125;std::cout &lt;&lt; std::endl; // 步骤4：释放内存delete[] array; return 0;&#125; 在这个示例中，我们首先确定要分配的内存大小（一个包含10个整数的数组）。然后，我们使用new操作符分配内存，并检查是否成功。接着，我们使用分配的内存来存储值，并打印数组的内容。最后，我们使用delete[]操作符来释放内存。 5.动态分配内存的分类及代码 在C++中，动态内存分配可以分为两类：动态分配单个对象的内存和动态分配对象数组的内存。 5.1 动态分配单个对象的内存 当你知道需要创建一个对象，但不知道它的生命周期时，可以使用new操作符动态地为其分配内存。这种分配方式在对象的大小不是固定大小时特别有用。 5.1.1 介绍 使用new为单个对象分配内存时，你需要指定对象的类型。new会返回指向新创建对象的指针。如果内存分配成功，你可以使用这个指针来访问和操作对象。如果内存分配失败，new会返回nullptr。 5.1.2 代码示例 12345678910111213141516171819202122#include &lt;iostream&gt; class MyClass &#123;public:MyClass(int value) : value_(value) &#123;&#125;void printValue() &#123; std::cout &lt;&lt; value_ &lt;&lt; std::endl; &#125;private:int value_;&#125;; int main() &#123;// 动态分配单个对象的内存MyClass* obj = new MyClass(42); // 使用对象obj-&gt;printValue(); // 释放内存delete obj; return 0;&#125; 5.2 动态分配对象数组的内存 当你需要创建多个同类型的对象时，可以使用new操作符来动态分配一个对象数组。这种方式在你不确定数组大小，或者数组大小在运行时才能确定时非常有用。 5.2.1 介绍 使用new为对象数组分配内存时，你需要指定对象的类型和数组的大小。new会返回一个指向数组第一个元素的指针。与单个对象不同，当你使用new为数组分配内存时，需要使用delete[]来释放内存。 5.2.2 代码示例 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt; class MyClass &#123;public:MyClass(int value) : value_(value) &#123;&#125;void printValue() &#123; std::cout &lt;&lt; value_ &lt;&lt; std::endl; &#125;private:int value_;&#125;; int main() &#123;// 动态分配对象数组的内存const int arraySize = 5;MyClass* array = new MyClass[arraySize]; // 初始化数组中的对象for (int i = 0; i &lt; arraySize; ++i) &#123;array[i] = MyClass(i * 10);&#125; // 使用数组中的对象for (int i = 0; i &lt; arraySize; ++i) &#123;array[i].printValue();&#125; // 释放内存delete[] array; return 0;&#125; 在上面的示例中，我们动态地创建了一个包含5个MyClass对象的数组，并分别初始化了它们。之后，我们遍历数组并打印每个对象的值。最后，我们使用delete[]释放了整个数组所占用的内存。 5.3 注意事项 1.使用new分配的内存必须使用delete或delete[]来释放，否则会导致内存泄漏。 2.new和delete是配对使用的，new[]和delete[]也是配对使用的。不应该混合使用它们，因为这会导致未定义的行为。 3.在使用new分配内存后，总是应该检查返回的指针是否为nullptr，以确保内存分配成功。 4.在C++11及以后的版本中，推荐使用智能指针（如std::unique_ptr和std::shared_ptr）来管理动态分配的内存，以自动处理内存释放，减少内存泄漏的风险。 6.动态分配内存的练习 6.1 题目描述 创建一个程序，该程序使用动态内存分配来创建一个字符串数组。用户将首先输入数组的大小，然后为每个字符串元素输入具体的字符串内容。程序将显示所有输入的字符串，并允许用户选择是否继续添加更多字符串或释放内存并退出程序。 6.2 知识点 动态内存分配与释放（new、delete[]） 字符串处理（std::string）：C++ 字符串详解 用户输入和输出 （std::cin、std::cout） 循环结构（while、for）: C++ 循环：简化重复的代码 条件语句（if、else）：C++分支语句 6.3 步骤 6.3.1 初始化 设置必要的变量和标志，如数组大小、当前索引、是否继续的标志等。 6.3.2 输入数组大小 提示用户输入字符串数组的大小，并读取输入。 6.3.3 分配内存 使用new[]为字符串数组分配内存。 6.3.4 输入字符串内容 使用循环让用户为每个数组元素输入字符串内容。 6.3.5 显示字符串内容 使用循环显示所有输入的字符串。 6.3.6 用户选择 提供选项让用户决定是否继续添加字符串或退出程序。 6.3.7 释放内存 如果用户选择退出，释放已分配的内存。 6.3.8 结束程序 退出程序。 6.4 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;iostream&gt;#include &lt;string&gt; int main() &#123;int size;std::cout &lt;&lt; &quot;Enter the size of the string array: &quot;;std::cin &gt;&gt; size; if (size &lt;= 0) &#123;std::cerr &lt;&lt; &quot;Invalid array size. Size must be a positive integer.&quot; &lt;&lt; std::endl;return 1;&#125; std::string* arr = new std::string[size];if (arr == nullptr) &#123;std::cerr &lt;&lt; &quot;Memory allocation failed!&quot; &lt;&lt; std::endl;return 1;&#125; // 输入字符串内容std::cout &lt;&lt; &quot;Enter &quot; &lt;&lt; size &lt;&lt; &quot; strings for the array:&quot; &lt;&lt; std::endl;for (int i = 0; i &lt; size; ++i) &#123;std::cin &gt;&gt; arr[i];&#125; // 显示字符串内容std::cout &lt;&lt; &quot;The array contents are:&quot; &lt;&lt; std::endl;for (int i = 0; i &lt; size; ++i) &#123;std::cout &lt;&lt; arr[i] &lt;&lt; std::endl;&#125; // 用户选择char choice;do &#123;std::cout &lt;&lt; &quot;Do you want to continue adding more strings? (y/n): &quot;;std::cin &gt;&gt; choice;std::cin.ignore(); // 忽略换行符 if (choice == &#x27;y&#x27; || choice == &#x27;Y&#x27;) &#123;// 如果用户选择继续，再次分配内存并输入字符串size *= 2; // 假设我们每次翻倍std::string* newArr = new std::string[size];for (int i = 0; i &lt; size / 2; ++i) &#123;newArr[i] = arr[i];&#125;delete[] arr;arr = newArr; std::cout &lt;&lt; &quot;Enter &quot; &lt;&lt; size / 2 &lt;&lt; &quot; additional strings:&quot; &lt;&lt; std::endl;for (int i = size / 2; i &lt; size; ++i) &#123;std::cin &gt;&gt; arr[i];&#125; // 再次显示字符串内容（可选）// ... &#125; else if (choice == &#x27;n&#x27; || choice == &#x27;N&#x27;) &#123;// 如果用户选择退出，释放内存并退出程序std::cout &lt;&lt; &quot;Exiting program.&quot; &lt;&lt; std::endl;break;&#125; else &#123;std::cout &lt;&lt; &quot;Invalid choice. Please enter &#x27;y&#x27; or &#x27;n&#x27;: &quot; &lt;&lt; std::endl;&#125;&#125; while (true); // 释放内存delete[] arr; return 0;&#125; 这个程序演示了如何动态分配内存来创建一个字符串数组，如何让用户输入字符串内容，如何根据用户的选择动态调整数组大小，以及如何释放内存。同时，它也展示了基本的错误处理和用户交互。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":"PingdiGuo_guo"},{"title":"C++之红黑树认识与实现","slug":"C/C++之红黑树认识与实现","date":"2025-07-10T01:06:20.000Z","updated":"2025-07-10T01:24:22.769Z","comments":true,"path":"2025/07/10/C/C++之红黑树认识与实现/","link":"","permalink":"http://www.formeasy.cc/2025/07/10/C/C++%E4%B9%8B%E7%BA%A2%E9%BB%91%E6%A0%91%E8%AE%A4%E8%AF%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"一.红黑树的概念 红⿊树是⼀棵⼆叉搜索树，他的每个结点增加⼀个存储位来表⽰结点的颜⾊，可以是红⾊或者⿊⾊。通过对任何⼀条从根到叶⼦的路径上各个结点的颜⾊进⾏约束，红⿊树确保没有⼀条路径会⽐其他路径⻓出2倍，因⽽是接近平衡的。 红黑树的结构 123456789101112131415161718192021222324252627282930313233343536// 枚举值表⽰颜⾊ enum Colour&#123; RED, BLACK&#125;;template&lt;class K, class V&gt;struct RBTreeNode&#123; // 这⾥更新控制平衡也要加⼊parent指针 pair&lt;K, V&gt; _kv; RBTreeNode&lt;K, V&gt;* _left; RBTreeNode&lt;K, V&gt;* _right; RBTreeNode&lt;K, V&gt;* _parent; Colour _col; RBTreeNode(const pair&lt;K, V&gt;&amp; kv) :_kv(kv) , _left(nullptr) , _right(nullptr) , _parent(nullptr) &#123;&#125;&#125;;template&lt;class K, class V&gt;class RBTree&#123; typedef RBTreeNode&lt;K, V&gt; Node;public:private: Node* _root = nullptr;&#125;; 二.红黑树的定义与特性 红黑树是一种自平衡的二叉查找树，它满足以下五条基本性质： 节点是红色或黑色：每个节点都有一个颜色属性，红色或黑色。 根节点是黑色：树的根节点必须是黑色。 叶子节点是黑色：叶子节点（即空节点或NULL节点）是黑色。 红色节点的子节点是黑色：如果一个节点是红色，则它的两个子节点都是黑色。 从任意节点到其每个叶子的所有路径都包含相同数量的黑色节点：这确保了树的平衡性。 这些性质保证了红黑树在插入和删除操作后能够保持大致平衡，从而使得查找、插入和删除操作的时间复杂度都能保持在(O(log n))。 一.红黑树的插入操作 插入操作是红黑树中最复杂的部分之一。插入一个新节点后，可能会破坏红黑树的性质，因此需要通过一系列的调整来恢复这些性质。插入操作可以分为以下几个步骤： 1. 插入节点 首先，将新节点插入到红黑树中，就像在普通二叉查找树中插入一样。新插入的节点会被标记为红色，因为插入红色节点比插入黑色节点更容易保持树的平衡。 2. 修复红黑树 插入红色节点后，可能会违反红黑树的性质4（红色节点的子节点是黑色）。因此，需要通过以下几种情况进行调整： 情况1：新节点的父节点是黑色 这种情况下，插入的红色节点不会破坏红黑树的性质，无需进行任何调整。 情况2：新节点的父节点和叔叔节点都是红色 这种情况下，将父节点和叔叔节点变为黑色，祖父节点变为红色。然后，将祖父节点作为新的当前节点，继续向上调整。 情况3：新节点的父节点是红色，叔叔节点是黑色或为空 这种情况下，不仅仅需要变色，还需要进行旋转来调整。 插入操作的步骤 1. 插入新节点 如果树为空（_root == nullptr），直接创建一个黑色节点作为根节点并返回。 如果树不为空，从根节点开始，通过比较键值来找到插入位置。如果键值已经存在，则返回false，表示插入失败。 找到插入位置后，创建一个红色节点（新节点默认为红色），并将其插入到合适的位置（作为某个节点的左子节点或右子节点）。 2. 修复红黑树的性质 插入红色节点后，可能会违反红黑树的性质（尤其是第4条性质：不能有两个连续的红色节点）。因此需要通过旋转和变色操作来修复。 修复逻辑 循环条件：只要当前节点的父节点是红色，就需要进行修复。 祖父节点和叔叔节点： 祖父节点是当前节点的父节点的父节点。 叔叔节点是祖父节点的另一个子节点（与父节点不同）。 修复情况 叔叔节点存在且为红色： 父节点和叔叔节点都变色为黑色。 祖父节点变色为红色。 将当前节点更新为祖父节点，继续向上检查。 叔叔节点不存在或者为黑色： 如果父节点是祖父节点的左子节点： 如果当前节点是父节点的左子节点： 右旋祖父节点。 父节点变色为黑色，祖父节点变色为红色。 如果当前节点是父节点的右子节点： 左旋父节点。 右旋祖父节点。 当前节点变色为黑色，祖父节点变色为红色。 如果父节点是祖父节点的右子节点： 如果当前节点是父节点的右子节点： 左旋祖父节点。 父节点变色为黑色，祖父节点变色为红色。 如果当前节点是父节点的左子节点： 右旋父节点。 左旋祖父节点。 当前节点变色为黑色，祖父节点变色为红色。 单旋： 双旋： 3. 根节点的颜色 最后，确保根节点是黑色。 代码逻辑解析 插入新节点： 123456if (_root == nullptr)&#123; _root = new Node(kv); _root-&gt;_col = BLACK; return true;&#125; 如果树为空，直接创建一个黑色的根节点。 12345678910111213141516171819Node* parent = nullptr;Node* cur = _root;while (cur)&#123; if (cur-&gt;_kv.first &lt; kv.first) &#123; parent = cur; cur = cur-&gt;_right; &#125; else if (cur-&gt;_kv.first &gt; kv.first) &#123; parent = cur; cur = cur-&gt;_left; &#125; else &#123; return false; &#125;&#125; 从根节点开始，通过比较键值找到插入位置。如果键值已存在，返回`false`。 1234567891011cur = new Node(kv);cur-&gt;_col = RED;if (parent-&gt;_kv.first &lt; kv.first)&#123; parent-&gt;_right = cur;&#125;else&#123; parent-&gt;_left = cur;&#125;cur-&gt;_parent = parent; 创建一个红色的新节点，并将其插入到合适的位置。 修复红黑树性质： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960while (parent &amp;&amp; parent-&gt;_col == RED)&#123; Node* grandfather = parent-&gt;_parent; if (parent == grandfather-&gt;_left) &#123; Node* uncle = grandfather-&gt;_right; if (uncle &amp;&amp; uncle-&gt;_col == RED) &#123; parent-&gt;_col = uncle-&gt;_col = BLACK; grandfather-&gt;_col = RED; cur = grandfather; parent = cur-&gt;_parent; &#125; else &#123; if (cur == parent-&gt;_left) &#123; RotateR(grandfather); parent-&gt;_col = BLACK; grandfather-&gt;_col = RED; &#125; else &#123; RotateL(parent); RotateR(grandfather); cur-&gt;_col = BLACK; grandfather-&gt;_col = RED; &#125; break; &#125; &#125; else &#123; Node* uncle = grandfather-&gt;_left; if (uncle &amp;&amp; uncle-&gt;_col == RED) &#123; parent-&gt;_col = uncle-&gt;_col = BLACK; grandfather-&gt;_col = RED; cur = grandfather; parent = cur-&gt;_parent; &#125; else &#123; if (cur == parent-&gt;_right) &#123; RotateL(grandfather); parent-&gt;_col = BLACK; grandfather-&gt;_col = RED; &#125; else &#123; RotateR(parent); RotateL(grandfather); cur-&gt;_col = BLACK; grandfather-&gt;_col = RED; &#125; break; &#125; &#125;&#125; 根据父节点和叔叔节点的颜色，以及当前节点的位置，选择合适的旋转和变色操作来修复红黑树的性质。 确保根节点为黑色： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 _root-&gt;_col = BLACK;``` ### 二.红黑树的删除操作（作为了解即可）删除操作比插入操作更为复杂，因为它可能会破坏红黑树的平衡。删除操作可以分为以下几个步骤：#### 1\\. 删除节点首先，找到需要删除的节点。如果该节点有两个子节点，则需要找到它的后继节点（右子树中的最小节点）来替换它。然后，将该节点的值替换为后继节点的值，并将后继节点删除。#### 2\\. 修复红黑树删除节点后，可能会违反红黑树的性质。需要通过以下几种情况进行调整：- **情况1：被删除的节点是红色** 这种情况下，直接删除该节点不会破坏红黑树的性质。 - **情况2：被删除的节点是黑色，且其子节点是红色** 这种情况下，将子节点变为黑色，然后删除该节点。 - **情况3：被删除的节点是黑色，且其子节点是黑色** 这种情况下，需要通过一系列复杂的调整来恢复红黑树的性质，包括颜色调整和旋转操作。 ### 三.红黑树的查找操作按⼆叉搜索树逻辑实现即可，搜索效率为O(logN)```C Node* Find(const K&amp; key) &#123; Node* cur = _root; while (cur) &#123; if (cur-&gt;_kv.first &lt; key) &#123; cur = cur-&gt;_right; &#125; else if (cur-&gt;_kv.first &gt; key) &#123; cur = cur-&gt;_left; &#125; else &#123; return cur; &#125; &#125; return nullptr; &#125; 四.红黑树的验证 每个节点是红色或黑色。 根节点是黑色。 所有叶子节点（空节点）是黑色。 如果一个节点是红色，则它的两个子节点都是黑色（不能有两个连续的红色节点）。 从任何节点到其每个叶子的所有路径都包含相同数量的黑色节点。 代码中的检查逻辑 1. IsBalance函数 这个函数是入口函数，用于初始化检查过程。 1234567891011121314151617181920bool IsBalance()&#123; if (_root == nullptr) return true; // 如果树为空，直接返回true，空树满足红黑树的性质 if (_root-&gt;_col == RED) return false; // 根节点必须是黑色，否则直接返回false // 计算从根节点到最左边叶子节点的黑色节点数量作为参考值 int refNum = 0; Node* cur = _root; while (cur) &#123; if (cur-&gt;_col == BLACK) ++refNum; // 如果当前节点是黑色，增加黑色节点计数 cur = cur-&gt;_left; // 沿着左子树向下遍历 &#125; // 使用参考值调用Check函数检查整棵树 return Check(_root, 0, refNum);&#125; 检查根节点颜色：如果根节点是红色，直接返回false，因为红黑树的根节点必须是黑色。 计算参考值refNum：从根节点开始，沿着左子树一直向下，统计路径上的黑色节点数量。这个值将作为后续路径检查的参考值。 调用Check函数：使用计算出的refNum，从根节点开始递归检查整棵树。 2. Check函数 这个函数是递归函数，用于检查树的每个路径是否满足红黑树的性质。 12345678910111213141516171819202122232425262728bool Check(Node* root, int blackNum, const int refNum)&#123; if (root == nullptr) &#123; // 前序遍历走到空节点，意味着一条路径走完了 if (refNum != blackNum) &#123; cout &lt;&lt; &quot;存在黑色节点的数量不相等的路径&quot; &lt;&lt; endl; return false; // 如果当前路径的黑色节点数量与参考值不同，返回false &#125; return true; &#125; // 检查是否存在连续的红色节点 if (root-&gt;_col == RED &amp;&amp; root-&gt;_parent-&gt;_col == RED) &#123; cout &lt;&lt; root-&gt;_kv.first &lt;&lt; &quot;存在连续的红色节点&quot; &lt;&lt; endl; return false; // 如果当前节点和父节点都是红色，返回false &#125; if (root-&gt;_col == BLACK) &#123; blackNum++; // 如果当前节点是黑色，增加黑色节点计数 &#125; // 递归检查左右子树 return Check(root-&gt;_left, blackNum, refNum) &amp;&amp; Check(root-&gt;_right, blackNum, refNum);&#125; 检查路径结束：如果当前节点是空节点（root == nullptr），说明已经到达路径的末端。此时检查当前路径的黑色节点数量blackNum是否与参考值refNum相等。如果不相等，说明违反了红黑树的第5条性质。 检查连续红色节点：如果当前节点是红色，并且它的父节点也是红色，直接返回false，因为这违反了红黑树的第4条性质。 统计黑色节点：如果当前节点是黑色，将blackNum加1。 递归检查子树：递归调用Check函数，分别检查当前节点的左子树和右子树。只有当左右子树都满足红黑树的性质时，当前节点才满足性质。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950bool Check(Node* root, int blackNum, const int refNum)&#123; if (root == nullptr) &#123; // 前序遍历⾛到空时，意味着⼀条路径⾛完了 //cout &lt;&lt; blackNum &lt;&lt; endl; if (refNum != blackNum) &#123; cout &lt;&lt; &quot;存在⿊⾊结点的数量不相等的路径&quot; &lt;&lt; endl; return false; &#125; return true; &#125; // 检查孩⼦不太⽅便，因为孩⼦有两个，且不⼀定存在，反过来检查⽗亲就⽅便多了 if (root-&gt;_col == RED &amp;&amp; root-&gt;_parent-&gt;_col == RED) &#123; cout &lt;&lt; root-&gt;_kv.first &lt;&lt; &quot;存在连续的红⾊结点&quot; &lt;&lt; endl; return false; &#125; if (root-&gt;_col == BLACK) &#123; blackNum++; &#125; return Check(root-&gt;_left, blackNum, refNum) &amp;&amp; Check(root-&gt;_right, blackNum, refNum);&#125; bool IsBalance()&#123; if (_root == nullptr) return true; if (_root-&gt;_col == RED) return false; // 参考值 int refNum = 0; Node* cur = _root; while (cur) &#123; if (cur-&gt;_col == BLACK) &#123; ++refNum; &#125; cur = cur-&gt;_left; &#125; return Check(_root, 0, refNum);&#125; 红黑树 vs AVL树 特性 红黑树 AVL树 平衡严格度 宽松（最长路径≤2×最短） 严格（高度差≤1） 插入/删除 更快（平均更少旋转） 较慢（旋转次数多） 查找效率 稍慢（高度略高） 更快（高度最小化） 适用场景 频繁修改的关联容器（如map） 查询密集型场景","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":"zzh_Zao"},{"title":"高效工作法则：学会思考，掌握五大管理工具","slug":"Other/高效工作法则：学会思考，掌握五大管理工具","date":"2025-07-04T13:23:47.000Z","updated":"2025-07-04T13:45:22.893Z","comments":true,"path":"2025/07/04/Other/高效工作法则：学会思考，掌握五大管理工具/","link":"","permalink":"http://www.formeasy.cc/2025/07/04/Other/%E9%AB%98%E6%95%88%E5%B7%A5%E4%BD%9C%E6%B3%95%E5%88%99%EF%BC%9A%E5%AD%A6%E4%BC%9A%E6%80%9D%E8%80%83%EF%BC%8C%E6%8E%8C%E6%8F%A1%E4%BA%94%E5%A4%A7%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"在职场中，如何不断提升自己的效率、优化工作流程，是每位职业人都会面对的问题。本文聚焦于几种经典的管理方法论，如PDCA循环、RACI模型、RCA法则、SWOT分析、SMART目标等，帮助你掌握从计划到执行、从分析到反馈的系统化思维模式。无论你是新晋职场小白，还是希望进一步精进技能的管理者，这些工具都能为你的日常工作提供有效指导，助你在不断思考和改进中迈向更高效的职场表现。让我们从了解这些方法开始，探索如何在工作中活学活用，真正做到在思考中成长，在应用中进步。 一、PDCA循环 （戴明循环） （一）简单介绍 PDCA循环，也称为戴明循环或科学循环，是一种管理方法，用于持续改进和优化过程。它由四个步骤组成：计划（Plan）、执行（Do）、检查（Check）和行动（Action）。 下面是每个步骤的详细介绍和应用： 计划（Plan）：在这一阶段，确定目标、制定计划和确定要解决的问题。设定明确的目标和指标是重要的，以便后续步骤中进行对比和评估。 执行（Do）：在这个阶段，根据制定的计划实施措施。这可能包括在小范围内进行试点测试或在整个组织内实施新策略。 检查（Check）：这一步是对执行阶段的结果进行评估和对比。收集数据并与预定的目标进行比较，以了解实施计划的效果如何。 行动（Action）：基于检查阶段的结果，采取相应的行动。如果结果达到了预期目标，可以将成功的做法推广应用。如果结果不理想，需要找出问题所在，并制定改进措施。 PDCA循环是一种灵活的管理方法，可以应用于各种场景，例如生产流程优化、项目管理、质量改进以及个人目标实现。通过反复循环这四个步骤，持续不断地进行改进，组织或个人能够不断提高效率、优化成果，并逐步实现更高的目标。 （二）戴明循环的步骤 P（Plan）--计划，通过集体讨论或个人思考确定某一行动或某一系列行动的方案，包括5W1H； D（Do）--执行人执行，按照计划去做，落实计划； C/S（Check/Study）--检查或研究执行人的执行情况，比如到计划执行过程中的“控制点”“管理点”去收集信息，“计划执行的怎么样？有没有达到预期的效果或要求？”，找出问题； A（Action）--效果，对检查的结果进行处理，认可或否定。成功的经验要加以肯定，或者模式化或者标准化以适当推广；失败的教训要加以总结，以免重现；这一轮未解决的问题放到下一个PDCA循环。 （三）戴明循环的步骤和方法 阶段 步骤 主要办法 P 1、分析现状，找出问题 排列图、直方图、控制图 2、分析各种影响因素或原因 因果图 3、找出主要影响因素 排列图，相关图 4、针对主要原因，制定措施计划 回答“5W1H” 为什么制定该措施(Why)？ 达到什么目标（What）? 在何处执行（Where）？ 由谁负责完成（Who）？ 什么时间完成（When）？ 如何完成（How）？ D 5、执行、实施计划 C 6、检查计划执行结果 排列图](http://wiki.mbalib.com/wiki/排列图 “排列图”)、直方图、控制图 A 7、总结成功经验，制定相应标准 制定或修改工作规程、检查规程及其它有关规章制度 8、把未解决或新出现的问题转入下一个PDCA循环 二、RACI模型 在快速发展的过程中，会不时的冒出一些之前没有明确界定的事情，往往产生一些看似大家都在负责，事实上无人负责的事情。RACI模型对快速发展的我们的最重要的启发是：每件事都要尽早确定谁负责，也就是确定R。 RACI的一个扩展，RASCI，是更加全面及适用我们的情况的。 谁负责（R = Responsible），负责执行任务的角色，具体负责操控项目、解决问题。 谁批准（A = Accountable），对任务负全责的角色，只有经其同意或签署之后，项目才能得以进行。 谁支持（S = Support），参与具体任务，协助R完成工作的角色。 咨询谁（C = Consulted），在任务实施前或中提供指定性意见的人员。 告知谁（I = Informed），及时被通知结果的人员，不必向其咨询、征求意见。 三、RCA法则 RCA法则是一种问题解决方法，RCA代表根本原因分析（Root Cause Analysis）。它是一种系统性的方法，用于确定问题背后的根本原因，而不仅仅是处理问题的表面症状。RCA法则的目标是找出导致问题出现的根本原因，以便采取正确的措施来预防类似问题再次发生。 RCA法则的主要步骤通常包括： 确定问题：首先，需要明确定义问题或事件，包括问题的性质、时间、地点和影响等。 收集数据：收集与问题相关的数据和信息。这可能包括观察、记录、文件审查或采访相关人员。 分析数据：对收集到的数据进行仔细分析，以理解问题的背景和相关因素。 确定根本原因：通过细致的分析，找出导致问题发生的根本原因。这一步骤可能涉及使用不同的工具和技术，如5W1H法、鱼骨图（Ishikawa图）或因果图。 制定解决方案：基于找出的根本原因，制定适当的解决方案来消除或减轻问题的影响。解决方案可能包括修复程序、流程改进、培训等。 实施措施：将制定的解决方案付诸实施，并确保所有相关人员了解并参与其中。 监控和评估：跟踪实施后的效果，监控问题是否得到解决，并评估是否需要进一步的调整和改进。 RCA法则可以应用于各种场景，包括事故调查、质量问题处理、客户投诉解决等。通过找出问题的根本原因，组织和个人可以避免反复出现相同的问题，提高工作和服务的质量，促进持续改进。 四、SWOT分析法 （一）基本说明 SWOT分析法是一种常用的战略管理工具，用于评估一个组织、项目或个人的优势、劣势、机会和威胁。SWOT是Strengths（优势）、Weaknesses（劣势）、Opportunities（机会）和Threats（威胁）的首字母缩写。通过SWOT分析，可以帮助识别内部优势和劣势，以及外部机会和威胁，从而制定更有效的战略和决策。 下面是SWOT分析法的详细说明： 优势（Strengths）：这是指组织、项目或个人的内部优势和优点。包括他们擅长的技能、资源、优质的产品或服务以及独特的竞争优势等。通过了解自身的优势，可以进一步发展和利用这些优势，以增强竞争力。 劣势（Weaknesses）：劣势是指组织、项目或个人的内部弱点和不足之处。可能包括缺乏关键技能、有限的资源、低效的流程或其他方面的不足。通过识别和分析劣势，可以采取措施来改进或弥补这些问题，以提高绩效和竞争力。 机会（Opportunities）：机会是指外部环境中有利的因素，可以为组织、项目或个人带来潜在的发展机遇。这些因素可能包括市场需求的增长、新技术的出现、竞争对手的弱点等。通过抓住机会，可以实现增长和拓展。 威胁（Threats）：威胁是指外部环境中的不利因素，可能对组织、项目或个人的发展构成潜在的风险和挑战。这些因素可能包括竞争加剧、经济不稳定、法规变化等。通过了解和应对威胁，可以减少潜在风险，保护利益。 SWOT分析法可以应用于各种场景，包括组织战略规划、市场调查、项目决策以及个人职业发展等。通过综合考虑内外部因素，SWOT分析提供了一个全面的视角，帮助制定更明智的战略和行动计划。 （二）SWOT分析模型的方法 在适应性分析过程中，企业高层管理人员应在确定内外部各种变量的基础上，采用杠杆效应、抑制性、脆弱性和问题性四个基本概念进行这一模式的分析。 杠杆效应（优势+机会）：杠杆效应产生于内部优势与外部机会相互一致和适应时。在这种情形下，企业可以用自身内部优势撬起外部机会，使机会与优势充分结合发挥出来。然而，机会往往是稍瞬即逝的，因此企业必须敏锐地捕捉机会，把握时机，以寻求更大的发展。 抑制性（劣势+机会）：抑制性意味着妨碍、阻止、影响与控制。当环境提供的机会与企业内部资源优势不相适合，或者不能相互重叠时，企业的优势再大也将得不到发挥。在这种情形下，企业就需要提供和追加某种资源，以促进内部资源劣势向优势方面转化，从而迎合或适应外部机会。 脆弱性（优势+威胁）：脆弱性意味着优势的程度或强度的降低、减少。当环境状况对公司优势构成威胁时，优势得不到充分发挥，出现优势不优的脆弱局面。在这种情形下，企业必须克服威胁，以发挥优势。 问题性（劣势+威胁）：当企业内部劣势与企业外部威胁相遇时，企业就面临着严峻挑战，如果处理不当，可能直接威胁到企业的生死存亡。 （三）SWOT分析步骤 步骤1：确认当前的战略是什么？ 步骤2：确认企业外部环境的变化（波特五力或者PEST） 步骤3：根据企业资源组合情况，确认企业的关键能力和关键限制。 步骤4：按照通用矩阵或类似的方式打分评价 把识别出的所有优势分成两组，分的时候以两个原则为基础：它们是与行业中潜在的机会有关，还是与潜在的威胁有关。用同样的办法把所有的劣势分成两组，一组与机会有关，另一组与威胁有关。 步骤5：将结果在SWOT分析图上定位 或者用SWOT分析表，将刚才的优势和劣势按机会和威胁分别填入表格。 步骤6：战略分析 举一个科尔尼SWOT分析得出战略的例子。 （四）成功应用SWOT分析法的简单规则 进行SWOT分析的时候必须对公司的优势与劣势有客观的认识； 进行SWOT分析的时候必须区分公司的现状与前景； 进行SWOT分析的时候必须考虑全面。 进行SWOT分析的时候必须与竞争对手进行比较，比如优于或是劣于你的竞争对手； 保持SWOT分析法的简洁化，避免复杂化与过度分析； SWOT分析法因人而异。 一旦使用SWOT分析法决定了关键问题，也就确定是市场营销的目标。SWOT分析法可与PEST analysis和Porter’s Five-Forces analysis等工具一起使用。市场营销课程的学生之所以热衷于SWOT分析法是因为它的易学性与易用性。运用SWOT分析法的时候，要将不用的要素列入相关的表格当中去，很容易操作。 （五）SWOT模型的局限性 与很多其他的战略模型一样，SWOT模型已由麦肯锡提出很久了，带有时代的局限性。以前的企业可能比较关注成本、质量，现在的企业可能更强调组织流程。例如以前的电动打字机被印表机取代，该怎么转型？是应该做印表机还是其他与机电有关的产品？从SWOT分析来看，电动打字机厂商优势在机电，但是发展印表机又显得比较有机会。结果有的朝印表机发展，死得很惨；有的朝剃须刀生产发展很成功。这就要看，你要的是以机会为主的成长策略，还是要以能力为主的成长策略。SWOT没有考虑到企业改变现状的主动性，企业是可以通过寻找新的资源来创造企业所需要的优势，从而达到过去无法达成的战略目标。 在运用SWOT分析法的过程中，你或许会碰到一些问题，这就是它的适应性。因为有太多的场合可以运用SWOT分析法，所以它必须具有适应性。然而这也会导致反常现象的产生。基础SWOT分析法所产生的问题可以由更高级的POWER SWOT分析法得到解决。 五、目标SMART 目标SMART是一种目标设定的方法，它是一个缩写，每个字母代表特定的特征，用于确保目标是具体、可衡量、可实现、与现实相关和有时限的。以下是每个字母的详细说明： S - 具体（Specific）：目标应该是具体和清晰的，明确描述想要实现的结果。避免模糊和含糊不清的表述，而是明确指定目标的内容和范围。 M - 可衡量（Measurable）：目标应该是可衡量的，可以用具体的指标或量化方式来评估其达成程度。这样可以跟踪进展并确定是否已成功实现目标。 A - 可实现（Achievable）：目标应该是可实现的，即在给定的资源和条件下，有合理的机会实现。目标应该挑战性，但也要基于现实可行性进行设定。 R - 与现实相关（Relevant）：目标应该与整体目标和愿景相关，对组织或个人有意义，并与其它目标相协调。确保目标与战略一致，以保持整体的一致性。 T - 有时限（Time-bound）：目标应该设定明确的时间限制，即截止日期。这有助于建立紧迫感，并为目标实现提供时间框架。 SMART方法可应用于各种领域，包括个人目标设定、项目管理、业务计划和团队目标设定等。它在以下方面有显著的优势： 清晰性：SMART目标明确具体，避免了模糊的表述，使人们对目标的要求和方向有明确的了解。 可测量性：通过设定可衡量的指标，可以追踪目标的进展和达成情况。这有助于及时调整策略，确保目标的实现。 实现可行性：通过要求目标可实现，SMART方法帮助避免设定过于理想化或不切实际的目标，从而增加实现的可能性。 与战略一致性：SMART方法要求目标与现实相关，与组织或个人的整体战略和目标一致，有助于确保目标对整体发展有积极的推动作用。 时间框架：通过设定截止日期，SMART目标建立了紧迫感，促使人们专注于目标的实现，避免拖延行为。 综上所述，目标SMART方法是一个简单而有效的目标设定工具，可以帮助组织和个人制定具体、可行、有方向性的目标，并提高目标实现的成功率。 六、述职反馈 这里省去述职报告时间。 （一）提问互动环节 常见问题 如何应对提问 （二）反馈环节 这个环节主要是给述职人进行反馈，包括激励性反馈和建设性反馈。最主要的是两个场景：如何接收别人的反馈，以及如何给别人做反馈。 1.如何接收反馈 常见问题 如何解决 2.如何给他人反馈 常见问题 如何解决 （三）述职时，怎样反馈才有效？ 反馈是一份备受期待的礼物，被反馈人是抱着自我成长的心态来接受礼物，他期待你的反馈能帮助他明晰优势、了解盲区，在未来持续发扬或改进提升，同时公司也期待述职能够帮助个人和团队成长。因此希望每一位同学在反馈环节都能够“敢于说真话，不怕得罪人”，为共同成长一起努力。 反馈不在多，而在有用。好的反馈应该是有针对性、聚焦的，也应该是全面的、着眼未来的。大家只要按照下面的【述职反馈金字塔】，自下而上完成“了解事实-探索思考逻辑-形成反馈”三步，就能给出有效反馈。 STEP1：首先，在给他人反馈前，你需要思考自己是否足够了解事实。如果发现述职材料有不太清楚的地方，可以对照STAR原则，请对方补充没有说到的地方。 比如：文档中写了你的做法和取得的结果，能说说当时你是在什么情况下接了这项任务？任务的初衷是什么吗？ 在这个项目中，你的协作方有哪些？核心客户又是谁？ STEP2：了解事实后，还需要通过一些探索类问题，进一步明确和探索对方行为背后的思考和分析逻辑。明白了对方的思考逻辑，也就明白了为什么结果是理想的，或不理想的，进而形成了你对员工的判断。 比如：当时选择这样做，而不是采取另一个方案，你是怎么考虑的呢？ 目标为什么定在10万？当时是怎么估计的？目前来看你觉得合理吗？ STEP3：接下来需要将你的判断整理成激励性和建设性反馈给出，需要注意三点： ①两类反馈都要有。只给建设性反馈会让对方感到被批评、难接受；只给激励性反馈，则很难让对方觉察和改进。 ②反馈要有针对性。不要反馈无关痛痒的内容，而要结合对方的职责需要，在激励和建设性上分别聚焦2-3个要点。 ③反馈要着眼未来。只告诉对方哪些好和不好，帮助很有限，是优势则要提出能让其发挥更大作用的方法；是不足则要提出改善或补救的具体措施。 比如：我有2条激励性反馈和3条建设性反馈给到你。 激励性反馈第一条是“严谨”，你在决策前，做了市场调研、研究了对标公司的做法、并且把多种方案进行了对比，最后规避了不太合适的方案，非常的严谨，尤其适用于你的岗位，未来可以把这种方式方法也交给你的下属，发挥出更大作用。第二条是……。 建设性反馈第一条是“加强复盘”，你描述的两个项目是有相似之处的，但是在结果来看都存在XX指标相比于其他指标落后较多的情况，在第二个项目中其实是有机会做一些策略的调整和优化，建议未来更重视项目复盘，公司有一门课程叫《有效的数据复盘》，可以学习一下。第二条是……。第三条是……。 七、总结 本文梳理了PDCA循环、RACI模型、RCA法则、SWOT分析以及SMART目标设定等关键管理方法，为高效工作和目标达成提供了系统化思路。这些方法各具特点：PDCA循环通过持续改进帮助我们不断优化流程，RACI模型强调责任明确，确保团队高效协作，RCA法则深入挖掘问题根源以防止重复错误，SWOT分析为战略规划提供了全面视角，而SMART目标设定则确保我们设立的目标清晰、可执行且符合实际需求。 通过这些工具的应用，我们能够在面对复杂的工作挑战时更具条理性和目标感。每一个方法都不是孤立的，结合应用更能产生协同效应。例如，通过PDCA循环的持续优化，配合SMART目标的设定，可以在实现个人和团队目标的过程中逐步积累成功经验。此外，SWOT分析和RCA法则也为我们在制定计划前和解决问题时提供了独特的思考角度。希望大家能够在实际工作中灵活运用这些方法，在反复实践和不断反馈中提高工作效率和管理水平，迈向更成熟的职业阶段。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://www.formeasy.cc/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"xiaofeng10330111"},{"title":"CentOS 系统、数据库、网络面试知识点总结","slug":"Other/CentOS 系统、数据库、网络面试知识点总结-CSDN博客","date":"2025-06-24T00:56:50.000Z","updated":"2025-06-24T01:08:32.674Z","comments":true,"path":"2025/06/24/Other/CentOS 系统、数据库、网络面试知识点总结-CSDN博客/","link":"","permalink":"http://www.formeasy.cc/2025/06/24/Other/CentOS%20%E7%B3%BB%E7%BB%9F%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93-CSDN%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"Linux CentOS 面试知识点整理 一、Linux 基础命令 （一）文件和目录操作 命令 功能 常用选项 示例 ls 列出目录内容 -l（长格式）、-a（显示隐藏文件）、-h（易读格式） ls -lh cd 切换目录 无 cd /etc pwd 显示当前工作目录 无 pwd mkdir 创建目录 -p（递归创建） mkdir -p dir1/dir2/dir3 rm 删除文件或目录 -r（递归删除）、-f（强制删除） rm -rf file.txt cp 复制文件或目录 -r（递归复制） cp -r file1 file2 mv 移动或重命名文件或目录 无 mv file1 /dir 面试知识点补充： 批量删除特定文件类型：在实际工作中，可能需要批量删除某个目录下的特定文件类型。例如，删除所有.log文件，可以使用rm -f *.log。面试中可能会问到如何删除多个目录下的特定文件类型，可以使用find命令结合rm命令，例如find /path/to/directory -type f -name &quot;*.log&quot; -exec rm -f &#123;&#125; \\;。 rm -rf的谨慎使用：rm -rf命令非常强大，但也非常危险，因为它会强制删除文件或目录，且不会提示确认。面试官可能会问到如何避免误删除重要文件。一个常见的做法是使用rm -i（交互模式）进行删除，或者在脚本中添加额外的检查逻辑。 cp和mv的区别：cp用于复制文件或目录，而mv用于移动或重命名文件或目录。面试中可能会问到它们的区别以及使用场景。cp适用于需要保留原始文件的情况，而mv适用于需要移动文件或重命名文件的情况。 （二）文件查看和编辑 命令 功能 示例 cat 查看文件内容 cat file.txt more 和 less 分页查看文件内容 less file.txt head 和 tail 查看文件头部和尾部内容 head -n 5 file.txt、tail -f file.log vi 或 vim 文本编辑器 命令模式（i进入插入模式，Esc退出，:wq保存退出） 面试知识点补充： vim编辑器的高级用法：在面试中，可能会被问到vim编辑器的一些高级功能，例如使用正则表达式批量替换文本。可以使用:s/old/new/g命令替换文件中的所有old为new，或者使用:g/pattern/s/old/new/g命令只替换匹配pattern的行。 日志文件的实时监控：tail -f命令用于实时查看文件的新增内容，常用于监控日志文件。面试中可能会问到如何结合grep命令过滤特定内容。例如，tail -f file.log | grep &quot;error&quot;可以实时显示包含error的日志内容。 less和more的区别：less比more更强大，支持上下翻页和搜索功能。面试中可能会问到如何在less中搜索特定内容，可以使用/pattern向前搜索，使用?pattern向后搜索。 （三）系统信息和进程管理 命令 功能 示例 uname 显示系统信息 uname -a df 显示磁盘空间使用情况 df -h du 显示目录或文件的磁盘使用情况 du -sh /dir ps 显示当前运行的进程 ps aux top 实时显示系统中资源占用最高的进程 top kill 终止进程 kill -9 PID nice 和 renice 调整进程优先级 nice -n 10 command systemctl 管理服务和系统状态 systemctl restart service 面试知识点补充： 查找占用磁盘空间最大的目录：面试中可能会问到如何查找占用磁盘空间最大的前几个目录。可以使用du -sh /dir/* | sort -rh | head -n 5命令。这个命令会列出指定目录下所有子目录的大小，并按降序排列，显示前5个最大的目录。 使用ps和grep查找特定进程：面试中可能会问到如何查找特定进程。可以使用ps aux | grep process_name命令。例如，查找名为httpd的进程，可以使用ps aux | grep httpd。 kill命令的信号类型：kill命令可以发送不同的信号给进程。面试中可能会问到常见的信号类型，例如SIGTERM（默认信号，请求进程终止）、SIGKILL（强制终止进程，kill -9）和SIGINT（中断信号，通常由Ctrl+C产生）。 （四）网络相关命令 命令 功能 示例 ifconfig 或 ip 查看和配置网络接口 ip a ping 测试网络连通性 ping -c 4 8.8.8.8 netstat 或 ss 查看网络连接和监听端口 ss -tuln curl 或 wget 下载文件或测试HTTP请求 curl -O http://example.com/file.zip 面试知识点补充： 查看所有监听端口：面试中可能会问到如何查看当前系统的所有监听端口。可以使用ss -tuln命令。这个命令会列出所有TCP、UDP和监听状态的端口。 使用ping和traceroute定位网络故障点：面试中可能会问到如何排查网络问题。可以使用ping命令测试网络连通性，使用traceroute命令查看数据包的传输路径。例如，traceroute 8.8.8.8可以显示到达目标IP的路径。 curl命令的高级用法：curl命令不仅可以下载文件，还可以用于测试HTTP请求。面试中可能会问到如何使用curl发送POST请求。例如，curl -X POST -d &quot;key=value&quot; http://example.com/api可以发送一个POST请求。 （五）用户和权限管理 命令 功能 示例 whoami 显示当前登录用户 whoami who 显示当前登录的用户信息 who su 切换用户 su - useradd 创建用户 useradd username passwd 设置用户密码 passwd username chmod 修改文件或目录的权限 chmod 755 file.txt chown 修改文件或目录的所有者 chown user:group file.txt 面试知识点补充： 批量创建用户：面试中可能会问到如何批量创建用户。可以使用useradd命令结合循环脚本实现。例如，使用for i in &#123;1..10&#125;; do useradd user$i; done可以批量创建user1到user10。 设置目录的特殊权限：面试中可能会问到如何设置目录的特殊权限，例如setuid、setgid和sticky bit。可以使用chmod命令。例如，chmod +s file.txt可以设置setuid权限，chmod g+s dir可以设置setgid权限，chmod +t dir可以设置sticky bit权限。 用户组管理：面试中可能会问到如何管理用户组。可以使用groupadd命令创建用户组，使用usermod命令将用户添加到用户组。例如，groupadd groupname可以创建一个用户组，usermod -aG groupname username可以将用户添加到用户组。 （六）其他常用命令 命令 功能 示例 grep 在文件中搜索文本 grep &quot;pattern&quot; file.txt find 查找文件或目录 find / -name &quot;file.txt&quot; history 显示命令历史 history man 查看命令的手册页 man ls 面试知识点补充： 使用find命令查找特定权限的文件：面试中可能会问到如何查找具有特定权限的文件。可以使用find命令结合权限选项。例如，find / -perm 777可以查找权限为777的文件。 清空命令历史：面试中可能会问到如何清空命令历史。可以使用history -c命令。此外，还可以通过编辑~/.bash_history文件来手动清空历史记录。 man命令的高级用法：面试中可能会问到如何查看特定章节的手册页。可以使用man命令的章节选项。例如，man 1 ls可以查看ls命令的手册页，man 5 crontab可以查看crontab文件格式的手册页。 二、数据库安装与配置 （一）MySQL 安装 使用yum安装MySQL 1sudo yum install -y mysql-community-server 启动MySQL服务并设置开机自启 12sudo systemctl start mysqldsudo systemctl enable mysqld 检查MySQL服务状态 123456789101112131415sudo systemctl status mysqld``` **面试知识点补充**：- **查看MySQL服务是否已经安装成功**：面试中可能会问到如何查看MySQL服务是否已经安装成功。可以使用`rpm -q mysql-community-server`命令。如果返回`mysql-community-server-版本号`，则表示已安装成功。- **服务管理**：面试中可能会问到如何查看服务的依赖关系。可以使用`systemctl list-dependencies service`命令。例如，`systemctl list-dependencies mysqld`可以查看MySQL服务的依赖关系。#### （二）MySQL 配置1. **安全配置**```bash sudo mysql_secure_installation 修改配置文件 配置文件路径：/etc/my.cnf 常见配置项：datadir、port、bind-address 字符集配置 123456789[client]default-character-set = utf8mb4[mysql]default-character-set = utf8mb4[mysqld]character-set-server = utf8mb4collation-server = utf8mb4_unicode_ci 面试知识点补充： 查看MySQL的当前字符集：面试中可能会问到如何查看MySQL的当前字符集。可以使用SHOW VARIABLES LIKE 'character_set_server';命令。 动态修改MySQL配置：面试中可能会问到如何动态修改MySQL配置而无需重启服务。可以使用SET GLOBAL命令。例如，SET GLOBAL max_connections = 1000;可以动态修改最大连接数。 （三）MySQL 文件路径 数据文件路径：/var/lib/mysql 配置文件路径：/etc/my.cnf 日志文件路径：/var/log/mysql/ 面试知识点补充： 查看MySQL的错误日志文件路径：面试中可能会问到如何查看MySQL的错误日志文件路径。可以使用SHOW VARIABLES LIKE 'log_error';命令。 日志文件的自动轮转：面试中可能会问到如何设置日志文件的自动轮转。可以使用logrotate工具。例如，可以编辑/etc/logrotate.d/mysql文件，配置日志轮转策略。 三、计算机网络 各层详细知识点总结 一、链路层（Link Layer） 1. 核心概念 功能： 将数据封装成帧（Frame）。 负责物理传输，包括信号的编码和解码。 错误检测和纠正（通过CRC校验等）。 流量控制（如滑动窗口机制）。 提供硬件地址（MAC地址）。 硬件地址（MAC地址）： 48位的唯一标识符，用于在局域网内识别设备。 格式：XX:XX:XX:XX:XX:XX。 2. 常见协议 以太网（Ethernet）： 最常用的链路层协议，支持多种物理介质（如双绞线、光纤）。 以太网帧结构： 前导码（Preamble）：用于同步。 目标MAC地址（Destination MAC Address）：6字节。 源MAC地址（Source MAC Address）：6字节。 类型/长度字段（Type/Length）：2字节。 数据负载（Payload）：46-1500字节。 帧校验序列（FCS）：4字节。 无线局域网（WLAN）： 使用无线信号进行通信，遵循IEEE 802.11标准。 支持多种加密方式（如WEP、WPA、WPA2）。 点对点协议（PPP）： 用于点对点连接，常用于拨号上网。 提供链路控制协议（LCP）和多种网络控制协议（NCP）。 3. 面试问题 问题1：以太网帧的结构是什么？ 答案：以太网帧包括前导码、目标MAC地址、源MAC地址、类型/长度字段、数据负载和帧校验序列（FCS）。 问题2：如何检测和纠正链路层的错误？ 答案：使用循环冗余校验（CRC）进行错误检测，通过重传机制进行错误纠正。 问题3：什么是MAC地址？它的作用是什么？ 答案：MAC地址是网络设备的唯一标识符，用于在链路层识别设备。它是一个48位的地址，通常以十六进制表示。 问题4：以太网中的最小帧大小是多少？ 答案：以太网中的最小帧大小是64字节，包括8字节的前导码和4字节的FCS。 问题5：什么是碰撞检测（CSMA/CD）？它在以太网中的作用是什么？ 答案：CSMA/CD（Carrier Sense Multiple Access with Collision Detection）是一种介质访问控制方法，用于检测和避免数据冲突。在以太网中，当多个设备尝试同时发送数据时，CSMA/CD机制可以检测到冲突并重新发送数据。 二、网络层（Internet Layer） 1. 核心概念 功能： 寻址：为每个网络设备分配一个唯一的IP地址。 路由：根据IP地址将数据包从源主机发送到目标主机。 分片和重组：将大数据包分割成小片段，以便在不同网络中传输。 提供逻辑地址（IP地址）。 IP地址： IPv4：32位地址，格式为A.B.C.D，分为A、B、C、D、E五类。 IPv6：128位地址，格式为A:B:C:D:E:F:G:H，提供更多的地址空间。 子网掩码： 用于将IP地址划分为网络部分和主机部分。 常见的子网掩码：255.255.255.0（/24）。 2. 常见协议 IP（Internet Protocol）： 网络层的核心协议，负责数据包的寻址和路由。 IPv4：32位地址，格式为A.B.C.D。 IPv6：128位地址，格式为A:B:C:D:E:F:G:H。 ICMP（Internet Control Message Protocol）： 用于发送错误消息和操作信息。 常见的ICMP消息类型：回显请求（ping）、回显应答、目的不可达。 ARP（Address Resolution Protocol）： 将IP地址解析为MAC地址。 常见的ARP消息类型：ARP请求、ARP应答。 3. 面试问题 问题1：IPv4和IPv6的主要区别是什么？ 答案：IPv4使用32位地址，而IPv6使用128位地址，提供了更多的地址空间。IPv6还支持无状态地址自动配置（SLAAC）和更好的安全性。 问题2：什么是子网掩码？它的作用是什么？ 答案：子网掩码用于将IP地址划分为网络部分和主机部分。它帮助路由器确定数据包是否属于同一网络或需要转发到其他网络。 问题3：如何查看当前主机的路由表？ 答案：在Linux系统中，可以使用route -n或ip route命令查看路由表。 问题4：什么是CIDR（无类别域间路由）？它的作用是什么？ 答案：CIDR是一种IP地址的表示方法，通过子网掩码的位数来表示网络部分和主机部分。例如，192.168.1.0/24表示网络部分为192.168.1.0，子网掩码为255.255.255.0。CIDR的作用是提高IP地址的利用率，减少路由表的大小。 问题5：什么是NAT（网络地址转换）？它的作用是什么？ 答案：NAT是一种将一个IP地址空间转换为另一个IP地址空间的技术，常用于将私有IP地址转换为公共IP地址。NAT的作用是节省公共IP地址资源，提高网络安全性。 三、传输层（Transport Layer） 1. 核心概念 功能： 提供可靠的、面向连接的传输服务（如TCP）。 提供无连接的、不可靠的传输服务（如UDP）。 流量控制和拥塞控制。 提供端到端的通信。 端口号： 用于标识主机上的应用程序。 范围：0-65535。 常见的端口号：80（HTTP）、443（HTTPS）、22（SSH）、25（SMTP）。 2. 常见协议 TCP/IP 协议 定义：TCP/IP 是一组用于互联网及相关网络的通信协议，包括 TCP 和 IP。 层次结构： 链路层：负责物理链路的管理，如以太网。 网络层：负责数据包的路由和转发，主要协议是 IP。 传输层：负责端到端的数据传输和可靠性保证，主要协议是 TCP 和 UDP。 应用层：负责处理特定的应用程序之间的通信，主要协议是 HTTP、FTP、SMTP 等。 TCP 协议特点： 面向连接：在数据传输之前，必须建立一个可靠的连接。 可靠传输：通过确认（ACK）、重传机制、滑动窗口等技术，确保数据的完整性和顺序性。 应用场景：文件传输、网页浏览、邮件传输等。 面试知识点补充： TCP 的三次握手和四次挥手过程：面试中可能会问到 TCP 的三次握手和四次挥手过程。三次握手过程如下： 客户端发送一个 SYN 包到服务器，请求建立连接。 服务器收到 SYN 包后，回复一个 SYN-ACK 包，确认客户端的请求。 客户端收到 SYN-ACK 包后，发送一个 ACK 包到服务器，完成连接建立。 四次挥手过程如下： 客户端发送一个 FIN 包到服务器，请求关闭连接。 服务器收到 FIN 包后，回复一个 ACK 包，确认客户端的请求。 服务器发送一个 FIN 包到客户端，请求关闭连接。 客户端收到 FIN 包后，发送一个 ACK 包到服务器，完成连接关闭。 查看本机的 IP 地址：面试中可能会问到如何查看本机的 IP 地址。可以使用ifconfig或ip a命令。ip a命令是现代 Linux 系统中推荐使用的命令。 UDP 协议 定义：UDP 是一种无连接的、不可靠的传输层协议。 特点： 无连接：不需要建立连接，开销较小。 不可靠：不提供确认和重传机制。 应用场景：视频流、语音通话、游戏、DNS 查询等。 面试知识点补充： UDP 和 TCP 的主要区别：面试中可能会问到 UDP 和 TCP 的主要区别。TCP 是面向连接的、可靠的传输协议，而 UDP 是无连接的、不可靠的传输协议。TCP 适用于对可靠性要求较高的场景，如文件传输和网页浏览；UDP 适用于对实时性要求较高的场景，如视频流和语音通话。 使用 UDP 协议实现简单的数据传输：面试中可能会问到如何使用 UDP 协议实现简单的数据传输。可以使用netcat工具。例如，服务器端可以使用nc -u -l 1234监听 UDP 端口 1234，客户端可以使用nc -u server_ip 1234发送数据到服务器。 3. 面试问题 问题1：TCP和UDP的主要区别是什么？ 答案：TCP是面向连接的、可靠的传输协议，提供流量控制和拥塞控制，适用于对可靠性要求较高的应用。UDP是无连接的、不可靠的传输协议，适用于对实时性要求较高的应用。 问题2：TCP的三次握手和四次挥手过程是什么？ 答案： 三次握手： 客户端发送一个SYN包到服务器，请求建立连接。 服务器收到SYN包后，回复一个SYN-ACK包，确认客户端的请求。 客户端收到SYN-ACK包后，发送一个ACK包到服务器，完成连接建立。 四次挥手： 客户端发送一个FIN包到服务器，请求关闭连接。 服务器收到FIN包后，回复一个ACK包，确认客户端的请求。 服务器发送一个FIN包到客户端，请求关闭连接。 客户端收到FIN包后，发送一个ACK包到服务器，完成连接关闭。 问题3：什么是滑动窗口协议？它的作用是什么？ 答案：滑动窗口协议是一种流量控制机制，用于控制发送方在等待确认之前可以发送的数据量。它通过动态调整窗口大小来优化网络利用率，防止发送方发送过多数据导致接收方溢出。 问题4：TCP的拥塞控制机制有哪些？ 答案：TCP的拥塞控制机制包括慢启动（Slow Start）、拥塞避免（Congestion Avoidance）、快速重传（Fast Retransmit）和快速恢复（Fast Recovery）。 问题5：UDP适用于哪些应用场景？ 答案：UDP适用于对实时性要求较高的应用，如视频流、语音通话、游戏和DNS查询。这些应用对延迟敏感，可以容忍一定程度的数据丢失。 四、应用层（Application Layer） 1. 核心概念 功能： 提供应用程序之间的通信接口。 支持多种应用层协议，如HTTP、FTP、SMTP、DNS等。 提供用户界面和应用程序逻辑。 2. 常见协议 HTTP协议 HTTP（HyperText Transfer Protocol）： 定义：HTTP 是一种应用层协议，用于在客户端和服务器之间传输超文本数据。 特点： 无状态：每次请求都是独立的。 基于 TCP：确保数据的可靠传输。 请求/响应模型：客户端发送请求，服务器返回响应。 请求和响应： 请求行：包含请求方法（GET、POST、PUT、DELETE等）、请求的URL和HTTP版本。 请求头：包含附加信息，如Host、User-Agent、Content-Type等。 请求体：对于POST请求，包含要提交的数据。 响应行：包含HTTP版本、状态码和状态消息。 响应头：包含附加信息，如Content-Type、Content-Length等。 响应体：包含服务器返回的数据，如HTML页面、JSON数据等。 状态码： 1xx：信息性状态码。 2xx：成功状态码，如 200（请求成功）、201（资源已创建）。 3xx：重定向状态码，如 301（永久重定向）、302（临时重定向）。 4xx：客户端错误状态码，如 400（请求格式错误）、404（未找到资源）。 5xx：服务器错误状态码，如 500（服务器内部错误）、503（服务不可用）。 面试知识点补充： 查看 HTTP 请求的详细信息：面试中可能会问到如何查看HTTP 请求的详细信息。可以使用curl -v命令。例如，curl -v http://example.com可以显示 HTTP 请求和响应的详细信息。 常见的 404 和 500 错误的原因及解决方法：面试中可能会问到常见的 404 和 500 错误的原因及解决方法。404 错误表示请求的资源未找到，可能是因为 URL 错误或文件不存在。500 错误表示服务器内部错误，可能是因为服务器配置错误或代码问题。解决方法包括检查 URL、检查服务器日志、检查应用程序代码等。 HTTPS（HTTP Secure）： 特点：在HTTP基础上添加了SSL/TLS加密。 应用场景：安全的网页浏览、电子商务、在线银行。 FTP（File Transfer Protocol）： 特点：用于文件传输，支持文件上传和下载。 应用场景：文件服务器、文件共享。 SMTP（Simple Mail Transfer Protocol）： 特点：用于发送电子邮件。 应用场景：邮件服务器。 DNS（Domain Name System）： 特点：将域名解析为IP地址。 应用场景：域名解析、负载均衡。 3. 面试问题 问题1：HTTP和HTTPS的主要区别是什么？ 答案：HTTPS在HTTP的基础上添加了SSL/TLS加密，确保数据传输的安全性。HTTPS使用端口443，而HTTP使用端口80。 问题2：什么是HTTP状态码？常见的状态码有哪些？ 答案：HTTP状态码是服务器对客户端请求的响应状态的描述。常见的状态码包括： 200：请求成功。 301/302：重定向。 400：请求格式错误。 401：未授权。 403：禁止访问。 404：未找到资源。 500：服务器内部错误。 503：服务不可用。 问题3：DNS的作用是什么？它是如何工作的？ 答案：DNS的作用是将域名解析为IP地址。当客户端请求一个域名时，DNS服务器会查找该域名对应的IP地址，并将结果返回给客户端。DNS解析过程包括递归查询和迭代查询。 问题4：什么是RESTful API？它的特点是什么？ 答案：RESTful API是一种基于HTTP协议的网络应用程序接口，遵循REST（Representational State Transfer）架构风格。它的特点包括无状态、统一接口、资源导向、超媒体作为应用状态的引擎（HATEOAS）。 问题5：什么是Web缓存？它的作用是什么？ 答案：Web缓存是一种存储机制，用于临时存储Web资源的副本。它的作用是减少对服务器的请求次数，提高响应速度，降低网络带宽的使用。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"qq_25383607"},{"title":"蒙特卡洛算法（C++）","slug":"algo/蒙特卡洛算法（C++）","date":"2025-06-16T03:01:57.000Z","updated":"2025-06-24T01:11:29.211Z","comments":true,"path":"2025/06/16/algo/蒙特卡洛算法（C++）/","link":"","permalink":"http://www.formeasy.cc/2025/06/16/algo/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%AE%97%E6%B3%95%EF%BC%88C++%EF%BC%89/","excerpt":"","text":"蒙特卡洛算法是一个基于几何概率模型的近似估计真实值的方法，可以近似估计出圆周率π和一些被积函数比较复杂不容易求出积分的积分值。 近似估计出圆周率π举例： 假设在正方形内投掷随机点数量为N(N∈N*)，则按几何概率，当N很大时，落在圆中数量为n(n∈N*), 而N与n的比值等价于两者的面积比，即： πr²/4r²= n/N =&gt; π = 4n/N C++代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;#include &lt;random&gt;#include &lt;cmath&gt; const double r = 2; double Random(int min, int max); class location &#123;public: double x, y; location(double x, double y) &#123; this-&gt;x = x; this-&gt;y = y; &#125; location() &#123; this-&gt;x = Random(0, 2 * r); this-&gt;y = Random(0, 2 * r); &#125;&#125;; // 随机[min,max]double Random(int min, int max) &#123; // 生成[0,1] double random_number = (double)std::rand() / RAND_MAX; // 生成一个整数部分范围为 [min,max-1] 的随机数。 int integer_part = std::rand() % max; // 将整数部分与随机数的小数部分相加。 double result = static_cast&lt;double&gt;(integer_part) + random_number; return result;&#125; double GetPai(int N) &#123; location center(r, r); int n = 0; for(size_t i = 0; i &lt; N; i++) &#123; location happen; bool ifCircle = pow((happen.x - center.x), 2) + pow((happen.y - center.y), 2) &lt;= pow(r, 2); ifCircle&amp;&amp; n++; &#125; double Pai = (double)4 * n / N; return Pai;&#125;int main() &#123; int N; while(true) &#123; std::cout &lt;&lt; &quot;请输入蒙特卡洛试验次数：&quot; &lt;&lt; std::endl; std::cin &gt;&gt; N; double pai = GetPai(N); std::cout &lt;&lt; &quot;PAI计算结果为：&quot; &lt;&lt; std::endl &lt;&lt; pai; std::cout &lt;&lt; Random(1, 10)&lt;&lt;std::endl; &#125;&#125; 运行结果：","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"algo","slug":"algo","permalink":"http://www.formeasy.cc/tags/algo/"}],"author":"weixin_53088153"},{"title":"蒙特罗卡π算法（C++语言描述）","slug":"algo/蒙特罗卡π算法（C++语言描述）","date":"2025-06-16T02:25:55.000Z","updated":"2025-06-24T01:11:38.840Z","comments":true,"path":"2025/06/16/algo/蒙特罗卡π算法（C++语言描述）/","link":"","permalink":"http://www.formeasy.cc/2025/06/16/algo/%E8%92%99%E7%89%B9%E7%BD%97%E5%8D%A1%CF%80%E7%AE%97%E6%B3%95%EF%BC%88C++%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0%EF%BC%89/","excerpt":"","text":"圆的面积计算公式为：S=π*r*r 将圆放到一个直角坐标系中，如图黄色部分的面积是S/4=(π*r*r)/4;如果我们将取一个单位圆，则S/4=π/4. 因为是单位圆，半径为1，所以图中红色正方形的面积为1。 那么如果向正方形内均匀的撒点，那么落入阴影部分的点数与全部的点数之比应该是： S阴影/S正方形=π/4.==============》π=4*S阴影/S正方形 根据概率统计的规律，只要撒的点足够多，那么将得到近似的结果。 使用蒙特卡罗算法计算圆周率有如下两个关键点： 均匀撒点：通过rand函数残生[0,1]之间随即的坐标值[x,y] 区域判断：图中黄色部分的特点是距离坐标原点的距离小于等于1，这样，可以通过计算判断x2+y2&lt;=1来实现。 C++语言代码： 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include&lt;ctime&gt;#define s_rand() double(1.0*rand()/RAND_MAX)using namespace std;double MontePI(int n)&#123; double PI; double x,y; int i=0,sum=0; srand(time(0)); for(i=0;i&lt;n;i++) &#123; x=s_rand(); y=s_rand(); if(x*x+y*y&lt;1) &#123; sum++; &#125; &#125; PI=4.0*sum/n; return PI;&#125;int main()&#123; int n; double PI; cout&lt;&lt;&quot;蒙特罗卡π算法\\n&quot;&lt;&lt;endl; cout&lt;&lt;&quot;请输入撒入的点的个数：&quot;; cin&gt;&gt;n; PI=MontePI(n); cout&lt;&lt;&quot;PI=&quot;&lt;&lt;PI&lt;&lt;endl; return 0; &#125; 结果：","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"algo","slug":"algo","permalink":"http://www.formeasy.cc/tags/algo/"}],"author":"千手宇智波"},{"title":"Qt WebAssembly实验记录","slug":"Qt/Qt WebAssembly实验记录","date":"2025-06-13T05:41:13.000Z","updated":"2025-06-13T05:49:57.878Z","comments":true,"path":"2025/06/13/Qt/Qt WebAssembly实验记录/","link":"","permalink":"http://www.formeasy.cc/2025/06/13/Qt/Qt%20WebAssembly%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/","excerpt":"","text":"1.安装及介绍 【Qt杂谈2.快速体验Qt for WebAssembly（Windows平台）】 【qt for webassembly环境搭建图文教程】 2.问题及解决方案 2.1.在C++中调用js函数 关于在wasm编译环境中，在c++中调用js，可以参考以下网址： 【emscripten.h】 【asm.js 和 Emscripten 入门教程】 【EM_JS : unable to free const char* in cpp】 2.2.中文无法显示（乱码）： 【Qt for WebAssembly中文显示异常】 弄一个otf或者ttf字体文件，然后加到资源库中，然后 12//注意选择你自己的文件QFontDatabase::addApplicationFont(&quot;:/qml/Font/Alibaba-PuHuiTi-Light.otf&quot;); 2.3.无法输入中文 好像没有有效的资料解决这个问题，所以我只能调用html的api了。（Qt6.8能够输入中文了，请看这篇文章的最后讨论【Unable to input Chinese (Chinese characters) ?】） 具体实现代码请看另外一篇文章【QtWebAssembly实现中文输入】 123456789101112131415161718192021222324252627282930313233343536373839#ifdef Q_OS_WASM#include &lt;emscripten.h&gt;#include &lt;emscripten/html5.h&gt;//获取用户输入，因为Qt不支持直接输入中文。。EM_JS(const char*, getInput, (const char *str), &#123; const text = UTF8ToString(str); val = prompt(&quot;&quot;, text); if(val == null) &#123; val = &quot;&quot; &#125; var jstring = val; var lengthBytes = lengthBytesUTF8(jstring)+1; var stringOnWasmHeap = _malloc(lengthBytes); stringToUTF8(jstring, stringOnWasmHeap, lengthBytes); return stringOnWasmHeap; &#125;) #endif......// 此函数可以作为静态函数，在适当的时候使用// 调用此函数的效果为：在页面上弹出啊一个输出窗口，用户在输入好信息后，点击确定，窗口消失，此函数返回用户输入的字符串QString Manager::getUserInput(QString currentText)&#123; QString input = &quot;&quot;;#ifdef Q_OS_WASM input = getInput(currentText.toUtf8().data());#else#endif return input;&#125; 2.4.qt对应的emsdk版本 【Qt for WebAssembly】 设置的时候，直接在 Tools --》Options --》device–》webAssembly设置emsk的根目录就行。（记得在设置之前要先安装好python并设置好环境变量，因为QtCreator会调用） 假如在emsdk install 比较新的版本时，可能会出现： 12D:\\Qt\\emsdk\\emsdk&gt;emsdk install 3.1.25error: tool or SDK not found: &#x27;3.1.25&#x27; 此时可以先pull一下再install 1D:\\Qt\\emsdk\\emsdk&gt;git pull 2.5.文件的下载以及上传： 【webassembly: support local system file access】 文件的下载（保存）可以选择用label显示下载链接（点击label后触发下载）。 12ui-&gt;label-&gt;setText(&quot;&lt;a style=&#x27;color: green;&#x27; href = https://download.qt.io/archive/online_installers/4.1/qt-unified-windows-x86-4.1.1-online.exe&gt; click to download&lt;/a&gt;&quot;);ui-&gt;label-&gt;setOpenExternalLinks(true); 或者选择稍微复杂一点的，通过wasm提供的接口，调用js实现。 12345678910111213141516171819202122232425262728293031323334#ifdef Q_OS_WASM#include &lt;emscripten.h&gt;#include &lt;emscripten/html5.h&gt;#endif//获取服务器的地址、端口之类的。//这个EM_JS是用来声明js函数的，声明之后就可以直接在c++里面用了。EM_JS(const char*, getTitle, (), &#123; var urlPath = window.document.location.href; console.log(urlPath); var jstring = urlPath; var lengthBytes = lengthBytesUTF8(jstring)+1; var stringOnWasmHeap = _malloc(lengthBytes); stringToUTF8(jstring, stringOnWasmHeap, lengthBytes); return stringOnWasmHeap; &#125;) void MainWindow::on_pushButton_download_clicked()&#123;#ifdef Q_OS_WASM //执行js程序，这个是直接执行的。 EM_ASM(&#123; window.open(&quot;http://127.0.0.1/resources/main.cpp&quot;); &#125;);#endif //前面用EM_JS声明的函数 const char *str = getTitle(); qDebug() &lt;&lt; str; free((void*)str);&#125; 文件的上传这样（这个是会读取整个文件内容的） 1234567891011void something(const QString &amp;name, const QByteArray &amp;content)&#123; qDebug() &lt;&lt; &quot;name:&quot; &lt;&lt; name; qDebug() &lt;&lt; &quot;content&quot; &lt;&lt; content;&#125;void MainWindow::on_pushButton_clicked()&#123;// QFileDialog::getSaveFileUrl();//这个会打开选择的文件，然后将文件的名称以及内容通过上面的something来反馈出来。对于小文件的处理应该是够了。 QFileDialog::getOpenFileContent(&quot;*&quot;, something);&#125; 2.6.设置调试时的网页浏览器 调试时默认为ie，可以更改为其他浏览器 假如你这里的列表有ie一个，但是实际上你已经装了其他浏览器；那么，你需要在电脑的环境变量path上加上你的浏览器的路径，然后重启QtCreator 2.7.编译时报空间太小 wasm-ld: error: initial memory too small, 18222032 bytes needed 【解决 wasm-ld: error: initial memory too small, 18319040 bytes needed】 修改emsdk/upstream/emscripten/src目录里面的settings.js 里面的 INITIAL_MEM 旧版叫 TOTAL_MEMORY 或者在pro文件中增加 12#值为64KB的倍数wasm:QMAKE_LFLAGS += -s \\&quot;TOTAL_MEMORY=33554432\\&quot; 2.8.编译时报 The program “mingw32-make.exe” does not exist or is not executable. 参考【 QtCreator无法启动进程“mingw32-make.exe】 到project里面看，的确是没有找到这个mingw32-make.exe. ok,用everything来查看一下，这个东西在哪里。 有好几个，但我用的是Qt5.15.2版本的，所以我选择这个：D:\\Qt5.15\\Tools\\mingw810_64\\bin\\mingw32-make.exe。 将这个：D:\\Qt5.15\\Tools\\mingw810_64\\bin路径加到环境变量path中去。 重启一下QtCreator就好了。 2.9.无法显示SVG格式图片，报错误：qrc:/xxx.qml:70:11: QML Image: Error decoding: qrc:/xxx.svg: Unsupported image format。. 在.pro文件中添加： 1QT += svg xml 2.10.获取服务器IP（不适用于域名访问的方式） 参考：【Getting server IP within wasm application】 1234567891011121314151617181920212223242526272829303132#ifdef Q_OS_WASM#include &lt;emscripten.h&gt;#include &lt;emscripten/val.h&gt;#include &lt;emscripten/html5.h&gt;#endif// ---这是第一种方式---void getServerInfo1()&#123;#ifdef Q_OS_WASM emscripten::val location = emscripten::val::global(&quot;location&quot;); auto host = QString::fromStdString(location[&quot;host&quot;].as&lt;std::string&gt;()); auto port = QString::fromStdString(location[&quot;port&quot;].as&lt;std::string&gt;()); qDebug() &lt;&lt; &quot;Server Host:&quot; &lt;&lt; host; qDebug() &lt;&lt; &quot;Server Port:&quot; &lt;&lt; port;#endif&#125;// ---这是第二种方式---//获取服务器的地址、端口之类的。//这个EM_JS是用来声明js函数的，声明之后就可以直接在c++里面用了。EM_JS(const char*, getTitle, (), &#123; var urlPath = window.document.location.href; console.log(urlPath); var jstring = urlPath; var lengthBytes = lengthBytesUTF8(jstring)+1; var stringOnWasmHeap = _malloc(lengthBytes); stringToUTF8(jstring, stringOnWasmHeap, lengthBytes); return stringOnWasmHeap; &#125;) 2.11.Qt5.15.2的webAssembly版本不支持多线程 因为不支持多线程，因此无法使用QEventLoop，因为一旦调用QEventLoop::quit(),程序就会退出Qt主循环。 【Qt for WebAssembly官网介绍】 【Qt WebAssembly Platform Notes】 而试图同步QNetwrokReply的数据获取，也是不可能的。哪怕你如此处理，整个系统还是会卡住。 do&#123; qApp-&gt;processEvents(); // 这个函数没有生效 &#125; while(reply-&gt;isFinshed() == false) 难搞。 貌似qt6的webAssembly版本才支持多线程，但是我的代码是Qt5的，Qt6在qml上与Qt5差异挺大，所以我换不了Qt6.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":null},{"title":"Qt6.6搭建WebAssembly","slug":"Qt/Qt6.6搭建WebAssembly","date":"2025-06-13T05:37:10.000Z","updated":"2025-06-13T05:40:11.386Z","comments":true,"path":"2025/06/13/Qt/Qt6.6搭建WebAssembly/","link":"","permalink":"http://www.formeasy.cc/2025/06/13/Qt/Qt6.6%E6%90%AD%E5%BB%BAWebAssembly/","excerpt":"","text":"1.首先安装python ， 链接： https://www.python.org/ 2.下载并安装qt6. 3.克隆emsdk工程 3.1 进入emsdk目录，然后更新emsdk代码 3.2 下载并安装最新的SDK工具。（C:\\Qt\\emsdk&gt;emsdk install --global latest） 3.3 激活：（C:\\Qt\\emsdk&gt;emsdk activate latest） 3.4配置环境变量（C:\\Qt\\emsdk&gt;emsdk_env.bat） 3.5检查是否成功：（C:\\Qt\\emsdk&gt;em++ --version） 4.以上步骤如果不出错的话，打开qtcreator就可以看到该环境配置好了。 5.发布一个应用来看下吧","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"ITlsy"},{"title":"Qt在线安装时出现网络错误的解决办法(Windows)_qt 安装时 network error","slug":"Qt/Qt在线安装时出现网络错误的解决办法(Windows)_qt 安装时 network error","date":"2025-06-13T05:28:15.000Z","updated":"2025-06-13T05:29:50.393Z","comments":true,"path":"2025/06/13/Qt/Qt在线安装时出现网络错误的解决办法(Windows)_qt 安装时 network error/","link":"","permalink":"http://www.formeasy.cc/2025/06/13/Qt/Qt%E5%9C%A8%E7%BA%BF%E5%AE%89%E8%A3%85%E6%97%B6%E5%87%BA%E7%8E%B0%E7%BD%91%E7%BB%9C%E9%94%99%E8%AF%AF%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95(Windows)_qt%20%E5%AE%89%E8%A3%85%E6%97%B6%20network%20error/","excerpt":"","text":"1. “win+R&quot; 打开运行； 2. 输入”CMD“打开命令窗口 3. 将Qt安装包鼠标拖入命令窗口 后加空格 也就是安装包名称加空格 4. 输入 --mirror https://mirrors.aliyun.com/qt 按回车打开 如果遇到失效不起作用，到清华网更新一下qt安装包，https://mirrors.tuna.tsinghua.edu.cn/help/qt/","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":null},{"title":"下载安装Qt6时建议勾选的组件_qt安装组件选哪几个","slug":"Qt/下载安装Qt6时建议勾选的组件_qt安装组件选哪几个","date":"2025-06-11T06:35:39.000Z","updated":"2025-06-11T06:39:37.465Z","comments":true,"path":"2025/06/11/Qt/下载安装Qt6时建议勾选的组件_qt安装组件选哪几个/","link":"","permalink":"http://www.formeasy.cc/2025/06/11/Qt/%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85Qt6%E6%97%B6%E5%BB%BA%E8%AE%AE%E5%8B%BE%E9%80%89%E7%9A%84%E7%BB%84%E4%BB%B6_qt%E5%AE%89%E8%A3%85%E7%BB%84%E4%BB%B6%E9%80%89%E5%93%AA%E5%87%A0%E4%B8%AA/","excerpt":"","text":"如果你是一个大学生并且只是想做个带有界面的课设（如xx管理系统、xx专家系统），并且你下载了vs2022，建议勾选组件如图一所示，其他保持默认（如图二所示）。 首先说明：如果你以后要用到某个组件但是下载时没有勾选，还是有方法下载的，具体方法大家可以查看其他博客等。 首先选一个Qt版本，就是图中Qt选项下你可以看到有很多版本，如图一所示，我选的是Qt6.7.3。选这个版本的原因是里面的MSVC 2022 64-bit组件可以让我在VS2022中使用Qt。 WebAssembly(single-threaded) / WebAssembly(multi-threaded)（用不到不勾选）： 这些组件提供了将Qt应用程序编译成WebAssembly格式的支持，允许在Web浏览器中运行Qt应用程序。 LLVM-MinGW 64-bit（用不到不勾选）： LLVM-MinGW是一个基于LLVM的GNU编译器集合，这个组件允许开发者在Windows上使用MinGW编译器来编译Qt应用程序。 MSVC2019 64-bit / MSVC2022 64-bit（勾选）： 这些组件是指为Microsoft Visual Studio编译器提供的Qt版本，它们允许开发者在Visual Studio环境中使用Qt库来构建64位应用程序。2019对应VS2019, 2022对应VS2022。 MinGW 11.2.0 64-bit（勾选）： 这是GNU编译器集合（GCC）的一个版本，用于在Windows上编译Qt应用程序。 Qt Quick 3D（用不到不勾选）： Qt Quick 3D是一个用于3D图形渲染的模块，它提供了一套易于使用的API来创建3D场景和动画。 Qt 5 Compatibility Module（勾选）： 这个模块提供了从Qt 5到Qt 6的兼容性支持，帮助开发者平滑迁移旧的Qt 5应用程序到Qt 6。 Qt Shader Tools（用不到不勾选）： 这些工具用于开发和调试着色器，它们是用于3D图形编程的一部分。 **Additional Libraries（看自己需求，里面的可选可不选）：**除了Qt核心库之外的其他库，可能包括第三方库和插件，用于扩展Qt的功能。这里面有部分不常用到可以不勾选，我只勾选了Qt Charts、Qt HTTP Server、Qt WebEngine、Qt WebSockets。 Android（用不到不勾选）： 这个组件提供了在Android平台上开发和部署Qt应用程序的支持。 Sources（勾选）： Qt库的源代码，允许开发者查看和修改Qt的底层代码。 Qt Debug Information Files（用不到不勾选）： Qt6调试信息文件。 Qt Quick Timeline（用不到不勾选）： Qt Quick Timeline 模块支持基于关键帧的动画和参数化。 它采用工具友好的方法，因此受到 Qt Design Studio 和 Qt Quick Designer 的直接支持，其中包含用于创建基于关键帧的动画的时间线编辑器。 其他的组件如图所示，保持默认即可。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"m0_72760405"},{"title":"qt for webassembly环境搭建图文教程","slug":"Qt/qt for webassembly环境搭建图文教程","date":"2025-06-11T03:17:34.000Z","updated":"2025-06-13T06:22:33.990Z","comments":true,"path":"2025/06/11/Qt/qt for webassembly环境搭建图文教程/","link":"","permalink":"http://www.formeasy.cc/2025/06/11/Qt/qt%20for%20webassembly%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%9B%BE%E6%96%87%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、前言 从Qt5.14开始，官方的在线安装提供了qt for webassembly构建套件，这对很多小白来说绝对是个好消息，也绝对是个好东西，好消息是不用再去交叉编译自己生成qt for webassembly的qt库，在线安装版本直接就给你安装好，很多小白就困在如何交叉编译qt for webassembly的qt库上了，环境简直是弄哭了，望而却步；好东西是你可以直接将你现有的qt程序直接编译成wasm文件然后直接网页运行，注意这里不是说activex的形式在IE中运行，而是直接各种支持wasm的浏览器上直接运行，比如谷歌浏览器、火狐浏览器、edge浏览器等，反正主流的浏览器都支持，是不是很牛逼，大致的原理就是借助emsdk中的emscripten编译器将qt的程序直接静态编译生成wasm文件，然后同时生成对应的js文件和html文件，js文件负责加载wasm文件进行编译使用canvs绘制程序。理论上c++程序执行效率要比js高，个人体验下来也是效率蛮高，最激动的就是一行代码不用修改，直接就可以编译成网页程序。 WebAssembly介绍： WebAssembly是一种可以使用非JavaScript编程语言编写代码并且能在浏览器上运行的技术方案。 WebAssembly有一套完整的语义，实际上wasm是体积小且加载快的二进制格式，其目标就是充分发挥硬件能力以达到原生执行效率。 WebAssembly运行在一个沙箱化的执行环境中，甚至可以在现有的JavaScript虚拟机中实现。在web环境中，WebAssembly将会严格遵守同源策略以及浏览器安全策略。 WebAssembly设计了一个非常规整的文本格式用来、调试、测试、实验、优化、学习、教学或者编写程序。可以以这种文本格式在web页面上查看wasm模块的源码。 WebAssembly在web中被设计成无版本、特性可测试、向后兼容的。WebAssembly可以被JavaScript调用，进入JavaScript上下文，也可以像WebAPI一样调用浏览器的功能。当然，WebAssembly不仅可以运行在浏览器上，也可以运行在非web环境下。 qt+widget编译的程序网页地址： https://feiyangqingyun.gitee.io/qwidgetdemo/ qt+quick编译的程序网页地址： https://feiyangqingyun.gitee.io/qwidgetdemo/gallery.html WebAssembly中文网 https://www.wasm.com.cn/ qt for webassembly官网介绍 https://doc.qt.io/qt-5/wasm.html 新版的qtcreator只要指定下emsdk的目录即可，更简单。 下载好 https://github.com/emscripten-core/emsdk 解压出目录 emsdk-main，进入cmd执行 emsdk install 1.39.8 或者 2.0.14 或者 latest emsdk activate 1.39.8 emsdk activate --embedded 1.39.8 或者对应版本 执行 em++ --version 查看版本。 qtcreator 设备 webassembly 选择 emsdk-main 目录，自动识别。如果有多个Qt版本不同需要，动态切换这个目录即可。比如Qt5.15对应选择1.39.8，Qt6.2选择2.0.14。 切换到构建套件看下是否正常。 二、搭建步骤 （一）、安装Qt集成开发环境 从Qt5.15开始官方不再提供离线安装包，只提供源码包自行编译或者在线安装，在线安装的时候需要输入账号信息登录才能在线下载选择的Qt版本和构建套件及其他工具，慢慢的各位Qt开发者要习惯这种方式，要么自己熟悉编译流程自行编译，对应大部分初学者来说一个是没有这个必要还一个是太难了，建议放弃这种方式，所以从现在开始就慢慢的要习惯在线安装方式，官方提供了在线安装的程序，双击即可运行，相信90%的Qt开发者都使用过，这里直接略过，只需要在选择安装的构建套件的时候记得勾选WebAssembly构建套件就行，这样已经很方便了，之前都是需要自己编译呢。 安装好以后如果勾选了mingw版本的Qt构建套件，则可以自行测试hello跑起来，同时你也会发现qt for webassembly这个构建条件是不可用的，别急，那是因为现在你只安装了qt for webassembly的qt的库，而并没有找到需要的编译器emscripten。 （二）、安装emsdk编译器 任何编程语言开发环境，都离不开编译器，需要用对应的编译器将代码编译成对应的可执行文件，Qt是一个兼容了N种编译器的通用代码库，你使用何种编译器则调用对应的Qt库然后再编译生成对应的程序，qt for webassembly就需要借助emsdk中的编译器emscripten来编译，而不是使用msvc、mingw、gcc等，所以需要单独安装emsdk编译器。 1、常规安装办法 前提：电脑安装有git环境，能从github下载项目，安装有python环境，比如python3.7.4，如果不会玩git命令行请自行百度。 第一步：双击python-3.7.4-amd64.exe，安装python开发环境，记得勾选添加环境变量。 第二步：获取源码，打开git命令行工具，输入 git clone https://github.com/emscripten-core/emsdk.git ，等待下载完成，一般1-2分钟就下载完成。 第三步：打开cmd工具，进入到emsdk目录，执行 emsdk install 1.39.7 安装emsdk编译器（Qt5.15对应的是1.39.7版本，而不是1.39.8，之前下载的1.39.8用下来每次编译都有警告提示版本不一致说是要1.39.7）。这个下载需要点时间请耐心等待，我电脑大概13分钟，具体看网速。 第四步：安装完成后继续在当前的cmd命令行窗口执行 emsdk activate --embedded 1.39.7 激活sdk。 第五步：激活成功以后，将emsdk目录下的.emscripten文件复制到C:\\Users\\Administrator目录下（即用户目录），Qt for webass构建套件编译的时候会去这里找编译器和各种编译需要的变量。 第六步：用记事本打开.emscripten，将 emsdk_path = os.path.dirname(os.environ.get(‘EM_CONFIG’)).replace(‘\\’, ‘/’) 改成emsdk目录的绝对路径，比如 emsdk_path = ‘H:/github/emsdk’，如果运行有问题则全部改成绝对路径。 第七步：打开QtCreator，配置Qt for WebAssembly构建套件，此时可以看到编译器中能够识别到所需的em编译器。 第八步：编译好以后如果弹出的是IE浏览器则复制地址拷贝到谷歌浏览器或者edge或者火狐浏览器运行，目前IE浏览器不支持WebAssembly。 第九步：默认采用的是静态编译，意味着可以脱离Qt环境运行，.wasm文件比较大因为静态集成了Qt的运行库。除了编译运行以外，还可以直接发布到有ngix或者apche环境的站点，直接可以运行。他就类似于PHP需要站点环境支持才能运行。 2、小白懒人办法 常规的办法是万能的，包括选用其他版本的编译器等，但是大部分的初学者其实还没有git环境和python环境呢，怎破，此时非常想体验一把将qt程序编译到网页运行的想法超级强烈，马上安排懒人办法，注意此办法针对的是Qt5.15.2版本，本人特意将下载好的编译器整个文件夹中各种无关的文件全部删除。 emsdk地址：https://pan.baidu.com/s/1ZxG-oyUKe286LPMPxOrO2A 提取码：o05q 名称：emsdk.zip 第一步：将下载好的emsdk压缩包解压到目录，为了方便统一管理，我这里放在C:/Qt。 第二步：将emsdk目录下的.emscripten文件复制到C:\\Users\\Administrator目录下（即用户目录），Qt for webass构建套件编译的时候会去这里找编译器和各种编译需要的变量。 第三步：默认.emscripten文件中填写的是我这边安装的目录，你可以用记事本打开进行编辑改成你的目录。 第四步：重新打开QtCreator，切换到工具-选项-kits，重新设置Qt5.15.2 webassemly的编译器，下拉选择Emscripten Compiler。 第五步：新建个项目，拖几个控件放界面，编译大概一分钟左右，由于是静态编译时间会久一点，此时会生成五个文件，其中qtloader.js和qtlogo.svg每个项目是一样的，不同的文件是untitled.js、untitled.html、untitled.wasm。需要发布的话只需要将这5个文件拷贝到网站的WWW目录下就行。 第六步：编译完成以后会自动打开电脑默认浏览器比如IE浏览器，因为IE浏览器不支持wasm，所以你需要将地址复制拷贝到edge或者谷歌火狐等浏览器运行。 第七步：如果要支持中文则需要将中文字体文件添加到项目的资源文件一起编译。 其他说明：首次加载比较慢，后面由于有缓存的原因重新加载非常快，建议发布的时候可以放一个带宽很好的服务器。 （三）、支持的模块 目前qt for webassembly套件不是支持所有的模块，比如常见的sql数据库模块就不支持，估计现在wasm还是定位在客户端的原因吧，network中的tcp udp也不支持，好消息是websocket client是支持的，也就意味着你可以写个websocket的server端负责监听和解析，web端直接websocket通信交互，比如传输视频数据，这不就是网页中显示实时视频了！亲测无误。 Qt5Charts Qt5Core Qt5Gui Qt5Quick Qt5Svg Qt5WebSockets Qt5Widgets Qt5QuickControls2 其他部分模块 三、效果图 Qt 的每个次版本都以特定的 Emscripten 版本为目标，该版本在补丁发布时保持不变。Qt 的二进制包使用目标 Emscripten 版本构建。应用程序应使用相同的版本，因为 Emscripten 并不保证不同版本之间的ABI 兼容性。 Emscripten 版本如下: Qt 6.2: 2.0.14 Qt 6.3: 3.0.0 Qt 6.4: 3.1.14 Qt 6.5: 3.1.25 Qt 6.6: 3.1.37 Qt 6.7: 3.1.503.1.50 Qt 6.8: 3.1.56 Qt 6.9: 3.1.70","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"微信名片"},{"title":"Qt5.15.2实现Qt for WebAssembly与示例","slug":"Qt/Qt5.15.2实现Qt for WebAssembly与示例","date":"2025-06-11T03:09:26.000Z","updated":"2025-06-11T03:17:09.136Z","comments":true,"path":"2025/06/11/Qt/Qt5.15.2实现Qt for WebAssembly与示例/","link":"","permalink":"http://www.formeasy.cc/2025/06/11/Qt/Qt5.15.2%E5%AE%9E%E7%8E%B0Qt%20for%20WebAssembly%E4%B8%8E%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"1.什么是Qt for WebAssembly？ Qt for WebAssembly 是 Qt 框架的一个模块，它允许开发者将 Qt 应用程序编译为 WebAssembly（Wasm）格式，从而可以在现代 Web 浏览器中运行。WebAssembly 是一种低级的二进制指令格式，旨在为 Web 提供高性能的执行环境。通过 Qt for WebAssembly，开发者可以使用 Qt 的强大功能（如 GUI、网络、文件系统等）来构建跨平台的 Web 应用程序。 1.1 什么是 WebAssembly？ WebAssembly（Wasm） 是一种基于堆栈的虚拟机的二进制指令格式，旨在为 Web 提供高性能的执行环境。 它允许开发者使用 C、C++、Rust 等语言编写代码，并将其编译为 Wasm 格式，在浏览器中运行。 WebAssembly 的主要目标是实现接近原生的性能，同时保持与 Web 平台的兼容性。 1.2 WebAssembly 的优势 高性能：接近原生的执行速度。 跨平台：可以在所有现代浏览器中运行。 安全性：运行在浏览器的沙盒环境中，确保安全性。 可移植性：支持多种编程语言（如 C、C++、Rust 等）。 1.3 什么是 Qt for WebAssembly？ Qt for WebAssembly 是 Qt 框架的一个模块，它允许将 Qt 应用程序编译为 WebAssembly 格式。 通过 Qt for WebAssembly，开发者可以使用 Qt 的强大功能（如 GUI、网络、文件系统等）来构建跨平台的 Web 应用程序。 它特别适合将现有的 Qt 桌面应用程序移植到 Web 平台。 1.4 Qt for WebAssembly 的特点 跨平台：可以在所有现代浏览器中运行。 高性能：利用 WebAssembly 的高性能特性。 丰富的功能：支持 Qt 的核心模块（如 Qt Core、Qt GUI、Qt Widgets 等）。 易于移植：现有的 Qt 应用程序可以相对容易地移植到 WebAssembly。 1.5 编译过程 使用 Emscripten 工具链将 Qt 应用程序的 C++ 代码编译为 WebAssembly 格式。 生成 .wasm 文件（WebAssembly 二进制文件）和 .js 文件（JavaScript 胶水代码）。 通过 HTML 文件加载和运行 WebAssembly 应用程序。 1.6 运行时环境 WebAssembly 应用程序运行在浏览器的沙盒环境中。 Qt for WebAssembly 使用 Emscripten 提供的 API 与浏览器进行交互（如 DOM 操作、文件系统访问等）。 人话就是把某些qt实现的桌面程序编译成wasm支持的web形式，但存在局限性。 感兴趣的也可以自己去看看：QT官方5.15.2的说明文档 注意！！！注意！！！注意！！！Qt版本和Emscripten版本有对应关系，在官方文档里就给出了最适合的版本，比如Qt5.15.2和Emscripten1.39.8版本合适 不然你可能在后面都配置好了之后，发现编译报错 [Makefile:74: .\\TestWebAssembly.js] Error 1 具体原因这个博主解释了，主要是js的语法适配问题 “具体原因这个博主解释了，主要是js的语法适配问题”) 接下来我主要描述怎么在windows版本下进行环境准备。 2.环境准备 2.1 安装python3.9.0 2.2 安装 Qt for WebAssembly 下载并安装 Qt 安装程序（Qt 5.15 或更高版本）。 在安装过程中，选择 Qt for WebAssembly 模块。 2.3 配置 Emscripten 下载并安装 Emscripten 工具链。 先克隆Emscripten的sdk仓库 git clone https://github.com/emscripten-core/emsdk.git cd到刚刚克隆的文件夹下，进行安装激活与查看版本，需要下载一些东西 .\\emsdk install 1.39.8 .\\emsdk activate 1.39.8 emcc --version em++ --version 正确的情况下应该会看到： 2.配置 Emscripten 的环境变量。 自动利用脚本配置 .\\emsdk_env.bat 手动配置 3.编译生成 3.1 创建和编译项目 1.在Qt中配置启用webassembly编译器 先要配置设备中的路径，这个时候Qt自己会识别版本。 重启QtCreator之后，就会在编译器中看到有对应的版本的C和C++的编译器 如果没有的话，就自己添加 调试器的话，其实不支持调试，所以有没有都无所谓，可以无视警告黄色感叹号。 3.2 在 Qt Creator 中创建一个新的 Qt 项目 这个时候，可以勾选两个编译器，因为我使用的时候，切换到webassembly编译器的时候，就无法加载出来pro中加入的文件了，可以先把项目运行好在切换成webassembly编译器编译就行。 选择 WebAssembly 作为构建套件。 3.3 编译项目，生成 .wasm 和 .js 文件 4.运行示例 4.1 编译生成内容 TestWebAssembly/ ├── TestWebAssembly.html # HTML 入口文件 ├── TestWebAssembly.js # JavaScript 胶水代码 ├── TestWebAssembly.wasm # WebAssembly 二进制文件 ├── TestWebAssembly.data # 静态资源文件（可选） ├── TestWebAssembly.wasm.map # WebAssembly 源映射文件（可选） ├── TestWebAssembly.js.map # JavaScript 源映射文件（可选） └── TestWebAssembly.worker.js # Web Worker 文件（可选） 4.2 运行项目 如果走到这一步，你直接打开了html的话，就会看到这样的画面 这就需要使用web服务器的方式加载才可以 4.2.1使用 Web 服务器（如 Python 内置 HTTP 服务器）运行生成的 .html 文件。 4.2.2在浏览器中打开 .html 文件，运行 WebAssembly 应用程序。 http://localhost:8000/TestWebAssembly.html 5.遗留问题 出现了中文乱码问题，尚未解决，看过一些教程，说是Qt自带的三种字体并不支持中文，所以需要自己加载字体。 Qt 字体加载、图标字体的使用 | 解决 Qt for WebAssembly 中文字体问题_哔哩哔哩_bilibili 希望知道怎么解决的朋友可以分享一下。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":"CodeWorld1999"},{"title":"UE虚化使用Cesium插件FlyTo问题","slug":"UE/UE虚化使用Cesium插件FlyTo问题","date":"2025-06-11T01:31:22.000Z","updated":"2025-06-11T01:41:05.805Z","comments":true,"path":"2025/06/11/UE/UE虚化使用Cesium插件FlyTo问题/","link":"","permalink":"http://www.formeasy.cc/2025/06/11/UE/UE%E8%99%9A%E5%8C%96%E4%BD%BF%E7%94%A8Cesium%E6%8F%92%E4%BB%B6FlyTo%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题 在做UE5项目时，使用了Cesium插件，将插件自带的DynamicPawn，从一个经纬地点移动到另外地点，使用了FlyTo方法： 但是是使用过程中，如果实时飞行时，两点的数据之间较远，就会出现跳跃或不连贯的飞行。 解决 通过设置DynamicPawn的FlyTo属性，将Duration默认值5改为0.01，Progress Curve、Height Percentage Curve和Maximum Height by Distance Curve的曲线根据业务需求修改。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"Git 使用大全：从入门到精通","slug":"Other/Git 使用大全：从入门到精通","date":"2025-06-11T01:15:58.000Z","updated":"2025-06-11T01:25:39.722Z","comments":true,"path":"2025/06/11/Other/Git 使用大全：从入门到精通/","link":"","permalink":"http://www.formeasy.cc/2025/06/11/Other/Git%20%E4%BD%BF%E7%94%A8%E5%A4%A7%E5%85%A8%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/","excerpt":"","text":"Git是目前最流行的分布式版本控制系统，被广泛应用于软件开发中。本文将全面介绍 Git 的各种功能和使用方法，包含大量代码示例和实践建议。 Git 基础概念 版本控制系统 版本控制系统 (Version Control System, VCS) 是记录文件内容变化，以便将来查阅特定版本修订情况的系统。 Git 的特点 分布式：每个开发者都有完整的仓库副本 高效：大部分操作在本地完成 完整性：使用 SHA-1 哈希保证数据完整性 灵活性：支持多种非线性开发流程 Git 的三个区域 工作目录 (Working Directory)：实际文件所在目录 暂存区 (Staging Area)：准备提交的文件快照 Git 仓库 (Repository)：永久存储的文件快照 Git 文件状态 未跟踪 (Untracked)：新文件，未被 Git 管理 已修改 (Modified)：文件已修改但未暂存 已暂存 (Staged)：文件已修改并标记为下次提交 已提交 (Committed)：文件已安全保存在本地数据库 Git 安装与配置 安装 Git Linux 12345678# Debian/Ubuntusudo apt-get install git# Fedorasudo dnf install git# CentOSsudo yum install git macOS 12345# 使用 Homebrewbrew install git# 或下载官方安装包https://git-scm.com/download/mac Windows 下载 Git for Windows: https://git-scm.com/download/win 初始配置 配置用户信息： 12git config --global user.name &quot;Your Name&quot;git config --global user.email &quot;your.email@example.com&quot; 配置默认编辑器： 1git config --global core.editor &quot;vim&quot; 查看配置： 1git config --list 常用别名配置： 123456git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st statusgit config --global alias.unstage &#x27;reset HEAD --&#x27;git config --global alias.last &#x27;log -1 HEAD&#x27; Git 仓库创建与管理 初始化新仓库 123mkdir my-projectcd my-projectgit init 克隆现有仓库 123git clone https://github.com/user/repo.gitgit clone https://github.com/user/repo.git my-local-folder # 指定本地目录名git clone --depth 1 https://github.com/user/repo.git # 浅克隆，只获取最新版本 查看仓库状态 12git statusgit status -s # 简洁输出 忽略文件 创建 .gitignore 文件： 1234567891011121314151617181920212223242526# 忽略所有 .a 文件*.a# 但跟踪所有的 lib.a，即便你在前面忽略了 .a 文件!lib.a# 忽略当前目录下的 TODO 文件/TODO# 忽略 build/ 目录下的所有文件build/# 忽略 doc/notes.txt，但不忽略 doc/server/arch.txtdoc/*.txt# 忽略 doc/ 目录下所有 .pdf 文件doc/**/*.pdf# 忽略所有 .log 文件*.log# 忽略 node_modules 目录node_modules/# 忽略 .env 环境文件.env Git 基本工作流程 添加文件到暂存区 123456git add file1.txt # 添加单个文件git add file2.txt file3.txt # 添加多个文件git add . # 添加所有修改和新文件git add -A # 添加所有修改、新文件和删除操作git add -u # 添加所有修改和删除，但不包括新文件git add -p # 交互式添加 提交更改 1234git commit -m &quot;Initial commit&quot; # 简单提交git commit -a -m &quot;Commit all changes&quot; # 跳过暂存区，直接提交所有已跟踪文件的修改git commit --amend # 修改最后一次提交git commit --amend --no-edit # 修改最后一次提交但不修改提交信息 查看提交历史 123456789101112git loggit log -p # 显示每次提交的内容差异git log -2 # 显示最近2次提交git log --stat # 显示简略统计信息git log --pretty=oneline # 单行显示git log --pretty=format:&quot;%h - %an, %ar : %s&quot;git log --since=2.weeks # 显示两周内的提交git log --author=&quot;John&quot; # 按作者筛选git log --grep=&quot;bug fix&quot; # 按提交信息筛选git log -S&quot;function_name&quot; # 按代码内容筛选git log -- path/to/file # 查看特定文件的修改历史git log --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit # 漂亮的图形化输出 比较差异 1234567git diff # 工作目录与暂存区的差异git diff --staged # 暂存区与最后一次提交的差异git diff HEAD # 工作目录与最后一次提交的差异git diff branch1..branch2 # 两个分支间的差异git diff commit1 commit2 # 两次提交间的差异git diff --name-only commit1 commit2 # 只显示有差异的文件名git diff --word-diff # 单词级别的差异 Git 分支管理 创建与切换分支 1234567891011git branch # 查看本地分支git branch -a # 查看所有分支（包括远程）git branch new-branch # 创建新分支git checkout branch-name # 切换分支git checkout -b new-branch # 创建并切换到新分支git checkout -b new-branch origin/remote-branch # 基于远程分支创建本地分支git branch -d branch-name # 删除已合并的分支git branch -D branch-name # 强制删除分支git branch -m old-name new-name # 重命名分支git branch --merged # 查看已合并到当前分支的分支git branch --no-merged # 查看未合并到当前分支的分支 合并分支 1234git merge branch-name # 合并指定分支到当前分支git merge --no-ff branch-name # 禁用快进合并git merge --squash branch-name # 压缩合并git merge --abort # 中止合并 解决冲突 当合并发生冲突时，Git 会在冲突文件中标记冲突部分： 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD当前分支的内容=======要合并的分支的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch-name 手动解决冲突后： 12git add resolved-file.txtgit commit 变基 (Rebase) 1234git rebase branch-name # 将当前分支变基到指定分支git rebase --continue # 解决冲突后继续变基git rebase --abort # 中止变基git rebase -i HEAD~3 # 交互式变基，修改最近3次提交 交互式变基常用操作： pick: 使用提交 reword: 使用提交但修改提交信息 edit: 使用提交但暂停修改 squash: 将提交合并到前一个提交 fixup: 类似 squash 但丢弃提交信息 drop: 删除提交 Git 远程仓库操作 查看远程仓库 123git remote # 列出远程仓库git remote -v # 显示远程仓库URLgit remote show origin # 显示远程仓库详细信息 添加/移除远程仓库 1234git remote add origin https://github.com/user/repo.git # 添加远程仓库git remote rename origin new-name # 重命名远程仓库git remote remove origin # 移除远程仓库git remote set-url origin https://github.com/user/new-repo.git # 修改远程仓库URL 获取与拉取 1234git fetch origin # 从远程获取最新信息但不合并git fetch --prune # 清理已不存在的远程分支的本地引用git pull origin master # 获取并合并远程分支git pull --rebase # 使用变基方式拉取 推送 1234567git push origin master # 推送本地分支到远程git push -u origin master # 推送并设置上游分支git push origin --delete branch-name # 删除远程分支git push origin --tags # 推送所有标签git push origin HEAD # 推送当前分支git push --force # 强制推送（慎用）git push --force-with-lease # 更安全的强制推送 Git 撤销与回退 撤销工作目录修改 12git checkout -- file.txt # 撤销工作目录中文件的修改git checkout -- . # 撤销所有工作目录修改 撤销暂存区修改 1git reset HEAD file.txt # 将文件从暂存区移出 修改最后一次提交 12git commit --amend # 修改提交信息或内容git commit --amend --no-edit # 修改提交内容但不修改信息 回退提交 1234git reset --soft HEAD~1 # 回退提交但保留修改在暂存区git reset --mixed HEAD~1 # 回退提交并保留修改在工作目录（默认）git reset --hard HEAD~1 # 彻底回退提交，丢弃所有修改git revert HEAD # 创建新提交来撤销之前的提交 恢复删除的文件 12git checkout HEAD -- deleted-file.txt # 恢复已删除的文件git checkout $(git rev-list -n 1 HEAD -- deleted-file.txt)^ -- deleted-file.txt # 恢复在之前提交中删除的文件 Git 标签管理 创建标签 1234git tag v1.0 # 轻量标签git tag -a v1.0 -m &quot;Version 1.0&quot; # 附注标签git tag -a v1.0 9fceb02 # 给特定提交打标签git tag -s v1.0 -m &quot;Signed version 1.0&quot; # 签名标签 查看标签 123git tag # 列出所有标签git show v1.0 # 查看标签详情git tag -l &quot;v1.*&quot; # 过滤标签 推送标签 12git push origin v1.0 # 推送单个标签git push origin --tags # 推送所有标签 删除标签 123git tag -d v1.0 # 删除本地标签git push origin --delete v1.0 # 删除远程标签git push origin :refs/tags/v1.0 # 另一种删除远程标签的方式 检出标签 12git checkout v1.0 # 检出标签（进入分离头指针状态）git checkout -b version1 v1.0 # 基于标签创建新分支 Git 高级操作 储藏更改 1234567891011git stash # 储藏当前工作目录和暂存区的修改git stash save &quot;message&quot; # 带消息的储藏git stash list # 列出所有储藏git stash apply # 应用最近的储藏git stash apply stash@&#123;1&#125; # 应用特定储藏git stash pop # 应用并移除最近的储藏git stash drop stash@&#123;1&#125; # 删除特定储藏git stash clear # 清除所有储藏git stash branch new-branch # 从储藏创建新分支git stash -u # 储藏包括未跟踪文件git stash -a # 储藏包括所有文件（包括.gitignore忽略的） 二分查找 12345git bisect start # 开始二分查找git bisect bad # 当前版本有问题git bisect good v1.0 # v1.0版本是好的git bisect reset # 结束二分查找git bisect run test-script.sh # 自动运行测试脚本进行二分查找 子模块 123456git submodule add https://github.com/user/repo.git path/to/submodule # 添加子模块git submodule init # 初始化子模块git submodule update # 更新子模块git submodule update --init --recursive # 递归初始化并更新所有子模块git submodule foreach &#x27;git checkout master&#x27; # 对所有子模块执行命令git clone --recurse-submodules https://github.com/user/repo.git # 克隆包含子模块的仓库 重写历史 12345678910git filter-branch --tree-filter &#x27;rm -f passwords.txt&#x27; HEAD # 从所有提交中删除文件git filter-branch --commit-filter &#x27; if [ &quot;$GIT_AUTHOR_EMAIL&quot; = &quot;old@email.com&quot; ]; then GIT_AUTHOR_NAME=&quot;New Name&quot;; GIT_AUTHOR_EMAIL=&quot;new@email.com&quot;; git commit-tree &quot;$@&quot;; else git commit-tree &quot;$@&quot;; fi&#x27; HEAD # 修改作者信息 注意：重写历史会改变提交哈希，只适用于尚未共享的提交。 打包与归档 1234git bundle create repo.bundle HEAD master # 创建包含master分支的bundle文件git clone repo.bundle repo -b master # 从bundle文件克隆git archive --format=zip HEAD &gt; archive.zip # 创建当前提交的zip归档git archive --format=tar --prefix=project/ HEAD | gzip &gt; project.tar.gz # 创建带前缀的tar.gz归档 Git 协作工作流 集中式工作流 开发者克隆中央仓库 在本地提交更改 推送更改到中央仓库 解决冲突（如果有） 功能分支工作流 为每个新功能创建独立分支 在功能分支上开发 完成后合并到主分支 删除功能分支 123456git checkout -b new-feature# 开发功能...git commit -a -m &quot;Implement new feature&quot;git checkout mastergit merge new-featuregit branch -d new-feature Git Flow Git Flow 是一种流行的分支模型，定义严格的分支角色和交互方式。 主要分支： master: 生产代码 develop: 集成开发分支 支持分支： feature/*: 功能开发分支 release/*: 准备发布分支 hotfix/*: 紧急修复分支 12345678910111213141516# 初始化Git Flowgit flow init# 开始新功能git flow feature start myfeature# 完成功能git flow feature finish myfeature# 发布新版本git flow release start 1.0.0git flow release finish 1.0.0# 紧急修复git flow hotfix start 1.0.1git flow hotfix finish 1.0.1 Forking 工作流 开发者fork中央仓库 克隆自己的fork到本地 创建功能分支开发 推送更改到自己的fork 创建Pull Request请求合并到中央仓库 1234567891011121314151617# 克隆fork的仓库git clone https://github.com/yourname/repo.git# 添加上游仓库git remote add upstream https://github.com/original/repo.git# 获取上游更改git fetch upstreamgit merge upstream/master# 创建功能分支git checkout -b new-feature# 开发完成后推送到自己的forkgit push origin new-feature# 然后在GitHub上创建Pull Request Git 问题排查 查看文件修改历史 1234git blame file.txt # 查看文件的逐行修改历史git blame -L 10,20 file.txt # 查看特定行的修改历史git log -p file.txt # 查看文件的完整修改历史git show commit-id:file.txt # 查看特定提交中的文件内容 查找问题提交 12345git bisect start # 开始二分查找git bisect bad # 标记当前版本有问题git bisect good v1.0 # 标记v1.0版本是好的# Git会自动检出中间版本，你测试后标记good或badgit bisect reset # 结束二分查找 恢复丢失的提交 1234git reflog # 查看所有HEAD指向的历史git fsck --lost-found # 查找悬空对象git show commit-id # 检查找到的提交git merge commit-id # 恢复丢失的提交 清理仓库 12345git gc # 清理不必要的文件并优化本地仓库git clean -n # 显示将被删除的未跟踪文件（干跑）git clean -f # 删除未跟踪文件git clean -fd # 删除未跟踪文件和目录git prune # 删除悬空对象 Git 最佳实践 提交规范 提交信息应清晰描述修改内容 第一行不超过50字符，作为摘要 第二行空行 第三行开始详细说明（如有必要） 使用现在时态、命令语气（如&quot;Fix bug&quot;而非&quot;Fixed bug&quot;） 示例： 123456789101112131415161718192021Summarize changes in around 50 characters or lessMore detailed explanatory text, if necessary. Wrap it to about 72characters or so. In some contexts, the first line is treated as thesubject of the commit and the rest of the text as the body. Theblank line separating the summary from the body is critical (unlessyou omit the body entirely); various tools like `log`, `shortlog`and `rebase` can get confused if you run the two together.Explain the problem that this commit is solving. Focus on why youare making this change as opposed to how (the code explains that).Are there side effects or other unintuitive consequences of thischange? Here&#x27;s the place to explain them.Further paragraphs come after blank lines.- Bullet points are okay, too- Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary here 分支命名规范 feature/*: 新功能开发 bugfix/*: 错误修复 hotfix/*: 紧急修复 release/*: 版本发布准备 docs/*: 文档更新 test/*: 测试相关 工作流程建议 频繁提交，原子性提交（每个提交只做一件事） 在推送前整理本地提交历史 使用分支进行功能开发和问题修复 定期从上游拉取更改 使用Pull Request进行代码审查 大型项目建议 使用子模块或子树管理依赖 使用浅克隆减少下载量 使用稀疏检出只获取需要的文件 使用Git LFS管理大文件 12345678910# 浅克隆git clone --depth 1 https://github.com/user/repo.git# 稀疏检出git init repocd repogit remote add origin https://github.com/user/repo.gitgit config core.sparseCheckout trueecho &quot;some/dir/&quot; &gt;&gt; .git/info/sparse-checkoutgit pull origin master 安全性建议 不要提交敏感信息（密码、密钥等） 使用.gitignore忽略不必要的文件 定期检查提交历史中的敏感信息 必要时重写历史删除敏感信息 12# 检查历史中是否包含敏感信息git log -p | grep &quot;password&quot; 总结 Git 是一个功能强大且灵活的工具，掌握它可以极大提高开发效率。本文涵盖了 Git 的各个方面，从基础操作到高级技巧，从个人使用到团队协作。建议读者在实际项目中多加练习，逐步掌握 Git 的各种功能。 记住，Git 的核心概念是快照而非差异，理解这一点有助于更好地使用 Git。同时，遵循最佳实践可以使版本控制更加高效和安全。 Git 的学习曲线可能较陡峭，但一旦掌握，它将成为你开发工作中不可或缺的利器。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":"sixpp"},{"title":"Docker 与 kubectl 命令对比","slug":"kubernetes/Docker 与 kubectl 命令对比","date":"2025-05-31T08:54:16.000Z","updated":"2025-05-31T09:40:05.512Z","comments":true,"path":"2025/05/31/kubernetes/Docker 与 kubectl 命令对比/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/Docker%20%E4%B8%8E%20kubectl%20%E5%91%BD%E4%BB%A4%E5%AF%B9%E6%AF%94/","excerpt":"","text":"使用 Kubernetes 命令行工具 kubectl 与 API 服务器进行交互。如果您熟悉 Docker 命令行工具，则使用 kubectl 非常简单。但是，docker 命令和 kubectl 命令之间有一些区别。以下显示了 docker 子命令，并描述了等效的 kubectl 命令。 运行 Nginx 部署并将其暴露 docker ps 123456docker run -d --restart=always -e DOMAIN=cluster --name nginx-app -p 80:80 nginx55c103fa129692154a7652490236fee9be47d70a8dd562281ae7d2f9a339a6dbdocker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES55c103fa1296 nginx &quot;nginx -g &#x27;daemon of…&quot; 9 seconds ago Up 9 seconds 0.0.0.0:80-&gt;80/tcp nginx-app kubectl create deployment 1234567# 启动运行 nginx 的 Podkubectl create deployment --image=nginx nginx-appdeployment.apps/nginx-app created# add env to nginx-appkubectl set env deployment/nginx-app DOMAIN=clusterdeployment.apps/nginx-app env updated 说明： kubectl 命令打印创建或突变资源的类型和名称，然后可以在后续命令中使用。部署后，您可以公开新服务。 123# 通过服务公开端口kubectl expose deployment nginx-app --port=80 --name=nginx-httpservice &quot;nginx-http&quot; exposed 在 kubectl 命令中，我们创建了一个 Deployment，这将保证有 N 个运行 nginx 的 pod(N 代表 spec 中声明的 replica 数，默认为 1)。我们还创建了一个 service，其选择器与容器标签匹配。 默认情况下镜像会在后台运行，与 docker run -d … 类似，如果您想在前台运行，使用 kubectl run 在前台运行 Pod: kubectl run [-i] [–tty] --attach --image= 与 docker run … 不同的是，如果指定了 --attach ，我们将连接到 stdin，stdout 和 stderr，而不能控制具体连接到哪个输出流（docker -a …）。要从容器中退出，可以输入 Ctrl + P，然后按 Ctrl + Q。 因为我们使用 Deployment 启动了容器，如果您终止连接到的进程（例如 ctrl-c），容器将会重启，这跟 docker run -it 不同。如果想销毁该 Deployment（和它的 pod），您需要运行 kubectl delete deployment 。 注意： 执行的命令 kubectl expose deployment nginx-app --port=80 --name=nginx-http 创建了一个 Kubernetes Service，但默认情况下它的类型是 ClusterIP（仅集群内部可访问）。若要从外部访问 Nginx，需将服务类型改为 NodePort 或 LoadBalancer。 kubectl get svc nginx-http -o wide NAME TYPE CLUSTER-IP PORT(S) AGE SELECTOR nginx-http ClusterIP 10.96.0.1 80/TCP 5m app=nginx 修改服务类型为 NodePort kubectl edit svc nginx-http 列出正在运行的容器 docker ps 1234docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES14636241935f ubuntu:16.04 &quot;echo test&quot; 5 seconds ago Exited (0) 5 seconds ago cocky_fermi55c103fa1296 nginx &quot;nginx -g &#x27;daemon of…&quot; About a minute ago Up About a minute 0.0.0.0:80-&gt;80/tcp nginx-app kubectl get 1234kubectl get poNAME READY STATUS RESTARTS AGEnginx-app-8df569cb7-4gd89 1/1 Running 0 3mubuntu 0/1 Completed 0 20s 连接已运行在容器中的进程 docker attach 12345docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES55c103fa1296 nginx &quot;nginx -g &#x27;daemon of…&quot; 5 minutes ago Up 5 minutes 0.0.0.0:80-&gt;80/tcp nginx-appdocker attach 55c103fa1296 kubectl attach 12345kubectl get podsNAME READY STATUS RESTARTS AGEnginx-app-5jyvm 1/1 Running 0 10mkubectl attach -it nginx-app-5jyvm 要从容器中分离，可以输入 Ctrl + P，然后按 Ctrl + Q。 在容器中执行命令 docker exec 123456docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES55c103fa1296 nginx &quot;nginx -g &#x27;daemon of…&quot; 6 minutes ago Up 6 minutes 0.0.0.0:80-&gt;80/tcp nginx-appdocker exec 55c103fa1296 cat etc/hostname55c103fa1296 kubectl exec 123456kubectl get poNAME READY STATUS RESTARTS AGEnginx-app-5jyvm 1/1 Running 0 10mkubectl exec nginx-app-5jyvm -- cat etc/hostnamenginx-app-5jyvm 执行交互式命令 1234567# 使用 docker 命令：docker exec -ti 55c103fa1296 bin/sh# exit# kubectl:kubectl exec -ti nginx-app-5jyvm -- bin/sh# exit 查看运行中进程的 stdout/stderr docker logs 123docker logs -f a9e192.168.9.1 - - [14/Jul/2015:01:04:02 +0000] &quot;GET HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.35.0&quot; &quot;-&quot;192.168.9.1 - - [14/Jul/2015:01:04:03 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.35.0&quot; &quot;-&quot; kubectl logs 123kubectl logs -f nginx-app-zibvs10.240.63.110 - - [14/Jul/2015:01:09:01 +0000] &quot;GET HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.26.0&quot; &quot;-&quot;10.240.63.110 - - [14/Jul/2015:01:09:02 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.26.0&quot; &quot;-&quot; 现在是时候提一下 pod 和容器之间的细微差别了；默认情况下如果 pod 中的进程退出 pod 也不会终止，相反它将会重启该进程。这类似于 docker run 时的 --restart=always 选项， 这是主要差别。在 docker 中，进程的每个调用的输出都是被连接起来的，但是对于 kubernetes，每个调用都是分开的。要查看以前在 kubernetes 中执行的输出，请执行以下操作： 123kubectl logs --previous nginx-app-zibvs10.240.63.110 - - [14/Jul/2015:01:09:01 +0000] &quot;GET HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.26.0&quot; &quot;-&quot;10.240.63.110 - - [14/Jul/2015:01:09:02 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.26.0&quot; &quot;-&quot; 停止和删除运行中的进程？ docker stop and docker rm 123456789docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa9ec34d98787 nginx &quot;nginx -g &#x27;daemon of&quot; 22 hours ago Up 22 hours 0.0.0.0:80-&gt;80/tcp, 443/tcp nginx-appdocker stop a9ec34d98787a9ec34d98787docker rm a9ec34d98787a9ec34d98787 kubectl 12345678910111213kubectl get deployment nginx-appNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-app 1 1 1 1 2mkubectl get po -l run=nginx-appNAME READY STATUS RESTARTS AGEnginx-app-2883164633-aklf7 1/1 Running 0 2mkubectl delete deployment nginx-appdeployment &quot;nginx-app&quot; deletedkubectl get po -l run=nginx-app# Return nothing 说明： 请注意，我们不直接删除 pod。使用 kubectl 命令，我们要删除拥有该 pod 的 Deployment。如果我们直接删除 pod，Deployment 将会重新创建该 pod。 docker login 在 kubectl 中没有对 docker login 的直接模拟。 查看客户端和服务端的版本 docker 123456789101112docker versionClient version: 1.7.0Client API version: 1.19Go version (client): go1.4.2Git commit (client): 0baf609OS/Arch (client): linux/amd64Server version: 1.7.0Server API version: 1.19Go version (server): go1.4.2Git commit (server): 0baf609OS/Arch (server): linux/amd64 kubectl 1234kubectl versionClient Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;6&quot;, GitVersion:&quot;v1.6.9+a3d1dfa6f4335&quot;, GitCommit:&quot;9b77fed11a9843ce3780f70dd251e92901c43072&quot;, GitTreeState:&quot;dirty&quot;, BuildDate:&quot;2017-08-29T20:32:58Z&quot;, OpenPaasKubernetesVersion:&quot;v1.03.02&quot;, GoVersion:&quot;go1.7.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;6&quot;, GitVersion:&quot;v1.6.9+a3d1dfa6f4335&quot;, GitCommit:&quot;9b77fed11a9843ce3780f70dd251e92901c43072&quot;, GitTreeState:&quot;dirty&quot;, BuildDate:&quot;2017-08-29T20:32:58Z&quot;, OpenPaasKubernetesVersion:&quot;v1.03.02&quot;, GoVersion:&quot;go1.7.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125; 获取有关环境和配置的各种信息 docker 123456789101112131415161718docker infoContainers: 40Images: 168Storage Driver: aufsRoot Dir: /usr/local/google/docker/aufsBacking Filesystem: extfsDirs: 248Dirperm1 Supported: falseExecution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.13.0-53-genericOperating System: Ubuntu 14.04.2 LTSCPUs: 12Total Memory: 31.32 GiBName: k8s-is-fun.mtv.corp.google.comID: ADUV:GCYR:B3VJ:HMPO:LNPQ:KD5S:YKFQ:76VN:IANZ:7TFV:ZBF4:BYJOWARNING: No swap limit support kubectl 12345678kubectl cluster-infoKubernetes master is running at https://108.59.85.141KubeDNS is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/kube-dns/proxykubernetes-dashboard is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxyGrafana is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-grafana/proxyHeapster is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-heapster/proxyInfluxDB is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":null},{"title":"K8s运维管理平台：Dashboard_kubernetes-dashboard","slug":"kubernetes/K8s运维管理平台：Dashboard_kubernetes-dashboard","date":"2025-05-31T08:47:16.000Z","updated":"2025-05-31T09:40:49.772Z","comments":true,"path":"2025/05/31/kubernetes/K8s运维管理平台：Dashboard_kubernetes-dashboard/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/K8s%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%EF%BC%9ADashboard_kubernetes-dashboard/","excerpt":"","text":"1、创建命名空间 在 Kubernetes 中，命名空间（Namespace）是一种非常重要的资源管理方式，它能够将不同的业务、项目或者团队的资源隔离开来，避免资源之间的冲突。接下来，我们将创建一个名为 kubernetes-dashboard 的命名空间，用于部署 Kubernetes Dashboard。 12kubectl create ns kubernetes-dashboardalias kd=&#x27;kubectl -n kubernetes-dashboard&#x27; 上述命令中，kubectl create ns kubernetes-dashboard 用于创建 kubernetes-dashboard 命名空间。而 alias kd=‘kubectl -n kubernetes-dashboard’ 则是为了方便后续操作，创建了一个别名 kd，这样在后续的命令中，我们可以直接使用 kd 来代表在 kubernetes-dashboard 命名空间下执行命令。更多关于命名空间的详细介绍，可以参考Kubernetes 命名空间官方文档。 2、编辑YAML 在部署 Kubernetes Dashboard 之前，我们需要编辑一个 YAML 文件来定义相关的资源。YAML 文件是 Kubernetes 中用于描述资源配置的常用文件格式，通过它可以精确地定义我们需要部署的资源的各种属性。 执行上述命令后，会打开一个文本编辑器，我们可以在其中编写或者修改 kubernetes-dashboard.yaml 文件的内容。下面是编辑该文件时可能涉及的一些关键内容及对应的配置示例： 1vi kubernetes-dashboard.yaml 编辑过程中可能会遇到各种问题，例如语法错误等，你可以参考Kubernetes YAML 语法指南来确保文件的正确性。编辑完成后的文件示例截图如下： 3、部署Pod 当 YAML 文件编辑完成后，我们就可以使用 kubectl apply 命令来部署相关的资源了。该命令会根据 YAML 文件中的定义，在 Kubernetes 集群中创建或更新相应的资源。 1kubectl apply -f kubernetes-dashboard.yaml 执行上述命令后，可能会出现如下提示信息： 123456789101112131415Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl applynamespace/kubernetes-dashboard configuredserviceaccount/kubernetes-dashboard createdservice/kubernetes-dashboard createdsecret/kubernetes-dashboard-certs createdsecret/kubernetes-dashboard-csrf createdsecret/kubernetes-dashboard-key-holder createdconfigmap/kubernetes-dashboard-settings createdrole.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createddeployment.apps/kubernetes-dashboard createdservice/dashboard-metrics-scraper createddeployment.apps/dashboard-metrics-scraper created 从输出信息中可以看到，Kubernetes 依次创建或配置了命名空间、服务账户、服务、密钥、配置映射、角色、集群角色、角色绑定、集群角色绑定、部署和指标收集服务等资源。更多关于 kubectl apply 命令的详细用法，可以参考Kubectl 命令官方文档。 4、查看资源 部署完成后，我们可以使用 kubectl get 命令来查看在 kubernetes-dashboard 命名空间下部署的 Pod 和服务的详细信息。 1kubectl get pod,svc -n kubernetes-dashboard -o wide 该命令会以详细的格式输出 kubernetes-dashboard 命名空间下的所有 Pod 和服务的信息，包括 Pod 的名称、状态、所在节点、IP 地址，以及服务的名称、类型、IP 地址、端口等信息。通过查看这些信息，我们可以确认资源是否成功部署，以及资源的运行状态是否正常。 5、生产Token 为了能够登录 Kubernetes Dashboard 的 Web 界面，我们需要生成一个有效的 Token。Token 是一种身份验证的凭证，用于验证用户的身份，确保只有授权的用户能够访问 Dashboard。 1kubectl describe -n kube-system $(kubectl -n kube-system get secret -n kube-system -o name | grep namespace) | grep token 上述命令会在 kube-system 命名空间下查找与命名空间相关的密钥，并从中提取出 Token 信息。生成的 Token 是一串长字符串，我们需要妥善保存，后续登录 Dashboard 时会用到。更多关于 Kubernetes 身份验证和 Token 的详细内容，可以参考Kubernetes 身份验证官方文档。 6、Web界面访问 注意：一定是https，否则无法访问 在访问 Kubernetes Dashboard 的 Web 界面时，需要注意一定要使用 https 协议，否则将无法正常访问。这是因为 Dashboard 默认配置了安全的访问方式，使用 https 可以确保数据在传输过程中的安全性。 在访问之前，我们可以先检查一下网络连接是否正常。可以使用以下命令来查看 Pod 的详细信息和端口监听情况 12345kd get pod -o widenetstat -aptn|grep 311telnet ip地址 31111 kd get pod -o wide 命令用于查看 kubernetes-dashboard 命名空间下所有 Pod 的详细信息，包括 Pod 的 IP 地址、所在节点等。netstat -aptn|grep 311 命令用于查看系统中是否有进程监听 311 相关的端口。telnet ip地址 31111 命令用于测试与指定 IP 地址和端口的网络连接是否正常。如果这些命令执行后没有出现错误，说明网络连接正常，可以尝试访问 Dashboard 的 Web 界面。 访问登录页面 打开浏览器，输入 https://ip地址:31111/ （将ip地址 替换为实际的 IP 地址），即可打开 Kubernetes Dashboard 的登录页面。在登录页面中，输入之前生成的 Token，然后点击登录按钮，即可登录到 Dashboard。 查看资源 登录成功后，我们可以在 Dashboard 中查看各种资源的详细信息。Dashboard 提供了直观的界面，方便我们查看 Pod、服务、部署等资源的状态、配置信息等。 编辑资源 除了查看资源，我们还可以在 Dashboard 中直接编辑资源的配置信息。通过点击相应资源的编辑按钮，我们可以修改资源的各种属性，例如 Pod 的副本数量、服务的端口配置等。 查看日志 在排查问题或者监控应用程序运行状态时，查看 Pod 的日志信息是非常重要的。在 Dashboard 中，我们可以方便地查看每个 Pod 的日志内容，帮助我们快速定位和解决问题。 7、使用体验 优点： 1、功能相对全面 Kubernetes Dashboard 提供了丰富的功能，涵盖了资源的查看、编辑、监控、日志查看等多个方面，能够满足我们日常对 Kubernetes 集群进行管理和运维的大部分需求。无论是查看 Pod 的运行状态，还是对部署进行滚动更新，都可以在 Dashboard 中方便地完成。 2、UI简介 Dashboard 的用户界面设计简洁明了，易于上手。即使是对 Kubernetes 不太熟悉的用户，也能够快速找到自己需要的功能入口，通过直观的界面操作来完成各种管理任务。 8、附录：部署文件 以下是完整的 kubernetes-dashboard.yaml 部署文件示例，你可以根据实际需求进行调整和修改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304# Copyright 2017 The Kubernetes Authors.## Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.apiVersion: v1kind: Namespacemetadata: name: kubernetes-dashboard---apiVersion: v1kind: ServiceAccountmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 31111 selector: k8s-app: kubernetes-dashboard---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-certs namespace: kubernetes-dashboardtype: Opaque---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-csrf namespace: kubernetes-dashboardtype: Opaquedata: csrf: &quot;&quot;---apiVersion: v1kind: Secretmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-key-holder namespace: kubernetes-dashboardtype: Opaque---kind: ConfigMapapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-settings namespace: kubernetes-dashboard---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardrules: # Allow Dashboard to get, update and delete Dashboard exclusive secrets. - apiGroups: [&quot;&quot;] resources: [&quot;secrets&quot;] resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;] verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;] # Allow Dashboard to get and update &#x27;kubernetes-dashboard-settings&#x27; config map. - apiGroups: [&quot;&quot;] resources: [&quot;configmaps&quot;] resourceNames: [&quot;kubernetes-dashboard-settings&quot;] verbs: [&quot;get&quot;, &quot;update&quot;] # Allow Dashboard to get metrics. - apiGroups: [&quot;&quot;] resources: [&quot;services&quot;] resourceNames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;] verbs: [&quot;proxy&quot;] - apiGroups: [&quot;&quot;] resources: [&quot;services/proxy&quot;] resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;] verbs: [&quot;get&quot;]---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboardrules: # Allow Metrics Scraper to get metrics from the Metrics server - apiGroups: [&quot;metrics.k8s.io&quot;] resources: [&quot;pods&quot;, &quot;nodes&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kubernetes-dashboardsubjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboardsubjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard---kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard image: registry.cn-beijing.aliyuncs.com/qingfeng666/dashboard:v2.0.4 imagePullPolicy: Always ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates - --namespace=kubernetes-dashboard # Uncomment the following line to manually specify Kubernetes API server Host # If not specified, Dashboard will attempt to auto discover the API server and connect # to it. Uncomment only if the default does not work. # - --apiserver-host=http://my-address:port volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs # Create on-disk volume to store exec logs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: &#123;&#125; serviceAccountName: kubernetes-dashboard nodeSelector: &quot;kubernetes.io/os&quot;: linux # Comment the following tolerations if Dashboard must not be deployed on master tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---kind: ServiceapiVersion: v1metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboardspec: ports: - port: 8000 targetPort: 8000 selector: k8s-app: dashboard-metrics-scraper---kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboardspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: dashboard-metrics-scraper template: metadata: labels: k8s-app: dashboard-metrics-scraper annotations: seccomp.security.alpha.kubernetes.io/pod: &#x27;runtime/default&#x27; spec: containers: - name: dashboard-metrics-scraper image: registry.cn-beijing.aliyuncs.com/qingfeng666/metrics-scraper:v1.0.4 ports: - containerPort: 8000 protocol: TCP livenessProbe: httpGet: scheme: HTTP path: / port: 8000 initialDelaySeconds: 30 timeoutSeconds: 30 volumeMounts: - mountPath: /tmp name: tmp-volume securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 serviceAccountName: kubernetes-dashboard nodeSelector: &quot;kubernetes.io/os&quot;: linux # Comment the following tolerations if Dashboard must not be deployed on master tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule volumes: - name: tmp-volume emptyDir: &#123;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":null},{"title":"K8s运维管理平台 - KubeSphere 3.x 和4.x 使用分析：功能较强，UI美观","slug":"kubernetes/K8s运维管理平台 - KubeSphere 3.x 和4.x 使用分析：功能较强，UI美观","date":"2025-05-31T08:35:26.000Z","updated":"2025-05-31T09:40:23.835Z","comments":true,"path":"2025/05/31/kubernetes/K8s运维管理平台 - KubeSphere 3.x 和4.x 使用分析：功能较强，UI美观/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/K8s%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%20-%20KubeSphere%203.x%20%E5%92%8C4.x%20%E4%BD%BF%E7%94%A8%E5%88%86%E6%9E%90%EF%BC%9A%E5%8A%9F%E8%83%BD%E8%BE%83%E5%BC%BA%EF%BC%8CUI%E7%BE%8E%E8%A7%82/","excerpt":"","text":"Lic License-1-ov-file 使用感受 优点： 1、部署简单 2、有访问控制功能 3、UI美观 4、3.x 免费开源 5、监控可观测性强 6、运维操作便捷 优化点： 1、缺少服务网格（Endpoint、Ingresses等管理） 2、缺少Storage Classes 3、缺少RBAC权限管理（ClusterRoleBinding、ClusterRoles、RoleBinding、Roles） - 认证授权 4、缺少Events 5、缺少Network Policies 6、缺少Replica Sets 7、缺少Pod容器运维功能（登录、日志查看） 8、缺少Nodes负载、磁盘延迟、文件句柄、网络丢包和错误、Kubernetes API Server监控 9、缺少Etcd集群监控 实操 首页 4.x 集群配额统计清晰，容器组状态统计和QoS功能较好 项目 | 应用负载 | 配置 | 定制资源定义 功能类似 容器组无法查看日志和登录 定制资源定义（Custom Resource Definition，CRD）是一种 Kubernetes 实现自定义资源类型的扩展方式，您可以像操作内置资源对象一样操作定制资源定义对象。 编辑标签、污点 存储 3.x 有卷快照和卷快照类 监控告警 集群状态 3.x 多了1个组件状态 集群设置 3.x 有1个网关设置 KubeSphere 3.x 和 4.x 在 Kubernetes 生态系统中，KubeSphere 是一个开源的企业级容器管理平台，它提供了丰富的功能，以便简化 Kubernetes 集群的管理和应用部署。在 KubeSphere 3.x 和 4.x 版本之间，确实存在一些显著的差异，主要体现在功能扩展、架构设计、用户体验、性能优化等方面。下面我将详细说明这两个版本的区别： 1. 架构变化： KubeSphere 3.x： KubeSphere 3.x 基于 Kubernetes 平台构建，并通过多个微服务模块实现其功能，如多租户、应用部署、监控等。 采用了较为传统的 Kubernetes 加强版架构，功能模块较为分散，配置和管理可能较为复杂。 在版本 3.x 中，很多功能需要依赖外部组件（例如 Prometheus、Alertmanager）来实现监控、日志收集等功能。 KubeSphere 4.x： KubeSphere 4.x 引入了全新微服务架构，更注重对多租户、多集群的统一管理。 采用了 Kubernetes 原生的控制平面，进一步简化了 KubeSphere 与 Kubernetes 之间的集成。 增强了对多集群、多云环境的支持，可以在不同集群间实现更强的资源共享和协同。 2. 多集群管理： KubeSphere 3.x： 虽然 KubeSphere 3.x 支持多集群管理，但相较于 4.x 版本，其多集群功能相对较为基础，需要更多的手动配置和管理。 支持从单一界面管理不同集群，但功能有限，跨集群的服务发现和调度较为复杂。 KubeSphere 4.x： KubeSphere 4.x 在多集群管理方面做了很大提升。用户可以在 KubeSphere 控制台中直接管理多个集群，无论是本地集群还是云端集群。 通过多集群管理，KubeSphere 4.x 可以实现跨集群的应用部署、服务发现、日志和监控统一展示，支持跨集群的统一策略和权限管理。 3. 增强的 DevOps 功能： KubeSphere 3.x： KubeSphere 3.x 提供了基本的 DevOps 功能，支持 CI/CD 管道、代码构建、镜像构建等。 但这些功能在一些方面（如第三方集成和自定义化）可能存在一定限制。 KubeSphere 4.x： 4.x 版本进一步强化了 DevOps 支持，提供了更多的集成工具和功能，支持更加灵活的 CI/CD 流程。 更好地支持 Jenkins、GitLab 等第三方工具集成，并且在 DevOps 控制台的用户体验上做了进一步优化，使得开发者能够更加高效地管理和自动化应用部署。 4. 监控与日志： KubeSphere 3.x： 默认集成了 Prometheus 和 Grafana 作为监控工具，并使用 Elasticsearch + Fluentd + Kibana（EFK）进行日志管理。 监控和日志管理的配置需要一些额外的操作，且用户需要自行配置和维护这些集成工具。 KubeSphere 4.x： KubeSphere 4.x 在监控和日志管理方面做了更多优化，提供了更好的默认集成，简化了配置和维护过程。 增强了 Prometheus 和 Grafana 的集成，提供了更多的实时监控和告警功能，同时简化了日志收集、存储和查询的配置过程。 可以通过 KubeSphere 控制台直接查看集群、应用和服务的监控数据，并且支持跨集群的监控数据汇总。 5. 性能和可扩展性： KubeSphere 3.x： 性能方面已经较为优化，但由于多种功能模块较为独立，整体的可扩展性和性能可能在大规模集群中表现不如预期。 对于非常大的集群或应用规模，可能需要额外的调整和优化。 KubeSphere 4.x： KubeSphere 4.x 在性能和可扩展性上做了显著优化，特别是在对大规模集群和高并发场景下的支持。其架构设计更加模块化和灵活，能够适应更大的集群规模。 4.x 版本对于资源的管理更加高效，能够在多集群的场景下提供更好的资源调度和管理能力。 6. 用户体验： KubeSphere 3.x： 界面相对较为基础，但功能完整，适合一些标准的 Kubernetes 使用场景。 用户操作过程中可能需要更多的手动配置和调整。 KubeSphere 4.x： 4.x 版本在用户体验方面做了很多提升，提供了更加友好的 UI，支持更直观的操作。 增强了对 Kubernetes 原生资源（如 Custom Resource Definitions, CRDs）的支持，用户可以通过控制台方便地管理和配置。 7. 安全性： KubeSphere 3.x： 提供基础的安全性控制，如角色权限管理（RBAC）、多租户隔离等，但在安全性方面的增强功能较为基础。 KubeSphere 4.x： 在安全性方面进一步增强，支持更多的安全策略和权限管理选项，尤其是在多集群环境下的安全控制和审计功能。 提供了对更多安全插件和工具的支持，如对容器运行时安全、网络安全等方面的增强。 总结： KubeSphere 3.x 和 4.x 之间的主要区别体现在架构、功能和用户体验的全面提升上。4.x 版本在多集群管理、DevOps、监控、日志、性能和安全性等方面进行了显著的增强，特别是在大规模环境下的适应性和管理能力上有了大幅改善。如果你的需求涉及多个集群管理、高效的 DevOps 流程、以及更强的监控和日志集成功能，那么升级到 KubeSphere 4.x 将是一个更好的选择。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":"hezuijiudexiaobai"},{"title":"K8s运维管理平台 - xkube体验：功能较多_xkube管理平台","slug":"kubernetes/K8s运维管理平台 - xkube体验：功能较多_xkube管理平台","date":"2025-05-31T08:28:43.000Z","updated":"2025-05-31T09:40:41.172Z","comments":true,"path":"2025/05/31/kubernetes/K8s运维管理平台 - xkube体验：功能较多_xkube管理平台/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/K8s%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%20-%20xkube%E4%BD%93%E9%AA%8C%EF%BC%9A%E5%8A%9F%E8%83%BD%E8%BE%83%E5%A4%9A_xkube%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/","excerpt":"","text":"简介 一款基于client-go、layui、layuimini、beego开发的kubernetes多集群管理系统，该系统具备将多个IDC、公有云的K8s进行统一进行管理。比Kubernetes Dashboard的功能更丰富，界面更友好更直观。 gitee Lic 安装 1、需要手动安装MySQL，建库 8.0需要修改2个地方 1）在 MySQL 中，INT(11) 中的 (11) 是显示宽度，用于指定显示时的字符宽度，但这并不会限制实际存储的数字大小。例如，INT(11) 和 INT 在存储和处理上是完全相同的，只是显示宽度不同。在 MySQL 8.0 及更高版本中，显示宽度被认为是没有实际意义的，因此被弃用。 1sed -i &#x27;s/\\(int\\|bigint\\|tinyint\\|smallint\\|mediumint\\)([0-9]*\\( unsigned\\)\\?)/\\1/g&#x27; db_xkube.sql 2）utf8 字符集在 MySQL 8.0 中被逐步替换为 utf8mb4，以支持更广泛的 Unicode 字符。 12sed -i &#x27;s/utf8/utf8mb4/g&#x27; xkube/db_xkube.sqlsed -i &#x27;s/utf8mb4mb4/utf8mb4/g&#x27; xkube/db_xkube.sql 2、启动命令 12chmod 755 xkubenohup ./xkube &amp; 3、[ERROR] GetNodeMetric Fail:the server is currently unable to handle the request (get nodes.metrics.k8s.io qfusion-1) metrics-server 服务安装 使用总结 优点 1、开源免费 2、功能强大全面，细节完善（导出功能） 3、文档中心功能 优化 1、安装步骤 2、点开一个菜单栏是跳转一个链接的感觉，不美观且有上限 3、ssh终端报错 sockjs: session not in open state -4、CRD不能编辑CR 5、事件中心对象类型选择较少，ns、事件类型不能选择 6、操作完页面应该关闭 补充1：layui、layuimini和beego的详细介绍 1. Layui Layui是一款由国人开发的轻量级前端UI框架，于2016年首次发布。其设计理念是“返璞归真”，通过模块化开发和原生HTML/CSS/JS的开发方式，为开发者提供简洁、易用且功能丰富的界面组件。Layui的核心特点包括： 模块化设计：支持按需加载，例如表单、按钮、表格、导航条等组件，极大提高了开发效率。 简洁轻盈：代码体积小，加载速度快，适合快速响应式网页开发。 易上手：无需复杂配置，直接通过浏览器即可操作元素，适合后端开发者快速构建界面。 丰富的组件库：提供从基础到复杂的样式组件，满足不同需求，同时支持自定义主题和扩展。 Layui广泛应用于各种类型的项目中，从小型网站到大型应用都能轻松应对。虽然官网在2021年10月已关闭，但其社区仍在持续维护和更新。 2. Layuimini Layuimini是基于Layui框架开发的后台管理模板，专为高效、简洁的后台管理界面设计。其主要特点如下： 极简风格：以清爽、简洁、易用为设计理念，专注于提升用户体验。 响应式设计：支持PC端和移动端，确保在各种设备上都能良好展示。 丰富的组件库：继承了Layui的组件优势，同时优化了界面布局和响应式适配，提升了移动端的用户体验。 轻量级框架：仅需引入少量核心文件即可使用，无需复杂配置。 安全性：不涉及动态功能，如数据存储或用户隐私传输，仅提供UI组件或素材。 Layuimini适用于企业内部系统、CMS后台网站以及数据分析平台等场景，特别适合需要快速开发后台管理系统的项目。 3. Beego Beego是一个用Go语言编写的Web框架，旨在提供高效、易用的开发体验。其主要特点包括： 快速开发：Beego通过模块化设计和内置路由功能，简化了Web应用的开发流程。 性能优化：支持多语言支持、性能调试工具（如pprof）以及静态文件服务。 丰富的功能：支持表单处理、用户认证、数据库操作（如ORM）、路由分发等功能。 扩展性：Beego允许用户根据需求进行定制化开发，例如通过扩展插件或自定义控制器来增强功能。 Beego还支持多种部署方式，包括一键部署到云平台（如阿里云函数计算）。它适合快速构建高性能的企业级Web应用，并且由于其简洁的设计和强大的功能，受到了许多开发者的青睐。 总结 Layui 是一款轻量级前端UI框架，适合快速开发响应式网页，特别适合后端开发者使用。 Layuimini 是基于Layui的后台管理模板，专注于提供简洁高效的后台管理界面。 Beego 是一个高效、易用的Go语言Web框架，适用于快速构建高性能的企业级Web应用。 这三者各有特色，可以根据具体需求选择合适的工具进行开发。 Layui的模块化设计具体实现方式如下： 模块化开发思想：Layui采用模块化开发思想，每个组件和工具都是独立的模块，核心文件为Lay.js ，所有功能都包含在Lay.js 中。这种设计使得开发者可以根据需要引入特定的模块，避免不必要的资源加载，从而提高页面加载速度。 AMD规范管理：Layui使用AMD（Asynchronous Module Definition）规范来管理模块。AMD规范允许开发者将模块定义为独立的文件，并通过define函数注册模块。这种方式使得模块之间的依赖关系清晰，便于管理和维护。 按需加载：Layui支持按需加载模块，即只有在需要时才加载特定的模块。这种方式可以进一步减少初始加载时间，提高页面性能。 模块规范：Layui提供了一套模块规范，帮助开发者建立自己的模块作为入口，简化模块化使用。例如，可以通过创建入口文件并使用layui.use ()方法加载所需模块。 内置模块：Layui提供了丰富的内置模块，如表格、按钮、弹出层、表单元素和图标等，这些模块都是基于HTML、CSS和JavaScript实现的，高度可定制。此外，Layui还提供了扩展组件，如图片懒加载、文件上传等，进一步增强了框架的功能。 轻量级设计：Layui采用类AMD管理方式，轻量且简单，避免了CommonJS的复杂性。这种设计使得Layui在保持高效的同时，也易于上手和使用。 响应式布局：Layui内置响应式布局，能够自动适应不同屏幕尺寸，确保在桌面和移动端都能提供良好的用户体验。 原生开发模式：Layui遵循原生HTML/CSS/JS的书写与组织方式，门槛低，易于使用。这种设计使得开发者无需复杂配置，直接在浏览器中实现所需元素与交互。 Layuimini在移动端用户体验优化中采用了哪些技术手段？ Layuimini在移动端用户体验优化中采用了以下技术手段： 响应式布局：Layuimini支持响应式布局，能够自动适应屏幕尺寸变化，确保在不同设备上都能提供良好的用户体验。 轻量级设计：Layuimini的设计更加轻量，专注于小屏幕设备的使用体验，界面简洁，加载速度快。 模块化设计：Layuimini采用模块化设计，提供独立的组件和页面，便于代码复用和定制开发。 丰富的组件库：Layuimini拥有丰富的组件库，包括弹出层、滑动菜单、列表、表单等，满足移动端常见需求。 触屏设备交互优化：针对触屏设备的交互特性，Layuimini增加了点击事件的优化，扩大了点击区域，使按钮和链接更容易被手指触碰。同时，引入了touch事件监听机制，支持长按、滑动等多种手势识别功能。 自动聚焦技术：在输入框等需要频繁输入信息的地方，Layuimini采用了自动聚焦技术，提高用户操作的便捷性。 多主题颜色切换和个性化图标选择：Layuimini支持高度定制化的多主题颜色切换和个性化图标选择，进一步提升用户的个性化体验。 持续更新与维护：Layuimini团队承诺定期进行功能更新和性能优化，确保项目的长期稳定性和用户体验的持续提升。 Beego框架中pprof工具如何帮助开发者进行性能调试？ 根据提供的信息，无法回答问题。我搜索到的资料中没有详细说明Beego框架中pprof工具如何帮助开发者进行性能调试的具体步骤和方法。虽然有几篇文献提到Beego框架集成了pprof工具，但没有提供具体的使用示例或详细的操作步骤。 例如， 提到Beego框架集成了pprof工具，但没有详细说明如何使用。 介绍了pprof工具的基本功能和Beego框架的改造，但也没有提供具体的使用方法。其他资料也主要集中在pprof工具的介绍和一般使用方法上，没有针对Beego框架的具体操作步骤。 因此，根据现有的证据，无法回答Beego框架中pprof工具如何帮助开发者进行性能调试的问题。 Layui社区目前的维护和更新情况如何？ Layui社区目前的维护和更新情况如下： 官网下线与迁移：Layui的官网于2021年10月13日宣布下线，所有框架维护工作迁移到了GitHub和Gitee上。尽管官网下线，但Layui项目并未停止更新，仍在GitHub和Gitee上持续进行。 文档站的回归：Layui在2023年4月27日发布了2.8.0版本，并推出了全新的文档站。这个新文档站基于laytpl和markdown驱动，进行了大量优化，内容精简，旨在为用户提供更好的使用体验。新版文档站不仅解决了原官网下线后第三方文档镜像站点内容滞后的问题，还提供了更优质的内容和使用体验。 社区支持：尽管Layui的更新频率有所减缓，但其核心功能依然稳定，社区依然活跃。开发者可以在GitHub或其他技术论坛中找到解决方案或寻求帮助。Layui社区通过线上和线下活动，如技术沙龙和黑客松，促进了技术交流，增强了社区的凝聚力。 开源项目：Layui作为一个开源项目，得到了许多开发者的支持和贡献。Layui文档也已与项目一同开源，支持在线和离线阅读及协同维护。 Beego框架支持的扩展插件或自定义控制器有哪些示例？ Beego框架支持的扩展插件或自定义控制器有以下示例： 静态文件支持：Beego框架内置了静态文件服务，可以轻松地提供静态资源，如CSS、JavaScript和图片等。 SessionManager：Beego框架支持session管理，可以用于用户认证和会话跟踪。 表单和验证：Beego框架提供了强大的表单处理和验证功能，可以确保用户输入的数据符合预期格式。 多语言支持：Beego框架支持多语言，可以根据用户选择的语言显示相应的界面内容。 用户认证：Beego框架集成了用户认证功能，可以实现用户登录、登出和权限管理。 自定义控制器：Beego框架允许用户通过重写控制器类来实现自定义逻辑。例如，可以通过继承beego.Controller并实现ControllerInterface接口来创建自定义控制器。此外，还可以通过嵌入方式让自定义的控制器继承beego.Controller，利用其内置的方法如Init、Prepare、Finish和Render等。 自定义路由：Beego框架支持自定义路由，可以通过创建Route对象并将其添加到路由数组中来实现。例如，可以在router.go 中添加新的路由和对应的控制器。 热更新：Beego框架支持热更新功能，开发过程中可以实时查看修改后的代码效果。 中间件和插件：Beego框架提供了丰富的内置中间件和插件，如日志、缓存、会话、鉴权、限流等。此外，还支持自定义中间件和插件，以扩展框架的功能。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":"hezuijiudexiaobai"},{"title":"K8s运维管理平台 - Kuboard体验：真心好用，强力安利一波","slug":"kubernetes/K8s运维管理平台 - Kuboard体验：真心好用，强力安利一波","date":"2025-05-31T08:22:26.000Z","updated":"2025-05-31T09:40:31.704Z","comments":true,"path":"2025/05/31/kubernetes/K8s运维管理平台 - Kuboard体验：真心好用，强力安利一波/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/K8s%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%20-%20Kuboard%E4%BD%93%E9%AA%8C%EF%BC%9A%E7%9C%9F%E5%BF%83%E5%A5%BD%E7%94%A8%EF%BC%8C%E5%BC%BA%E5%8A%9B%E5%AE%89%E5%88%A9%E4%B8%80%E6%B3%A2/","excerpt":"","text":"简介 Kuboard 是一款免费的 Kubernetes 管理工具，提供了丰富的功能，结合已有或新建的代码仓库、镜像仓库、CI/CD工具等，可以便捷的搭建一个生产可用的 Kubernetes 容器云平台，轻松管理和运行云原生应用。您也可以直接将 Kuboard 安装到现有的 Kubernetes 集群，通过 Kuboard 提供的 Kubernetes RBAC 管理界面，将 Kubernetes 提供的能力开放给您的开发/测试团队。 Kuboard for K8S 安装 1、hostPort: 280 2、image: ‘swr.cn-east-2.myhuaweicloud.com/kuboard/kuboard:v3’ 3、注意会重启kubelet 安装 Kubernetes 多集群管理工具 - Kuboard v3 扩展：QuestDB questdb-versus-influxdb 使用体验 优点 1、UI、交互式做的非常好 2、界面Logo 支持设置，常见问题文档 3、套件：存储卷浏览器 很好用 4、集群管理-&gt; 概要 5、集群管理-&gt; 节点 6、存储功能 7、Ceph CSI 8、自定义资源，CR编辑功能强大 9、IngressClass 10、名称空间 11、工作负载 12、容器组 13、HPA 14、网络策略 15、事件 17、访问控制 18、操作审计","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":"hezuijiudexiaobai"},{"title":"几种K8s运维管理平台对比说明","slug":"kubernetes/几种K8s运维管理平台对比说明","date":"2025-05-31T08:13:42.000Z","updated":"2025-05-31T09:41:15.707Z","comments":true,"path":"2025/05/31/kubernetes/几种K8s运维管理平台对比说明/","link":"","permalink":"http://www.formeasy.cc/2025/05/31/kubernetes/%E5%87%A0%E7%A7%8DK8s%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E5%AF%B9%E6%AF%94%E8%AF%B4%E6%98%8E/","excerpt":"","text":"深入体验 Kuboard xkube KubeSphere Dashboard 结论 如果您需要一个功能全面且适合企业级应用的平台，KubeSphere是最佳选择，其强大的多租户管理和DevOps支持使其在2025年依然占据主导地位。 如果您的需求较为简单，需快速上手的集群管理工具，可以选择Kuboard。 Dashboard适合对Kubernetes有深入了解的用户，用于基础的集群管理任务。 对比分析表格 以下是关于2025年Kuboard、xkube、KubeSphere和Dashboard在最新功能、用户界面、多租户支持和DevOps支持方面的详细对比分析表格： 1. 功能对比 功能方面 Kuboard xkube KubeSphere Dashboard 核心功能 基于Kubernetes的微服务管理界面，无需编写YAML文件，支持微服务架构设计。 功能较全面 提供全面的企业级功能，包括多云管理、DevOps工具链集成、可观测性、存储管理等。 Kubernetes官方基础Web界面，用于查看和管理集群资源。 监控与日志 支持上下文相关的监控和日志。 - 强大的监控和日志系统，支持自定义指标和告警规则。 提供基本的集群监控功能。 DevOps支持 支持微服务部署和编排 支持对接阿里云流水线 完整的DevOps工具链支持，包括CI/CD流水线、Jenkins集成、GitLab CI等。 无DevOps支持。 多租户管理 支持多租户，用户、用户组、角色。 支持 提供二层租户管理框架，支持灵活的权限策略。 支持多租户，但功能较为基础。 2. 用户界面 工具名称 用户界面特点 优势 劣势 Kuboard 图形化界面，直观展示微服务架构和工作负载，支持向导式操作和丰富的交互功能，且有关概念介绍链接，适合快速上手。 界面友好，适合中小型团队。 功能深度有限 xkube 简洁 导出功能 菜单栏是跳转不好 KubeSphere 提供基于Web的图形化操作界面，支持向导式操作和丰富的交互功能。 界面友好，功能丰富，适合复杂场景。 部署复杂度较高。 Dashboard 简洁的功能界面，适合基础操作。 界面简洁，易于上手。 功能深度有限 3. 多租户支持 工具名称 多租户支持特点 优势 劣势 Kuboard 支持多租户，但功能较为基础。 简单易用，适合小型团队。 功能深度不足，无法满足复杂场景需求。 xkube 支持 - - KubeSphere 提供二层租户管理框架，支持灵活的权限策略。 支持复杂的权限管理和资源隔离。 部署复杂度较高。 Dashboard 支持多租户，但功能较为基础。 简单易用，适合基础需求。 功能深度不足，无法满足复杂场景需求。 4. DevOps支持 工具名称 DevOps支持特点 优势 劣势 Kuboard 支持微服务部署和编排，但功能有限。 简单易用，适合快速上手。 功能深度不足，无法满足复杂场景需求。 xkube 支持 - - KubeSphere 完整的DevOps工具链支持，包括CI/CD流水线、Jenkins集成、GitLab CI等。 功能全面，适合复杂场景。 部署复杂度较高。 Dashboard 无DevOps支持。 - - 细对比分析 关于Kuboard、xkube、KubeSphere和Dashboard在2025年的最新功能、用户界面、多租户支持和DevOps支持的详细对比分析： 1. Kuboard 最新功能：Kuboard是一款基于Kubernetes的微服务管理工具，强调简化Kubernetes集群的管理和操作。其核心功能包括集群管理、日志查询与收集、告警通知、审计、应用程序管理和镜像管理等。 用户界面：Kuboard提供了一个直观的Web界面，支持用户通过图形化界面进行集群管理，降低了学习成本。 多租户支持：暂无明确证据表明Kuboard支持多租户功能，但其设计目标是简化Kubernetes操作，可能更适合小型团队或单租户环境。 DevOps支持：Kuboard未明确提及对DevOps的支持，但其强调了对日志、监控和告警的集成，这可能间接支持部分DevOps流程。 2. xkube 最新功能：较完善。 用户界面：简洁。 多租户支持：支持。 DevOps支持：支持对接阿里云流水线。 3. KubeSphere 最新功能： KubeSphere 新增了基于GitOps的持续部署方案，支持Argo CD作为CD后端，实现持续部署状态的实时统计。 支持GPU资源调度和管理，优化了GPU使用监控。 增强了存储管理功能，包括PVC自动扩展策略和租户级别的存储权限管理。 支持边缘计算和多云管理，提供更灵活的网络和存储解决方案。 支持微服务治理、可观测性、应用生命周期管理等功能。 用户界面：KubeSphere提供开发者友好的向导式操作界面，界面简洁且易于上手。 多租户支持：KubeSphere支持多租户隔离，允许不同团队和项目独立管理资源，并提供细粒度的权限控制。 DevOps支持： 提供完整的DevOps工具链，包括CI/CD、持续集成、持续交付、微服务治理等。 支持Jenkins插件和流水线模板，优化了CI/CD流程。 集成了Istio等技术，支持灰度发布、熔断等高级功能。 4. Dashboard 最新功能：Dashboard是Kubernetes官方提供的Web UI工具，用于管理Kubernetes集群。其主要功能包括资源监控、日志查看、服务管理等。 用户界面：Dashboard提供了一个基于浏览器的图形化界面，但其界面较为基础，适合快速查看集群状态。 多租户支持：Dashboard本身不支持多租户功能，需要结合其他工具（如RBAC）实现多租户管理。 DevOps支持：Dashboard不直接支持DevOps功能，但可以通过集成第三方工具（如Jenkins）实现部分CI/CD流程。 对比总结 功能丰富度： KubeSphere提供了最全面的功能集，包括多云管理、GPU调度、存储管理、微服务治理等。 Kuboard功能较为基础，适合小型团队或单租户环境。 Dashboard功能较为有限，仅适用于基础的集群管理。 用户界面友好性： KubeSphere提供向导式操作界面，新手友好。 Kuboard界面简洁直观，适合快速上手。 Dashboard界面较为基础，适合熟悉Kubernetes的用户。 多租户支持： KubeSphere支持多租户隔离和细粒度权限控制，适合企业级应用。 Kuboard暂无明确的多租户支持信息。 Dashboard需要结合其他工具实现多租户管理。 DevOps支持： KubeSphere提供完整的DevOps工具链，包括CI/CD、持续交付、微服务治理等。 Kuboard未明确提及DevOps支持。 Dashboard不直接支持DevOps功能。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":"hezuijiudexiaobai"},{"title":"Pinia（基本用法）_pinia的使用","slug":"VUE/Pinia（基本用法）_pinia的使用","date":"2025-05-28T09:20:54.000Z","updated":"2025-05-29T00:41:57.642Z","comments":true,"path":"2025/05/28/VUE/Pinia（基本用法）_pinia的使用/","link":"","permalink":"http://www.formeasy.cc/2025/05/28/VUE/Pinia%EF%BC%88%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%EF%BC%89_pinia%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"🍍🍍🍍 介绍（摘自官方文档） Pinia 是 Vue 的存储库，它允许您跨组件/页面共享状态。 如果您熟悉 Composition API，您可能会认为您已经可以通过一个简单的 export const state = reactive({}). 这对于单页应用程序来说是正确的，但如果它是服务器端呈现的，会使您的应用程序暴露于安全漏洞。 但即使在小型单页应用程序中，您也可以从使用 Pinia 中获得很多好处： dev-tools 支持 跟踪动作、突变的时间线 Store 出现在使用它们的组件中 time travel 和 更容易的调试 热模块更换 在不重新加载页面的情况下修改您的 Store 在开发时保持任何现有状态 插件：使用插件扩展 Pinia 功能 为 JS 用户提供适当的 TypeScript 支持或 autocompletion 服务器端渲染支持 与 Vuex 的比较（摘自官方文档） Pinia 最初是为了探索 Vuex 的下一次迭代会是什么样子，结合了 Vuex 5 核心团队讨论中的许多想法。最终，我们意识到 Pinia 已经实现了我们在 Vuex 5 中想要的大部分内容，并决定实现它 取而代之的是新的建议。 与 Vuex 相比，Pinia 提供了一个更简单的 API，具有更少的规范，提供了 Composition-API 风格的 API，最重要的是，在与 TypeScript 一起使用时具有可靠的类型推断支持。 开始 安装 123yarn add pinia# 或者使用 npmnpm install pinia 创建一个 pinia（根存储）并将其传递给应用程序 12import &#123; createPinia &#125; from &#x27;pinia&#x27;app.use(createPinia()) 什么时候应该使用 Store 存储应该包含可以在整个应用程序中访问的数据。这包括在许多地方使用的数据，例如导航栏中显示的用户信息，以及需要通过页面保留的数据，例如一个非常复杂的多步骤表格。 另一方面，您应该避免在存储中包含可以托管在组件中的本地数据，例如页面本地元素的可见性。 并非所有应用程序都需要访问全局状态，但如果您需要一个，Pania 将使您的生活更轻松。 定义一个 Store 在项目的src目录创建一个名为store的文件夹，内部创建ts文件名为index.ts 12345678// index.tsimport &#123; defineStore &#125; from &#x27;pinia&#x27; // usePinia 可以是 useUser、useCart 之类的任何东西（一般情况为use开头）// 第一个参数是应用程序中 piniaDemo 的唯一 idexport const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; // other options...&#125;) 组件内使用store 123456&lt;script setup lang=&quot;ts&quot;&gt; import &#123; usePinia &#125; from &#x27;@/store/index&#x27;;const store = usePinia(); &lt;/script&gt; 如需解构store内属性 需要引入storeToRefs包裹store再进行解构属性，为响应式 123456//错误const &#123; name &#125; = store; //name属性失去响应式 //正确import &#123; storeToRefs &#125; from &#x27;pinia&#x27;;const &#123; name &#125; = storeToRefs(store); //name为响应式属性 State 定义state初始属性 1234567891011121314// index.tsimport &#123; defineStore &#125; from &#x27;pinia&#x27; export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; // 推荐使用 完整类型推断的箭头函数 state: () =&gt; &#123; return &#123; // 所有这些属性都将自动推断其类型 counter: 0, name: &#x27;天天&#x27;, isAdmin: true, &#125; &#125;,&#125;) 访问State属性&amp;修改属性值 1234567891011121314&lt;script setup lang=&quot;ts&quot;&gt;import &#123; usePinia &#125; from &#x27;@/store/index&#x27;; const store = usePinia(); const changeName = () =&gt; &#123; store.name = &#x27;真白&#x27;;&#125;;&lt;/script&gt; &lt;template&gt; &lt;div&gt;&#123;&#123; store.name &#125;&#125;&lt;/div&gt; &lt;button @click=&quot;changeName&quot;&gt;修改name&lt;/button&gt;&lt;/template&gt; 重置State状态 您可以通过调用 store 上的 $reset() 方法将状态 重置 到其初始值： 12const store = useStore()store.$reset() 改变状态 除了直接用 store.counter++ 修改 store，你还可以调用 $patch 方法。 它允许您使用部分“state”对象同时应用多个更改： 1234567const changeStore = () =&gt; &#123; store.$patch(&#123; counter: store.counter + 1, name: &#x27;天天&#x27;, isAdmin: !store.isAdmin, &#125;);&#125;; $patch方法除了接收对象以外，还可以接收一个函数作为参数 123456const changeStore = () =&gt; &#123; store.$patch((state) =&gt; &#123; //参数state为State返回的响应式对象 st.name = &#x27;天天&#x27;; &#125;);&#125;; 替换state 可以通过将其 $state 属性设置为新对象来替换 Store 的整个状态： 1234567const changeStore = () =&gt; &#123; store.$state = &#123; counter: 100, name: &#x27;xxx&#x27;, isAdmin: false, &#125;;&#125;; 订阅状态 每当state被修改后，$subscribe()方法就会被调用 123456store.$subscribe((mutation, state) =&gt; &#123; console.log(&#x27;🚀 ~ file: App.vue:15 ~ store.$subscribe ~ state&#x27;, state); console.log(&#x27;🚀 ~ file: App.vue:15 ~ store.$subscribe ~ mutation&#x27;, mutation); // 每当它发生变化时，将整个状态持久化到本地存储 localStorage.setItem(&#x27;pinia&#x27;, JSON.stringify(state));&#125;); Getters Getter 完全等同于 Store 状态的计算值。 它们可以用 defineStore() 中的 getters 属性定义。 他们接收“状态”作为第一个参数 定义getters 123456789101112131415161718192021export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; // 推荐使用 完整类型推断的箭头函数 state: () =&gt; &#123; return &#123; // 所有这些属性都将自动推断其类型 counter: 999, name: &#x27;真白&#x27;, isAdmin: true, &#125; &#125;, getters: &#123; //接收 &quot;状态&quot; state 可以自动判断返回值类型 getName(state) &#123; return state.name &#125;, // 如果使用this访问，则需要手写返回值类型 doubleCount(): number &#123; return this.counter * 2 &#125;, &#125;&#125;) 访问getters 可以通过store实例 直接访问getters 123&lt;template&gt; &lt;div&gt;&#123;&#123; store.getName &#125;&#125;---&#123;&#123; store.doubleCount &#125;&#125;&lt;/div&gt;&lt;/template&gt; 访问其他getters 与计算属性一样，可以组合多个 getter。 通过 this 访问任何其他 getter。 即使您不使用 TypeScript，您也可以使用 JSDoc 提示您的 IDE 类型 getters接收参数 这里需要用到函数柯里化的内容，通过返回函数的形式来接收任何参数 12345getters: &#123; doubleCount(state) &#123; return (num: number) =&gt; state.counter + num &#125;&#125; 组件中使用 1&lt;div&gt;&#123;&#123; store.doubleCount(99) &#125;&#125;&lt;/div&gt; 注意：请注意，在执行此操作时，getter 不再缓存，它们只是您调用的函数。 但是，您可以在 getter 本身内部缓存一些结果。 访问其他 Store 的getter 1234567891011import &#123; useOtherStore &#125; from &#x27;./otherStore&#x27; export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; getters: &#123; doubleCount(state) &#123; //通过实例 调用其他store上面的getters const otherStore = useOtherStore() return `$&#123;otherStore.changeName&#125;---$&#123;state.name&#125;` &#125; &#125;&#125;) Actions 定义actions Actions 相当于组件中的 methods。 它们可以使用 defineStore() 中的 actions 属性定义，并且它们非常适合定义业务逻辑： 12345678910111213141516// index.tsimport &#123; defineStore &#125; from &#x27;pinia&#x27; export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; state: () =&gt; &#123; return &#123; counter: 999, &#125; &#125;, actions: &#123; increment() &#123; //通过this访问state中的属性 this.counter++ &#125;, &#125;&#125;) actions 可以是异步的，您可以在其中await 任何 API 调用甚至其他操作 模拟一下async await的使用，简单定义个返回promise的函数 123456789101112131415161718192021222324252627282930// index.tsimport &#123; defineStore &#125; from &#x27;pinia&#x27; //定义一个demo返回一个Promise对象，模拟一下异步任务const proDemo = () =&gt; &#123; return new Promise&lt;string&gt;((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&quot;到时间了&quot;) &#125;, 2000); &#125;)&#125; export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; state: () =&gt; &#123; return &#123; counter: 999, &#125; &#125;, actions: &#123; //使用async await 语法糖，处理一下Promise async increment() &#123; try &#123; let data = await proDemo() console.log(&quot;🚀 ~ file: index.ts:22 ~ increment ~ data&quot;, data) &#125; catch (error) &#123; console.log(&quot;报错了&quot;, error); &#125; &#125;, &#125;&#125;) 在组件中调用 12345&lt;script setup lang=&quot;ts&quot;&gt;import &#123; usePinia &#125; from &#x27;@/store/index&#x27;;const store = usePinia();store.increment();&lt;/script&gt; 访问其他 store 操作 要使用另一个 store ，可以直接在操作内部使用它 1234567891011import &#123; useOtherStore &#125; from &#x27;./otherStore&#x27; export const usePinia = defineStore(&quot;piniaDemo&quot;, &#123; actions: &#123; increment() &#123; const otherStore = useOtherStore() let name = otherStore.getName() console.log(&quot;🚀 ~ file: index.ts:22 ~ increment ~ name&quot;, name) &#125;, &#125;&#125;) 订阅 Actions 可以使用 store.$onAction() 订阅 action 及其结果。 传递给它的回调在 action 之前执行。 after 处理 Promise 并允许您在 action 完成后执行函数。 以类似的方式，onError 允许您在处理中抛出错误。 这些对于在运行时跟踪错误很有用，类似于 Vue 文档中的这个提示。 这是一个在运行 action 之前和它们 resolve/reject 之后记录的示例。 1234567891011121314151617181920212223242526272829303132333435const unsubscribe = someStore.$onAction( (&#123; name, // action 的名字 store, // store 实例 args, // 调用这个 action 的参数 after, // 在这个 action 执行完毕之后，执行这个函数 onError, // 在这个 action 抛出异常的时候，执行这个函数 &#125;) =&gt; &#123; // 记录开始的时间变量 const startTime = Date.now() // 这将在 `store` 上的操作执行之前触发 console.log(`Start &quot;$&#123;name&#125;&quot; with params [$&#123;args.join(&#x27;, &#x27;)&#125;].`) // 如果 action 成功并且完全运行后，after 将触发。 // 它将等待任何返回的 promise after((result) =&gt; &#123; console.log( `Finished &quot;$&#123;name&#125;&quot; after $&#123; Date.now() - startTime &#125;ms.\\nResult: $&#123;result&#125;.` ) &#125;) // 如果 action 抛出或返回 Promise.reject ，onError 将触发 onError((error) =&gt; &#123; console.warn( `Failed &quot;$&#123;name&#125;&quot; after $&#123;Date.now() - startTime&#125;ms.\\nError: $&#123;error&#125;.` ) &#125;) &#125;) // 手动移除订阅unsubscribe() 默认情况下，action subscriptions 绑定到添加它们的组件（如果 store 位于组件的 setup() 内）。 意思是，当组件被卸载时，它们将被自动删除。 如果要在卸载组件后保留它们，请将 true 作为第二个参数传递给当前组件的 detach action subscription： 12345678910export default &#123; setup() &#123; const someStore = useSomeStore() // 此订阅将在组件卸载后保留 someStore.$onAction(callback, true) // ... &#125;,&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VUE","slug":"VUE","permalink":"http://www.formeasy.cc/tags/VUE/"}],"author":null},{"title":"靠这九款国产AI大模型，就实现了6亿人的AI梦","slug":"LLM/靠这九款国产AI大模型，就实现了6亿人的AI梦","date":"2025-05-28T05:30:14.000Z","updated":"2025-05-28T05:39:36.263Z","comments":true,"path":"2025/05/28/LLM/靠这九款国产AI大模型，就实现了6亿人的AI梦/","link":"","permalink":"http://www.formeasy.cc/2025/05/28/LLM/%E9%9D%A0%E8%BF%99%E4%B9%9D%E6%AC%BE%E5%9B%BD%E4%BA%A7AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B0%B1%E5%AE%9E%E7%8E%B0%E4%BA%866%E4%BA%BF%E4%BA%BA%E7%9A%84AI%E6%A2%A6/","excerpt":"","text":"2024年 10 月 13 日，工业和信息化部总工程师，赵立国发表讲话：“我国人工智能核心产业的规模在不断提升，企业数量超过了 4500 家，完成注册并提供服务的生成式人工智能服务大模型数量已经超过200个，注册用户数超过了 6 亿。” 这些大模型在各个领域中发挥着重要作用，推动了技术创新和产业变革。 可以看出 2024 年，中国的人工智能技术发展速度真可谓是日新月异，国产AI大模型如雨后春笋般涌现，从 1 月份的 80 多个到 10 月份已经突破超过 200 个，不到十个月时间就激增了 100 多个大模型。 这些大模型中主要以通用大模型 Kimi、智谱清言、通义千问、文心一言、豆包、天工AI、讯飞星火、秘塔和腾讯元宝这九大模型格外引人注目。 在科技大国走向科技强国的号召下，AI 大模型的重要性尤其凸显，这九款国产大模型发展相当出色，它们铸就了中国人我们中国人的 AI 梦。 下面，让我们一起探索这些大模型的特点和面临的挑战，普及和了解它们在AI领域的地位和潜力。 一、原理概述 AI大模型都建立在深度学习技术之上，主要利用神经网络架构。它们通过分析海量数据来学习语言模式、知识表示和任务执行策略。 每个模型的独特之处体现在其网络结构、训练数据的选择和优化方法上，这些因素决定了它们在不同任务中的表现。 二、九大智能模型详解 1. Kimi模型 地址：https://kimi.moonshot.cn/ Kimi在自然语言处理领域表现出色，擅长情感分析和文本分类任务。 它准确捕捉文本中的细微情感和主题，这得益于其模型中的特殊注意力机制。 Kimi在处理长文本时性能可能会下降，它更适合处理简短、精炼的信息。 2. 智谱清言 地址：https://chatglm.cn/main/alltoolsdetail?lang=zh 智谱清言以强大的语言生成能力著称。 智谱清言采用多层次编码器-解码器框架，better理解和生成复杂的语言结构。 它生成流畅、自然的文本，在对话系统和内容创作方面表现优异。 在处理需要深入专业知识的问题时，智谱清言可能会遇到挑战。 3. 通义千问 地址：https://tongyi.aliyun.com/qianwen/ 通义千问专注于问答系统，通过预训练和微调，在广泛的主题上提供准确答案。 它强大的知识检索能力使其能快速从海量数据中找到相关信息。 涉及复杂推理或解释抽象概念时，通义千问的表现可能不尽如人意。 4. 文心一言 地址：https://yiyan.baidu.com/?utm\\_source=ai-bot.cn 文心一言是多功能AI模型，在文本生成、摘要和翻译等多个任务上表现出色。 它的优势在于模型的多任务学习能力，同时处理多种语言任务。 处理特定领域的专业问题时，文心一言可能需要更多的领域特定数据来提高准确性。 5. 豆包 地址：https://www.doubao.com/chat/ 豆包面向特定领域，通过大量领域数据预训练，为该领域提供专业服务和支持。 它在专精领域内表现卓越，提供深入、准确的知识。 这种专注也使它在处理跨领域问题时可能遇到困难。 6. 腾讯元宝 地址：https://yuanbao.tencent.com/chat/naQivTmsDa 腾讯元宝在游戏AI领域独具特色，设计出吸引人的游戏玩法，在虚拟世界和增强现实方面有独到之处。 它在游戏开发和互动娱乐方面优势明显，但在严肃的商业应用上还需要进一步优化和调整。 7. 讯飞星火 地址：https://xinghuo.xfyun.cn/desk 讯飞星火在语音识别和语音合成领域表现突出，提供准确且自然的语音交互体验。 它在语音处理方面的优势使其成为语音助手和语音交互系统的理想选择。 在纯文本处理和理解复杂文字语境方面，讯飞星火还有提升空间。 8. 秘塔 地址：https://metaso.cn/ 秘塔在保护用户隐私方面表现出色，完成任务的同时确保用户信息安全。 它擅长处理敏感数据，保证数据安全的同时保持高效率。 这种高度安全性有时可能影响模型在某些简单任务上的表现效率。 9. 天工AI 地址：https://www.tiangong.cn/ 天工AI基于强化学习，具有自我学习和优化能力。 它通过不断自我改进在特定任务上达到出色表现。 天工AI潜力巨大，但训练过程需要大量计算资源和时间，这可能限制其在某些应用场景中的实用性。 三、总结与展望 这九大AI模型各有所长： Kimi、智谱清言、通义千问和文心一言在通用AI能力方面表现突出，应对广泛的语言处理任务。 豆包、秘塔和腾讯元宝在各自的专业领域（如特定行业知识、隐私保护、游戏AI）有独特优势。 天工AI和讯飞星火在自我优化和语音处理等领域展现出巨大潜力。 这些模型反映了我国AI技术的快速进步，也展示了不同研究方向和应用领域的多样性。未来，这些模型会不断优化，弥补各自的不足，为用户提供更智能、更全面的服务。 这些AI模型之间的协作将成为重要趋势。通过优势互补，它们有望在更广泛的领域发挥作用，推动AI技术在各行各业的深入应用。 国产AI大模型的发展正处于激动人心的阶段。它们展示了我国在AI领域的创新能力，也为未来智能技术的发展描绘了充满可能性的蓝图。 随着这些模型的不断进化和新技术的涌现，AI将为我们的生活和工作方式带来更多令人惊叹的变革。 如何学习大模型 AI ？ 由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。 但是具体到个人，只能说是： “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。 这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"}],"author":null},{"title":"UE设置分辨率以及全屏模式","slug":"UE/UE设置分辨率以及全屏模式","date":"2025-05-22T07:03:22.000Z","updated":"2025-06-19T09:21:01.016Z","comments":true,"path":"2025/05/22/UE/UE设置分辨率以及全屏模式/","link":"","permalink":"http://www.formeasy.cc/2025/05/22/UE/UE%E8%AE%BE%E7%BD%AE%E5%88%86%E8%BE%A8%E7%8E%87%E4%BB%A5%E5%8F%8A%E5%85%A8%E5%B1%8F%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"方法一、通过蓝图设置 方法二、通过打包项目的配置文件进行修改 注：图中的FullscreenMode 其中：0=窗口化，1=无边框窗口，2=独占全屏 方法三、通过控制台命令修改 12r.SetRes 1920x720w ：&quot;x&quot;是英文字母x，w:窗口r.SetRes 1920x720f ：&quot;x&quot;是英文字母x， f:全屏 方法四、通过打包后执行命令 1YourGame.exe -ResX=1920 -ResY=720 -fullscreen 关于屏幕左右或上下有多余黑边问题 主要问题是当前摄像头约束了比例，需要将需要设置的“摄像头选项”去除“约束高宽比”，如果项目是第一人称视角的，再选中“重载高宽比轴约束”，并将高宽比轴约束选为“维持Y轴视野”。 关于Cesium在宽屏显示时，地图加载部分问题 在使用带鱼宽屏时，发现屏幕两侧的地图只能加载部分，用了很多的方法，比如： 加大 Maximum Screen Space Error 的值，如下图： 但问题根本没有解决 最后是通过修改摄像头的可视范围 将上图的约束高宽比选中打开，将输入当前带鱼屏的分辨率比值，最后再将约束高宽比选中取消（注意），即可达到可视范围内的地图加载。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"UE中通过游戏实例(Game Instance) 实现UI与关卡蓝图变量交互的详细步骤","slug":"UE/UE中通过游戏实例(Game Instance) 实现UI与关卡蓝图变量交互的详细步骤","date":"2025-05-19T03:01:42.000Z","updated":"2025-05-19T03:36:30.855Z","comments":true,"path":"2025/05/19/UE/UE中通过游戏实例(Game Instance) 实现UI与关卡蓝图变量交互的详细步骤/","link":"","permalink":"http://www.formeasy.cc/2025/05/19/UE/UE%E4%B8%AD%E9%80%9A%E8%BF%87%E6%B8%B8%E6%88%8F%E5%AE%9E%E4%BE%8B(Game%20Instance)%20%E5%AE%9E%E7%8E%B0UI%E4%B8%8E%E5%85%B3%E5%8D%A1%E8%93%9D%E5%9B%BE%E5%8F%98%E9%87%8F%E4%BA%A4%E4%BA%92%E7%9A%84%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"游戏实例（Game Instance）是UE5中跨关卡持久化的全局对象，适合存储需要在多个UI或关卡间共享的变量（如玩家分数、设置参数等）。通过将变量存储在游戏实例中，UI蓝图和关卡蓝图均可直接访问和修改。 步骤1、在游戏实例中定义变量 1.创建自定义游戏实例类（若未创建） 在内容浏览器中右键 → Blueprint Class → 选择 Game Instance。 命名为BP_MyGameInstance（示例）。 2.添加变量 打开BP_MyGameInstance蓝图。 在我的蓝图(My Blueprint)面板中，点击变量(Variables) → 添加变量。 命名变量（如PlayerScore），设置类型（如Integer），并勾选可编辑实例(Editable Instance)（可选，便于调试）。 步骤2、在关卡蓝图中更新游戏实例变量 1.获取游戏实例引用 在关卡蓝图中，右键添加节点 → Get Game Instance。 将返回的Game Instance引用转换为自定义类BP_MyGameInstance（通过Cast To BP_MyGameInstance节点）。 2.设置变量值 从转换后的引用拖出，选择变量（如PlayerScore）并添加Set节点。 输入要设置的值（例如通过关卡逻辑触发）。 步骤3、在UI蓝图中读取游戏实例变量 1.获取游戏实例引用 在UI蓝图中，右键添加Get Game Instance节点。 将返回的Game Instance引用转换为BP_MyGameInstance。 2.获取变量值 从转换后的引用拖出，选择变量（如PlayerScore）并添加Get节点。 将获取的值连接到UI控件（如文本框）的显示节点。 步骤4、在UI蓝图中修改游戏实例变量 1.通过UI事件触发修改 例如，在按钮点击事件中，获取游戏实例引用并调用Set节点更新变量。 2.实时更新UI 在变量值改变后，重新调用Get节点并更新UI显示。 关键注意事项 1.变量作用域 游戏实例变量是全局的，适合存储跨关卡数据（如玩家状态、设置参数）。 局部变量应存储在关卡蓝图或Actor中。 2.类型一致性 确保UI和关卡蓝图中使用的变量类型一致（如Integer、Float等）。 3.空引用检查 在转换游戏实例引用时，使用Branch节点检查是否转换成功，避免空引用错误。 4.性能优化 避免频繁读取/写入游戏实例变量，必要时可使用事件分发器或绑定机制。 通过以上步骤，你可以高效地利用游戏实例实现UI与关卡蓝图之间的变量共享，确保数据的一致性和可维护性。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"UE5入门教程：蓝图变量_ue5全局变量","slug":"UE/UE5入门教程：蓝图变量_ue5全局变量","date":"2025-05-18T09:01:42.000Z","updated":"2025-05-18T09:03:08.008Z","comments":true,"path":"2025/05/18/UE/UE5入门教程：蓝图变量_ue5全局变量/","link":"","permalink":"http://www.formeasy.cc/2025/05/18/UE/UE5%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%9A%E8%93%9D%E5%9B%BE%E5%8F%98%E9%87%8F_ue5%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/","excerpt":"","text":"一、变量介绍 定义：变量是保存一个值、或引用一个对象或Actor的属性。这些属性可被蓝图内部访问，也可被设置为外部访问（在关卡中的蓝图实例内，以便用户修改其值）。 显示形式：变量以圆形框的形式显示，在蓝图内Variables下拉列表中，会显示所有已存在的变量，包括组件实例变量及自定义变量。 二、变量类型 蓝图变量有多种类型，用于保存不同类型的数据。以下是一些常见的变量类型： 布尔值（Boolean）：只能保存真或假。 整数（Integer）：可以存储整数值。 浮点（Float）：可以存储带小数部分的数值。 字符串（String）：可以存储一组字母数字字符。 向量（Vector）：包含代表3D向量的X、Y和Z浮点值。 旋转体（Rotator）：包含X（滚动）、Y（俯仰）和Z（偏航）浮点值，表示3D空间中的旋转。 转变（Transform）：可以存储位置、旋转和缩放。 三、创建变量 在UE5中，创建变量的方法有多种： 直接创建：在蓝图编辑器的Variables面板中，点击“+”按钮，然后输入变量名称和选择变量类型。 提升为变量：在蓝图编辑器的图表中，选择一个节点（如常量节点或属性节点），然后右键选择“Promote to Variable”，将其提升为变量。 四、访问变量 在蓝图编辑器中，可以通过Get和Set操作来访问和修改变量的值： 获取变量值（Get）：将变量从Variables面板中拖入图表中，会自动生成一个Get节点，用于获取变量的当前值。 设置变量值（Set）：将变量从Variables面板中拖入图表中，并按住Alt键再拖一次，会自动生成一个Set节点，用于设置变量的新值。 五、变量细节设置 在变量的细节面板中，可以设置变量的各种属性和访问权限： 默认值：设置变量的初始值。注意，在设置默认值之前，需要先编译蓝图。 访问权限：可以设置变量为公开（Public）或私有（Private）。公开变量可以在蓝图外部访问和修改，而私有变量只能在蓝图内部访问。 可编辑实例：如果勾选此选项，则可以在关卡编辑器中编辑放置在关卡中的此蓝图的每个副本的变量值。 生成时公开：如果勾选此选项，则可以在生成蓝图时设置变量的值。 六、应用示例 以下是一个简单的应用示例，演示如何在UE5中使用蓝图变量来控制一个物体的移动速度： 在蓝图中创建两个浮点型变量，分别命名为“MoveSpeedX”和“MoveSpeedY”，用于控制物体在X轴和Y轴上的移动速度。 在事件图表中，创建一个“Event Tick”事件，该事件每帧都会执行。 在“Event Tick”事件中，使用“Set Actor Location”节点来设置物体的位置。将物体的当前位置加上“MoveSpeedX”和“MoveSpeedY”的值（乘以时间步长Delta Time），以实现平滑移动。 在关卡编辑器中，将物体放置在场景中，并选中该物体的蓝图实例。在细节面板中，找到“MoveSpeedX”和“MoveSpeedY”变量，并设置它们的值以控制物体的移动速度。 通过以上步骤，就可以使用蓝图变量来控制物体在UE5场景中的移动速度了。这只是蓝图变量应用的一个简单示例，实际上蓝图变量可以在各种复杂的游戏逻辑和交互中发挥重要作用。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"UE4_UE5 如何显示/调整游戏运行帧率","slug":"UE/UE4_UE5 如何显示调整游戏运行帧率_ue5显示帧率","date":"2025-05-18T08:55:30.000Z","updated":"2025-05-18T08:59:46.899Z","comments":true,"path":"2025/05/18/UE/UE4_UE5 如何显示调整游戏运行帧率_ue5显示帧率/","link":"","permalink":"http://www.formeasy.cc/2025/05/18/UE/UE4_UE5%20%E5%A6%82%E4%BD%95%E6%98%BE%E7%A4%BA%E8%B0%83%E6%95%B4%E6%B8%B8%E6%88%8F%E8%BF%90%E8%A1%8C%E5%B8%A7%E7%8E%87_ue5%E6%98%BE%E7%A4%BA%E5%B8%A7%E7%8E%87/","excerpt":"","text":"在创作中，我们往往需要查看游戏运行的帧率，用于判断程序运行的流畅度。那么如何调取帧率呢，接下来我就简单介绍几种方法： 1.在控制台命令中输入stat fps 可以看到，游戏帧率已经显示在屏幕右上角。 2.在控制台命令中输入“t.maxfps 帧数”以修改最大帧率 3.通过Get World Delta Seconds来获取帧率并打印到屏幕上 Delta Seconds其实就是游戏中每帧刷新所用的时间，用1除以Delta Seconds,得到的就是每秒中刷新的帧数。 下图的节点逻辑中，我通过按下数字键3，来向屏幕打印计算所得的FPS。（Appen节点是字符串组合节点，类似C++中对字符串的“+”重载） 可以看到，当我按下数字键3，我的帧数被打印到屏幕上。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"windows+vs2017 C++编译gRPC","slug":"RPC/windows+vs2017 C++编译gRPC","date":"2025-05-08T08:57:52.000Z","updated":"2025-05-08T09:08:28.070Z","comments":true,"path":"2025/05/08/RPC/windows+vs2017 C++编译gRPC/","link":"","permalink":"http://www.formeasy.cc/2025/05/08/RPC/windows+vs2017%20C++%E7%BC%96%E8%AF%91gRPC/","excerpt":"","text":"1、需求 因为项目需要，想要在windows+vs2017环境使用C下编程gRPC并编写demo程序，使得能够根据proto文件生成对应的c文件。 2、资料查阅 起初根据网络资料查阅，使用git从github中下载了gRPC最新的开源代码，并通过CMake编译，之后使用vs2017进行最终的编译生成，但在vs2017编译过程中，提示版本不匹配，需要vs2019及以上版本，本想进行vs的版本升级，但考虑到项目代码版本问题，最终选择低版本的gRPC进行编译与使用，再次查阅资料，最终，根据大佬的这篇文件在Windows搭建gRPC C++开发环境!，完成了vs2017+gRPC1.48版本的编译。 3、编译工具 （1）Git；用于从github中将代码拉下 （2）CMake；编译gRPC （3）Nasm；似乎是编译过程中openssl用到，不太了解，但网上搜索下载了一个 （4）VS2017 Professional； 4、编译步骤（就是把大佬的文章复制了一遍，为了防止大佬的文章链接失效） （1）下载gRPC源码 使用git命令行在预备存放grpc源码的目录下执行, 此处我们下载的是 grpc 1.48.0 1git clone -b v1.48.0 https://github.com/grpc/grpc 进入源码目录 下载依赖库 1git submodule update --init *此处注意，确保所有依赖库下载成功 （可以重复执行 git submodule update --init --recursive 命令，直到没有错误提示）。 （2）使用CMake生成工程文件 在生成工程文件时做，做如下调整： l 添加ABSL_PROPAGATE_CXX_STD选项，类型为bool设置为true； l 将源码目录下third_party\\zlib\\CMakeList.txt的第一行依赖的CMake版本修改为2.8.12； l 添加CMAKE_INSTALL_PREFIX选项，类型为Path，设置为gRPC编译后的安装目录。 如下图所示： 点击【Configure】设置需要的编译环境，如下图所示： 点击【Finish】后配置环境日志中没有报错后，点击【Generate】生成工程文件。 （3）编译、安装gRPC 使用管理员运行Visual Studio 2017，并打开上一步生成的工程grpc.sln。 将环境设置为Release x64生成ALL_BUILD项目。 生成INSTALL项目，此时会将生成的文件安装到第2步中CMAKE_INSTALL_PREFIX配置的路径中。 将安装目录下的bin目录路径添加到环境变量Path中，如下图所示： 至此，gRPC的c++环境已经配置好。 5、创建测试工程 大佬这里创建的C#项目，我的是C++项目，略有不同，此处略。 （1）编译proto文件 在protos文件夹的上级目录Project2中打开命令行终端，并输入两条指令，用于生成对应.proto文件的.grpc.pb.cc/.h以及.pb.cc/.h文件。 protoc -I=“./protos” --grpc_out=“./protos” --plugin=protoc-gen-grpc=“D:\\Project\\GRPCProject\\TestProject\\Project2\\Project2\\Project2\\grpc_cpp_plugin.exe” “./protos\\route_guide.proto” protoc -I=“./protos” --cpp_out=“./protos” “./protos\\route_guide.proto” 注意：其中：grpc_cpp_plugin.exe所在路径替换为您安装的路径。且proto路径根据自已的路径修改，如果不想修改，只需要根据我的路径存放proto文件即可。 （2）生成项目 将生成的 .grpc.pb.cc/.h .pb.cc/.h以及proto文件添加到vs中，vs切换为Release x64版本（对应gRPC编译的版本，不知道Debug版本是否有问题，暂未尝试）。 注意：此处已有xxx_client.cc客户端文件与xxx_server.cc服务端文件，是从grpc源代码的范例中拷贝出来的，并稍做了修改，路径为“xxx\\grpc\\examples\\cpp\\route_guide” 注意：需要查看生成的grpc.pb.h文件中是否包含中文注释，如果包含则需要删除中文注释，否则编译时将会出现 添加包含目录，如下图所示，路径为grpc的include安装路径： 添加附加库目录，如下图所示，路径为grpc的lib安装路径： 添加附加依赖项： absl_bad_optional_access.lib absl_bad_variant_access.lib absl_base.lib absl_city.lib absl_civil_time.lib absl_cord.lib absl_cordz_functions.lib absl_cordz_handle.lib absl_cordz_info.lib absl_cordz_sample_token.lib absl_cord_internal.lib absl_debugging_internal.lib absl_demangle_internal.lib absl_examine_stack.lib absl_exponential_biased.lib absl_failure_signal_handler.lib absl_flags.lib absl_flags_commandlineflag.lib absl_flags_commandlineflag_internal.lib absl_flags_config.lib absl_flags_internal.lib absl_flags_marshalling.lib absl_flags_parse.lib absl_flags_private_handle_accessor.lib absl_flags_program_name.lib absl_flags_reflection.lib absl_flags_usage.lib absl_flags_usage_internal.lib absl_graphcycles_internal.lib absl_hash.lib absl_hashtablez_sampler.lib absl_int128.lib absl_leak_check.lib absl_log_severity.lib absl_low_level_hash.lib absl_malloc_internal.lib absl_periodic_sampler.lib absl_random_distributions.lib absl_random_internal_distribution_test_util.lib absl_random_internal_platform.lib absl_random_internal_pool_urbg.lib absl_random_internal_randen.lib absl_random_internal_randen_hwaes.lib absl_random_internal_randen_hwaes_impl.lib absl_random_internal_randen_slow.lib absl_random_internal_seed_material.lib absl_random_seed_gen_exception.lib absl_random_seed_sequences.lib absl_raw_hash_set.lib absl_raw_logging_internal.lib absl_scoped_set_env.lib absl_spinlock_wait.lib absl_stacktrace.lib absl_status.lib absl_statusor.lib absl_strerror.lib absl_strings.lib absl_strings_internal.lib absl_str_format_internal.lib absl_symbolize.lib absl_synchronization.lib absl_throw_delegate.lib absl_time.lib absl_time_zone.lib address_sorting.lib cares.lib crypto.lib gpr.lib grpc++.lib grpc++_alts.lib grpc++_error_details.lib grpc++_reflection.lib grpc++_unsecure.lib grpc.lib grpcpp_channelz.lib grpc_plugin_support.lib grpc_unsecure.lib libprotobuf-lite.lib libprotobuf.lib libprotoc.lib re2.lib ssl.lib upb.lib zlib.lib （3）运行项目 分别注释xxx_client.cc与xxx_server.cc文件中的main函数，并编辑，即可生成对应的client与server程序，先运行server程序，在运行client程序，进行通讯尝试，成功通讯。 6、感谢大佬分享 最后，再次感谢大佬的分享 在Windows搭建gRPC C++开发环境!","categories":[],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"远程过程调用（RPC）入门","slug":"RPC/远程过程调用（RPC）入门","date":"2025-05-07T03:09:35.000Z","updated":"2025-05-07T03:14:00.842Z","comments":true,"path":"2025/05/07/RPC/远程过程调用（RPC）入门/","link":"","permalink":"http://www.formeasy.cc/2025/05/07/RPC/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8%EF%BC%88RPC%EF%BC%89%E5%85%A5%E9%97%A8/","excerpt":"","text":"本文简要介绍RPC的相关知识。 1 概述 RPC(Remote Procedure Call)，即远程过程调用，是一种通过网络从远程计算机程序上请求服务、而不需要了解底层网络技术的协议。RPC协议假定某些传输协议（如TCP或UDP）的存在，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发应用程序（包括网络分布式多程序在内）更加容易。 例如，有两台服务器A和B，一个应用部署在服务器A上，想要调用服务器B上的应用提供的函数/方法。由于服务器A和服务器B的应用程序不在一个内存空间，不能直接调用，就需要通过网络来传达调用的语义和调用的数据，这就是RPC协议。 2 背景 在单机时代，一台电脑上运行多个进程，为了实现进程之间的通信，就出现了IPC（Inter-process communication，单机中运行的进程之间的相互通信）。 而到了网络时代，大家的电脑都互相连起来了，以前程序只能调用自己电脑上的进程，能不能调用其他机器上的进程呢？为了实现这个目的，把IPC扩展到网络上，就是RPC（远程过程调用）了。 3 原理 本节通过本地过程调用和远程过程调用来介绍RPC的原理。 3.1 本地过程调用 在研究RPC前，我们先看看本地调用是怎么调的。 假设我们要调用函数Multiply来计算“lvalue * rvalue”的结果，代码如下： 12345678int Multiply(int l, int r) &#123; int y = l * r; return y;&#125; int lvalue = 10;int rvalue = 20;int l_times_r = Multiply(lvalue, rvalue); 在程序执行到第8行时，实际上执行了以下操作： 将lvalue和rvalue的值压栈； 进入Multiply函数，取出栈中的值10和20，将其赋予l和r； 执行第2行代码，计算“l * r”，并将结果存在y； 将y的值压栈，然后从Multiply返回； 回到第8行，从栈中取出返回值200，并赋值给l_times_r。 上述5步就是执行本地调用的过程。 3.2 远程过程调用（RPC） 实际上RPC就是要像调用本地的函数一样去调远程函数。 在进行远程过程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，3.1节中提到的Multiply函数是在另一个机器上的进程中执行的。这就带来了下面几个问题。 1. 我们怎么告诉远程机器我们要调用Multiply，而不是Add或者其他函数呢？ 解决方法：Call ID映射。 在本地调用中，函数体是直接通过函数指针来指定的。我们调用Multiply，编译器就自动帮我们调用它对应的函数指针。但是在远程调用中，调用函数指针的方法是行不通的，因为两个机器的两个进程的地址空间是完全不一样的。所以，在RPC中，**所有的函数都必须有自己的一个ID，**这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。同时，我们还需要在客户端和服务端分别维护一个“函数与Call ID”的对应表，客户端和服务端上的对应表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程过程调用时，它就查一下这个表，找出想要调用的函数相应的Call ID，然后把它（Call ID）传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 2. 客户端怎么把参数值传给远程的函数呢？ 解决方法：序列化和反序列化。 在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的（机器的）进程，不能通过内存来传递参数，甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python），这时候就需要客户端把参数先转成一个字节流，传给服务端后，服务端再把这个字节流转成自己能读取的格式，这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 3. 网络传输问题 远程过程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把“Call ID”和“序列化后的参数字节流”传给服务端，然后再把“序列化后的调用结果”传回客户端，只要能完成这两个功能的，都可以作为传输层使用。因此，RPC所使用的协议其实是不限的，只要能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。 综上所述，要实现一个RPC框架，其实只需要把以上三点实现了就基本完成了。Call ID映射可以直接使用函数字符串，也可以使用整数ID，映射表一般就是一个哈希表；序列化反序列化可以自己写，也可以使用Protobuf或者FlatBuffers之类的；网络传输库可以自己写Socket，或者用Asio，ZeroMQ，Netty之类。 4 简要流程 一次远程过程调用的简要流程如下（对照流程图理解下列的具体流程）： 1. 首先，要解决通信的问题。主要是通过在客户端和服务器之间建立连接（如TCP连接），远程过程调用的所有数据都在这个连接中传输。此连接可以是按需连接，调用结束后就断掉，即短连接；也可以是长连接，多个远程过程共享同一个连接。 2. 其次，要解决寻址问题。也就是说，服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口、方法名称（IP+端口+方法名），这样才能完成调用。 3. 然后，client上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议（如TCP）传递到server上。由于网络协议是基于二进制的，内存中的参数也要序列化成二进制的形式，这就是序列化过程（Serizlize），通过连接寻址，将序列化的二进制发送给server。 4. 再然后，server收到请求后，需要对参数进行反序列化，恢复为内存中的表达形式，然后找到对应的方法（根据CALL ID与函数的对应表），进行本地调用，然后得到函数的返回值。 5. 最后，server需要将函数返回值发送给client上的应用。该返回值也需要经过序列化后发送，client接到server发送的消息后，再对该消息进行反序列化，恢复为内存中的表达形式，交给client上的应用。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"Windows配置grpc","slug":"RPC/Windows配置grpc","date":"2025-05-07T01:46:39.000Z","updated":"2025-05-07T03:04:53.583Z","comments":true,"path":"2025/05/07/RPC/Windows配置grpc/","link":"","permalink":"http://www.formeasy.cc/2025/05/07/RPC/Windows%E9%85%8D%E7%BD%AEgrpc/","excerpt":"","text":"方法一 1. 使用git下载grph 123git clone -b v1.70.0 --recurse-submodules https://github.com/grpc/grpc.git# 指定版本下载# git clone -b v1.41.0 https://github.com/grpc/grpc 下载速度慢可以使用国内镜像 1git clone --recurse-submodules https://gitclone.com/github.com/grpc/grpc.git 1.1 更新子模块 1git submodule update --init --recursive 2. 使用Cmake进行编译 2.1 GUI编译 选自己的vs版本 默认设置 （可修改文件存放位置） 2.2 命令行直接编译 123mkdir -p cmake/buildcd cmake/buildcmake ../.. 3. 使用Visual Studio 生成解决方法 打开项目中 右击重新生成解决方法 方法二 1. 安装vcpkg 123git clone https://github.com/microsoft/vcpkg.gitcd vcpkgbootstrap-vcpkg.bat 3.配置vckg的环境变量 1setx Path &quot;%Path%;C:\\new_path&quot; 2. 使用 vcpkg 安装 gRPC 1vcpkg install grpc:x64-windows 3. 安装 Protobuf 1vcpkg install protobuf:x64-windows 4. 配置 CMake 在 CMakeLists.txt 中添加： 12345find_package(Protobuf REQUIRED)find_package(gRPC CONFIG REQUIRED)add_executable(my_server server.cpp)target_link_libraries(my_server PRIVATE gRPC::grpc++ protobuf::libprotobuf) 5. 让 vcpkg 自动集成 1vcpkg integrate install 6. 编译 gRPC 项目 1234mkdir build &amp;&amp; cd buildcmake .. -DCMAKE_TOOLCHAIN_FILE=D:/vcpkg/scripts/buildsystems/vcpkg.cmake# 生成Release版本：cmake --build . --config Release -j 4cmake --build . 测试是否安装成功 进入 示例目录 并运行 greeter_server 和 greeter_client： 1cd examples/cpp/helloworld 如果你使用 CMake： 123mkdir build &amp;&amp; cd buildcmake ..make -j# 或者使用VS生成解决方法 如果你使用 vcpkg： 1234mkdir build &amp;&amp; cd buildcmake .. -DCMAKE_TOOLCHAIN_FILE=D:/vcpkg/scripts/buildsystems/vcpkg.cmake# 生成Release版本：cmake --build . --config Release -j 4cmake --build .# # 或者使用VS生成解决方法 运行 gRPC 示例 123cd Debug./greeter_server./greeter_client Visual Studio 配置 grpc 配置包含目录 配置库目录 配置依赖项 abseil_dll.lib absl_decode_rust_punycode.lib absl_demangle_rust.lib absl_flags_commandlineflag.lib absl_flags_commandlineflag_internal.lib absl_flags_config.lib absl_flags_internal.lib absl_flags_marshalling.lib absl_flags_parse.lib absl_flags_private_handle_accessor.lib absl_flags_program_name.lib absl_flags_reflection.lib absl_flags_usage.lib absl_flags_usage_internal.lib absl_log_flags.lib absl_poison.lib absl_utf8_for_code_point.lib cares.lib address_sorting.lib gpr.lib grpc.lib grpc_authorization_provider.lib grpc_plugin_support.lib grpc_unsecure.lib grpc++.lib grpc++_alts.lib grpc++_error_details.lib grpc++_reflection.lib grpc++_unsecure.lib grpcpp_channelz.lib upb_base_lib.lib upb_json_lib.lib upb_mem_lib.lib upb_message_lib.lib upb_mini_descriptor_lib.lib upb_textformat_lib.lib upb_wire_lib.lib re2.lib zlibd.lib libprotobufd.lib libprotobuf-lited.lib libprotocd.lib 第一个grpc demo 1. 创建demo.proto文件，写入一下内容： 1234567891011syntax = &quot;proto3&quot;;package hello;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string message = 1;&#125;message HelloReply &#123; string message = 1;&#125; 2. 编译demo.proto文件，生成的proc.exe生成proto的头文件和源文件 1protoc -I=&quot;.&quot; --grpc_out=&quot;.&quot; --plugin=protoc-gen-grpc=&quot;D:\\OpenSource\\vcpkg-2025.01.13\\packages\\grpc_x64-windows\\tools\\grpc\\grpc_cpp_plugin.exe&quot; &quot;demo.proto&quot; 3. 生成grpc类需要的pb文件，因为要序列化数据。 1protoc -I=&quot;.&quot; --grpc_out=&quot;.&quot; &quot;demo.proto&quot; 5. 分别建立server和client的项目 server.cpp 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;string&gt;#include &lt;grpcpp/grpcpp.h&gt;#include &quot;D:\\Workshops\\vs_shop\\grpc_learning\\demo_server\\demo.grpc.pb.h&quot;using grpc::Server;using grpc::ServerBuilder;using grpc::ServerContext;using grpc::Status;using hello::HelloRequest;using hello::HelloReply;using hello::Greeter;// Logic and data behind the server&#x27;s behavior.class GreeterServiceImpl final : public Greeter::Service &#123; Status SayHello(ServerContext* context, const HelloRequest* request, HelloReply* reply) override &#123; std::string prefix(&quot;llfc grpc server has received : &quot;); reply-&gt;set_message(prefix + request-&gt;message()); return Status::OK; &#125;&#125;;void RunServer() &#123; std::string server_address(&quot;127.0.0.1:50051&quot;); GreeterServiceImpl service; ServerBuilder builder; // Listen on the given address without any authentication mechanism. // 监听给定的地址 builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); // Register &quot;service&quot; as the instance through which we&#x27;ll communicate with // clients. In this case it corresponds to an *synchronous* service. builder.RegisterService(&amp;service); // Finally assemble the server. std::unique_ptr&lt;Server&gt; server(builder.BuildAndStart()); std::cout &lt;&lt; &quot;Server listening on &quot; &lt;&lt; server_address &lt;&lt; std::endl; // Wait for the server to shutdown. Note that some other thread must be // responsible for shutting down the server for this call to ever return. server-&gt;Wait();&#125;int main(int argc, char** argv) &#123; RunServer(); return 0;&#125; client.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;grpcpp/grpcpp.h&gt;#include &quot;D:\\Workshops\\vs_shop\\grpc_learning\\demo_server\\demo.grpc.pb.h&quot;using grpc::ClientContext;using grpc::Channel;using grpc::Status;using hello::HelloReply;using hello::HelloRequest;using hello::Greeter;// static method : Greeter::NewStubclass FCClient &#123;public: FCClient(std::shared_ptr&lt;Channel&gt; channel) :stub_(Greeter::NewStub(channel)) &#123; &#125; std::string SayHello(std::string name) &#123; ClientContext context; HelloReply reply; HelloRequest request; request.set_message(name); Status status = stub_-&gt;SayHello(&amp;context, request, &amp;reply); if (status.ok()) &#123; return reply.message(); &#125; else &#123; return &quot;failure &quot; + status.error_message(); &#125; &#125;private: std::unique_ptr&lt;Greeter::Stub&gt; stub_;&#125;;int main(int argc, char* argv[]) &#123; auto channel = grpc::CreateChannel(&quot;127.0.0.1:50051&quot;, grpc::InsecureChannelCredentials()); FCClient client(channel); // block until get result from RPC server std::string result = client.SayHello(&quot;hello , llfc.club !&quot;); printf(&quot;get result [%s]\\n&quot;, result.c_str()); std::getchar(); return 0;&#125; 4. 将生成的proto的头文件和源文件，grpc类需要的pb文件拷贝到server和client的项目 server项目 client的项目","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"Windows系统下GRPC在C++中的使用","slug":"RPC/Windows系统下GRPC在C++中的使用","date":"2025-05-06T09:10:54.000Z","updated":"2025-05-07T03:05:05.169Z","comments":true,"path":"2025/05/06/RPC/Windows系统下GRPC在C++中的使用/","link":"","permalink":"http://www.formeasy.cc/2025/05/06/RPC/Windows%E7%B3%BB%E7%BB%9F%E4%B8%8BGRPC%E5%9C%A8C++%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1. 准备工作 按照grpc官网的指引先做环境配置，选好版本，不同版本要求下载的软件不一样，先选的1.15.1版本，但是安装 Active State Perl 总是安装失败，于是后边换了新一点的版本。先说1.15.1版本的安装历程，网址：https://github.com/grpc/grpc/blob/v1.15.1/BUILDING.md （1） 安装vs2017 网址：https://my.visualstudio.com/Downloads?q=visual%20studio%202017&amp;wt.mc_id=omsftvscom~older-downloads 社区版不能下载，下载的专业版 点击下载，然后安装，安装时选择与C++相关的项。 （2）安装Git 直接索引到上面的链接Git，下载安装即可。 （3）安装CMake 索引到链接Download CMake，我选择的是二进制分布中的windows x64版本。 （4）安装Active State Perl 1）首先索引到网址Download &amp; Install Perl - ActiveState安装，不能直接下载安装包，得注册账号，新建项目，然后安装指引进行安装 点击Install 有这样三个步骤，第一步下载使用state命令的工具安装， 第二步将命令行粘贴，在cmd中执行，但是会报错，不知如何解决。另外，执行这条命令成功的话会在C:\\Users\\Admin文件夹下创建MyFirstProject，失败会生成一个activestate.yaml的文件。 2）后边括号中的choco install activeperl 的意思是可以在安装软件安装工具包后使用命令行安装。 安装chocolatey软件安装包管理器，可以到官网下载Chocolatey Software | Installing Chocolatey，我使用的是命令行安装。 1@&quot;%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe&quot; -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command &quot;iex ((New-Object System.Net.WebClient).DownloadString(&#x27;https://chocolatey.org/install.ps1&#x27;))&quot; &amp;&amp; SET &quot;PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin&quot; 安装完毕，可以使用choco install activeperl命令了，但是会报错，换了电脑也没成功。 （5）安装Go 同样使用命令行choco install golang安装，此时会报一个错误 ERROR: The term ‘Write-ChocolateyFailure’ is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again. The install of yasm was NOT successful. Error while running ‘C:\\ProgramData\\chocolatey\\lib\\yasm\\tools\\chocolateyInstall.ps1’. See log for details. 于是又安装了一个chocolatey的扩展包choco install chocolatey-compatibility.extension，然后安装Go成功了。 （6）安装yasm，使用命令行choco install yasm安装成功。 由于Perl安装失败，在编译源代码时会报缺少perl的错误，所以进行不下去了，猜测是由于1.15.1版本太老，是2018年的，环境依赖也不适用于现在的电脑系统或者与电脑中安装的某些环境冲突，所以换新一点的版本试试。 1.28.0版本，网址：https://github.com/grpc/grpc/blob/v1.28.0/BUILDING.md 前三步与1.15.1版本的安装一致，第四步使用命令行安装nasm，安装成功。 2. 克隆源代码 选好存放源代码的文件夹，右键选择Git bash here，将下列命令粘贴，然后Enter. 1git clone --recurse-submodules -b v1.28.0 --depth 1 --shallow-submodules https://github.com/grpc/grpc &quot;–recurse-submodules&quot;会将third_party中的子模块也下载下来，但是1.15.1版本用同样的方法就只下载到third_party下的一层，再下一层文件夹就下载不到了，得自己手动下载。更新子模块也可用“git submodule update --init”。 3. 代码编译 （1）命令行编译 在grpc文件夹下，git分别执行以下命令 1234md .build //新建.build 文件夹(mkdir .build)cd .build //定位到.build下(pushd .build)cmake .. -G &quot;Visual Studio 15 2017 Win64&quot; //使用vs2017打开，会生成grpc.sln等工程（不知道算不算编译，算的话跟下一句的区别是什么）32位的话不需要写Win64cmake --build . --config Release //编译Release版本,如果不加Release则默认为Debug版本 （2）用vs编译 打开vs2017，选择打开文件夹，选择grpc文件夹，会自动编译。 4. 搭建C++ 示例工程 （1）VS2017中新建空的C++工程TestCPP； （2）从grpc\\examples\\protos文件夹拷贝helloworld.proto到工程目录TestCPP下 ，从.build\\third_party\\protobuf\\Release文件夹拷贝protoc.exe到工程目录下，从.build\\Release拷贝grpc_cpp_plugin.exe到工程目录下，从grpc\\examples\\cpp\\helloworld拷贝greeter_client.cc，greeter_server.cc到工程目录下； （3）打开cmd，cd到工程目录TestCPP下，输入以下命令，Enter，生成helloworld.grpc.pb.cc、helloworld.grpc.pb.h； 1protoc.exe -I=. --grpc_out=. --plugin=protoc-gen-grpc=.\\grpc_cpp_plugin.exe helloworld.proto 输入以下命令，生成helloworld.pb.cc、helloworld.pb.h； 1protoc.exe -I=. --cpp_out=. helloworld.proto （4）在解决方案资源管理器右键添加现有项，选择helloworld.pb.cc、helloworld.pb.h、helloworld.pb.cc、helloworld.pb.h，greeter_server.cc（greeter_client.cc不要同时添加，编译时会出错）。 （5）在vs工程中，菜单栏设置配置和平台，我设置的是Release、x64。注意一定要和选择的类库版本一致，Release和Debug不一致编译会报错。 在解决方案资源管理器右键TestCPP选择属性， 1）选择调试，设置环境PATH=E:\\Others\\GRPC28\\grpc\\.allbuild\\third_party\\zlib\\Release 注：此处的.allbuild即上文中提到的.build，因为我重新编译在了.allbuild中； 2）选择C/C++ 常规，设置附加包含目录，E:\\Others\\GRPC28\\grpc\\include；E:\\Others\\GRPC28\\grpc\\third_party\\protobuf\\src 3）选择预处理器，配置预处理器定义_WIN32_WINNT=0x600 4）选择命令行，其他选项中填写-D_WIN32_WINNT=0x600 5）选择链接器常规，设置附加库目录，第三方库中编译出Release的都选择，手动去选，根据自己生成的文件夹设置，不要完全按我的拷贝，因为不同版本生成的文件会不一样； E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\protobuf\\Release E:\\Others\\GRPC28\\grpc.allbuild\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\zlib\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\cares\\cares\\lib\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\boringssl-with-bazel\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\boringssl-with-bazel\\bssl.dir\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\boringssl-with-bazel\\crypto.dir\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\base\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\container\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\flags\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\hash\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\numeric\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\random\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\strings\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\synchronization\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\time\\Release E:\\Others\\GRPC28\\grpc.allbuild\\third_party\\abseil-cpp\\absl\\types\\Release 6）选择输入，设置附加依赖项，注意Debug版本和Release生成的不一样，比如zlib.lib，Debug生成的是zlibd.lib，所以按照自己的生成库填写。 grpc++_unsecure.lib zlib.lib ssl.lib libprotobuf.lib libprotobuf-lite.lib libprotoc.lib WS2_32.Lib cares.lib upb.lib grpcpp_channelz.lib grpc_csharp_ext.lib grpc++_reflection.lib grpc++_error_details.lib grpc_plugin_support.lib grpc++_alts.lib address_sorting.lib grpc.lib grpc++.lib grpc_unsecure.lib zlibstatic.lib crypto.lib gpr.lib grpc_cronet.lib absl_base.lib absl_dynamic_annotations.lib absl_exponential_biased.lib absl_log_severity.lib absl_malloc_internal.lib absl_periodic_sampler.lib absl_raw_logging_internal.lib absl_scoped_set_env.lib absl_spinlock_wait.lib absl_throw_delegate.lib absl_hashtablez_sampler.lib absl_raw_hash_set.lib absl_flags.lib absl_flags_config.lib absl_flags_internal.lib absl_flags_marshalling.lib absl_flags_program_name.lib absl_flags_parse.lib absl_flags_registry.lib absl_flags_usage.lib absl_flags_usage_internal.lib absl_city.lib absl_hash.lib absl_int128.lib absl_random_distributions.lib absl_random_internal_distribution_test_util.lib absl_random_internal_pool_urbg.lib absl_random_internal_randen.lib absl_random_internal_randen_hwaes.lib absl_random_internal_randen_hwaes_impl.lib absl_random_internal_randen_slow.lib absl_random_internal_seed_material.lib absl_random_seed_gen_exception.lib absl_random_seed_sequences.lib absl_str_format_internal.lib absl_strings.lib absl_strings_internal.lib absl_graphcycles_internal.lib absl_synchronization.lib absl_civil_time.lib absl_time.lib absl_time_zone.lib absl_bad_any_cast_impl.lib absl_bad_optional_access.lib absl_bad_variant_access.lib （6）编译工程 右键TestCPP，生成，会在TestCPP\\x64\\Release文件夹中生成TestCPP.exe，将Release文件夹改名为ReleaseServer，将TestCPP.exe启动； 在资源管理器中选择greeter_server.cc右键移除，再添加greeter_client.cc，在main函数中添加std::cin.get();避免调试时启动窗口一闪而退， 编译，会在TestCPP\\x64\\Release文件夹中生成TestCPP.exe，启动或在vs中调试，出现下图中的消息表示通信成功。 编译时出现的错误： LNK2038 检测到“_ITERATOR_DEBUG_LEVEL”的不匹配项: 值“0”不匹配值“2”，因为我编译grpc源码时编译的是Release版本，生成的库是Release版本的，调试用的Debug模式，两者该统一。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"在Windows搭建gRPC C++开发环境","slug":"RPC/在Windows搭建gRPC C++开发环境","date":"2025-05-06T09:00:29.000Z","updated":"2025-05-07T03:05:16.125Z","comments":true,"path":"2025/05/06/RPC/在Windows搭建gRPC C++开发环境/","link":"","permalink":"http://www.formeasy.cc/2025/05/06/RPC/%E5%9C%A8Windows%E6%90%AD%E5%BB%BAgRPC%20C++%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","excerpt":"","text":"一、环境构建 1. CMake Download CMake 2. Git Git for Windows 3. gRPC源码 1git clone -b v1.48.0 https://github.com/grpc/grpc 进入源码目录 1cd grpc 下载依赖库 1git submodule update --init 二、使用CMake生成工程文件 三、使用vs2019编译grpc库文件 四、使用vs2019编译grpc库文件 将库文件和头文件提取出来放入include和lib 头文件需要 还有absl,grpc-1.4.8\\grpc\\third_party\\protobuf\\src 库文件需要的有下面这些 absl_bad_optional_access.lib absl_bad_variant_access.lib absl_base.lib absl_city.lib absl_civil_time.lib absl_cord.lib absl_cordz_functions.lib absl_cordz_handle.lib absl_cordz_info.lib absl_cordz_sample_token.lib absl_cord_internal.lib absl_debugging_internal.lib absl_demangle_internal.lib absl_examine_stack.lib absl_exponential_biased.lib absl_failure_signal_handler.lib absl_flags.lib absl_flags_commandlineflag.lib absl_flags_commandlineflag_internal.lib absl_flags_config.lib absl_flags_internal.lib absl_flags_marshalling.lib absl_flags_parse.lib absl_flags_private_handle_accessor.lib absl_flags_program_name.lib absl_flags_reflection.lib absl_flags_usage.lib absl_flags_usage_internal.lib absl_graphcycles_internal.lib absl_hash.lib absl_hashtablez_sampler.lib absl_int128.lib absl_leak_check.lib absl_log_severity.lib absl_low_level_hash.lib absl_malloc_internal.lib absl_periodic_sampler.lib absl_random_distributions.lib absl_random_internal_distribution_test_util.lib absl_random_internal_platform.lib absl_random_internal_pool_urbg.lib absl_random_internal_randen.lib absl_random_internal_randen_hwaes.lib absl_random_internal_randen_hwaes_impl.lib absl_random_internal_randen_slow.lib absl_random_internal_seed_material.lib absl_random_seed_gen_exception.lib absl_random_seed_sequences.lib absl_raw_hash_set.lib absl_raw_logging_internal.lib absl_scoped_set_env.lib absl_spinlock_wait.lib absl_stacktrace.lib absl_status.lib absl_statusor.lib absl_strerror.lib absl_strings.lib absl_strings_internal.lib absl_str_format_internal.lib absl_symbolize.lib absl_synchronization.lib absl_throw_delegate.lib absl_time.lib absl_time_zone.lib address_sorting.lib cares.lib crypto.lib gpr.lib grpc++.lib grpc++_alts.lib grpc++_error_details.lib grpc++_reflection.lib grpc++_unsecure.lib grpc.lib grpcpp_channelz.lib grpc_plugin_support.lib grpc_unsecure.lib libprotobuf-lite.lib libprotobuf.lib libprotoc.lib re2.lib ssl.lib upb.lib zlib.lib 五、编译proto文件 注意：其中：grpc_cpp_plugin.exe所在路径替换为您安装的路径。 且proto路径根据自已的路径修改 12protoc -I=&quot;./protos&quot; --grpc_out=&quot;./protos&quot; --plugin=protoc-gen-grpc=&quot;D:\\workplace\\grpc-1.4.8\\grpc\\cmake_build\\Release\\grpc_cpp_plugin.exe&quot; &quot;./protos\\greet.proto&quot;protoc -I=&quot;./protos&quot; --cpp_out=&quot;./protos&quot; &quot;./protos\\greet.proto&quot; 六、生成gprc客户端服务端 将生成的 .grpc.pb.cc/.h .pb.cc/.h 以及proto文件添加到vs中，vs切换为Release x64版本（对应gRPC编译的版本，不知道Debug版本是否有问题，暂未尝试）。 添加上面的库文件和头文件目录，还有lib文件进工程","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"基于VS2022在Windows上首次尝试开发C++ gRPC服务端和客户端的详细步骤","slug":"RPC/基于VS2022在Windows上首次尝试开发C++ gRPC服务端和客户端的详细步骤","date":"2025-04-30T08:54:30.000Z","updated":"2025-05-09T02:01:58.007Z","comments":true,"path":"2025/04/30/RPC/基于VS2022在Windows上首次尝试开发C++ gRPC服务端和客户端的详细步骤/","link":"","permalink":"http://www.formeasy.cc/2025/04/30/RPC/%E5%9F%BA%E4%BA%8EVS2022%E5%9C%A8Windows%E4%B8%8A%E9%A6%96%E6%AC%A1%E5%B0%9D%E8%AF%95%E5%BC%80%E5%8F%91C++%20gRPC%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"0. 安装vcpkg 123https://github.com/microsoft/vcpkg.git.\\bootstrap-vcpkg.bat vcpkg --version 1.grpc安装与编译 1vcpkg install grpc:x64-windows 2.protocbuf安装与编译 1vcpkg install protobuf protobuf:x64-windows 安装后，您可以在文件夹 &lt;vcpkg_installed_path&gt;\\packages 下的 vcpkg 目录中找到已安装的软件包。 为了使软件包在系统范围内可用，您需要使用命令： 1vcpkg integrate install 注：以上安装完大约47GB 1. 创建解决方案与项目 打开VS2022 → 创建新项目 → 选择 “空项目” ，分别创建服务端（如gRPCServer）和客户端（如gRPCClient）项目 右键解决方案 → 添加 → 新建项 → “头文件(.h)” 和 “源文件(.cpp)” ，分别用于服务端和客户端代码 2. 编写proto文件 在解决方案目录下创建protos文件夹，新建greet.proto文件（示例内容如下）： 123456syntax = &quot;proto3&quot;;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1; &#125;message HelloReply &#123; string message = 1; &#125; 3. 生成gRPC代码 打开开发者命令行工具，执行以下命令（注意路径替换）： 12345# 生成消息序列化代码protoc -I=protos/ --cpp_out=protos/ protos/greet.proto# 生成gRPC服务代码（注意grpc_cpp_plugin路径）protoc -I=protos/ --grpc_out=protos/ --plugin=protoc-gen-grpc=&quot;C:\\vcpkg\\vcpkg\\installed\\x64-windows\\tools\\grpc\\grpc_cpp_plugin.exe&quot; protos/greet.proto 生成greet.pb.h、greet.pb.cc 、greet.grpc.pb.h、greet.grpc.pb.cc 四个文件 4. 配置项目属性 服务端项目（gRPCServer） C/C++ → 常规 → 附加包含目录 添加： 12C:\\vcpkg\\vcpkg\\installed\\x64-windows\\include$(ProjectDir)\\protos 链接器 → 常规 → 附加库目录 添加： 1C:\\vcpkg\\vcpkg\\installed\\x64-windows\\lib 链接器 → 输入 → 附加依赖项 添加： 1grpc++.lib;grpc++_reflection.lib;grpc.lib;gpr.lib;libprotobuf.lib;libprotoc.lib C/C++ → 语言 → C++ 语言标准 设置为 “ISO C++17 标准” 客户端项目（gRPCClient） 配置步骤同上，与服务端完全一致 5. 实现服务端代码 在gRPCServer项目中添加server.cpp： 1234567891011121314151617181920212223242526272829#include &lt;grpcpp/grpcpp.h&gt;#include &quot;protos/greet.grpc.pb.h&quot;class GreeterServiceImpl final : public Greeter::Service &#123; grpc::Status SayHello(grpc::ServerContext* context, const HelloRequest* request, HelloReply* reply) override &#123; reply-&gt;set_message(&quot;Hello &quot; + request-&gt;name()); return grpc::Status::OK; &#125;&#125;;void RunServer() &#123; std::string server_address(&quot;0.0.0.0:50051&quot;); GreeterServiceImpl service; grpc::ServerBuilder builder; builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); builder.RegisterService(&amp;service); std::unique_ptr&lt;grpc::Server&gt; server(builder.BuildAndStart()); std::cout &lt;&lt; &quot;Server listening on &quot; &lt;&lt; server_address &lt;&lt; std::endl; server-&gt;Wait();&#125;int main() &#123; RunServer(); return 0;&#125; 6. 实现客户端代码 在gRPCClient项目中添加client.cpp： 123456789101112131415161718192021222324252627282930#include &lt;grpcpp/grpcpp.h&gt;#include &quot;protos/greet.grpc.pb.h&quot;class GreeterClient &#123;public: GreeterClient(std::shared_ptr&lt;grpc::Channel&gt; channel) : stub_(Greeter::NewStub(channel)) &#123;&#125; std::string SayHello(const std::string&amp; name) &#123; HelloRequest request; request.set_name(name); HelloReply reply; grpc::ClientContext context; grpc::Status status = stub_-&gt;SayHello(&amp;context, request, &amp;reply); if (status.ok()) return reply.message(); else return &quot;RPC failed&quot;; &#125;private: std::unique_ptr&lt;Greeter::Stub&gt; stub_;&#125;;int main() &#123; GreeterClient client(grpc::CreateChannel(&quot;localhost:50051&quot;, grpc::InsecureChannelCredentials())); std::cout &lt;&lt; client.SayHello(&quot;World&quot;) &lt;&lt; std::endl; return 0;&#125; 7. 编译与运行 生成解决方案：右键解决方案 → 生成解决方案 启动服务端：右键gRPCServer → 调试 → 启动新实例 启动客户端：右键gRPCClient → 调试 → 启动新实例 正确输出应为：Hello World 注意事项 若出现 “无法打开 grpc++/impl/codegen/config.h” 错误，检查vcpkg是否安装完整（执行vcpkg install grpc:x64-windows） 若链接失败，确认所有.lib文件是否存在于C:\\vcpkg\\vcpkg\\installed\\x64-windows\\lib目录 服务器端输出： Server listening on 0.0.0.0:50051 客户端输出： Hello World Press Enter to exit…","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"GRPC 快速入门","slug":"RPC/GRPC 快速入门","date":"2025-04-30T08:49:56.000Z","updated":"2025-05-07T03:04:28.444Z","comments":true,"path":"2025/04/30/RPC/GRPC 快速入门/","link":"","permalink":"http://www.formeasy.cc/2025/04/30/RPC/GRPC%20%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"","text":"1. 背景介绍 gRPC全称Google Remote Procedure Call. 它是一种基于Protobuf buffer 格式的高效的通讯协议。与许多 RPC 系统一样，gRPC 基于定义服务的理念，指定可以远程调用的方法及其参数和返回类型。在服务器端，服务器实现此接口并运行 gRPC 服务器以处理客户端调用。在客户端，客户端具有一个存根（在某些语言中称为客户端），它提供与服务器相同的 方法。 2. 快速入门 安装 cmake 您需要 cmake 的 3.13 版或更高版本。请按照以下说明进行安装 Linux 1sudo apt install -y cmake macOS 1brew install cmake 安装其他必需工具 Linux 1sudo apt install -y build-essential autoconf libtool pkg-config macOS 1brew install autoconf automake libtool pkg-config 克隆 grpc 仓库 设置安装路径 123export MY_INSTALL_DIR=$HOME/.localmkdir -p $MY_INSTALL_DIRexport PATH=&quot;$MY_INSTALL_DIR/bin:$PATH&quot; 使用cmake进行源码编译 1234567891011git clone --recurse-submodules -b v1.62.0 --depth 1 --shallow-submodules https://github.com/grpc/grpccd grpcmkdir -p cmake/buildcd cmake/buildcmake -DgRPC_INSTALL=ON \\ -DgRPC_BUILD_TESTS=OFF \\ -DCMAKE_INSTALL_PREFIX=$MY_INSTALL_DIR \\ ../..make -j32make insatllcd - 重要 我们强烈建议您本地安装 gRPC——使用适当设置的 CMAKE_INSTALL_PREFIX——因为在您全局安装 gRPC 后，没有简单的方法将其卸载。 用例测试 12345cd examples/cpp/helloworldmkdir -p cmake/buildpushd cmake/buildcmake ../..make -j 4 运行服务器 1./greeter_server 运行终端 12./greeter_client&gt;&gt;&gt; Greeter received: Hello world 恭喜！您刚刚使用 gRPC 运行了一个客户端-服务器应用程序。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"gRPC实现第一个C++服务器","slug":"RPC/gRPC实现第一个C++服务器","date":"2025-04-30T08:38:31.000Z","updated":"2025-05-07T03:04:42.751Z","comments":true,"path":"2025/04/30/RPC/gRPC实现第一个C++服务器/","link":"","permalink":"http://www.formeasy.cc/2025/04/30/RPC/gRPC%E5%AE%9E%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%B8%AAC++%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"1. 前言 本章节将实现C++版本的个人注册页面的gRPC服务器 更多基础知识可以参考上一节: GRPC 快速入门 2. 定义服务 要定义服务，需要在login.proto文件中指定一个名为service的内容，另外我们还需要定义一个LoginInfo的消息体用来传递信息 12345678910111213141516171819202122syntax = &quot;proto3&quot;; //指定版本信息，不指定会报错package tutorial; //package声明符，用来防止不同的消息类型有命名冲突// 注册消息体message LoginInfo &#123; string usrname = 1; string password = 2;&#125;// login responsemessage LoginResponse &#123; // 状态码，0表示成功 int32 status_code = 1; // 返回信息，包含成功或错误描述 string message = 2;&#125;// 定义服务service LoginService &#123; rpc login(LoginInfo) returns (LoginResponse);&#125; 将.proto 翻译成C++文件 12protoc -I . --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` login.protoprotoc -I . --cpp_out=. login.proto 运行此命令将在您的当前目录中生成以下文件: login.pb.h: 声明生成的客户端的头文件 login.pb.cc: 包含客户端的实现 login.grpc.pb.h: 声明生成的服务器端的头文件 login.grpc.pb.cc: 包含服务器端的实现 如果要生成python 文件 123 # 安装依赖pip3 install grpcio-toolspython -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. login.proto 3. 服务器代码 下面我们来编写服务器代码 12345678910111213141516171819202122232425262728293031323334#include &lt;grpcpp/grpcpp.h&gt;#include &quot;login.pb.h&quot;#include &quot;login.grpc.pb.h&quot;class LoginServiceImpl final : public tutorial::LoginService::Service&#123; grpc::Status login(::grpc::ServerContext *context, const ::tutorial::LoginInfo *request, ::tutorial::LoginResponse *response) override &#123; std::cout &lt;&lt; &quot; usrname: &quot; &lt;&lt; request-&gt;usrname() &lt;&lt; &quot; password: &quot; &lt;&lt; request-&gt;password() &lt;&lt; std::endl; std::string msg(&quot;Login successfully!&quot;); response-&gt;set_status_code(0); response-&gt;set_message(msg); return grpc::Status::OK; &#125;&#125;;int main(int argv, char **argc)&#123; const std::string server_address = &quot;localhost:50051&quot;; LoginServiceImpl service = LoginServiceImpl(); grpc::ServerBuilder builder; builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); builder.RegisterService(&amp;service); std::unique_ptr&lt;grpc::Server&gt; server(builder.BuildAndStart()); std::cout &lt;&lt; &quot;Server listening on &quot; &lt;&lt; server_address &lt;&lt; std::endl; server-&gt;Wait(); return 0;&#125; 4. 客户端代码 下面我们来编写客户端代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;grpcpp/grpcpp.h&gt;#include &quot;login.pb.h&quot;#include &quot;login.grpc.pb.h&quot;#include &lt;unordered_map&gt;std::unordered_map&lt;std::string, std::string&gt; user_maps = &#123; &#123;&quot;张三&quot;, &quot;123456&quot;&#125;, &#123;&quot;李四&quot;, &quot;666666&quot;&#125;,&#125;;int main(int argc, char **argv)&#123; const std::string server_address = &quot;localhost:50051&quot;; grpc::ChannelArguments channel_args; channel_args.SetMaxReceiveMessageSize(1024 * 1024 * 1024); // 1GB channel_args.SetMaxSendMessageSize(1024 * 1024 * 1024); auto channel = grpc::CreateCustomChannel( server_address, grpc::InsecureChannelCredentials(), channel_args); std::unique_ptr&lt;tutorial::LoginService::Stub&gt; stub = tutorial::LoginService::NewStub(channel); for (auto user : user_maps) &#123; tutorial::LoginInfo info; tutorial::LoginResponse res; info.set_usrname(user.first); info.set_password(user.second); grpc::ClientContext context; grpc::Status status = stub-&gt;login(&amp;context, info, &amp;res); if (!status.ok()) &#123; std::cerr &lt;&lt; &quot;检查网络是否发生错误: &quot; &lt;&lt; status.error_message() &lt;&lt; std::endl; continue; &#125; if (!res.status_code() == 0) &#123; std::cerr &lt;&lt; user.first &lt;&lt; &quot;注册失败: &quot; &lt;&lt; res.message() &lt;&lt; std::endl; continue; &#125; std::cerr &lt;&lt; user.first &lt;&lt; &quot;注册成功: &quot; &lt;&lt; res.message() &lt;&lt; std::endl; continue; &#125; return 0;&#125; 5. 编译 测试过Makefile，编译依赖库太多，不建议使用。建议使用cmake比较好处理， CMakeLists.txt 如下： 123456789101112131415161718192021222324252627282930313233cmake_minimum_required(VERSION 3.8)project(Tutorial C CXX)set(_PROTOBUF_LIBPROTOBUF protobuf::libprotobuf)find_package(Threads REQUIRED)set(_REFLECTION gRPC::grpc++_reflection)find_package(Protobuf CONFIG REQUIRED)set(_GRPC_GRPCPP gRPC::grpc++)find_package(gRPC CONFIG REQUIRED)set(PROTO_SRCS login.grpc.pb.cc login.pb.cc)set(CMAKE_CXX_STANDARD 17)add_executable(login_client $&#123;PROTO_SRCS&#125; client.cpp)add_executable(login_server $&#123;PROTO_SRCS&#125; server.cpp)target_link_libraries(login_client absl::flags absl::flags_parse $&#123;_REFLECTION&#125; $&#123;_GRPC_GRPCPP&#125; $&#123;_PROTOBUF_LIBPROTOBUF&#125;)target_link_libraries(login_server absl::flags absl::flags_parse $&#123;_REFLECTION&#125; $&#123;_GRPC_GRPCPP&#125; $&#123;_PROTOBUF_LIBPROTOBUF&#125;) 12mkdir build &amp;&amp; cd buildcmake .. 编译服务器和客户端 1make login_server login_client 先运行服务器，再运行客户端，服务器端看到正常打印时，恭喜你完成了第一个C++通讯程序 6. 故障解决 故障一： 在编译时可能会遇到protocol版本冲突，出现如下报错(error: #error PROTOBUF_VERSION was previously defined)： 说明grpc中使用的protocol和本地版本不一致，需要保证两个版本一致，两个解决方法 方法一： 或者卸载掉本地版本，卸载指令 先查看位置 12which protoc# protoc: /usr/local/bin/protoc 删除可执行和库 123rm -rf /usr/local/bin/protoc #可执行sudo rm -rf /usr/local/include/google/protobuf #头文件sudo rm -rf /usr/local/lib/libproto* # 库文件 配置grpc的bin到path中 1export PATH=$PATH:&lt;your grpc install path&gt;/bin 然后查看protoc是否是使用的grpc中的protoc 1which protoc 方法二 先检查你的grpc使用的protoc版本，然后安装相应版本 12&lt;your grpc install path&gt;/bin/protoc --version# libprotoc 25.1 故障二： 使用C++17可以解决","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"}],"author":null},{"title":"Windows安装vcpkg教程（VS2022）","slug":"VS/Windows安装vcpkg教程（VS2022）","date":"2025-04-30T08:03:45.000Z","updated":"2025-04-30T08:12:13.579Z","comments":true,"path":"2025/04/30/VS/Windows安装vcpkg教程（VS2022）/","link":"","permalink":"http://www.formeasy.cc/2025/04/30/VS/Windows%E5%AE%89%E8%A3%85vcpkg%E6%95%99%E7%A8%8B%EF%BC%88VS2022%EF%BC%89/","excerpt":"","text":"一、关于vcpkg vcpkg 是一个开源的 C++ 包管理工具，旨在简化 C++ 库的管理、安装和集成。它帮助开发者轻松地将第三方 C++ 库集成到自己的项目中，并提供了一种跨平台的方式来管理和分发 C++ 库。vcpkg 支持 Windows、Linux 和 macOS，能够自动处理库的下载、构建和依赖关系，极大地简化了 C++ 开发中的外部库管理问题。 vcpkg与其它管理工具的对比： vcpkg vs Conan： Conan 是另一个流行的 C++ 包管理工具，旨在简化 C++ 项目的依赖管理。Conan 提供更强大的跨平台支持，支持与多种构建系统（如 CMake、Visual Studio、Make 等）集成。 vcpkg 更注重与 Visual Studio 和 CMake 的无缝集成，并提供了更为简单的命令行界面和安装方式。 差异：vcpkg 主要用于管理由 Microsoft 和其他开源社区提供的 C++ 库，并且通常支持 Windows 和 Linux/macOS 平台。而 Conan 支持更多的构建系统、版本和配置，可以为多种平台提供更多定制选项。 vcpkg vs 自行管理依赖： 在没有 vcpkg 的情况下，开发者需要手动下载、构建和集成外部库，管理所有的依赖关系。这不仅耗时，而且容易出错。vcpkg 提供了一个简单、高效的方式来自动处理这些任务，减少了人工错误的发生。 vcpkg的优点： 易用性：通过命令行一行命令安装、卸载库，简化了 C++ 项目中库的管理。 跨平台支持：支持 Windows、Linux 和 macOS，让同一个项目可以在多个平台上使用相同的依赖。 自动化依赖管理：自动处理库的构建和依赖关系，不需要手动解决版本和依赖冲突。 与 CMake 完美集成：通过 CMAKE_TOOLCHAIN_FILE 配置，vcpkg 能自动配置 CMake 项目，省去了手动配置路径的麻烦。 二、开发环境 1.操作系统：Win10/Win11 2.开发工具：Visual Studio 2022 3.开发语言：C/C++ 4.Git版本：2.47.0.2 三、安装Git 在安装 vcpkg 之前，Git 是一个必要的工具，因为 vcpkg 是通过 Git 从 GitHub 仓库克隆下来的。Git 是一个分布式版本控制系统，允许你从远程仓库（例如 GitHub）下载源代码并管理版本。 1.下载地址： Git官方网址： http://git-scm.com（包含不同系统不同平台的安装包和源代码） 适用于Windows的Git下载网址：http://gitforwindows.org （只有 windows 系统的安装包） 2.安装步骤： 下载后双击exe进行安装，如下图所示。 点击next，笔者设置安装位置为D:\\METIS\\GIT。 根据自己的需要选择组件进行下载，默认如下图所示。 方框内 Git 为安装组件的文件夹名称，可改为其他名字，也可点击 “Browse…” 选择其他文件夹或者给&quot;Don't create a Start Menu folder&quot; 打勾不要文件夹。 后续一直点击next，选择默认设置即可，安装完成后点击finish。 3.配置环境： 安装好后将git.exe的路径添加到系统 path 环境变量当中去，这样就可以在Windows系统Win+R的系统cmd命令行中使用vcpkg。我们主要使用的是 Git CMD ，当添加完Gti环境变量后，你也就可以使用Windos系统自带的cmd命令行工具。 右键此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量，如下图所示。 在系统变量中双击Path，点击新建，将bin文件夹的地址填入，笔者地址为D:\\METIS\\GIT\\Git\\bin，点击确定。 其中D:\\METIS\\GIT为安装位置，Git为安装组件的文件夹名。 4.检测安装是否成功： 使用快捷键Win+R，输入cmd打开终端，输入以下命令： 1git --version 如果 Git 已成功安装并且环境变量已正确配置，你应该看到类似以下的输出： 这表示你安装的 Git 版本（例如版本 2.47.1.windows.2）。如果你看到类似这样的版本号输出，说明 Git 已经成功安装并配置好环境变量。 四、使用 Git 克隆 vcpkg 仓库 1.下载地址： vcpkg 官方网站：https://vcpkg.io 这个网站提供了 vcpkg 的详细文档、安装指南、使用教程以及如何为 vcpkg 添加新的库等内容，可以在这个网站上找到关于 vcpkg 的所有资源。 vcpkg GitHub 仓库：https://github.com/microsoft/vcpkg vcpkg 的源代码和贡献指南都托管在 GitHub 上，在 GitHub 上可以找到 vcpkg 的源代码、发布历史以及其他开发者的贡献。（本文安装方法使用该网址） 2.准备工作： 新建空文件夹，建议使用短路径名称（不含空格）（如 C:\\src\\win32\\ 或 C:\\dev\\iot\\），笔者以D:\\vcpkg为例。首先下载引导vcpkg，安装位置随意，但是为了之后方便与Visual Studio以及其他C/C++编译器链接，建议使用类似 C:\\src 或者 C:\\dev ，可以理解为在本地建立一个库的仓库，之后所有的安装都在该目录下，否则会由于路径的缘故会遇到某些端口构建系统的路径问题。 3.使用 Git 克隆 vcpkg 仓库： 打开Git CMD命令行工具，使用 cd 到建立的目标路径（本文以D:\\vcpkg为例） 使用 Git 克隆 vcpkg 仓库，输入以下命令： 1git clone https://github.com/Microsoft/vcpkg 终端如下图所示。 这将会把 vcpkg 仓库克隆到当前目录中，并创建一个 vcpkg 文件夹。vcpkg 的所有源代码和工具都会被下载到该文件夹中。 下载完成如下图所示。 再次使用 cd 命令到vcpkg文件路径内（本文以D:\\vcpkg\\vcpkg为例） 运行构建脚本来编译 vcpkg，输入以下命令： 1.\\bootstrap-vcpkg.bat 终端如下图所示。 下载完成后会编译并生成 vcpkg.exe 工具。 4.配置环境： 为了方便在任何地方使用 vcpkg 命令，可以将 vcpkg 的路径添加到环境变量中，使其在命令行中全局可用。右键此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量，在系统变量中双击Path，点击新建，将bin文件夹的地址填入，笔者地址为D:\\vcpkg\\vcpkg，点击确定。 5.检测安装是否成功： 使用快捷键Win+R，输入cmd打开终端，输入以下命令： 1vcpkg --version 如果vcpkg已成功安装并且环境变量已正确配置，你应该看到类似以下的输出： 123vcpkg package management program version 2024-11-12-eb492805e92a2c14a230f5c3deb3e89f6771c321 See LICENSE.txt for license information. 这表示 vcpkg 已成功安装并正确运行。输出的内容包括以下信息： vcpkg版本号： 输出中的 2024-11-12-eb492805e92a2c14a230f5c3deb3e89f6771c321 部分是 vcpkg 的版本信息。版本号包含两个部分： 日期：2024-11-12 表示 vcpkg 的版本发布日期。 提交哈希：eb492805e92a2c14a230f5c3deb3e89f6771c321 是当前 vcpkg 版本的 Git 提交哈希（唯一标识）。 这意味着安装的 vcpkg 是一个特定日期和版本的构建。 LICENSE.txt 提示： See LICENSE.txt for license information 表示你可以查看 vcpkg 项目的 LICENSE.txt 文件，了解 vcpkg 的许可协议。 6.链接Visual Studio 2022： 继续在Git CMD的D:\\vcpkg\\vcpkg地址下输入以下命令： 1.\\vcpkg integrate install 运行结果如下，即链接成功。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"}],"author":null},{"title":"UE/虚幻 蓝图实现通过http获取数据（以高德地图API为例）&Json格式数据的读取","slug":"UE/UE虚幻 蓝图实现通过http获取数据（以高德地图API为例）&Json格式数据的读取","date":"2025-04-27T02:07:04.000Z","updated":"2025-04-27T02:23:13.895Z","comments":true,"path":"2025/04/27/UE/UE虚幻 蓝图实现通过http获取数据（以高德地图API为例）&Json格式数据的读取/","link":"","permalink":"http://www.formeasy.cc/2025/04/27/UE/UE%E8%99%9A%E5%B9%BB%20%E8%93%9D%E5%9B%BE%E5%AE%9E%E7%8E%B0%E9%80%9A%E8%BF%87http%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%88%E4%BB%A5%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BEAPI%E4%B8%BA%E4%BE%8B%EF%BC%89&Json%E6%A0%BC%E5%BC%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%BB%E5%8F%96/","excerpt":"","text":"准备工作 安装插件_VictoryPlugin_与_vaRest_ __VictoryPlugin插件分享： 链接: https://pan.baidu.com/s/1w4CBf6xK25U0HHzolAFMyQ?pwd=8888 提取码: 8888 vaRest可在EPIC中自行安装 注册高德开发平台账户 注册完成后选择Web服务API 在使用之前需要获取Key值，具体参考高德地图文档 这里使用的是天气查询API 网页中测试高德API是否能将获取成功 获取天气查API地址，譬如查询南昌市天气：https://restapi.amap.com/v3/weather/weatherInfo?key=你的应用Key值&amp;city=360100 中间使用&amp;连接，城市码可以直接通过文档规格说明下载相关表格 查询结果： 在虚幻中通过HTTP获取数据 需要使用vaRest插件，需要使用需要在插件中开启插件，并将节点相关性关闭 将地址粘贴到URL中，选择获取方式为GET，内容类型为x-www-from-urlencoded(URl)，如果选择JSON会获取失败 最后会将获取的数据返回到回调函数中，这里直接将其打印 JSON数据的读取 存储JSON数据 FileIOSaveStringArraytoFile最下面两个参数分别是允许写覆盖和允许添加，如果勾选允许添加，那每次更新数据都会以新的一条数据出现在文件中， 方便测试直接获取两个城市的数据进行存储 查看结果，可以生成相对应json文件，并且文件中成功存储了获取的数据： 读取JSON文件数据 读取得到文件中的数据","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 会话暴露给蓝图 ，无法识别会话相关类型","slug":"UE/UEC++ 会话暴露给蓝图 ，无法识别会话相关类型","date":"2025-04-27T02:02:40.000Z","updated":"2025-04-27T02:06:18.544Z","comments":true,"path":"2025/04/27/UE/UEC++ 会话暴露给蓝图 ，无法识别会话相关类型/","link":"","permalink":"http://www.formeasy.cc/2025/04/27/UE/UEC++%20%E4%BC%9A%E8%AF%9D%E6%9A%B4%E9%9C%B2%E7%BB%99%E8%93%9D%E5%9B%BE%20%EF%BC%8C%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%AB%E4%BC%9A%E8%AF%9D%E7%9B%B8%E5%85%B3%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"在实在联网功能时，我们常常需要获取到会话类型，当我们需要在蓝图中使用这些类型的时候。如果我们直接在头文件中直接使用会话相关类型在编译时就会报错 1Unrecognized type “你所引用的类” - type must be a UCLASS，USTRUCT or UENUM 这时候就需要利用结构体对需要使用的会话类型进行一个包装，具体的实现方式我们可以借鉴（对，是借鉴不是抄） BlueprintSession 的实现形式。找到相关头文件 1\\引擎安装路径\\Engine\\Plugins\\Online\\OnlineSubsystemUtils\\Source\\OnlineSubsystemUtils\\Classes\\FindSessionsCallbackProxy.h 1\\引擎安装路径\\Engine\\Plugins\\Online\\OnlineSubsystemUtils\\Source\\OnlineSubsystemUtils\\Private\\FindSessionsCallbackProxy.cpp 这里只他们的展示部分代码，具体可以自己去找这两个文件看 FindSessionsCallbackProxy.h 相关类型的封装 1234567USTRUCT(BlueprintType)struct FBlueprintSessionResult&#123; GENERATED_USTRUCT_BODY() FOnlineSessionSearchResult OnlineResult;&#125;; 综上，我们就可以得出我们需要的代码 1234567891011121314151617181920212223242526USTRUCT(BlueprintType)struct FSearchResultSession &#123; GENERATED_USTRUCT_BODY() FOnlineSessionSearchResult OnlineResult; // 注意此处不要添加UPROPERTY 不然又得找不到了&#125;;// 以下为类型实现，注意在结构体内是无法使用 UFUNCTION 的UFUNCTION(BlueprintPure)static int32 GetPingInMs(const FSearchResultSession&amp; ResultSession) &#123; return ResultSession.OnlineResult.PingInMs;&#125;UFUNCTION(BlueprintPure)static FString GetServerName(const FSearchResultSession&amp; ResultSession) &#123; return ResultSession.OnlineResult.Session.OwningUserName;&#125;UFUNCTION(BlueprintPure)static int32 GetCurrentPlayer(const FSearchResultSession&amp; ResultSession) &#123; return ResultSession.OnlineResult.Session.SessionSettings.NumPublicConnections - ResultSession.OnlineResult.Session.NumOpenPublicConnections;&#125;UFUNCTION(BlueprintPure)static int32 GetMaxPlayer(const FSearchResultSession&amp; ResultSession) &#123; return ResultSession.OnlineResult.Session.SessionSettings.NumPublicConnections;&#125; 需要其他什么功能可以另行添加，注意函数的形参类型是自己定义的结构体名称 试一试~ emmmmm 非常~好用！","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE/虚幻 Widget Blueprint could not be loaded because it derives from an invalid class","slug":"UE/UE虚幻 Widget Blueprint could not be loaded because it derives from an invalid class","date":"2025-04-27T01:57:20.000Z","updated":"2025-04-27T02:02:00.997Z","comments":true,"path":"2025/04/27/UE/UE虚幻 Widget Blueprint could not be loaded because it derives from an invalid class/","link":"","permalink":"http://www.formeasy.cc/2025/04/27/UE/UE%E8%99%9A%E5%B9%BB%20Widget%20Blueprint%20could%20not%20be%20loaded%20because%20it%20derives%20from%20an%20invalid%20class/","excerpt":"","text":"Widget Blueprint could not be loaded because it derives from an invalid class 蓝图控件无法加载，因为它来自无效的类 生成节点部件必须创建一个类 这是我在打包一个含自定义插件的项目时出现的问题 出现问题的原因：在打开编译器的时候，插件是默认在编译器加载完之后再去加载插件的 解决办法： 在.uplugin文件中将 1&quot;LoadingPhase&quot; : &quot;Default&quot; 改成 1&quot;LoadingPhase&quot; : &quot;PreDefault&quot; 意思是将插件的加载顺序提到编译器加载之前，这样就可以解决这个问题了。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE/虚幻 通过在线子系统访问线上服务（OnlineSubsystem/OnlineSubsystemSteam）","slug":"UE/UE虚幻 通过在线子系统访问线上服务（OnlineSubsystemOnlineSubsystemSteam）","date":"2025-04-27T01:51:37.000Z","updated":"2025-04-27T01:55:05.301Z","comments":true,"path":"2025/04/27/UE/UE虚幻 通过在线子系统访问线上服务（OnlineSubsystemOnlineSubsystemSteam）/","link":"","permalink":"http://www.formeasy.cc/2025/04/27/UE/UE%E8%99%9A%E5%B9%BB%20%E9%80%9A%E8%BF%87%E5%9C%A8%E7%BA%BF%E5%AD%90%E7%B3%BB%E7%BB%9F%E8%AE%BF%E9%97%AE%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%EF%BC%88OnlineSubsystemOnlineSubsystemSteam%EF%BC%89/","excerpt":"","text":"我们通过Steam访问线上服务不知道怎么配置的可以看我的另一篇 [UE /虚幻 Steam配置] 配置完成后在角色类的头文件中添加一个变量用于存储获取到的会话接口 123456public: // 指向在线会话接口的指针 // #include &quot;Interfaces/OnlineSessionInterface.h&quot; 添加头文件 IOnlineSessionPtr OnlineSessionInterface; // IOnlineSessionPtr 就是 TSharedPtr&lt;class IOnlineSession, ESPMode::ThreadSafe&gt; // TSharedPtr&lt;class IOnlineSession, ESPMode::ThreadSafe&gt; OnlineSessionInterface; 然后在角色类的构造函数中获取到在线子系统，并通过在线子系统获取会话接口，然后打印出在线子系统的名称 12345678910// #include &quot;OnlineSubsystem.h&quot;IOnlineSubsystem* OnlineSubsystem = IOnlineSubsystem::Get();if (OnlineSubsystem)&#123; OnlineSessionInterface = OnlineSubsystem-&gt;GetSessionInterface(); if (GEngine) &#123; GEngine-&gt;AddOnScreenDebugMessage(-1, 15.f, FColor::Red, FString::Printf(TEXT(&quot;Found Subsystem %s&quot;), *OnlineSubsystem-&gt;GetSubsystemName().ToString())); &#125;&#125; 直接利用UE编译器运行，无论使用那种运行方式，发现打印显示都为NULL 这不是NULL指针，而是虚幻中有一个名为NULL的在线子系统，它是为陆地连接设计的，所以我们可以通过陆地连接测试在线子系统 结果显示： Found Subsystem NULL 我们将项目打包运行，发现这时，打印显示为Steam连接，并且右下角有Steam弹窗，这表示我们已经找到了Stea在线子系统 结果显示： Found Subsystem Steam","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE /虚幻 Steam配置","slug":"UE/UE 虚幻 Steam配置","date":"2025-04-27T01:48:47.000Z","updated":"2025-04-27T01:50:50.444Z","comments":true,"path":"2025/04/27/UE/UE 虚幻 Steam配置/","link":"","permalink":"http://www.formeasy.cc/2025/04/27/UE/UE%20%E8%99%9A%E5%B9%BB%20Steam%E9%85%8D%E7%BD%AE/","excerpt":"","text":"第一步：在项目插件中，打开Online Subsystem Steam 第二步：打开项目C++文件，在 .Build.cs文件下的公共依赖模块名称中添加 OnlineSubsystem 和 OnlineSubsystem 第三步：找到官方文档的OnlineSubsystemSteam的DefaultEngine.ini中需要添加的配置，并找到当前项目文件夹内的该文件，将配置内容添加上去，其中 SteamDevAppId 既开发者应用ID需要自己去Steam申请，这里480是Steam“太空战”使用的开发ID 第四步：关闭项目编译器和VisualStudio，找到项目文件下三个文件，将其删除后重新生成VisualStudio文件 以上就完成了UE中的Steam配置","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE/虚幻 简单局域网连接","slug":"UE/UE虚幻 简单局域网连接","date":"2025-04-25T06:47:00.000Z","updated":"2025-04-25T06:49:23.784Z","comments":true,"path":"2025/04/25/UE/UE虚幻 简单局域网连接/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%E8%99%9A%E5%B9%BB%20%E7%AE%80%E5%8D%95%E5%B1%80%E5%9F%9F%E7%BD%91%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"蓝图实现 创建一个联机地图，我命名为 “ onlineMap01 ” ，然后在角色蓝图中创建两个按钮事件，一个用于打开地图，另一个用于加入创建的地图 OpenLevel的options中的listen是指定监听服务器，简单来说就是将当前端设为服务端 可以利用UE编辑器直接开两个标准窗口测试，或者打包到同局域网下进行测试，不过如果是不同电脑，则需要修改ip地址，一端先按1键，创建地图，并将当前端设置为监听服务器，然后通过另一端按2键加入该地图 UEC实现 创建一个联机地图，我命名为 “ onlineMap01 ” ，然后去到角色类中，创建相关函数进行开启服务和加入服务 这里有两种方式加入服务 第一种是通过OpenLevel函数利用ip加入 第二种是通过获取当前玩家的玩家控制器，在利用玩家控制器的Client Travel 函数通过ip加入 头文件，申明所需要的自定义函数 123456UFUNCTION(BlueprintCallable) void OpenOnlineMap();UFUNCTION(BlueprintCallable) void CallOpenLevel(const FString&amp; Adr);UFUNCTION(BlueprintCallable) void CallClientTravel(const FString&amp; Adr); 源代码文件，实现函数功能 1234567891011121314151617181920212223// 创建服务void AOnLineTestingCharacter::OpenOnlineMap()&#123; UWorld* world = GetWorld(); if (world) &#123; // listen 为服务监听器 world-&gt;ServerTravel(&quot;/Game/Maps/onlineMap01?listen&quot;); &#125;&#125;// 第一种通过OpenLevel加入void AOnLineTestingCharacter::CallOpenLevel(const FString&amp; Adr)&#123; UGameplayStatics::OpenLevel(this, *Adr);&#125;// 第二种通过角色控制器加入void AOnLineTestingCharacter::CallClientTravel(const FString&amp; Adr)&#123; APlayerController* PlayerController = GetGameInstance()-&gt;GetFirstLocalPlayerController(); if (PlayerController) &#123; // 通过绝对路径加入 PlayerController-&gt;ClientTravel(Adr, ETravelType::TRAVEL_Absolute); &#125;&#125; 使用同蓝图部分，利用按键事件触发写好的自定义函数，使用两种方式皆可进入，且两个函数中的 Adr 是服务端的ip地址","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE/虚幻 蓄力攻击思路","slug":"UE/UE虚幻 蓄力攻击思路","date":"2025-04-25T06:44:42.000Z","updated":"2025-04-25T06:46:21.288Z","comments":true,"path":"2025/04/25/UE/UE虚幻 蓄力攻击思路/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%E8%99%9A%E5%B9%BB%20%E8%93%84%E5%8A%9B%E6%94%BB%E5%87%BB%E6%80%9D%E8%B7%AF/","excerpt":"","text":"蓄力攻击：按住攻击键一段时间后自动或松开时释放攻击 这里写的是按住攻击键一段时间后自动攻击。 通过两个布尔值进行判断，一个判断是否正在攻击（IsAttack），一个判断是否蓄力完成（IsFocoEenrgia），这里当蓄力部分完成时，那么这一次攻击就是蓄力攻击，在松开时就不需要进行普通攻击了。然后在每次按下攻击键时，重置一下蓄力的判断。 没有蓄力攻击（IsFocoEenrgia）这个布尔值，也能达到蓄力攻击的效果，不过这时如果一直按住攻击键到蓄力攻击结束，再松开攻击键，就会进行一次额外的普通攻击 但是如果蓄力攻击是在释放攻击键时进行的攻击部分就不需要考虑这个问题","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE/虚幻 组合键攻击思路","slug":"UE/UE虚幻 组合键攻击思路","date":"2025-04-25T06:42:45.000Z","updated":"2025-04-25T06:44:12.048Z","comments":true,"path":"2025/04/25/UE/UE虚幻 组合键攻击思路/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%E8%99%9A%E5%B9%BB%20%E7%BB%84%E5%90%88%E9%94%AE%E6%94%BB%E5%87%BB%E6%80%9D%E8%B7%AF/","excerpt":"","text":"通过第一次按键改变一个布尔值当松开或按下一段时间后重置该值，在短时间内值重置之前按下第二个按钮，达到组合键的效果 这是只有两个键的组合键，如果需要增加组合键的数量，只需要重复增加判断值，和1键按下的操作即可","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE蓝图 利用轴输入计算运动方向","slug":"UE/UE蓝图 利用轴输入计算运动方向","date":"2025-04-25T06:39:33.000Z","updated":"2025-04-25T06:42:01.348Z","comments":true,"path":"2025/04/25/UE/UE蓝图 利用轴输入计算运动方向/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%E8%93%9D%E5%9B%BE%20%E5%88%A9%E7%94%A8%E8%BD%B4%E8%BE%93%E5%85%A5%E8%AE%A1%E7%AE%97%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91/","excerpt":"","text":"首先获取到轴输入，前后为 Y 轴输入，左右为 X 轴输入，将这两个值存为一个 向量2D 再通过获取到的向量2D的值计算出运动的方向值 其中Direction得到的值为与具体方向如下图","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 利用代理/委托写一个生命组件","slug":"UE/UEC++ 利用代理委托写一个生命组件 ","date":"2025-04-25T06:29:45.000Z","updated":"2025-04-25T06:38:04.486Z","comments":true,"path":"2025/04/25/UE/UEC++ 利用代理委托写一个生命组件 /","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UEC++%20%E5%88%A9%E7%94%A8%E4%BB%A3%E7%90%86%E5%A7%94%E6%89%98%E5%86%99%E4%B8%80%E4%B8%AA%E7%94%9F%E5%91%BD%E7%BB%84%E4%BB%B6%20/","excerpt":"","text":"首先基于ActorComponent创建一个组件 HealthComponent，将需要的变量与函数创建 123456789101112131415161718192021222324252627282930313233343536#include &quot;CoreMinimal.h&quot;#include &quot;Components/ActorComponent.h&quot;#include &quot;HealthComponent.generated.h&quot;UCLASS( ClassGroup=(Custom), meta=(BlueprintSpawnableComponent) )class PVETPC_API UHealthComponent : public UActorComponent&#123; GENERATED_BODY()public: // Sets default values for this component&#x27;s properties UHealthComponent(); // 初始化健康值 UFUNCTION(BlueprintCallable) void Init(int taotalHealth,int currentHealth); // 造成伤害 UFUNCTION(BlueprintCallable) void HanldTakeAnyDamaged(AActor* DamagedActor, float Damage, const class UDamageType* DamageType, class AController* InstigatedBy, AActor* DamageCauser); // 恢复健康值 UFUNCTION(BlueprintCallable) void RestoreHealth(int restoreValue); UFUNCTION(BlueprintPure) float GetHealth() &#123; return CurrentHealth; &#125;protected: // 总健康值 float TotalHealth; // 当前健康值 float CurrentHealth; // Called when the game starts virtual void BeginPlay() override;public: // Called every frame virtual void TickComponent(float DeltaTime, ELevelTick TickType, FActorComponentTickFunction* ThisTickFunction) override;&#125;; 这里的 HanldTakeAnyDamaged 函数是通过代理绑定到拥有者身上 HanldTakeAnyDamaged 需要的形参需要与 OnTakeAnyDamage 的宏定义一致 除此之外还有OnTakePointDamage 和 OnTakeRadialDamage 也是一样的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &quot;Components/HealthComponent.h&quot;#include &quot;Engine.h&quot;#include &quot;Kismet/KismetSystemLibrary.h&quot;// Sets default values for this component&#x27;s propertiesUHealthComponent::UHealthComponent()&#123; // Set this component to be initialized when the game starts, and to be ticked every frame. You can turn these features // off to improve performance if you don&#x27;t need them. PrimaryComponentTick.bCanEverTick = true; // ...&#125;void UHealthComponent::Init(int taotalHealth, int currentHealth)&#123; TotalHealth = taotalHealth; CurrentHealth = currentHealth;&#125;void UHealthComponent::HanldTakeAnyDamaged(AActor* DamagedActor, float Damage, const class UDamageType* DamageType, class AController* InstigatedBy, AActor* DamageCauser)&#123; if (Damage &lt;= 0) &#123; return; &#125; CurrentHealth = FMath::Clamp( CurrentHealth - Damage , 0.f, TotalHealth); UE_LOG(LogTemp, Warning, TEXT(&quot;I am Demaged! CurrentHealth = %f&quot;), CurrentHealth);&#125;void UHealthComponent::RestoreHealth(int restoreValue)&#123; CurrentHealth = FMath::Clamp(CurrentHealth + restoreValue, 0.f, TotalHealth); GEngine-&gt;AddOnScreenDebugMessage(-1, 20, FColor::Red, FString(TEXT(&quot;I am RestoreHealth!&quot;)));&#125;// Called when the game startsvoid UHealthComponent::BeginPlay()&#123; Super::BeginPlay(); // 获取拥有者 AActor* MyOwner = GetOwner(); // 如果存在就将伤害接收函数绑定 if (MyOwner) &#123; UE_LOG(LogTemp, Warning, TEXT(&quot;I am bound!&quot;)); MyOwner-&gt;OnTakeAnyDamage.AddDynamic(this, &amp;UHealthComponent::HanldTakeAnyDamaged); &#125; Init(100,100); // ... &#125;// Called every framevoid UHealthComponent::TickComponent(float DeltaTime, ELevelTick TickType, FActorComponentTickFunction* ThisTickFunction)&#123; Super::TickComponent(DeltaTime, TickType, ThisTickFunction); // ...&#125; 这时候我们将该组件挂载在角色身上，已经有了效果，但是角色不知道组件生命值是否改变 接着我们在组件头文件的头文件申明下添加代理的宏定义，并创建一个代理对象 并在需要响应的函数中添加广播 1234567891011121314151617#include &quot;CoreMinimal.h&quot;#include &quot;Components/ActorComponent.h&quot;#include &quot;HealthComponent.generated.h&quot;// 自定义六参数代理事件DECLARE_DYNAMIC_MULTICAST_DELEGATE_SixParams(FOnHealthChangedSignature, UHealthComponent*, HealthComp, float, Health, float, HealthDelta, const class UDamageType*, DamageType, class AController*, InstigatedBy, AActor*, DamageCauser);...... // 恢复健康值 UFUNCTION(BlueprintCallable) void RestoreHealth(int restoreValue); UFUNCTION(BlueprintPure) float GetHealth() &#123; return CurrentHealth; &#125; // 定义代理 UPROPERTY(BlueprintAssignable, Category = &quot;Events&quot;) FOnHealthChangedSignature OnHealthChanged;...... 12345678void UHealthComponent::HanldTakeAnyDamaged(AActor* DamagedActor, float Damage, const class UDamageType* DamageType, class AController* InstigatedBy, AActor* DamageCauser)&#123; if (Damage &lt;= 0) &#123; return; &#125; CurrentHealth = FMath::Clamp( CurrentHealth - Damage , 0.f, TotalHealth); UE_LOG(LogTemp, Warning, TEXT(&quot;I am Demaged! CurrentHealth = %f&quot;), CurrentHealth); // 每当该函数被调用时，就将调用一次代理函数 OnHealthChanged.Broadcast(this, CurrentHealth, Damage, DamageType, InstigatedBy, DamageCauser);&#125; 最后再到拥有者类中添加一个用于回调的操作函数，其中形参对应在生命组件中定义的那样（注意命名是否重复） 头文件 1234// 代理事件UFUNCTION()void OnHealthChanged(UHealthComponent* OnwerHealthComp, float Health, float HealthDelta,const class UDamageType* DamageType, class AController* InstigatedBy, AActor* DamageCauser); cpp文件 123456789101112131415161718192021222324void APCharacter::OnHealthChanged(UHealthComponent* OnwerHealthComp, float Health, float HealthDelta, const class UDamageType* DamageType, class AController* InstigatedBy, AActor* DamageCauser)&#123; if (IsDeath) return; UE_LOG(LogTemp, Warning, TEXT(&quot;I know I was hurt! &quot;)); if (Health &lt;= 0 &amp;&amp; !IsDeath) &#123; UE_LOG(LogTemp, Warning, TEXT(&quot;I am Death! &quot;)); IsDeath = true; Death(); GetMovementComponent()-&gt;StopMovementImmediately(); GetCapsuleComponent()-&gt;SetCollisionEnabled(ECollisionEnabled::NoCollision); // 分离控制器 DetachFromControllerPendingDestroy(); // 3秒后执行 SetLifeSpan(3.0f); &#125;&#125;void APCharacter::BeginPlay()&#123; Super::BeginPlay(); HealthComp-&gt;OnHealthChanged.AddDynamic(this, &amp;APCharacter::OnHealthChanged); &#125; 最后测试，结果无误 LogWorld:Bringing up level for play took:0.000830 LogOnline:0SS:Creating online subsystem instance for: :Context 29 LogTemp: Warning: I am bound! PIE:Server logged in PIE:Play in editor total start time 0.184 seconds. LogTemp: Warning:I am Demaged! CurrentHealth=80.000000 LogTemp: Warning:I know I was hurt! LogTemp: Warning:I am Demaged! CurrentHealth=60.000000 LogTemp: Warning:I know I was hurt! LogTemp: Warning:I am Demaged! CurrentHealth=40.000000 LogTemp: Warning:I know I was hurt! LogTemp: Warning:I am Demaged! CurrentHealth=20.000000 LogTemp: Warning:I know I was hurt! LogTemp: Warning:I am Demaged! CurrentHealth=0.000000 LogTemp: Warning:I know I was hurt! LogTemp: Warning:I am Death!","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 播放蒙太奇动画","slug":"UE/UEC++ 播放蒙太奇动画","date":"2025-04-25T06:26:05.000Z","updated":"2025-04-25T06:29:23.922Z","comments":true,"path":"2025/04/25/UE/UEC++ 播放蒙太奇动画/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UEC++%20%E6%92%AD%E6%94%BE%E8%92%99%E5%A4%AA%E5%A5%87%E5%8A%A8%E7%94%BB/","excerpt":"","text":"在蓝图中播放蒙太奇动画，可以使用 PlayAnimMontage 和 PlayMontage，并且PlayMontage可以在，蒙太奇动画播放完的时候执行想要执行的程序 但是在UEC++中，没有PlayMontage（emmmm有可能只是我没找到） 这时候需要实现在播放蒙太奇动画之后需要的程序时间，可以在蒙太奇动画中添加一个通知，通过通知执行需要的程序 譬如利用蒙太奇播放一个攻击动画 12345678910// 头文件声明变量与攻击函数// 是否正在攻击bool IsAttack = false;UFUNCTION(BlueprintCallable) void Notify_EndAttack() &#123; IsAttack = false; &#125;// 需要播放的蒙太奇动画资源UPROPERTY(EditAnywhere, Category = &quot;Anim&quot;) class UAnimMontage* AttackMontage;// 攻击void Attack(); 实现攻击函数（记得绑定输入和添加操作映射） 1234567void APCharacter::Attack()&#123; if (!IsAttack) &#123; IsAttack = true; PlayAnimMontage(AttackMontage, 1.f); &#125;&#125; 这时候使用攻击函数播放攻击动画，只能播放一次，当播放完之后就无法再播放第二次，而如果在Attack() 中 PlayAnimMontage(AttackMontage, 1.f) 下添加IsAttack = false; 就会立即重置，无法达到想要的效果，而导致攻击鬼畜 再去角色类中添加一个函数，用于实现结束攻击需要执行的功能 12UFUNCTION(BlueprintCallable)void Notify_EndAttack() &#123; IsAttack = false; &#125; 然后在动画蓝图中执行添加的通知 现在去执行就可以！","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE C++实现第三人称角色基本功能","slug":"UE/UE C++实现第三人称角色基本功能","date":"2025-04-25T06:17:27.000Z","updated":"2025-04-25T06:25:28.489Z","comments":true,"path":"2025/04/25/UE/UE C++实现第三人称角色基本功能/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%20C++%E5%AE%9E%E7%8E%B0%E7%AC%AC%E4%B8%89%E4%BA%BA%E7%A7%B0%E8%A7%92%E8%89%B2%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/","excerpt":"","text":"首先基于Character创建一个角色类，在头文件为其添加弹簧臂和摄像机组件 1234UPROPERTY(VisibleAnywhere, Category = &quot;Comp&quot;) class UCameraComponent* CameraComp;UPROPERTY(VisibleAnywhere, Category = &quot;Comp&quot;) class USpringArmComponent* SpringComp; 在构造函数中将相关组件创建出来 12345678910111213141516171819202122// 所需要添加的头文件#include &quot;Camera/CameraComponent.h&quot;#include &quot;GameFramework/SpringArmComponent.h&quot;#include &quot;GameFramework/CharacterMovementComponent.h&quot; // 创建摄像机组件 CameraComp = CreateDefaultSubobject&lt;UCameraComponent&gt;(TEXT(&quot;CameraComp&quot;)); // 创建弹簧臂组件 SpringComp = CreateDefaultSubobject&lt;USpringArmComponent&gt;(TEXT(&quot;SpringComp&quot;)); // 将弹簧臂附加到根组件上 SpringComp-&gt;SetupAttachment(RootComponent); // 将摄像机组件附加到弹簧臂组件上 CameraComp-&gt;SetupAttachment(SpringComp); // 使用Pawn控制旋转 SpringComp-&gt;bUsePawnControlRotation = true; CameraComp-&gt;bUsePawnControlRotation = true; // 如果为真 会跟随控制器移动 bUseControllerRotationRoll = false; bUseControllerRotationYaw = false; bUseControllerRotationPitch = false; // 旋转朝向移动 GetCharacterMovement()-&gt;bOrientRotationToMovement = true; //GetCharacterMovement()-&gt;RotationRate = FRotator(0.f, 500.f, 0.f); 回到角色类头文件中，申明所需的移动、视角旋转函数 1234void MoveForward(float value);void MoveRight(float value);void Turn(float value);void LookUp(float value); 实现移动、视角旋转函数，并且绑定输入 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748void APCharacter::MoveForward(float value)&#123; if (Controller != NULL &amp;&amp; value != 0) &#123; // 获取控制器旋转 const FRotator ControllerRotator = Controller-&gt;GetControlRotation(); // 制造一个只有Z轴的旋转 const FRotator YawRotator(0.f, ControllerRotator.Yaw, 0.f); // 获取控制器向前的方向向量 即获取YawRotator的单位长度轴 const FVector Direction = FRotationMatrix(YawRotator).GetUnitAxis(EAxis::X); AddMovementInput(Direction, value); &#125; &#125;void APCharacter::MoveRight(float value)&#123; if (Controller != NULL &amp;&amp; value != 0) &#123; const FRotator ControllerRotator = Controller-&gt;GetControlRotation(); const FRotator YawRotator(0.f, ControllerRotator.Yaw, 0.f); const FVector Direction = FRotationMatrix(YawRotator).GetUnitAxis(EAxis::Y); AddMovementInput(Direction, value); &#125;&#125;void APCharacter::Turn(float value)&#123; if (Controller != NULL &amp;&amp; value != 0) &#123; AddControllerYawInput(value); &#125;&#125;void APCharacter::LookUp(float value)&#123; if (Controller != NULL &amp;&amp; value != 0) &#123; AddControllerPitchInput(value); &#125;&#125;// Called to bind functionality to inputvoid APCharacter::SetupPlayerInputComponent(UInputComponent* PlayerInputComponent)&#123; Super::SetupPlayerInputComponent(PlayerInputComponent); PlayerInputComponent-&gt;BindAxis(&quot;MoveForward&quot;, this, &amp;APCharacter::MoveForward); PlayerInputComponent-&gt;BindAxis(&quot;MoveRight&quot;, this, &amp;APCharacter::MoveRight); PlayerInputComponent-&gt;BindAxis(&quot;Turn&quot;, this, &amp;APCharacter::Turn); PlayerInputComponent-&gt;BindAxis(&quot;LookUp&quot;, this, &amp;APCharacter::LookUp);&#125; 回到虚幻编辑器中，在项目设置中添加，相关的操作映射 Axis Mappings MoveForward W Scale 1.0 S Scale -1.0 MoveRight D Scale 1.0 A Scale -1.0 Turn Mouse X Scale 1.0 LookUp Mouse Y Scale -1.0 再创建一个相关蓝图类，将模型与动画蓝图设置上就完成了","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE 文件目录结构","slug":"UE/UE 文件目录结构","date":"2025-04-25T06:14:16.000Z","updated":"2025-04-25T06:16:55.036Z","comments":true,"path":"2025/04/25/UE/UE 文件目录结构/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%20%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/","excerpt":"","text":"在最高一级目录中，是你的引擎（Engine）目录以及你的所有游戏项目目录。Engine目录包含引擎自身及其随附工具。每个游戏目录都包含与该游戏有关的所有文件。与先前的引擎版本相比，UE4中的引擎和游戏在目录结构上有了更明显的区分。 根目录 Engine - 包含构成引擎的所有源代码、内容等。 Templates - [创建新项目](Basics/Projects/Browser) 时可用的项目模板集合。 GenerateProjectFiles.bat - 用于创建在Visual Studio中使用引擎和游戏所需的UE4解决方案和项目文件。请参阅 [](ProductionPipelines/BuildTools/UnrealBuildTool/ProjectFilesForIDEs) 以了解详细信息。 UE4Games.uprojectdirs - 辅助文件，帮助引擎找到子目录中的项目。 通用目录 某些子目录在引擎目录和游戏项目目录中都能找到： Binaries - 包含可执行文件或编译期间创建的其他文件。 Build - 包含编译引擎或游戏所需的文件，包括为某些特定平台创建项目版本时所需的文件。 Config - 配置文件，包含的参数可用于控制引擎的行为。你在游戏项目Config文件中设置的值会覆盖 Engine\\Config 目录中设置的值。 Content - 保存引擎或游戏中的内容，例如资产包、贴图。 DerivedDataCache - 包含派生数据文件。这类数据专为被引用内容生成，并且在加载时生成。假如被引用内容未生成过缓存文件，则加载时间会显著增加。 Intermediate - 包含编译引擎或游戏时生成的临时文件。在游戏目录中，着色器也保存在Intermediate目录中。 Saved - 包含自动保存文件、配置（.ini）文件和日志文件。此外，Engine &gt; Saved 目录还包含崩溃日志、硬件信息和Swarm选项与数据。 Source - 包含引擎或游戏的所有源文件，包括引擎源代码、工具和游戏类等。 Engine - Engine目录中的源文件组织结构如下： Developer - 编辑器和引擎共同使用的文件。 Editor - 仅供编辑器使用的文件。 Programs - 引擎或编辑器使用的外部工具。 Runtime - 仅供引擎使用的文件。 Game - 游戏项目目录中的源文件按模块分组，一个模块一个目录。每个模块包含以下内容： Classes - 包含所有的头文件（.h）。 Private - 包含所有 .cpp 文件，包括游戏逻辑类以及各种模块的实现文件。 Public - 包含模块的头文件。 引擎专有目录 部分子目录只存在于Engine目录中。 Documentation - 包含引擎文档，包括源文件和发布的文件。 HTML - 发布的HTML文档文件。 Source - 源markdown文档文件。 Extras - 其他辅助和工具文件。 Plugins - 包含引擎中使用的插件。 Programs - 包含UE4根目录中各个项目及其他虚幻程序（如UnrealFrontend和UnrealHeaderTool）的配置文件和日志文件。 Shaders - 保存引擎的着色器源文件（.usf）。 游戏项目目录 目录 说明 Binaries 包含可执行文件或编译期间创建的其他文件。 Config 游戏的默认项目设置。 Content 包含引擎或游戏的内容，包括资产包和贴图。 External dependencies 显示公有的引擎头文件（仅在Visual Studio中可见）。 Intermediate 包含UnrealBuildTool生成的文件，如Visual Studio项目文件。这些文件可以删除并重新构建。 Saved 包含引擎生成的文件，如配置文件和日志。这些文件可以删除并重新构建。 Source 包含游戏模块对象类文件。 解决方案目录 目录 说明 Classes 包含游戏对象的类定义（.h 文件）。 Config 游戏的默认项目设置。 External dependencies 显示公有引擎头文件（仅在Visual Studio中可见）。 Private 包含私有游戏对象类的实现文件（.cpp 文件）。 Public 包含公有游戏对象类的实现文件（.cpp 文件）。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE 术语","slug":"UE/UE 术语","date":"2025-04-25T06:11:46.000Z","updated":"2025-04-25T06:13:17.933Z","comments":true,"path":"2025/04/25/UE/UE 术语/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UE%20%E6%9C%AF%E8%AF%AD/","excerpt":"","text":"项目 虚幻引擎项目（Project） 保存着构成游戏所需的所有内容和代码。项目在你的电脑硬盘上由许多目录构成，例如 蓝图 和 材质。你可以随时修改项目目录的名称和层级关系。 虚幻编辑器 中的 内容浏览器 所展示的目录结构和你在硬盘上看到的 项目 目录结构相同。 _内容浏览器面板会镜像显示磁盘上的项目目录结构。点击图片查看大图。 每个项目都有一个与之对应的 .uproject 文件。.uproject 文件是你创建、打开或保存项目必须用到的文件。你可以创建任何数量的不同项目，并同时操作它们。 蓝图 蓝图可视化脚本（Blueprint Visual Scripting） 系统（或缩写 蓝图（Blueprints））是一种功能齐全的游戏脚本系统，它允许你在虚幻编辑器（Unreal Editor）中通过基于节点的界面来创建游戏元素。和许多常见脚本语言一样，你可以用它在引擎中定义面向对象的类或object。在使用UE4时，你会发现使用蓝图定义的类一般也统称蓝图。 对象 在虚幻引擎中，最基本的类叫做 Object。换句话说，它就像最基本的构建单位，包含了资产的基本功能。虚幻引擎中的大多数类都继承自Object（或从中获取部分功能）。 在C++中，UObject 是所有Object的基类，包含各类功能，诸如垃圾回收、通过元数据（UProperty）将变量公开给编辑器，以及保存和加载时的序列化功能。 类 类（Class） 用于定义虚幻引擎中Actor或对象的行为和属性。类可以被继承，这意味着某个类可以从其父类（衍生或派生出该类的类）获得信息，然后再将信息传递给子类。类可用C++代码或蓝图创建。 Actor 所有可以放入关卡的对象都是 Actor，比如摄像机、静态网格体、玩家起始位置。Actor支持三维变换，例如平移、旋转和缩放。你可以通过游戏逻辑代码（C++或蓝图）创建（生成）或销毁Actor。 在C++中，AActor是所有Actor的基类。 类型转换 类型转换（Casting） 本质上是获取某个特定Actor（或类），然后将它视为另一种类进行处理。类型转换可以成功，也可以失败。如果转换成功，你就能访问目标Actor的特有函数和功能。 举个例子，你希望在游戏中创建多种体积，让它们以不同方式影响玩家。其中一个体积是 火焰，它会不断伤害玩家生命值。当玩家遇到关卡中的体积时，你可以将该体积 转换 成 火焰，以此访问它的&quot;伤害玩家&quot;函数。 如果转换成功，表示玩家站在火中，那么玩家生命值就会开始减少。 如果转换失败，表示玩家站在其他体积中，那么生命值不会减少。 类型转换不同于单纯地检查某个Actor是否属于某个类，然后返回一个二元值（是或否）；这种情况下，你无法访问该类的函数。 组件 组件（Component） 是可以添加到Actor上的一项功能。 当你为Actor添加组件后，该Actor便获得了该组件所提供的功能。例如： 聚光灯组件（Spot Light Component）允许你的Actor像聚光灯一样发光， 旋转移动组件（Rotating Movement Component）能使你的Actor四处旋转， 音频组件（Audio Component）将使你的Actor能够播放声音。 组件必须绑定在Actor身上，它们无法单独存在。 Pawn Pawn 是Actor的子类，它可以充当游戏中的化身或人物（例如游戏中的角色）。Pawn可以由玩家控制，也可以由游戏AI控制并以非玩家角色（NPC）的形式存在于游戏中。 当Pawn被人类玩家或AI玩家控制时，它被视为 已被控制（Possessed）。相反，当Pawn未被人类玩家或AI玩家控制时，它被视为 未被控制（Unpossessed）。 角色 角色（Character） 是Pawn Actor的子类，旨在用作玩家角色。角色子类包括碰撞设置、双足运动的输入绑定，以及用于控制运动的附加代码。 玩家控制器 玩家控制器（Player Controller） 会获取游戏中玩家的输入信息，然后转换为交互效果，每个游戏中至少有一个玩家控制器。玩家控制器通常会控制一个Pawn或角色，将其作为玩家在游戏中的化身。 玩家控制器还是多人游戏中的主要网络交互节点。在多人游戏中，服务器会为游戏中的每个玩家生成一个玩家控制器实例，因为它必须对每个玩家进行网络函数调用。每个客户端只拥有与其玩家相对应的玩家控制器，并且只能使用其玩家控制器与服务器通信。 相关的C++类是 PlayerController。 AI控制器 玩家控制器通过控制Pawn来表示游戏中的玩家，与此类似，AI控制器 通过控制Pawn来表示游戏中的非玩家角色（NPC）。默认情况下，Pawn和角色最终都会由基本的AI控制器控制，除非它们被指定通过玩家控制器控制，或被告知不需要为它们自己创建AI控制器。 关联的C++类是 AIController。 玩家状态 玩家状态（Player State） 表示某个游戏参与者的状态，可以是人类玩家，也可以是模拟玩家的机器人。作为游戏场景的一部分而存在的非玩家类AI不会有玩家状态。 玩家状态（Player State）能包括的玩家信息包括： 名称 当前关卡 生命值 分数 在某些抢旗游戏中，玩家当前是否携带旗子。 在多人游戏中，所有电脑都保存着所有玩家的玩家状态，并且玩家状态可以将数据从服务器复制到客户端以保持同步。这点与玩家控制器不同，它只会保存在玩家所在的客户端上。 关联的C++类是 PlayerState。 游戏模式 游戏模式（GameMode） 类负责设置当前游戏的规则。规则包括： 玩家如何加入游戏。 是否可以暂停游戏。 任何与游戏相关的行为，例如获胜条件。 你可以在 项目设置中设置默认的游戏模式，也可以关卡中覆盖这些设置。无论你如何实现游戏模式，每个关卡始终只能有一个游戏模式。 在多人游戏中，游戏模式只存在于服务器上，规则会被复制（发送）给所有联网的客户端。 相关的C++类是 GameMode。 游戏状态 游戏状态（GameState） 是一种容器，保存着你希望在游戏中复制给每个客户端的信息。简而言之，它表示每个联网玩家的&quot;游戏状态&quot;。 游戏状态包含的部分信息包括： 游戏分数 比赛是否已开始 根据场景中玩家的人数，需要生成多少AI 如果是多人游戏，则每个玩家的电脑上都只有一个游戏状态实例，而服务器的实例为权威实例（即客户端的信息更新来源）。 相关的C++类是 GameState。 笔刷 笔刷（Brush） 是一种Actor，用于描述一个3D几何体，例如方形或圆形。你可以在关卡中应用笔刷，以便定义关卡几何体（称为二元空间划分笔刷，简称BSP笔刷）。假如你想快速搭建关卡，则可以使用这种方法。 体积 体积（Volumes） 是一种存在边框的3D空间，会根据施加给它们的效果产生不同的用途。例如： 阻挡体积（Blocking Volumes），一种不可见的体积，用来防止Actor穿过它们。 伤害生成体积（Pain Causing Volumes），会对进入它们的Actor产生持续性的伤害。 触发体积（Trigger Volumes），可以通过编程，让Actor在进入或离开它们是触发事件。 关卡 关卡（Level） 是用户定义的游戏区域。关卡包含了玩家能看到的所有内容，例如几何体、Pawn和Actor。 在虚幻编辑器中，每个关卡都被保存为单独的 .umap 文件，它们有时也被称为 地图。 世界 世界场景（World） 是一个容器，包含了游戏中的所有关卡。它可以处理关卡流送，还能生成（创建）动态Actor。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 智能指针——共享指针、共享引用、弱指针","slug":"UE/UEC++ 智能指针——共享指针、共享引用、弱指针","date":"2025-04-25T06:06:10.000Z","updated":"2025-04-25T06:11:01.997Z","comments":true,"path":"2025/04/25/UE/UEC++ 智能指针——共享指针、共享引用、弱指针/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UEC++%20%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E2%80%94%E2%80%94%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E3%80%81%E5%85%B1%E4%BA%AB%E5%BC%95%E7%94%A8%E3%80%81%E5%BC%B1%E6%8C%87%E9%92%88/","excerpt":"","text":"C++ 中，往往令人头痛的是指针的管理问题！在对象动态构建时，我们需要将对象指针进行存储，一旦忘记释放，那么将会导致不可预估的错误。在C++中排查指针导致的内存泄漏问题实在令人头痛！在虚幻中，为了解决此类问题，加入了智能指针（共享指针，共享引用，弱指针），当我们使用动态方式构建对象时，再也不需要担心内存释放问题！指针的释放规则由引擎制定，包括释放时机！ 1、自定义类 在构建自定义类时，我们经常遇到一种情况，当类中持有U类对象指针时，我们希望阻止垃圾回收器对对象释放。但是自定义类中又无法使用UPROPERTY宏，那么我们可以采取将类继承自FGCObject，并重写父类函数AddReferencedObjects。将需要阻止释放的指针加入到操作队列，以防止对象被垃圾回收器回收！ 注意：当构建类被释放时（需要我们保证），并且调用其析构函数（析构函数需要重写父类析构函数），对象将自动清除其所添加的所有引用。 2、智能指针 虚幻中存在一套非常强大的动态内存管理机制，而这套机制中根本在于智能指针（非侵入式），并且UE的智能指针速度相比STL更快，速度和普通C++指针速度一样。 智能指针本质的目的是将释放内存工作进行托管。当两个智能指针指向同一个空间，一个设置为空，另一个不会跟随为空，智能指针设置为空并不是释放内存空间，只是在减少空间引用。 注意：智能指针只能使用于自定义类，U类禁止使用 共享指针和共享引用的优点： 三个指针 3、共享指针 共享指针是虚幻中最常用的智能指针，在操作上可以帮助我们构建托管内存指针！共享指针本身非侵入式的，这使得指针的使用与操作和普通指针一致！共享指针支持主动指向空，并且共享指针是线程安全的，节省内存，性能高效 注意：构建自定义类时，需要使用 F 开头 基本操作语法： 123456789// 自定义类class MX_API FTestClass&#123;public: FTestClass(); ~FTestClass(); void TestFun();&#125;; 1234567891011121314151617181920212223// 其他类// 构建一个共享指针，但是没有维护任何空间TSharedPtr&lt;FTestClass&gt; Ftc01;// 不推荐// 构建一个共享指针，并维护一快内存TSharedPtr&lt;FTestClass&gt; Ftc02(new FTestClass());//MakeShareable函数是用来构建共享指针的快捷方式// 构建一个共享指针，并维护一快内存TSharedPtr&lt;FTestClass&gt; Ftc03 = MakeShareable(new FTestClass());// 解引用和操作Ftc02-&gt;TestFun();Ftc02.Get()-&gt;TestFun();(*Ftc02).TestFun();// 比较两个智能管理的内存是否是同一个if (Ftc02 == Ftc03) &#123;&#125;// 判断是否为空 注意操作函数是共享指针的成员函数if (Ftc02.IsValid()) &#123;&#125;// 注意操作函数是共享指针的成员函数if (Ftc02.Get() == nullptr) &#123;&#125;// 获取引用计时器 获得当前地址被引用个数Ftc02.GetSharedReferenceCount();// 释放Ftc02.Reset();Ftc03 = nullptr; 4、共享引用 共享引用禁止为空，表明了共享引用创建后必须给予有效初始化，可以使得代码更加安全简洁，保证了对象访问的安全性。无法主动释放共享引用，可以跟随对象释放减少引用计数器 共享引用的安全性体现在，如果使用共享引用构建的对象，无法将对象空间设置为空。如果想释放内存，可以借助指向其他共享引用来减少引用计数，来释放空间 共享引用本质，无法主动减少引用计数器，只能通过被动方法，例如生命周期终结，共享引用易主 基本语法操作 12345678910111213// 定义TSharedRef&lt;FTestClass&gt; Ftc01;// 错误执行将导致崩溃TSharedRef&lt;FTestClass&gt; Ftc02(new FTestClass);// 正确// 解引用操作Ftc02-&gt;TestFun();(*Ftc02).TestFun();// 返回cosnt 引用 ，禁止将对象主动释放const FTestClass&amp; Ftc03 = Ftc02.Get();// 和共享指针转换// 共享引用支持隐式转换为共享指针，由于共享引用是安全的，所以转换是隐式转换TSharedPtr&lt;FTestClass&gt; Ftc04 = Ftc02;// 从共享指针转换到共享引用是不安全的，所以需要调用TS函数TSharedRef&lt;FTestClass&gt; Ftc05 = Ftc04.ToSharedRef(); 5、弱指针 不会阻止对象的销毁，如果引用对象被销毁，则弱指针也将自动清空。一般弱指针的操作意图是保存了一个到达目标对象的指针，担不会控制该对象的生命周期，弱指针不会增加引用计数，可以用来断开引用循环问题。 、 无论谁销毁了对象，只要其对象被销毁，弱指针都将自动清空，这使你能够安全缓存指向可变对象的指针。这也意味着，弱指针可能会意外清空，并且，你可以使用弱指针断开引用循环。 当不再存在对对象的共享引用时，弱指针的对象将被销毁。 弱指针有助于表明意图。当你在某个类中看到一个弱指针时，你就会明白该类仅缓存指向对象的指针，它并不控制它的生命周期。 基本语法操作 123456789101112131415// 定义// 构建空的弱指针TWeakPtr&lt;FTestClass&gt; WpFtc01;// 利用共享指针构建弱指针TSharedPtr&lt;FTestClass&gt; PFtc;TWeakPtr&lt;FTestClass&gt; WpFtc02(PFtc);// 利用共享引用构建弱指针TSharedRef&lt;FTestClass&gt; RFtc;TWeakPtr&lt;FTestClass&gt; WpFtc03(RFtc);// 检查是否有效// 检查弱指针指向的对象空间是否存在if (WpFtc01.IsValid()) &#123;&#125;// 释放操作// 主动释放，但是不会影响引用计数WpFtc01 = nullptr; 总结 一块内存，如果存在有效引用（可直接到达内存的操作方式），则我们可以认为当前内存是有效并且合理的！但是当一块内存不存在引用，则我们可以视为此块内存为被弃用无效的，则可以回收重复利用，这就是内存垃圾回收机制的基本原理。 智能指针强调的是当前内存的使用者存在多少，当不存在时，进行回收！ 注意：智能指针构建的均是栈对象数据类型","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 接口","slug":"UE/UEC++ 接口","date":"2025-04-25T06:02:04.000Z","updated":"2025-04-25T06:05:32.104Z","comments":true,"path":"2025/04/25/UE/UEC++ 接口/","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UEC++%20%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"词义广泛，用来陈述功能，选项，与其他程序结构进行沟通的方式。接口抽象出了交互结构，提供了两个未知逻辑交互的便捷性。对于编程中，如何更好的设计低耦合程序起到了至关重要的作用。设计者可以在互不关心的情况下，进行友好的程序设计，并且通过接口来完成设计的整合交互。 虚幻引擎中，加入了接口设计，从一定程度上“去掉了”多继承。接口可以帮助我们解决在不同类型的类之间却有相同行为的特性。接口的设计增加了代码编写的便捷性。 例如在设计射击类游戏时，我们需要子弹与场景中的物体进行交互，场景中的桌椅板凳，角色，怪物（都是独立的对象）都希望受到子弹的攻击伤害。那么子弹在打到目标后要逐一排查，审查目标是否属于上述的对象！这很麻烦！但是我们可以通过接口，增加上述目标具有受伤的能力。当子弹打到目标时，我只需要检查目标是否继承受伤的接口，如果有，则调用接口函数即可！ 构建接口类： 我们可以直接在虚幻编辑器中继承接口类，然后完成构建 编写接口： 如果在C++中希望获得接口能力，则需要继承接口。需要注意的是，必须继承I开头的接口名称，并且继承修饰为public。不要尝试重写接口中的函数！ 如果接口中的函数使用BlueprintNativeEvent说明，则在继承类中可以编写同名函数，并用后缀“_Implementation”进行标记。 如果接口中的函数使用BlueprintImplementableEvent说明，则无法在C++的继承类中实现接口函数 实现接口： 继承I类接口完毕后，可以选择的将接口中的函数进行定义。如果需要定义，则需要将接口中函数说明是BlueprintNativeEvent的函数进行定义。 注意，不要省略override，函数的返回值，参数列表需要和接口的一致 调用操作： 调用函数，持有继承接口对象指针，第一步先转换到I类指针，调用Execute_接口函数名，参数第一位需要传递原对象指针，后面直接按照原函数参数填入即可 整体代码演示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// TestInterface.hUINTERFACE(MinimalAPI)class UTestInterface : public UInterface&#123; GENERATED_BODY()&#125;;/** * 1、U类中不能去写接口函数，只能用来检查是否继承了接口类 * 2、接口函数，必须写在I类中，并且必须写共有域中 * 3、接口函数在接口类中不能进行定义 * */class MX_API ITestInterface&#123; GENERATED_BODY() // Add interface functions to this class. This is the class that will be inherited to implement this interface.public: // 定义接口函数 UFUNCTION(BlueprintNativeEvent) void Notify_None(); UFUNCTION(BlueprintNativeEvent) int32 Notify_RetVal(); UFUNCTION(BlueprintNativeEvent) int32 Notify_RetVal_Params(int32 Num);&#125;;/////////////////////////////////////////////////////////////// Actor2.hpublic: // Called every frame virtual void Tick(float DeltaTime) override; // 实现接口 virtual void Notify_None_Implementation() override; virtual int32 Notify_RetVal_Implementation() override; virtual int32 Notify_RetVal_Params_Implementation(int32 Num) override;// Actor2.cppvoid AActor2::Notify_None_Implementation()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----无参无返回值----&quot;));&#125;int32 AActor2::Notify_RetVal_Implementation()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----无参有返回值----&quot;)); return 0;&#125;int32 AActor2::Notify_RetVal_Params_Implementation(int32 Num)&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----有参有返回值----&quot;)); return Num;&#125;void AActor2::Notify_None_Implementation()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----无参无返回值----&quot;));&#125;int32 AActor2::Notify_RetVal_Implementation()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----无参有返回值----&quot;)); return 0;&#125;int32 AActor2::Notify_RetVal_Params_Implementation(int32 Num)&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;----有参有返回值----&quot;)); return Num;&#125;///////////////////////////////////////////////////////////Actor1.cpp ac2 = GetWorld()-&gt;SpawnActor&lt;AActor2&gt;(AActor2::StaticClass()); // 检查是否继承了接口 ITestInterface* testInterface = Cast&lt;ITestInterface&gt;(ac2); // 如果继承了接口，就执行接口函数 if (testInterface) &#123; testInterface-&gt;Execute_Notify_None(ac2); testInterface-&gt;Execute_Notify_RetVal(ac2); testInterface-&gt;Execute_Notify_RetVal_Params(ac2,10); &#125; 测试结果： ----有参有返回值---- ----无参有返回值---- ----无参无返回值---- 包裹接口： 借助模板类TScriptInterface可以将接口包裹，用于使用UPROPERTY描述，并且可以暴露到蓝图中。使用时同普通接口一样使用。接口不支持智能指针的管理，所以需要使用TS类进行管理 12UPROPERTY(EditAnywhere)TScriptInterface&lt;ITestInterface&gt; TestInterface; 蓝图继承接口： 如果接口在蓝图中被继承，则需要注意下面的问题 如果函数没有返回类型，则在蓝图中当作事件Event使用 如果函数存在返回类型或是存在传递引用参数，则在蓝图中当作函数使用 接口函数说明符使用BlueprintNativeEvent或是BlueprintImplementableEvent标记都可以在蓝图中找到 总结： 接口函数需要定在I开头的类中，不要修改访问域public关键字，声明需要使用宏标记BlueprintNativeEvent或BlueprintImplementableEvent 如需继承接口，继承I类，继承关系public 接口中的函数禁止重写 在继承类中实现接口函数，并添加后缀_Implementation，需要注意，函数前加入虚函数关键字virtual，函数结尾加override关键字（可以不添加，但是建议加上，加强函数编写正确性检查），在CPP文件中实现逻辑 调用函数，持有继承接口对象指针，第一步先转换到I类指针，调用Execute_接口函数名，参数第一位需要传递原对象指针，后面直接按照原函数参数填入即可 检查某一个类是否实现了对应接口可以使用如下语法进行检查 obj-&gt;GetClass()-&gt;ImplementsInterface(U类型：：StaticClass（）); act-&gt;GetClass()-&gt;ImplementsInterface(UMyInterface::StaticClass()); act是对象指指针 接口的优缺点： 优点： 具备多态特性，接口衍生类支持里氏转换原则 接口可以使得整个继承系统更加的干净单一 接口可以规范类的具体行为 接口可以隔离开发中的开发耦合，我们只需要针对接口去编码，无需关心具体行为 接口继承可以使得继承关系中出现真正的操作父类 缺点： 丢失了C++中的广泛继承特性 接口拘束了类型的属性拓展，无法进行更详细的内容定义 继承关系中容易让人混淆，接口本身不具备真正的继承特性","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 事件","slug":"UE/UEC++ 事件 ","date":"2025-04-25T05:57:36.000Z","updated":"2025-04-25T06:01:12.549Z","comments":true,"path":"2025/04/25/UE/UEC++ 事件 /","link":"","permalink":"http://www.formeasy.cc/2025/04/25/UE/UEC++%20%E4%BA%8B%E4%BB%B6%20/","excerpt":"","text":"事件本身和多播代理一样，为了操作的安全性，事件提供了额外的操作限定。即禁止在声明事件对象的外部调用事件传播，清理，检查等函数。通过操作隔离，最大程度的增加了事件的安全性。派生类允许调用事件的广播。 在虚幻C++中事件和多播几乎相同。只是构建方式略不同 构建宏 事件类型构建宏由于需要限定事件对象调用约束关系，需要提供声明所在类型，并且需要在类内部进行声明。事件没有返回值。 声明宏 描述 DECLARE_EVENT( OwningType, EventName ) 创建一个事件。 DECLARE_EVENT_OneParam( OwningType, EventName, Param1Type ) 创建带一个参数的事件。 DECLARE_EVENT_TwoParams( OwningType, EventName, Param1Type, Param2Type ) 创建带两个参数的事件。 DECLARE_EVENT_&lt;Num&gt;Params( OwningType, EventName, Param1Type, Param2Type, ...) 创建带 N 个参数的事件。 注：OwningType即当前声明事件的类 绑定函数与广播：与多播代理的绑定相同 函数 说明 “Add()” 将函数委托添加到该多播委托的调用列表中。 “AddStatic()” 添加原始C++指针全局函数委托。 “AddRaw()” 添加原始C++指针委托。原始指针不使用任何类型的引用，因此如果从委托下面删除了对象，则调用此函数可能不安全。调用Execute()时请小心！ “AddSP()” 添加基于共享指针的（快速、非线程安全）成员函数委托。共享指针委托保留对对象的弱引用。 “AddUObject()” 添加基于UObject的成员函数委托。UObject委托保留对对象的弱引用。 “Remove()” 从该多播委托的调用列表中删除函数（性能为O(N)）。请注意，委托的顺序可能不会被保留！ “RemoveAll()” 从该多播委托的调用列表中删除绑定到指定UserObject的所有函数。请注意，委托的顺序可能不会被保留！ 执行：调用函数Broadcast，但是调用不保证执行顺序的正确性。事件广播无需检查是否存在有效的绑定。事件广播应发生在声明事件类型的类内部。 事件构建步骤： 1234567891011121314151617181920212223// Actor1.hprotected: class AActor2* ac2;public: // 事件在类内定义 DECLARE_EVENT(AActor1, FActorEvent) FActorEvent&amp; OnChanged_FActorEvent() &#123; return actorEvent; &#125;private: FActorEvent actorEvent;// Actor1.cpp ac2 = GetWorld()-&gt;SpawnActor&lt;AActor2&gt;(AActor2::StaticClass()); OnChanged_FActorEvent().AddUObject(ac2, &amp;AActor2::CallBackNone); OnChanged_FActorEvent().Broadcast();//////////////////////////////////////////////////// Actor2.h void CallBackNone();// Actor2.cppvoid AActor2::CallBackNone()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;无返回值无参数函数调用！&quot;));&#125; 测试结果： 无返回值无参数函数调用！","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"在Win7上安装VS2017的问题","slug":"VS/在Win7上安装VS2017的问题","date":"2025-04-24T09:32:43.000Z","updated":"2025-04-25T02:08:21.460Z","comments":true,"path":"2025/04/24/VS/在Win7上安装VS2017的问题/","link":"","permalink":"http://www.formeasy.cc/2025/04/24/VS/%E5%9C%A8Win7%E4%B8%8A%E5%AE%89%E8%A3%85VS2017%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"在Win7上安装VS2017的问题 win7安装2017需要授信任证书 certificates，找到这个目录，里面应该有三个文件需要双击操作一下，具体如下： 需要安装certifiates目录下的3个证书 选择【将所有证书放入下列存储】 证书存储：【受信任的根证书颁发机构】","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"}],"author":"易锦风"},{"title":"Qt中的信号与槽机制详解：连接、自定义与应用","slug":"Qt/Qt中的信号与槽机制详解：连接、自定义与应用","date":"2025-04-24T06:05:59.000Z","updated":"2025-04-24T06:24:23.451Z","comments":true,"path":"2025/04/24/Qt/Qt中的信号与槽机制详解：连接、自定义与应用/","link":"","permalink":"http://www.formeasy.cc/2025/04/24/Qt/Qt%E4%B8%AD%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%B8%8E%E6%A7%BD%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%EF%BC%9A%E8%BF%9E%E6%8E%A5%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%BA%94%E7%94%A8/","excerpt":"","text":"（一）信号和槽概述 在Qt中，每次用户与控件互动的过程都被称为一个事件。举例来说，&quot;用户点击按钮&quot;是一个事件，&quot;用户关闭窗口&quot;也是一个事件。每个事件都会触发相应的信号，例如，当用户点击按钮时，会发出&quot;按钮被点击&quot;的信号；当用户关闭窗口时，会发出&quot;窗口被关闭&quot;的信号。这种事件和信号的机制使得在Qt应用程序中能够方便地处理用户交互和相应的行为。 在Qt中，每个控件都具备接收信号的能力，并且一个控件可以同时接收多个不同的信号。每当控件接收到信号时，它会执行相应的响应动作。举例来说，当窗口中的按钮接收到&quot;按钮被点击&quot;的信号时，它会执行&quot;关闭自身&quot;的响应动作；又如，当文本输入框接收到&quot;文本框被点击&quot;的信号时，它会执行&quot;显示闪烁的光标，等待用户输入数据&quot;的响应动作。在Qt中，对信号所做出的响应动作被称为槽函数。 信号和槽是Qt独有的消息传递机制，它能够连接不同的控件并使它们相互影响。举例来说，&quot;按钮&quot;和&quot;窗口&quot;是两个独立的控件，单纯点击按钮并不会对窗口产生任何影响。通过信号和槽机制，可以将按钮和窗口连接起来，实现&quot;点击按钮会导致窗口关闭&quot;的效果。 1.1 信号的本质 信号是由用户对窗口或控件进行操作所触发的特定事件，这些事件会导致相应的窗口类或控件类发出特定的信号，从而对用户的操作作出响应。因此，从本质上讲，信号就是事件的一种体现。 例如： 按钮单击、双击 窗⼝刷新 ⿏标移动、⿏标按下、⿏标释放 键盘输⼊ 那么在Qt中信号是通过什么形式呈现给使⽤者的呢？ 我们对哪个窗⼝进⾏操作,哪个窗⼝就可以捕捉到这些被触发的事件。 对于使⽤者来说触发了⼀个事件我们就可以得到Qt框架给我们发出的某个特定信号。 信号的呈现形式就是函数，也就是说某个事件产⽣了，Qt框架就会调⽤某个对应的信号函数，通知使⽤者。 在Qt中信号的发出者是某个实例化的类对象。 1.2 槽的本质 槽（Slot）是对信号进行响应的函数。槽函数与一般的C++函数类似，可以定义在类的任何位置（public、protected或private），可以具有任意参数，可以被重载，也可以直接调用（但不能有默认参数）。 与一般函数不同的是：槽函数可以与一个信号相关联。当信号被发射时，与之关联的槽函数会自动执行。 1）信号和槽机制在底层通过函数间的相互调用来实现。每个信号可以用函数表示，称为信号函数；每个槽也可以用函数表示，称为槽函数。例如，&quot;按钮被按下&quot;这个信号可以用clicked()函数表示，而&quot;窗口关闭&quot;这个槽可以用close()函数表示。因此，使用信号和槽机制实现&quot;点击按钮会关闭窗口&quot;的功能实质上是clicked()函数调用close()函数的效果。 2）信号函数和槽函数通常位于某个类中。相较于普通的成员函数，它们的特殊之处在于： 信号函数用signals关键字修饰，槽函数用public slots、protected slots或private slots修饰。signals和slots是Qt在C++基础上扩展的关键字，专门用于指明信号函数和槽函数； 信号函数只需声明，无需定义（实现），而槽函数需要定义（实现）。 信号函数的定义是Qt⾃动在编译程序之前⽣成的.编写Qt应⽤程序的程序猿⽆需关注. 这种⾃动⽣成代码的机制称为元编程(Meta Programming).这种操作在很多场景中都能⻅到. （二）信号和槽的使用 2.1 信号和槽的连接 信号与槽的连接是Qt中用于建立信号与槽关联关系的重要机制。通过连接，一个信号可以触发一个或多个槽函数的执行，实现对象之间的通信。 在Qt中，QObject类（QObjectQt内置的⽗类.Qt中提供的很多类都是直接或者间接继承⾃QObject）提供了⼀个静态成员函数connect()，该函数专⻔⽤来关联指定的信号函数和槽函数。 connect()函数原型： 1connect (const QObject *sender,const char * signal ,const QObject * receiver ,const char * method , Qt::ConnectionType type = Qt::AutoConnection ) 参数说明： sender：信号的发送者； signal：发送的信号（信号函数）； receiver：信号的接收者； method：接收信号的槽函数； type：⽤于指定关联⽅式，默认的关联⽅式为Qt::AutoConnection，通常不需要⼿动设定。 2.2 查看内置信号和槽 1、系统⾃带的信号和槽通常是通过&quot;Qt帮助⽂档&quot;来查询。 2、如上述⽰例，要查询&quot;按钮&quot;的信号，在帮助⽂档中输⼊：QPushButton ⾸先可以在&quot;Contents&quot;中寻找关键字signals， 如果没有找到,继续去⽗类中查找.因此我们去他的⽗类QAbstractButton中继续查找关键字signals 这⾥的clicked()就是要找的信号。槽函数的寻找⽅式和信号⼀样，只不过它的关键字是slot。 2.3 通过Qt Creator⽣成信号槽代码 Qt Creator可以快速帮助我们⽣成信号槽相关的代码。 代码示例:在窗⼝中设置⼀个按钮，当点击&quot;按钮&quot;时关闭&quot;窗⼝&quot;. 1、新建项⽬，如下图为新建完成之后所包含的所有⽂件（创建时要⽣成UI设计⽂件） 2、双击widget.ui⽂件，进⼊UI设计界⾯； 3、在UI设计窗⼝中拖⼊⼀个&quot;按钮&quot;，并且修改&quot;按钮&quot;的名称及字体大小等； 4、可视化⽣成槽函数； 当单击&quot;转到槽…&quot;之后，出现如下界⾯：对于按钮来说，当点击时发送的信号是：clicked()，所以此处选择：clicked() 对于普通按钮来说,使⽤ clicked 信号即可.clicked(bool) 没有意义的.具有特殊状态的按钮(⽐如复选按钮)才会⽤到 clicked(bool) . 5、⾃动⽣成槽函数原型框架； （1）在&quot;widget.h&quot;头⽂件中⾃动添加槽函数的声明； 【解释说明】 ⾃动⽣成槽函数的名称有⼀定的规则。槽函数的命名规则为：on_XXX_SSS，其中： 1、以&quot;on&quot;开头，中间使⽤下划线连接起来； 2、&quot;XXX&quot;表⽰的是对象名(控件的 objectName 属性)。 3、&quot;SSS&quot;表⽰的是对应的信号。 如：“on_pushButton_clicked()”，pushButton代表的是对象名，clicked是对应的信号。 （2）在&quot;widget.cpp&quot;中⾃动⽣成槽函数定义. 6、在槽函数函数定义中添加要实现的功能.实现关闭窗⼝的效果（即当我们运行代码点击关闭按钮之后窗口就会自动关闭） （三）自定义信号和槽 3.1 基本语法 在Qt中，可以自定义信号和槽函数以满足特定需求。然而，自定义的信号函数和槽函数应该遵循一定的书写规范。 1、⾃定义信号函数书写规范 ⾃定义信号函数必须写到&quot;signals&quot;下； 返回值为void，只需要声明，不需要实现； 可以有参数，也可以发⽣重载； 2、⾃定义槽函数书写规范 早期的Qt版本要求槽函数必须写到&quot;publicslots&quot;下，但是现在⾼级版本的Qt允许写到类的&quot;public&quot;作⽤域中或者全局下； 返回值为void，需要声明，也需要实现； 可以有参数，可以发⽣重载； 3、发送信号 使⽤&quot;emit&quot;关键字发送信号。&quot;emit&quot;是⼀个空的宏。&quot;emit&quot;其实是可选的，没有什么含义，只是为了提醒开发⼈员。 ⽰例1： 1、在widget.h中声明⾃定义的信号和槽，如图所⽰; 2、在widget.cpp中实现槽函数，并且关联信号和槽 注意：图中的①和②的顺序不能颠倒 原因是,⾸先关联信号和槽，⼀旦检测到信号发射之后就会⽴⻢执⾏关联的槽函数。反之，若先发射信号，此时还没有关联槽函数，当信号发射之后槽函数不会响应. 3.2 带参数的信号和槽 Qt的信号和槽也⽀持带有参数,同时也可以⽀持重载. 此处我们要求,信号函数的参数列表要和对应连接的槽函数参数列表⼀致. 此时信号触发,调⽤到槽函数的时候,信号函数中的实参就能够被传递到槽函数的形参当中. (💡 通过这样的机制,就可以让信号给槽传递数据了.) 示例：重载信号槽 (1）在&quot;widget.h&quot;头⽂件中声明重载的信号函数以及重载的槽函数；如下图所⽰： （2）在&quot;Widget.cpp&quot;⽂件实现重载槽函数以及连接信号和槽。 需要注意的是：在定义函数指针时要指明函数指针的作⽤域。 （3）执⾏结果如下图所⽰： （四）信号与槽的连接⽅式 4.1 ⼀对⼀ 主要有两种形式，分别是**：⼀个信号连接⼀个槽和⼀个信号连接⼀个信号**。 （1）⼀个信号连接⼀个槽 代码⽰例： 1、在&quot;widget.h&quot;中声明信号和槽以及信号发射函数； 2、在&quot;widget.cpp&quot;中实现槽函数，信号发射函数以及连接信号和槽； （2）⼀个信号连接另⼀个信号 代码示例： 在上述⽰例的基础上，在&quot;widget.cpp&quot;⽂件中添加如下代码： 4.2 ⼀对多 ⼀个信号连接多个槽 ⽰例： （1）在&quot;widget.h&quot;头⽂件中声明⼀个信号和三个槽; （2）在&quot;widget.cpp&quot;⽂件中实现槽函数以及连接信号和槽； 4.3 多对⼀ 多个信号连接⼀个槽函数 ⽰例： （1）在&quot;widget.h&quot;头⽂件中声明两个信号以及⼀个槽； （2）在&quot;widget.cpp&quot;⽂件中实现槽函数以及连接信号和槽； （五）信号和槽的其他说明 5.1 信号与槽的断开 在Qt中，可以使用 disconnect 函数来断开信号与槽之间的连接。disconnect 函数允许你在运行时动态地断开连接，以便停止两个对象之间的信号和槽的关联。（disconnect的⽤法和connect基本⼀致.） 代码示例： 需要注意的是，断开连接时，必须提供与建立连接时相同的参数，包括信号函数和槽函数的指针或函数指针。 5.2 Qt4版本信号与槽的连接 Qt4中的connect⽤法和Qt5相⽐是更复杂的.需要搭配 SIGNAL 和 SLOT 宏来完成。⽽且缺少必要的函数类型的检查，使代码更容易出错。 代码示例： （1）在&quot;widget.h&quot;头⽂件中声明信号和槽 （2）在&quot;widget.cpp&quot;⽂件中实现槽函数以及连接信号与槽； Qt4版本信号与槽连接的优缺点： 优点：参数直观； 缺点：参数类型不做检测； 代码示例： 5.3 使⽤Lambda表达式定义槽函数 Qt5在Qt4的基础上提⾼了信号与槽的灵活性，允许使⽤任意函数作为槽函数。 但如果想⽅便的编写槽函数，⽐如在编写函数时连函数名都不想定义，则可以通过Lambda表达式来达到这个⽬的。 在Qt中，可以使用Lambda表达式来定义槽函数，这使得代码更加简洁和可读。Lambda表达式是C++11引入的一种匿名函数形式，允许我们在需要函数的地方内联定义函数。 下面是一个使用Lambda表达式定义槽函数的示例： 1connect(btn, &amp;QPushButton::clicked, [=]() &#123;qDebug() &lt;&lt; &quot;按钮被点击了&quot;;&#125;); 【解释说明】 在这个示例中，我们将按钮的clicked信号与一个Lambda表达式连接起来。 Lambda表达式作为槽函数，使用了方括号[]来捕获外部变量，这里使用了捕获所有外部变量的方式[=]。 Lambda表达式中的代码将会在按钮被点击时执行。 5.4 信号与槽的优缺点 优点:松散耦合 信号发送者不需要知道发出的信号被哪个对象的槽函数接收，槽函数也不需要知道哪些信号关联了⾃⼰，Qt的信号槽机制保证了信号与槽函数的调⽤。⽀持信号槽机制的类或者⽗类必须继承于QObject类。 缺点:效率较低 与回调函数相⽐，信号和槽稍微慢⼀些，因为它们提供了更⾼的灵活性，尽管在实际应⽤程序中差别不⼤。 通过信号调⽤的槽函数⽐直接调⽤的速度慢约10倍（这是定位信号的接收对象所需的开销；遍历所有关联；编组/解组传递的参数；多线程时，信号可能需要排队），这种调⽤速度对性能要求不是⾮常⾼的场景是可以忽略的，是可以满⾜绝⼤部分场景。 总结 在Qt中，信号与槽是一种强大的通信机制，用于在对象之间进行异步通信。以下是关于信号与槽的简要小结： 信号： 信号是Qt中特有的概念，是一种特殊的成员函数，用于通知其他对象发生了某种特定的事件。 信号由signals:关键字声明，在类的声明部分中定义。 信号函数通常不包含实际的实现，只是用来发出信号。 信号函数可以有参数，参数的类型必须是Qt元对象系统支持的数据类型。 槽： 槽是用于响应信号的函数，可以执行特定的操作以响应信号的发生。 槽函数由slots:关键字声明，在类的声明部分中定义。 槽函数可以是普通成员函数、静态成员函数或者Lambda表达式。 槽函数的参数类型必须与连接的信号的参数类型匹配。 连接： 连接是指建立信号与槽之间的关联，使得当信号被发出时，相关的槽函数会被调用。 连接通过QObject::connect()函数来实现，可以连接两个QObject对象之间的信号和槽。 在连接时，需要指定发送信号的对象、信号函数、接收信号的对象以及槽函数。 连接还可以使用Qt 5中引入的新语法，使得连接更加类型安全。 自定义信号与槽： Qt允许自定义信号和槽函数，以满足特定需求。 自定义的信号函数和槽函数应该遵循一定的书写规范，例如在类的声明部分中使用signals:和slots:关键字声明。 自定义的信号函数和槽函数可以有参数，参数的类型必须是Qt元对象系统支持的数据类型。 使用信号与槽机制可以实现对象之间的松耦合通信，使得代码更加模块化、可维护和可扩展。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":null},{"title":"UEC++ 代理/委托","slug":"UE/UEC++ 代理委托","date":"2025-04-23T09:20:40.000Z","updated":"2025-04-23T09:33:27.649Z","comments":true,"path":"2025/04/23/UE/UEC++ 代理委托/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E4%BB%A3%E7%90%86%E5%A7%94%E6%89%98/","excerpt":"","text":"代理： 代理可以帮助我们解决一对一或是一对多的任务分配工作。主要可以帮助我们解决通知问题。我们可以通过代理完成调用某一个对象的一个函数，而不直接持有该对象的任何指针。 代理就是为你跑腿送信的，你可以不用关心给送信的目标人具体是谁，只要按照约定好的信件格式进行送信即可 更简单理解，想去调用某个函数，但并不是直接去调用，而是通过另一个入口去调用（代理） 分类： 单播代理 只能进行通知一个人 多播代理 可以进行多人通知 动态代理 可以被序列化（这体现在于蓝图进行交互，C++中可以将通知事件进行蓝图广播） 单播代理： 通过宏进行构建，单播代理只能绑定一个通知对象，无法进行多个对象通知、 单播代理分为有返回值与无返回值两种 代理可使用声明宏 函数签名 声明宏 void Function() DECLARE_DELEGATE(DelegateName) void Function(Param1) DECLARE_DELEGATE_OneParam(DelegateName, Param1Type) void Function(Param1, Param2) DECLARE_DELEGATE_TwoParams(DelegateName, Param1Type, Param2Type) void Function(Param1, Param2, ...) DECLARE_DELEGATE_&lt;Num&gt;Params(DelegateName, Param1Type, Param2Type, ...) &lt;RetValType&gt; Function() DECLARE_DELEGATE_RetVal(RetValType, DelegateName) &lt;RetValType&gt; Function(Param1) DECLARE_DELEGATE_RetVal_OneParam(RetValType, DelegateName, Param1Type) &lt;RetValType&gt; Function(Param1, Param2) DECLARE_DELEGATE_RetVal_TwoParams(RetValType, DelegateName, Param1Type, Param2Type) &lt;RetValType&gt; Function(Param1, Param2, ...) DECLARE_DELEGATE_RetVal_&lt;Num&gt;Params(RetValType, DelegateName, Param1Type, Param2Type, ...) 常用绑定函数： BindUObject 绑定UObject类型对象成员函数的代理 BindSP 绑定基于共享引用的成员函数代理 BindRaw 绑定原始自定义对象成员函数的代理，操作调用需要注意执行需要检查 IsBound BindStatic 绑定全局函数成为代理 UnBind 解除绑定代理关系 注意：绑定中传递的对象类型必须和函数指针所属类的类型相同否则绑定会报错 调用执行： 为了保证调用的安全性，执行Execute函数之前需要检查是否存在有效绑定使用函数、 IsBound Execute 调用代理通知，不安全，需要注意 ExecuteIfBound 调用代理通知，安全，但是有返回类型的回调函数无法使用此函数执行回调 IsBound 检查当前是否存在有效代理绑定 构建步骤： 通过宏进行声明代理对象类型（根据回调函数选择不同的宏） 使用代理类型进行构建代理对象 绑定回调对象，和操作函数 执行代理对象回调 123456789101112131415161718192021222324252627282930313233343536373839// Actor1.h// 头文件下DECLARE_DELEGATE(DelegateOne)DECLARE_DELEGATE_RetVal_OneParam(int32 ,DelegateTwo, int32)// 变量声明 class AActor2* ac2; DelegateOne DegOne; DelegateTwo DegTwo;// Actor1.cpp // 这里将代码写在了BeginPlay中，方便测试 ac2 = GetWorld()-&gt;SpawnActor&lt;AActor2&gt;(AActor2::StaticClass()); // 绑定无参无返回值单播代理 DegOne.BindUObject(ac2, &amp;AActor2::CallBackNone); DegOne.ExecuteIfBound(); // 绑定有参有返回值单播代理 DegTwo.BindUObject(ac2, &amp;AActor2::CallBackRes); int32 num = 0; num = DegTwo.Execute(100); UKismetSystemLibrary::PrintString(this, FString::Printf(TEXT(&quot;%d&quot;),num));///////////////////////////////////////////////////////// Actor2.h//声明两个被用来绑定的的函数 void CallBackNone(); int32 CallBackRes(int32 num);// Actor2.cppvoid AActor2::CallBackNone()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;无返回值无参数函数调用！&quot;));&#125;int32 AActor2::CallBackRes(int32 num)&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;有返回值有参数函数调用！&quot;)); return num;&#125; 测试结果： 100 有返回值有参数函数调用！ 无返回值无参数函数调用! 多播代理： 无法构建具有返回值的多播代理——多播代理无返回值 多播代理绑定函数 函数 说明 “Add()” 将函数委托添加到该多播委托的调用列表中。 “AddStatic()” 添加原始C++指针全局函数委托。 “AddRaw()” 添加原始C++指针委托。原始指针不使用任何类型的引用，因此如果从委托下面删除了对象，则调用此函数可能不安全。调用Execute()时请小心！ “AddSP()” 添加基于共享指针的（快速、非线程安全）成员函数委托。共享指针委托保留对对象的弱引用。 “AddUObject()” 添加基于UObject的成员函数委托。UObject委托保留对对象的弱引用。 “Remove()” 从该多播委托的调用列表中删除函数（性能为O(N)）。请注意，委托的顺序可能不会被保留！ “RemoveAll()” 从该多播委托的调用列表中删除绑定到指定UserObject的所有函数。请注意，委托的顺序可能不会被保留！ 广博： 调用函数Broadcast，但是调用不保证执行顺序的正确性 构建步骤： 使用宏构建代理类型 使用代理类型构建多播代理对象 添加绑定代理 执行调用 多播代理执行使用的是 Broadcast() 进行执行函数 动态代理： 允许被序列化的数据结构，这将使得代理可以被数据化提供给蓝图进行使用，达到在CPP中调用代理广播，事件通知到蓝图中。 动态代理和普通代理基本相同，分为单向和多向，动态代理无法使用带有返回值的函数进行构建（动态单播除外，并且单播无法在蓝图中绑定无法使用宏BlueprintAssignable修饰） UE中的大部分通知事件均使用动态代理（方便蓝图操作），如碰撞通知 动态单播代理： DECLARE_DYNAMIC_DELEGATE[_Const, _RetVal, etc.]( DelegateName ) 动态多播代理： DECLARE_DYNAMIC_MULTICAST_DELEGATE[_Const, _RetVal, etc.]( DelegateName ) 操作函数： BindDynamic( UserObject, FuncName ) 在动态代理上调用BindDynamic()的辅助宏。 AddDynamic( UserObject, FuncName ) 在动态多播代理上调用AddDynamic()的辅助宏。 RemoveDynamic( UserObject, FuncName ) 在动态多播代理上调用RemoveDynamic()的辅助宏。 与单播多播区别： 动态代理构建类型名称需要用 F 开头（动态代理实现机制构建了类） 动态代理对象类型可以使用UPROPERTY标记，其他代理均无法使用（不加编译可过，调用出错） 动态代理绑定对象的函数需要使用UFUNCTION进行描述（因为需要跟随代理被序列化） 构建： 12345678910111213141516171819202122// Actor1.hDECLARE_DYNAMIC_DELEGATE(FDelegateTree); // 注意分号// 变量定义 class AActor2* ac2; FDelegateTree DegTree;// Actor1.cpp ac2 = GetWorld()-&gt;SpawnActor&lt;AActor2&gt;(AActor2::StaticClass()); DegTree.BindDynamic(ac2, &amp;AActor2::CallBackNone); if (DegTree.IsBound()) &#123; DegTree.ExecuteIfBound(); &#125;//////////////////////////////////////////////////////////// Actor2.h UFUNCTION() void CallBackNone();// Actor2.cppvoid AActor2::CallBackNone()&#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;无返回值无参数函数调用！&quot;));&#125; 测试结果： 无返回值无参数函数调用！ 动态代理用于蓝图： 在构建动态代理提供蓝图使用时，需要在代理上增加标记宏UPROPERTY(BlueprintAssignable)","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 打开资源管理器并返回选中文件路径","slug":"UE/UEC++ 打开资源管理器并返回选中文件路径","date":"2025-04-23T09:16:41.000Z","updated":"2025-04-23T09:19:40.748Z","comments":true,"path":"2025/04/23/UE/UEC++ 打开资源管理器并返回选中文件路径/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E6%89%93%E5%BC%80%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8%E5%B9%B6%E8%BF%94%E5%9B%9E%E9%80%89%E4%B8%AD%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84/","excerpt":"","text":"声明一个函数，我们利用这个函数来进行打开资源管理器操作 12UFUNCTION(BlueprintCallable, Category = &quot;OpenWindowsFile&quot;)TArray&lt;FString&gt; OpenWindowsFiles(); 函数实现： 12345678910TArray&lt;FString&gt; AActor1::OpenWindowsFiles()&#123; TArray&lt;FString&gt; AbsoluteOpenFileNames;//获取的文件绝对路径 FString ExtensionStr = TEXT(&quot;*.*&quot;);//文件类型 IDesktopPlatform* DesktopPlatform = FDesktopPlatformModule::Get(); DesktopPlatform-&gt;OpenFileDialog(nullptr, TEXT(&quot;文件管理器&quot;), FPaths::ConvertRelativePathToFull(FPaths::ProjectDir()), TEXT(&quot;&quot;), *ExtensionStr, EFileDialogFlags::None, AbsoluteOpenFileNames); return AbsoluteOpenFileNames;&#125; 然后我们在程序运行的时候调用一次这个函数 12345678void AActor1::BeginPlay()&#123; Super::BeginPlay(); TArray&lt;FString&gt; resStr = OpenWindowsFiles(); for (int i = 0; i &lt; resStr.Num(); i++) &#123; UKismetSystemLibrary::PrintString(this, resStr[i]); &#125;&#125; 查看结果： E:/UEProject/UE4C/mx/mx.sln 12// 异步加载m_Streamable.RequestAsyncLoad(SoftMesh.ToSoftObjectPath(), FStreamableDelegate::CreateUObject(this, &amp;UTestGameInstance::LoadSourceCallback)); 当程序运行就弹出了资源管理器，在选择了mx.sln文件之后，就将该文件的结果打印出来了 OpenFileDialog在UE中的定义： 1234567891011121314/** * Opens the &quot;open file&quot; dialog for the platform * * @param ParentWindowHandle 此对话框的父窗口的本机句柄 * @param DialogTitle 对话框窗口标题的文本 * @param DefaultPath 文件对话框最初打开的路径 * @param DefaultFile 对话框最初将选择的文件 * @param Flags 对话的详细信息。看到EFileDialogFlags。 * @param FileTypes 要在对话框中显示的类型过滤器。该字符串应该是一个“|”分隔的(描述|扩展列表)对列表。扩展列表用“;”分隔。 * @param OutFilenames 在对话框中选择的文件名 * @param OutFilterIndex 对话框中选择的类型 * @如果成功选择文件，则返回true */ virtual bool OpenFileDialog(const void* ParentWindowHandle, const FString&amp; DialogTitle, const FString&amp; DefaultPath, const FString&amp; DefaultFile, const FString&amp; FileTypes, uint32 Flags, TArray&lt;FString&gt;&amp; OutFilenames, int32&amp; outFilterIndex ) = 0","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 资源加载（四）模板资源拾取类","slug":"UE/UEC++ 资源加载（四）模板资源拾取类","date":"2025-04-23T09:11:41.000Z","updated":"2025-04-23T09:15:53.259Z","comments":true,"path":"2025/04/23/UE/UEC++ 资源加载（四）模板资源拾取类/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%EF%BC%88%E5%9B%9B%EF%BC%89%E6%A8%A1%E6%9D%BF%E8%B5%84%E6%BA%90%E6%8B%BE%E5%8F%96%E7%B1%BB/","excerpt":"","text":"TSoftObjectPtr和TSoftClassPtr 模板类帮助我们在进行资源操作时增加了类型安全检查，我们可以在细节面板中根据给定的模版类型拾取对应的资源，以获得更加高效的操作！ 同样的，TSoftObjectPtr和TSoftClassPtr也分为同步加载与异步加载！针对资源拾取类别不同，使用需要注意！ 1234UPROPERTY(EditAnywhere)TSoftObjectPtr&lt;class UStaticMesh&gt; SoftMesh;UPROPERTY(EditAnywhere)TSoftClassPtr&lt;class ATestActor&gt; SoftTestActor; TSoftObjectPtr： 同步加载 头文件： 12345UPROPERTY(EditAnywhere)TSoftObjectPtr&lt;class UStaticMesh&gt; SoftMesh;// 构建为栈对象，需要引入头文件，不要构建为堆对象// #include &quot;Engine/StreamableManager.h&quot;FStreamableManager m_Streamable; cpp文件： 12345678// 可以转换为FSoftObjectPath对象SoftMesh.ToSoftObjectPath();// 同步加载UObject* Source = m_Streamable.LoadSynchronous(SoftMesh);UStaticMesh* Mesh = Cast&lt;UStaticMesh&gt;(Source);if (Mesh) &#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;加载成功！&quot;));&#125; 异步加载 头文件：添加一个回调函数 12// 异步加载回调函数void LoadSourceCallback(); cpp文件：需要在初始化函数中绑定回调函数，然后实现回调函数 12// 异步加载m_Streamable.RequestAsyncLoad(SoftMesh.ToSoftObjectPath(), FStreamableDelegate::CreateUObject(this, &amp;UTestGameInstance::LoadSourceCallback)); 回调函数实现： 123456void UTestGameInstance::LoadSourceCallback() &#123; // 此函数调用，则表明异步加载完成 if (SoftMesh.Get()) &#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;加载成功！&quot;)); &#125;&#125; TSoftClassPtr 同步加载 头文件： 12345UPROPERTY(EditAnywhere)TSoftClassPtr&lt;class ATestActor&gt; SoftTestActor;// 构建为栈对象，需要引入头文件，不要构建为堆对象// #include &quot;Engine/StreamableManager.h&quot;FStreamableManager m_Streamable; cpp文件 12345// 同步加载TSubclassOf&lt;ATestActor&gt; TestActorClass = m_Streamable.LoadSynchronous(SoftTestActor);if (TestActorClass) &#123; GetWorld()-&gt;SpawnActor&lt;ATestActor&gt;(TestActorClass);&#125; 异步加载 头文件：同TSoftClassPtr需要添加回调函数 cpp文件 12// 异步加载m_Streamable.RequestAsyncLoad(SoftTestActor.ToSoftObjectPath(), FStreamableDelegate::CreateUObject(this, &amp;UTestGameInstance::LoadSourceCallback)); 回调函数实现 1234567void UTestGameInstance::LoadSourceCallback() &#123; // 此函数调用，则表明异步加载完成 UClass* TestActorClass = SoftTestActor.Get(); if (TestActorClass) &#123; GetWorld()-&gt;SpawnActor&lt;ATestActor&gt;(TestActorClass); &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 资源加载（三）异步加载","slug":"UE/UEC++ 资源加载（三）异步加载","date":"2025-04-23T09:07:41.000Z","updated":"2025-04-23T09:11:16.667Z","comments":true,"path":"2025/04/23/UE/UEC++ 资源加载（三）异步加载/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%EF%BC%88%E4%B8%89%EF%BC%89%E5%BC%82%E6%AD%A5%E5%8A%A0%E8%BD%BD/","excerpt":"","text":"异步加载 FStreamableManager FSreamableManager可以帮助我们构建异步处理逻辑，用来将加载逻辑与游戏主逻辑进行，以达到高效加载资源的目的。建议FSreamableManager创建在全局游戏的单例对象中，结合FSoftObjectPath进行加载。 FSreamableManager支持异步加载的同时也支持同步加载。 FSreamableManager创建： 123// 构建为栈对象，需要引入头文件，不要构建为堆对象// #include &quot;Engine/StreamableManager.h&quot;FStreamableManager m_treamable; FSoftObjectPath同步加载： 同步加载与之前使用的TryLoad基本一致 头文件： 12345UPROPERTY(EditAnywhere)FSoftObjectPath SourcePath;// 构建为栈对象，需要引入头文件，不要构建为堆对象// #include &quot;Engine/StreamableManager.h&quot;FStreamableManager m_treamable; 注意头文件引入头文件需要在 #include “TestGameInstance.generated.h” 头文件上面既 #include “TestGameInstance.generated.h” 必须是最后一个引入的头文件 cpp文件： 12345678// FSoftObjectPath 通过蓝图的细节面板拾取// 借助FStreamableManager配合FSoftObjectPath同步资源UObject* Source = m_Streamable.LoadSynchronous(SourcePath);//加载完成后转换资产UStaticMesh* Mesh = Cast&lt;UStaticMesh&gt;(Source);if (Mesh) &#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;加载成功！&quot;));&#125; FSoftObjectPath异步加载： 异步加载需要设置回调通知对象与通知函数 在上述同步加载的头文件基础上添加一个回调函数： 12// 异步加载回调函数void LoadSourceCallback(); 然后在初始化函数中，绑定回调函数，我使用的 GameInstance 类 所以这行代码写在 Init 中，一般Actor类，写在BeginPlay 中 1234// FSoftObjectPath 通过蓝图的细节面板拾取// 借助FStreamableManager配合FSoftObjectPath同步资源// 这个操作不会阻塞进程m_Streamable.RequestAsyncLoad(SourcePath, FStreamableDelegate::CreateUObject(this, &amp;UTestGameInstance::LoadSourceCallback)); 实现回调函数： 123456789void UTestGameInstance::LoadSourceCallback()&#123; // 此函数调用，则表明异步加载完成 // 加载之后完成转换资产 UStaticMesh* Mesh = Cast&lt;UStaticMesh&gt;(SourcePath.ResolveObject()); if (Mesh) &#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;加载成功！&quot;)); &#125;&#125; 加载的路径同同步加载一样通过 FSoftObjectPath 在蓝图的细节面板中指定","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 资源加载（二）间接属性引用","slug":"UE/UEC++ 资源加载（二）间接属性引用","date":"2025-04-23T09:01:41.000Z","updated":"2025-04-23T09:04:14.837Z","comments":true,"path":"2025/04/23/UE/UEC++ 资源加载（二）间接属性引用/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%EF%BC%88%E4%BA%8C%EF%BC%89%E9%97%B4%E6%8E%A5%E5%B1%9E%E6%80%A7%E5%BC%95%E7%94%A8/","excerpt":"","text":"FSoftObjectPath FSoftObjectPath是一个简单的结构体，使用一个字符串包含资源的完整名称。可以在编辑器中拾取资源（这与直接属性引用相同），但是并不加载资源！资源的加载需要通过额外的代码编写完成！ FSoftObjectPath被暴露到面板中对于资源的拾取并没有特定的要求，所有能够被序列化的资源均能被拾取（类资源，非类资源） 在头文件中声明一个FSoftObjectPath变量，暴露到蓝图中，在蓝图中指定资源路径 12UPROPERTY(EditAnywhere)FSoftObjectPath SourcePath; 资源加载 FSoftObjectPath只是存储了资源的路径，使用前必须通过加载方式方可获得资源！加载方式分为同步加载（如果资源过大会导致游戏程序卡顿）和异步加载 同步加载 在加载运行线程中，阻塞线程的流程执行，将线程停止在当前加载逻辑中，加载完成后继续线程的执行逻辑操作，对于加载小资源可以保证资源的不为空，但是加载大资源将导致调用线程卡顿 异步加载 在加载线程中，不阻塞当前线程逻辑加载资源，加载器本身具备线程进行资源加载。较之同步加载更加的灵活，但是相对维护成本较高，资源加载成功后需要进行回调通知，以完成整个加载流程 加载资产 12345678// 直接引用资源 替代蓝图获取SourcePath.SetPath(TEXT(&quot;StaticMesh&#x27;/Game/ThirdPerson/Meshes/Bump_StaticMesh.Bump_StaticMesh&#x27;&quot;));// 尝试加载 同步加载UObject* Source = SourcePath.TryLoad(); UStaticMesh* Mesh = Cast&lt;UStaticMesh&gt;(Source); if (Mesh) &#123; UKismetSystemLibrary::PrintString(this, TEXT(&quot;加载成功!&quot;)); &#125; 通过通过TSubClassOf构建指定的对象类型 123456// 拾取任意类UPROPERTY(EditDefaultsOnly)UClass* ActorClass;// 拾取指定的TestActor类或其子类UPROPERTY(EditDefaultsOnly)TSubclassOf&lt;class ATestActor&gt; TestActorclass; 加载类： 123456SourcePath.SetPath(TEXT(&quot;Blueprint&#x27;/Game/MyTestActor.MyTestActor_C&#x27;&quot;));UObject* Sorce = SourcePath.TryLoad();UClass* myActor = Cast&lt;UClass&gt;(Sorce);if (myActor) &#123; GetWorld()-&gt;SpawnActor&lt;ATestActor&gt;(myActor);&#125; 注：这里的加载都是同步加载","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 资源加载（一）直接属性引用","slug":"UE/UEC++ 资源加载（一）直接属性引用","date":"2025-04-23T08:54:41.000Z","updated":"2025-04-23T08:59:52.264Z","comments":true,"path":"2025/04/23/UE/UEC++ 资源加载（一）直接属性引用/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/UE/UEC++%20%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%EF%BC%88%E4%B8%80%EF%BC%89%E7%9B%B4%E6%8E%A5%E5%B1%9E%E6%80%A7%E5%BC%95%E7%94%A8/","excerpt":"","text":"1、编辑器直接加载： 通过使用属性宏标记UPROPERTY(Edit三个都可以3)来将资产对象指针暴露到编辑器面板，从而直接从编辑器面板拾取资产。 注意：UClass类指针，专门用来拾取类模版资产 123456// 拾取任意类UPROPERTY(EditDefaultsOnly)UClass* ActorClass;// 拾取音频类UPROPERTY(EditDefaultsOnly)class USoundBase* SoundSrc; 2、TSubClassOf TSubclassOf是提供UClass的安全模板类，通过此模板类我们可以快速在编辑器中进行类型选择，帮助我们快速构建某种类型对象数据。 TS对类型有约束，只能选取模版类型或是继承自模版类型的类或是蓝图 使用语法： 12TSubclassOf&lt;T&gt; type;type.Get();// 获取到Class数据对象 通过通过TSubClassOf构建指定的对象类型 123456// 拾取任意类UPROPERTY(EditDefaultsOnly)UClass* ActorClass;// 拾取指定的TestActor类或其子类UPROPERTY(EditDefaultsOnly)TSubclassOf&lt;class ATestActor&gt; TestActorclass; 3、构造函数加载 在构造函数中可以借助构造函数资产加载类进行资源引用，更加方便便捷。 静态资源引用类ConstructorHelpers可以进行类引用，源资源引用，注意ConstructorHelpers只能在构造函数中使用 常用资源加入分类 FClassFinder 常用来加载创建后的蓝图对象 FObjectFinder 用来加载各种资源，如音频，图片，材质，静态网格 FClassFinder语法 1234// 返回值是TSubClassOfConstructorHelpers::FClassFinder&lt;ATestActor&gt;(TEXT(&quot;/Game/MyTestActor.MyTestActor&quot;)).Class;// 拾取蓝图对象类 拾取蓝图类 必须加 &#x27;_C&#x27;ConstructorHelpers::FClassFinder&lt;ATestActor&gt; UnitSelector(TEXT(&quot;Blueprint&#x27;/Game/MyTestActor.MyTestActor_C&#x27;&quot;)); FObjectFinder语法 123UTexture2D* BarFillTure;ConstructorHelpers::FObjectFinder&lt;UTexture2D&gt; BarFillObj(TEXT(&quot;/Game/UI/HUD/BarFill&quot;));BarFillTure = BarFillObj.Object; 注意： 操作路径前加入/Game/前缀 ConstructorHelpers 类将尝试在内存中查找该资产，如果找不到，则进行加载 ConstructorHelpers只能在构造函数中使用，GameInstance中是 Init 函数（需要重载） 如果加载失败或是未找到资源，对象内的资产属性为null 如果加载蓝图类模版对象时，需要加注“_C” 查找加载 在只知道目标资源路径的基础上，进行运行时态的资源加载，UE提供了LoadObject用来加载资产，LoadClass用来加载类，通过模版约束对象类型，增加操作安全，但是注意，资源加载可能会失败或是无效，需要对操作的结果进行判定。 LoadObject 可直接返回资源有效对象指针 LoadClass 返回操作类，非对象返回UClass类型指针 函数定义： 12345678910111213141516171819/** * Load an object. * @see StaticLoadObject() */template&lt; class T &gt; inline T* LoadObject( UObject* Outer, const TCHAR* Name, const TCHAR* Filename=nullptr, uint32 LoadFlags=LOAD_None, UPackageMap* Sandbox=nullptr )&#123; return (T*)StaticLoadObject( T::StaticClass(), Outer, Name, Filename, LoadFlags, Sandbox );&#125;/** * Load a class object * @see StaticLoadClass */template&lt; class T &gt; inline UClass* LoadClass( UObject* Outer, const TCHAR* Name, const TCHAR* Filename=nullptr, uint32 LoadFlags=LOAD_None, UPackageMap* Sandbox=nullptr )&#123; return StaticLoadClass( T::StaticClass(), Outer, Name, Filename, LoadFlags, Sandbox );&#125; 参数含义： Outer 帮助我们进行搜索范围锁定，可以填入同目录资源，如不存在填入空 Name 资源文件名，可以在编辑器中通过选择资源右键获取引用名，注意蓝图加载需要加入后缀”_C” 函数使用： 1LoadObject&lt;AActor&gt;(nullptr, TEXT(&quot;Blueprint&#x27;/Game/MyTestActor.MyTestActor_C&#x27;&quot;));","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"Qt中实现高准确率的语音识别_qt","slug":"vosk/Qt中实现高准确率的语音识别_qt 语音识别","date":"2025-04-23T02:20:26.000Z","updated":"2025-04-30T08:59:04.432Z","comments":true,"path":"2025/04/23/vosk/Qt中实现高准确率的语音识别_qt 语音识别/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/vosk/Qt%E4%B8%AD%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%87%86%E7%A1%AE%E7%8E%87%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB_qt%20%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/","excerpt":"","text":"选择语音识别引擎 开源语音识别项目中，以下两款工具可以用于支持中英文识别，并且与Qt兼容： Vosk：Vosk是一个开源的语音识别工具，支持中英文及多种语言，具备离线识别能力，且不依赖互联网。 PaddleSpeech：PaddleSpeech是百度的开源语音识别工具，准确率较高，但需要稍微多一点的配置。 本示例将使用 Vosk，它支持多平台，且易于集成到C++项目中，满足离线使用、90%以上准确率、开源等要求。 Vosk资源下载 首先，下载Vosk的C++库及中英文模型文件： 如果不想编译库，这里有已经编译好的 中英文模型：Vosk 模型下载 下载对应的库和模型，并确保你的开发环境中已经配置好CMake和Qt开发环境。 示例代码 以下是一个完整的Qt项目代码示例，展示如何使用Vosk API在C++中进行中英文识别。假设你已经下载并解压了模型文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;QCoreApplication&gt;#include &lt;QAudioInput&gt;#include &lt;QBuffer&gt;#include &lt;QFile&gt;#include &lt;vosk_api.h&gt;#include &lt;iostream&gt;class SpeechRecognizer : public QObject &#123; Q_OBJECTpublic: SpeechRecognizer(const QString &amp;modelPath, QObject *parent = nullptr) : QObject(parent) &#123; model = vosk_model_new(modelPath.toStdString().c_str()); recognizer = vosk_recognizer_new(model, 16000.0); &#125; ~SpeechRecognizer() &#123; vosk_recognizer_free(recognizer); vosk_model_free(model); &#125; void startRecognition() &#123; QAudioFormat format; format.setSampleRate(16000); format.setChannelCount(1); format.setSampleSize(16); format.setCodec(&quot;audio/pcm&quot;); format.setByteOrder(QAudioFormat::LittleEndian); format.setSampleType(QAudioFormat::SignedInt); audioInput = new QAudioInput(format, this); audioBuffer.open(QIODevice::WriteOnly | QIODevice::Truncate); audioInput-&gt;start(&amp;audioBuffer); connect(audioInput, &amp;QAudioInput::stateChanged, this, &amp;SpeechRecognizer::onStateChanged); &#125;private slots: void onStateChanged(QAudio::State state) &#123; if (state == QAudio::IdleState) &#123; audioInput-&gt;stop(); audioBuffer.close(); processAudio(); &#125; &#125; void processAudio() &#123; QByteArray audioData = audioBuffer.buffer(); int length = audioData.size(); const char *data = audioData.data(); if (vosk_recognizer_accept_waveform(recognizer, data, length)) &#123; std::cout &lt;&lt; vosk_recognizer_result(recognizer) &lt;&lt; std::endl; &#125; else &#123; std::cout &lt;&lt; vosk_recognizer_partial_result(recognizer) &lt;&lt; std::endl; &#125; &#125;private: VoskModel *model; VoskRecognizer *recognizer; QAudioInput *audioInput; QBuffer audioBuffer;&#125;;int main(int argc, char *argv[]) &#123; QCoreApplication app(argc, argv); QString modelPath = &quot;/path/to/vosk-model&quot;; // 将此路径替换为实际模型路径 SpeechRecognizer recognizer(modelPath); recognizer.startRecognition(); return app.exec();&#125; 编译与运行 将vosk_api.h和vosk库文件添加到项目中，并在CMakeLists.txt中配置vosk库路径。编译后运行该程序，即可开始录音和实时中英文语音识别。 提示 确保麦克风采样率为16kHz，以匹配识别模型的采样率。 运行过程中需要确保模型路径正确，并安装所需的Qt和Vosk依赖库。 参考资源 Vosk官方文档和API：https://alphacephei.com/vosk","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"vosk","slug":"vosk","permalink":"http://www.formeasy.cc/tags/vosk/"}],"author":null},{"title":"语音识别——使用Vosk进行语音识别","slug":"vosk/语音识别——使用Vosk进行语音识别","date":"2025-04-23T02:04:12.000Z","updated":"2025-04-30T08:58:50.969Z","comments":true,"path":"2025/04/23/vosk/语音识别——使用Vosk进行语音识别/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/vosk/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E2%80%94%E2%80%94%E4%BD%BF%E7%94%A8Vosk%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/","excerpt":"","text":"前言 Vosk是语音识别开源框架，支持二十+种语言 - 中文，英语，印度英语，德语，法语，西班牙语，葡萄牙语，俄语，土耳其语，越南语，意大利语，荷兰人，加泰罗尼亚语，阿拉伯, 希腊语, 波斯语, 菲律宾语，乌克兰语, 哈萨克语, 瑞典语, 日语, 世界语, 印地语, 捷克语, 波兰语, 乌兹别克语, 韩国语, 塔吉克语。 Vosk还支持设备上离线语音识别 ，包括Raspberry Pi，Android，iOS等，API接口简单，并且有多种语言支持，同时会识别语义，最终输出合理的语句。 一、Vosk模型 1.准备好所需要的语音包 在开始使用Vosk之前，需要拥有语音识别的模型，如图中拥有很多语音模型，中文、英文、西班牙、印度等等，Vosk模型库，需要外网才可以下载 2.下载使用 下载并进行解压后如下图所示，例如这里有简单英文、轻量级中文、和用于服务器处理的大型通用中文模型等，根据需要进行下载 解压后放在对应目录下，值得注意的是，是整个解压后的文件夹，而不是某一固定文件，一定要放在对应位置，不然使用时会直接崩溃，连报错都没有。 二、使用示例 1.文件读取示例 首先语音文件和模型需要准备好，示例中的语音文件是自己录下来的，模型vosk-model-cn-0.22是中文模型 1234567891011121314151617181920212223242526272829#include &lt;vosk_api.h&gt;#include &lt;stdio.h&gt;int main() &#123; FILE *wavin; char buf[3200]; int nread, final; VoskModel *model = vosk_model_new(&quot;vosk-model-cn-0.22&quot;); VoskRecognizer *recognizer = vosk_recognizer_new(model, 16000.0); wavin = fopen(&quot;test.wav&quot;, &quot;rb&quot;); fseek(wavin, 44, SEEK_SET); while (!feof(wavin)) &#123; nread = fread(buf, 1, sizeof(buf), wavin); final = vosk_recognizer_accept_waveform(recognizer, buf, nread); if (final) &#123; printf(&quot;%s\\n&quot;, vosk_recognizer_result(recognizer)); &#125; else &#123; printf(&quot;%s\\n&quot;, vosk_recognizer_partial_result(recognizer)); &#125; &#125; printf(&quot;%s\\n&quot;, vosk_recognizer_final_result(recognizer)); vosk_recognizer_free(recognizer); vosk_model_free(model); fclose(wavin); return 0;&#125; 输出结果如下，partial是短时输出，text是识别语义后的输出： vosk_model_new:加载模型 vosk_recognizer_new:创建语音识别实例 vosk_recognizer_accept_waveform：塞入语音数据（pcm格式） vosk_recognizer_result:获取识别器的完整识别结果 vosk_recognizer_partial_result:返回当下识别结果，如果没有识别到，返回空 2.结合麦克风演示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;alsa/asoundlib.h&gt;#include &lt;vosk_api.h&gt;#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;memory&gt;#include &lt;array&gt;#define SAMPLE_RATE 44100#define BUFFER_SIZE 44100 * 2 * 2int main() &#123; // 初始化 Vosk 模型 VoskModel *model = vosk_model_new(&quot;vosk-model-cn-0.22&quot;); VoskRecognizer *recognizer = vosk_recognizer_new(model, SAMPLE_RATE); // 打开 ALSA 设备 snd_pcm_t *pcm_handle; int ret = snd_pcm_open(&amp;pcm_handle, &quot;default&quot;, SND_PCM_STREAM_CAPTURE, 0); ret = snd_pcm_set_params(pcm_handle, SND_PCM_FORMAT_S16_LE, SND_PCM_ACCESS_RW_INTERLEAVED, 1, SAMPLE_RATE, 1, 1000000); // 1秒 char buffer[BUFFER_SIZE]; int final_result; while (1) &#123; // 从麦克风读取音频数据 int nread = snd_pcm_readi(pcm_handle, buffer, BUFFER_SIZE / 2); if (nread &lt; 0) &#123; snd_pcm_recover(pcm_handle, nread, 0); continue; &#125; // 将音频数据传递给 Vosk final_result = vosk_recognizer_accept_waveform(recognizer, buffer, nread * 2); if (final_result) &#123; printf(&quot;%s\\n&quot;, vosk_recognizer_result(recognizer)); &#125; else &#123; std::string strTest = vosk_recognizer_partial_result(recognizer); printf(&quot;%s\\n&quot;, strTest.c_str()); &#125; &#125; printf(&quot;%s\\n&quot;, vosk_recognizer_final_result(recognizer)); // 清理 snd_pcm_close(pcm_handle); vosk_recognizer_free(recognizer); vosk_model_free(model); return 0;&#125; 识别到并且最终组成的语句如下： 总结 轻量级、资源消耗小的嵌入式设备进行语音识别使用Vosk是一个不错的选择，但是如果只是用于语音唤醒之类的，实际上应该有更好的选择。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"vosk","slug":"vosk","permalink":"http://www.formeasy.cc/tags/vosk/"}],"author":"山河君"},{"title":"Vosk 进行中文语音识别实例_vosk","slug":"vosk/Vosk 进行中文语音识别实例_vosk","date":"2025-04-23T02:03:15.000Z","updated":"2025-04-30T08:59:19.065Z","comments":true,"path":"2025/04/23/vosk/Vosk 进行中文语音识别实例_vosk/","link":"","permalink":"http://www.formeasy.cc/2025/04/23/vosk/Vosk%20%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%AE%9E%E4%BE%8B_vosk/","excerpt":"","text":"这个示例展示了如何在 Qt 中集成 Vosk 进行中文语音识别。该示例不仅涵盖了录音的设置与保存，还确保录制的音频文件符合 Vosk 的要求格式。通过 Vosk 的中文模型，我们可以对音频内容进行识别，获取准确的中文转写结果。此外，示例中通过 QString::fromUtf8 来正确解析 Vosk 返回的 UTF-8 编码字符串，确保最终显示的中文内容没有乱码。 示例详细概述 前期准备 在开始编写代码之前，确保已下载 Vosk 库和中文语音模型文件，并将其存放在项目路径中，使程序能够正确加载所需的资源。 功能说明 音频录制：通过 Qt 的 QAudioInput 类，我们设置了一个16kHz采样率、单声道、PCM 编码的录音格式，录制的音频将保存为 .wav 文件，这也是 Vosk 模型所要求的标准音频格式。 语音识别：示例中加载了 Vosk 的中文语音模型，录制完成后将音频文件输入到模型中，由 Vosk 提供的识别器对音频内容进行处理，并生成中文转写结果。 中文字符显示：由于 Vosk 返回的识别结果是 UTF-8 编码的字符串，为了确保 Qt 能正确显示中文，使用 QString::fromUtf8 将识别结果解析成 QString 类型。这样可以避免乱码，使最终的中文文本能够正确显示在控制台或界面中。 通过以上几个步骤，整个流程能够将录制的中文音频文件成功转换为文本，并正确显示。 代码示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#include &lt;QCoreApplication&gt;#include &lt;QAudioInput&gt;#include &lt;QFile&gt;#include &lt;QTimer&gt;#include &lt;QDebug&gt;#include &lt;vosk_api.h&gt;#include &lt;iostream&gt;// 音频录制类class AudioRecorder : public QObject &#123; Q_OBJECTpublic: AudioRecorder(QObject *parent = nullptr) : QObject(parent), audioFile(&quot;recorded_audio.wav&quot;) &#123; // 设置音频格式：16kHz、单声道、16位深度 QAudioFormat format; format.setSampleRate(16000); format.setChannelCount(1); format.setSampleSize(16); format.setCodec(&quot;audio/pcm&quot;); format.setByteOrder(QAudioFormat::LittleEndian); format.setSampleType(QAudioFormat::SignedInt); // 初始化音频输入 audioInput = new QAudioInput(format, this); // 打开文件 if (!audioFile.open(QIODevice::WriteOnly | QIODevice::Truncate)) &#123; qWarning() &lt;&lt; &quot;无法打开文件进行录音&quot;; return; &#125; &#125; void startRecording(int durationMs) &#123; audioInput-&gt;start(&amp;audioFile); qDebug() &lt;&lt; &quot;开始录音...&quot;; // 设置录音时间，完成后停止录音 QTimer::singleShot(durationMs, this, &amp;AudioRecorder::stopRecording); &#125;signals: void recordingFinished();public slots: void stopRecording() &#123; audioInput-&gt;stop(); audioFile.close(); qDebug() &lt;&lt; &quot;录音完成&quot;; // 触发录音完成信号 emit recordingFinished(); &#125;private: QAudioInput *audioInput; QFile audioFile;&#125;;// 语音识别类class SpeechRecognizer : public QObject &#123; Q_OBJECTpublic: SpeechRecognizer(const QString &amp;modelPath, QObject *parent = nullptr) : QObject(parent) &#123; // 加载模型 model = vosk_model_new(modelPath.toStdString().c_str()); if (model == nullptr) &#123; qWarning() &lt;&lt; &quot;无法加载模型&quot;; &#125; &#125; ~SpeechRecognizer() &#123; vosk_model_free(model); &#125; void recognize(const QString &amp;audioFilePath) &#123; // 创建识别器 VoskRecognizer *recognizer = vosk_recognizer_new(model, 16000.0); // 打开录音文件 FILE *audioFile = fopen(audioFilePath.toStdString().c_str(), &quot;rb&quot;); if (audioFile == nullptr) &#123; qWarning() &lt;&lt; &quot;无法打开音频文件&quot;; vosk_recognizer_free(recognizer); return; &#125; // 读取音频并识别 char buffer[4096]; int bytesRead; while ((bytesRead = fread(buffer, 1, sizeof(buffer), audioFile)) &gt; 0) &#123; if (vosk_recognizer_accept_waveform(recognizer, buffer, bytesRead)) &#123; QString result = QString::fromUtf8(vosk_recognizer_result(recognizer)); qDebug() &lt;&lt; &quot;识别结果:&quot; &lt;&lt; result; &#125; else &#123; QString partial = QString::fromUtf8(vosk_recognizer_partial_result(recognizer)); qDebug() &lt;&lt; &quot;部分识别:&quot; &lt;&lt; partial; &#125; &#125; // 获取最终识别结果 QString finalResult = QString::fromUtf8(vosk_recognizer_final_result(recognizer)); qDebug() &lt;&lt; &quot;最终结果:&quot; &lt;&lt; finalResult; // 释放资源 fclose(audioFile); vosk_recognizer_free(recognizer); &#125;private: VoskModel *model;&#125;;// 主程序int main(int argc, char *argv[]) &#123; QCoreApplication app(argc, argv); // 设置模型路径 QString modelPath = QApplication::applicationDirPath() + &quot;/vosk-model-cn&quot;; SpeechRecognizer recognizer(modelPath); // 创建录音对象 AudioRecorder recorder; // 录音完成后进行识别 QObject::connect(&amp;recorder, &amp;AudioRecorder::recordingFinished, [&amp;recognizer]() &#123; QString audioFilePath = QApplication::applicationDirPath() + &quot;/recorded_audio.wav&quot;; recognizer.recognize(audioFilePath); &#125;); // 开始录音（例如5秒） recorder.startRecording(5000); return app.exec();&#125; 详细说明 音频录制：AudioRecorder 类负责音频的录制。它使用了 Qt 的 QAudioInput 类，并将音频设置为符合 Vosk 要求的16kHz采样率、单声道、PCM格式。这种设置使得录制的音频文件适合直接输入给 Vosk 进行处理。录音结束后，音频数据会被保存到 recorded_audio.wav 文件中，便于后续的语音识别步骤使用。 语音识别：SpeechRecognizer 类负责将录制好的音频文件输入到 Vosk 的中文语音模型中进行识别。它通过 Vosk 提供的 API 加载中文模型，将音频文件内容转换为文本信息。为了确保中文字符正确显示，我们使用 QString::fromUtf8 来处理 Vosk 返回的 UTF-8 编码的识别结果字符串，从而避免了乱码问题。 主程序逻辑：在主程序中，我们创建了 AudioRecorder 实例来启动录音操作。当录音结束后，程序会自动触发 SpeechRecognizer 的识别流程，并将识别的中文文本结果输出到控制台。 编译与运行 准备工作：将 Vosk 的中文模型和所需的库文件放置在项目目录下，同时确保在项目配置中添加了 Vosk 库的路径和头文件路径，以便正确链接 Vosk 库。 编译与运行程序：完成项目配置后，编译并运行程序。启动后，程序将录制5秒钟的音频并保存文件，然后调用 Vosk 模型进行语音识别。识别结果将通过 qDebug() 输出到控制台，显示音频中识别出的中文内容。 注意事项 音频格式：录制的音频文件必须符合16kHz采样率、单声道、PCM格式的要求，这是 Vosk 模型所能处理的标准格式。其他格式可能会导致识别失败或不准确。 中文编码：Vosk 返回的识别结果是 UTF-8 编码的，为避免乱码问题，使用 QString::fromUtf8 来解析结果，从而正确显示中文字符。 输出路径：确保模型文件路径和音频文件路径在代码中正确设置，使程序能够顺利加载中文模型和录制的音频文件，从而完成整个语音识别过程。 Demo下载","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"vosk","slug":"vosk","permalink":"http://www.formeasy.cc/tags/vosk/"}],"author":null},{"title":"UEC++ 结构体和枚举","slug":"UE/UEC++ 结构体和枚举","date":"2025-04-22T15:35:41.000Z","updated":"2025-04-22T03:38:30.189Z","comments":true,"path":"2025/04/22/UE/UEC++ 结构体和枚举/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%20%E7%BB%93%E6%9E%84%E4%BD%93%E5%92%8C%E6%9E%9A%E4%B8%BE/","excerpt":"","text":"1、结构体 在虚幻C中结构体和普通C结构体构建方式相同，但是如果希望构建于蓝图交互的结构体则需要额外的处理！ UE支持结构体的构建和使用，但是由于蓝图特殊，普通的结构体定义无法被蓝图访问，我们需要借助USTRUCT宏进行构建UE中的结构体 语法： 123456 USTRUCT(BlueprintType) struct FBoxPosition &#123; GENERATED_USTRUCT_BODY() int32 x; int32 y;&#125;; 注意：结构体名称必须使用 F 开头，必须带两个操作宏，如需要在蓝图中使用，需要加入BlueprintType标记 2、枚举 语法与C++相同，总的来说可以使用以下两种方式进行构建 添加宏记可以使枚举在蓝图中也可使用 第一种：空间构建方式 1234567UENUM(BlueprintType)namespace GColor &#123; enum Type &#123; Blue, Red &#125;;&#125; 使用： 1GColor::Type::Blue; 特点：使用空间名称作为访问依据，可以更清晰的标明意图，方便使用。 第二种：直接创建 12345UENUM(BlueprintType)enum class ZColor : uint8 &#123; ERed, EBlue&#125;; 使用： 1ZColor::EBlue; 定义枚举对象： 12UPROPERTY(EditAnywhere)TEnumAsByte&lt;GColor::Type&gt; Color; 定义枚举 12UPROPERTY(EditAnywhere)GColor Color; 为枚举在蓝图中创建别名 可以帮助枚举名进行蓝图别名创建，方便在蓝图中寻找操作（空间声明枚举的方式不适用） 1234UENUM(BlueprintType)enum class ZColor : uint8 &#123; Game UMETA(DisplayName = &quot;GC&quot;)&#125;;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 容器：TSet","slug":"UE/UEC++ 容器：TSet","date":"2025-04-22T14:35:41.000Z","updated":"2025-04-22T02:52:36.034Z","comments":true,"path":"2025/04/22/UE/UEC++ 容器：TSet/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%20%E5%AE%B9%E5%99%A8%EF%BC%9ATSet/","excerpt":"","text":"TSet TSet也是键值容器和TMap类似，但速度快，无需提供单独的键进行关联元素，不允许有重复的键。 TSet 也是值类型，支持常规复制、赋值和析构函数操作，以及其元素较强的所有权。集合被销毁时，其元素也将被销毁。键类型也必须是值类型 与TArray的区别： TSet是KV容器 TSet不保证数据填充顺序。 TSet数据存储时无法重复存储，TArray可以 构建、添加数据： 1234567TSet&lt;FString&gt; set; set.Add(TEXT(&quot;set01&quot;));// 添加内容 TSet&lt;FString&gt; set2; set2.Add(TEXT(&quot;set02&quot;)); set.Append(set2); // 合并操作 遍历： 123456789101112for (auto&amp; Item : set) &#123; Item = TEXT(&quot;cg01&quot;);// 修改值 &#125; for (auto It = set.CreateIterator(); It; ++It) &#123; *It = TEXT(&quot;cg01&quot;);// 修改值 &#125; for (auto It = set.CreateConstIterator(); It; ++It) &#123; *It; // 可获取但无法修改 &#125; 常用查询函数： 1234567set.Num(); // 获取容器中元素的数量 // 检查是否包含给定的键值 返回布尔值 set.Contains(TEXT(&quot;set01&quot;)); // 返回指向元素的指针，没找到返回空 set.Find(TEXT(&quot;set01&quot;)); // 将TSet容器转为TArray容器 set.Array(); 常用移除函数： 123set.Remove(TEXT(&quot;set01&quot;)); // 使用给定的值内容 set.Empty(); // 清空容器，释放空间 set.Reset(); // 移除元素，但是不释放空间","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 容器：TArray","slug":"UE/UEC++ 容器：TArray","date":"2025-04-22T13:40:08.000Z","updated":"2025-04-22T02:48:08.045Z","comments":true,"path":"2025/04/22/UE/UEC++ 容器：TArray/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%20%E5%AE%B9%E5%99%A8%EF%BC%9ATArray/","excerpt":"","text":"说明：容器是方便我们存储数据的载体，在虚幻中，为我们提供了三种容器。分别是TArray，TMap，TSet。首先虚幻提供的容器都是同质容器，只能用来存储相同类型的数据。三种容器具备不同的特性，针对不同的特性，我们可以根据使用场景选择操作的容器。 并且在虚幻定义了丰富的API供开发者使用 注意：在使用这三种容器的时候需要注意，只有TArray可以使用UPROPERTY宏说明 TArray 最常用的数据容器，特点速度快，内存消耗小，安全性高。 TArray被称为同质容器：其所有元素均完全为相同类型。不能进行不同元素类型的混合。 TArray被设计成值类型，无法被继承，不要使用new和delete在堆上进行创建销毁。元素也是数值类型，为容器拥有。TArray被销毁时元素也被销毁。从一个TArray创建新的TArray变量，将把元素复制到新的变量中，不存在共享状态。 初始化： 注意事项：容器在构建时，不要构建为堆对象！直接构建为栈对象！由于容器是模版类，在构建时必须指出存储数据类型。 1234 // 容器需要构建为栈对象类型TArray&lt;FString&gt; Array; //向容器添加5个元素，且值均为 Hello!Array.Init(TEXT(&quot;Hello!&quot;), 5); 遍历数组: Num函数可以获取TArray当前元素个数。TArray重载了运算符[]，通过位置下标可以访问到对应位置元素 123for (int i = 0; i &lt; Array.Num(); i++) &#123; UE_LOG(LogTemp, Log, TEXT(&quot;第%d值是：%s&quot;),i,*Array[i]);&#125; 输出结果： LogTemp: 第0值是：Hello! LogTemp: 第1值是：Hello! LogTemp: 第2值是：Hello! LogTemp: 第3值是：Hello! LogTemp: 第4值是：Hello! 借助新语法进行遍历 123for (auto&amp; val : Array) &#123; UE_LOG(LogTemp, Log, TEXT(&quot;%s&quot;), *val);&#125; 输出结果： LogTemp: Hello! LogTemp: Hello! LogTemp: Hello! LogTemp: Hello! LogTemp: Hello! 添加元素: Add，Emplace，AddUnique函数均可向数组中添加元素（到末尾），元素被添加时，内存从分配器中被分配。Add和Emplace函数可达到同样的效果，但是存在细微不同。 Add函数将把一个元素类型实例复制（或移动）到数组中 Emplace添加元素到容器中，Add函数调用的是Emplace函数 AddUnique向容器中加入唯一元素，如果元素已经存在，则返回重复元素的位置 1234Array.Add(TEXT(&quot;Add01&quot;)); Array.Emplace(TEXT(&quot;Add02&quot;)); Array.AddUnique(TEXT(&quot;Add02&quot;)); Array.AddUnique(TEXT(&quot;Add03&quot;)); 输出结果： LogTemp: 第0值是：Hello! LogTemp: 第1值是：Hello! LogTemp: 第2值是：Hello! LogTemp: 第3值是：Hello! LogTemp: 第4值是：Hello! LogTemp: 第5值是：Add01 LogTemp: 第6值是：Add02 LogTemp: 第7值是：Add03 上面我们利用AddUnique又添加了一次Add02但是这里只有一个Add02； Append： Append函数可以复制普通的数组到容器中 第一个参数，普通数组，第二个参数数组中元素的个数 12FString StrArr[3]&#123; &quot;1&quot;,&quot;2&quot;,&quot;3&quot; &#125;; Array.Append(StrArr, ARRAY_COUNT(StrArr)); 输出结果： LogTemp: 第0值是：Hello! LogTemp: 第1值是：Hello! LogTemp: 第2值是：Hello! LogTemp: 第3值是：Hello! LogTemp: 第4值是：Hello! LogTemp: 第5值是：1 LogTemp: 第6值是：2 LogTemp: 第7值是：3 Insert插入元素： 允许在给定索引添加一个单一元素或元素数组的一个副本。 如果插入位置超过容器的大小，将会报错！ 1Array.Insert(TEXT(&quot;ins01&quot;), 3); 输出结果： LogTemp: 第0值是：Hello! LogTemp: 第1值是：Hello! LogTemp: 第2值是：Hello! LogTemp: 第3值是：ins01 LogTemp: 第4值是：Hello! LogTemp: 第5值是：Hello! SetNum： 主动设置容器的大小，如果长度大于原容器大小，空白位置将用模版类型默认对象填充。如果小于原容器大小，则超过设置大小的内容将被删除。 函数原型：第一个参数容器的大小，第二个是允许缩小容器当前元素数量 1void SetNum(SizeType NewNum, bool bAllowShrinking = true) 使用： 1Array.SetNum(3,true); 当你已经初始化过数组，但在后面又使用了 SetNum 且设置的长度比原长度小的时，数组会自动将超出的截去 如果设置的长度大于原长度，那么超出的部分就会被赋值为空 迭代器： 迭代器（iterator）有时又称游标（cursor）是程序设计的软件设计模式，可在容器（container，例如链表或阵列）上遍访的接口，设计人员无需关心容器的内容。 TArray有两种迭代器，一种是可以通过迭代器更改元素内容，一种是只能读取元素不能修改元素。 禁止在迭代器中修改容器的元素个数，禁止添加和移除元素 123456789101112for (auto It = Array.CreateIterator();It; ++It)&#123; // *It用来读取数据 *It = FString(TEXT(&quot;cg01&quot;)); // 可以修改元素内容 UE_LOG(LogTemp, Log, TEXT(&quot;%s&quot;), **It);&#125;for (auto It = Array.CreateConstIterator(); It; ++It)&#123; // *It用来读取数据 *It = FString(TEXT(&quot;cg01&quot;)); // 禁止修改元素内容 UE_LOG(LogTemp, Log, TEXT(&quot;%s&quot;), **It);&#125; 输出结果： LogTemp: 第0值是：cg01 LogTemp: 第1值是：cg01 LogTemp: 第2值是：cg01 LogTemp: 第3值是：cg01 LogTemp: 第4值是：cg01 转成普通数组： 返回类型指针，指针地址是数组中第一个元素的地址 1FString* StrData = Array.GetData(); 常规查询函数： 123456789101112// 查询指定位置是否存在有效元素，返回布尔值 Array.IsValidIndex(3); Array.Last();// 返回最后的元素 Array.Last(3);// 返回倒数第三个元素 Array.Top(); // 返回顶端元素 // 检查是否包含给定的元素 返回布尔值 Array.Contains(TEXT(&quot;Hello!&quot;)); // 查找是否包含给定的元素，并返回元素所在的位置，不包含返回-1 Array.Find(TEXT(&quot;Hello!&quot;)); // 查找是否包含给定的元素，将位置索引设置到Index，返回布尔值 int Index = 0; Array.Find(TEXT(&quot;Hello!&quot;), Index) 常规移除函数： TArray有Reset函数，清除内容，但保留空间 123456// 在容器中移除给定的元素，返回移除的个数 Array.Remove(TEXT(&quot;Hello!&quot;)); // 移除数组中首个给定元素，成功返回1，失败返回0 Array.RemoveSingle(TEXT(&quot;Hello!&quot;)); Array.RemoveAt(3); // 返回给定位置的元素 Array.Empty(); // 清空容器","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 数据类型","slug":"UE/UEC++ 数据类型","date":"2025-04-22T12:35:41.000Z","updated":"2025-04-22T02:38:14.729Z","comments":true,"path":"2025/04/22/UE/UEC++ 数据类型/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"禁止在UE中使用C++的基本数据类型，这样会影响引擎的跨平台特性 1、基本数据类型 bool 代表布尔值 (永远不要假设布尔值的大小) 。 BOOL 将不会进行编译。 TCHAR 代表字符型（永远不要假设TCHAR的大小）。 uint8 代表无符号字节（占1个字节）。 int8 代表有符号的字节（占1个字节）。 uint16 代表无符号&quot;短整型&quot; (占2 个字节)。 int16 代表有符号&quot;短整型&quot; (占2 个字节)。 uint32 代表无符号整型（占4字节）。 int32 代表带符号整型（占4字节）。 uint64 代表无符号&quot;四字&quot; (8个字节)。 int64 代表有符号&quot;四字&quot;（8个字节）。 UE float 代表单精度浮点型 (占4 个字节)。 double 代表双精度浮点型 (占8 个字节)。 PTRINT一个符号整数和一个指针一样大小（用来标记指针的大小） (永远不要假设PTRINT的大小)。 2、字符编码 编码解决的是文本问题。 3、字符类型 UE4中提供多种字符类型进行处理数据，在不同的情景下，我们需要选择不同的类型进行操作。 区别：大小不同，编码方式不同，所有的文本在进行存储的时候，编译器编译阶段会根据编码类型进行转码。 使用：通过结构体 FPlatformTypes typedef FPlatformTypes::ANSICHAR ANSICHAR; 转码宏的使用：下列是虚幻中提供的一些转码宏 // Usage of these should be replaced with StringCasts. #define TCHAR_TO_ANSI(str) (ANSICHAR*)StringCast(static_cast&lt;const TCHAR*&gt;(str)).Get() #define ANSI_TO_TCHAR(str) (TCHAR*)StringCast(static_cast&lt;const ANSICHAR*&gt;(str)).Get() #define TCHAR_TO_UTF8(str) (ANSICHAR*)FTCHARToUTF8((const TCHAR*)str).Get() #define UTF8_TO_TCHAR(str) (TCHAR*)FUTF8ToTCHAR((const ANSICHAR*)str).Get() 4、对象字符串 FName：资源命名字符串，FName 通过一个轻型系统使用字符串。在此系统中，特定字符串即使会被重复使用，在数据表中也只存储一次。FNames 不区分大小写（大小写不是他比较的依据）。它们为不可变，无法被操作。FNames 的存储系统和静态特性决定了通过键进行 FNames 的查找和访问速度较快。FName 子系统的另一个功能是使用散列表为 FName 转换提供快速字符串。 FText：表示一个显示字符串，用户的显式文本都需要由FText进行处理。支持格式化文本，不提供修改函数，无法进行内容修改 FString：可以被操作的字符串。开销大于其他类字符串类型","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++自定义日志分类","slug":"UE/UEC++自定义日志分类","date":"2025-04-22T10:35:41.000Z","updated":"2025-04-22T02:36:59.503Z","comments":true,"path":"2025/04/22/UE/UEC++自定义日志分类/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%E8%87%AA%E5%AE%9A%E4%B9%89%E6%97%A5%E5%BF%97%E5%88%86%E7%B1%BB/","excerpt":"","text":"以下两个步骤均完成才可 1、声明自定义日志分类 1234567891011 /** * A macro to declare a logging category as a C++ &quot;extern&quot;, usually declared in the header and paired with DEFINE_LOG_CATEGORY in the source. Accessible by all files that include the header. * @param CategoryName, category to declare * @param DefaultVerbosity, default run time verbosity * @param CompileTimeVerbosity, maximum verbosity to compile into the code **/#define DECLARE_LOG_CATEGORY_EXTERN(CategoryName, DefaultVerbosity, CompileTimeVerbosity) \\ extern struct FLogCategory##CategoryName : public FLogCategory&lt;ELogVerbosity::DefaultVerbosity, ELogVerbosity::CompileTimeVerbosity&gt; \\ &#123; \\ FORCEINLINE FLogCategory##CategoryName() : FLogCategory(TEXT(#CategoryName)) &#123;&#125; \\ &#125; CategoryName; 参数说明： CategoryName 自定义日志分类名称 Log开头 DefaultVerbosity 日志默认级别，一般使用Log CompileTimeVerbosity 日志编译级别 高于此级别的不会被编译 一般用All 这个操作需要在头文件中完成，并且完成一次 2、定义日志分类 定义 12345/** * A macro to define a logging category, usually paired with DECLARE_LOG_CATEGORY_EXTERN from the header. * @param CategoryName, category to define**/#define DEFINE_LOG_CATEGORY(CategoryName) FLogCategory##CategoryName CategoryName; 参数说明： CategoryName 自定义日志分类名称 这个操作必须在CPP文件中进行，只需要进行一次定义","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++生成Actor","slug":"UE/UEC++生成Actor","date":"2025-04-22T09:36:41.000Z","updated":"2025-04-22T01:08:05.984Z","comments":true,"path":"2025/04/22/UE/UEC++生成Actor/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%E7%94%9F%E6%88%90Actor/","excerpt":"","text":"1、直接生成Actor 1GetWorld()-&gt;SpawnActor&lt;AActor&gt;(); 1GetWorld()-&gt;SpawnActor(AActor::StaticClass()); 12UWorld* world = GetWorld();world-&gt;SpawnActor&lt;AActor&gt;(AActor::StaticClass()); SpawnActor 在 world 类中的定义 123456789101112131415161718192021222324252627282930313233343536373839/** Templated version of SpawnActor that allows you to specify a class type via the template type */ template&lt; class T &gt; T* SpawnActor( const FActorSpawnParameters&amp; SpawnParameters = FActorSpawnParameters() ) &#123; return CastChecked&lt;T&gt;(SpawnActor(T::StaticClass(), NULL, NULL, SpawnParameters),ECastCheckedType::NullAllowed); &#125; /** Templated version of SpawnActor that allows you to specify location and rotation in addition to class type via the template type */ template&lt; class T &gt; T* SpawnActor( FVector const&amp; Location, FRotator const&amp; Rotation, const FActorSpawnParameters&amp; SpawnParameters = FActorSpawnParameters() ) &#123; return CastChecked&lt;T&gt;(SpawnActor(T::StaticClass(), &amp;Location, &amp;Rotation, SpawnParameters),ECastCheckedType::NullAllowed); &#125; /** Templated version of SpawnActor that allows you to specify the class type via parameter while the return type is a parent class of that type */ template&lt; class T &gt; T* SpawnActor( UClass* Class, const FActorSpawnParameters&amp; SpawnParameters = FActorSpawnParameters() ) &#123; return CastChecked&lt;T&gt;(SpawnActor(Class, NULL, NULL, SpawnParameters),ECastCheckedType::NullAllowed); &#125; /** * Templated version of SpawnActor that allows you to specify the rotation and location in addition * class type via parameter while the return type is a parent class of that type */ template&lt; class T &gt; T* SpawnActor( UClass* Class, FVector const&amp; Location, FRotator const&amp; Rotation, const FActorSpawnParameters&amp; SpawnParameters = FActorSpawnParameters() ) &#123; return CastChecked&lt;T&gt;(SpawnActor(Class, &amp;Location, &amp;Rotation, SpawnParameters),ECastCheckedType::NullAllowed); &#125; /** * Templated version of SpawnActor that allows you to specify whole Transform * class type via parameter while the return type is a parent class of that type */ template&lt; class T &gt; T* SpawnActor(UClass* Class, FTransform const&amp; Transform,const FActorSpawnParameters&amp; SpawnParameters = FActorSpawnParameters()) &#123; return CastChecked&lt;T&gt;(SpawnActor(Class, &amp;Transform, SpawnParameters), ECastCheckedType::NullAllowed); &#125; 2、滞后生成Actor 123456// 创建actor生成变换 FTransform tran; // 滞后生成Actor AActor* actor = GetWorld()-&gt;SpawnActorDeferred&lt;AActor&gt;(AActor::StaticClass(), tran); // 确定生成对象到世界 actor-&gt;FinishSpawning(tran); SpawnActorDeferred 在 world 类中的定义 12345678910111213141516171819202122232425/** * Spawns given class and returns class T pointer, forcibly sets world transform (note this allows scale as well). WILL NOT run Construction Script of Blueprints * to give caller an opportunity to set parameters beforehand. Caller is responsible for invoking construction * manually by calling UGameplayStatics::FinishSpawningActor (see AActor::OnConstruction). */ template&lt; class T &gt; T* SpawnActorDeferred( UClass* Class, FTransform const&amp; Transform, AActor* Owner = nullptr, APawn* Instigator = nullptr, ESpawnActorCollisionHandlingMethod CollisionHandlingOverride = ESpawnActorCollisionHandlingMethod::Undefined ) &#123; if( Owner ) &#123; check(this==Owner-&gt;GetWorld()); &#125; FActorSpawnParameters SpawnInfo; SpawnInfo.SpawnCollisionHandlingOverride = CollisionHandlingOverride; SpawnInfo.Owner = Owner; SpawnInfo.Instigator = Instigator; SpawnInfo.bDeferConstruction = true; return (Class != nullptr) ? Cast&lt;T&gt;(SpawnActor(Class, &amp;Transform, SpawnInfo)) : nullptr; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 解决 AddOnScreenDebugMessage 输出中文乱码","slug":"UE/UEC++ 解决 AddOnScreenDebugMessage 输出中文乱码","date":"2025-04-22T09:35:41.000Z","updated":"2025-04-22T02:34:02.877Z","comments":true,"path":"2025/04/22/UE/UEC++ 解决 AddOnScreenDebugMessage 输出中文乱码/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%20%E8%A7%A3%E5%86%B3%20AddOnScreenDebugMessage%20%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/","excerpt":"","text":"在使用 AddOnScreenDebugMessage 进行日志输出时，输出中文会导致乱码情况 1GEngine-&gt;AddOnScreenDebugMessage(-1, 10, FColor::Green, TEXT(&quot;消息&quot;)); 结果： Click for Mouse Control XX 原因是所使用编码集无法解释中文字符 ###解决办法： 使文件处于未保存状态，在文件中找到高级保存选项，然后将编码格式设置为UTF-8 如果使用的Vs中没有高级保存选项，可以在工具自定义中将其添加上去 自定义-&gt;命令-&gt;菜单栏-&gt;添加命令 在添加命令中添加文件，高级保存选项 设置完之后再重新编译就可以正常显示中文日志输出","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++消亡Actor通知","slug":"UE/UEC++消亡Actor通知","date":"2025-04-22T09:35:41.000Z","updated":"2025-04-22T01:04:47.582Z","comments":true,"path":"2025/04/22/UE/UEC++消亡Actor通知/","link":"","permalink":"http://www.formeasy.cc/2025/04/22/UE/UEC++%E6%B6%88%E4%BA%A1Actor%E9%80%9A%E7%9F%A5/","excerpt":"","text":"1、Destroyed函数 调用自身Destroy函数进行强制消亡操作 当对象被删除时（非内存删除）进行回调操作 参数说明 bNetForce 是否强制网络同步删除 bShouldModifyLevel 主要是用来控制先删除actor再修改关卡，还是先修改关卡再删除actor，默认是true，即为先修改关卡，再删除actor（修改关卡即为把actor先移除出场景） 1Destroyed(); 在Actor中的定义 1234567void AActor::Destroyed()&#123; RouteEndPlay(EEndPlayReason::Destroyed); ReceiveDestroyed(); OnDestroyed.Broadcast(this);&#125; Actor被标记为等待销毁并从关卡的Actor阵列中移除。 12// 两秒后销毁 SetLifeSpan(2); 设置延时删除（单位秒） 注：这里的 Destroy 和 SetLifeSpan 函数直接调用都是销毁自身 2、EndPlay函数 对象被彻底清除时回调，回调会进行删除类型通知 1virtual void EndPlay(const EEndPlayReason::Type EndPlayReason); EEndPlayReason类型 既删除类型 1234567891011121314151617UENUM(BlueprintType)namespace EEndPlayReason&#123; enum Type &#123; /** 当actor或是component彻底被删除时（内存中） */ Destroyed, /** 关卡切换时删除回调（非关卡流） */ LevelTransition, /** 编辑器关闭时，回调通知 */ EndPlayInEditor, /** 关卡流切换被释放时调用 */ RemovedFromWorld, /** 游戏退出时被删除回调 */ Quit, &#125;;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 输出方式","slug":"UE/UEC++ 输出方式","date":"2025-04-21T09:35:41.000Z","updated":"2025-04-21T02:30:53.347Z","comments":true,"path":"2025/04/21/UE/UEC++ 输出方式/","link":"","permalink":"http://www.formeasy.cc/2025/04/21/UE/UEC++%20%E8%BE%93%E5%87%BA%E6%96%B9%E5%BC%8F/","excerpt":"","text":"1、使用PrintString输出 12#include &quot;Kismet/KismetSystemLibrary.h&quot;UKismetSystemLibrary::PrintString(this, TEXT(&quot;hello!&quot;)); 格式化输出，使用方法和C语言print函数一样 12#include &quot;Kismet/KismetSystemLibrary.h&quot;UKismetSystemLibrary::PrintString(this, TEXT(&quot;Num = %d&quot;),Num); 2、使用Engine的Debug功能 12#include &quot;Engine.h&quot;GEngine-&gt;AddOnScreenDebugMessage(-1, 20, FColor::Green, FString(TEXT(&quot;hello!&quot;))); 3、打印到日志 12#include &quot;Engine.h&quot;UE_LOG(LogTemp, Warning, TEXT(&quot;hello!&quot;)); 同可格式化输出","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 多线程（二） AsyncTask","slug":"UE/UEC++ 多线程（二） AsyncTask","date":"2025-04-20T09:35:41.000Z","updated":"2025-04-21T02:44:14.957Z","comments":true,"path":"2025/04/20/UE/UEC++ 多线程（二） AsyncTask/","link":"","permalink":"http://www.formeasy.cc/2025/04/20/UE/UEC++%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%20AsyncTask/","excerpt":"","text":"AsyncTask AsyncTask系统实现的多线程与自己实现继承的FRunnable实现的原理相似，还可以利用UE4提供的线程池。当使用多线程不满意时也可以调用StartSynchronousTask改成主线程执行。 来自头文件 AysncWork.h 文件中注释，直接仿照注释来实现AsyncTask 123456789101112131415161718192021222324252627282930313233343536FAutoDeleteAsyncTask - template task for jobs that delete themselves when completeSample code:class ExampleAutoDeleteAsyncTask : public FNonAbandonableTask&#123; friend class FAutoDeleteAsyncTask&lt;ExampleAutoDeleteAsyncTask&gt;; int32 ExampleData; ExampleAutoDeleteAsyncTask(int32 InExampleData) : ExampleData(InExampleData) &#123; &#125; void DoWork() &#123; ... do the work here &#125; FORCEINLINE TStatId GetStatId() const &#123; RETURN_QUICK_DECLARE_CYCLE_STAT(ExampleAutoDeleteAsyncTask, STATGROUP_ThreadPoolAsyncTasks); &#125;&#125;;void Example()&#123; // start an example job (new FAutoDeleteAsyncTask&lt;ExampleAutoDeleteAsyncTask&gt;(5)-&gt;StartBackgroundTask(); // do an example job now, on this thread (new FAutoDeleteAsyncTask&lt;ExampleAutoDeleteAsyncTask&gt;(5)-&gt;StartSynchronousTask();&#125; 代码实现： 继承FNonAbandonableTask创建一个线程类 在DoWork中实现需要实现的功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// FTestAsyncTask.h #include &quot;Async\\AsyncWork.h&quot; #include &quot;CoreMinimal.h&quot;class MX_API FTestAsyncTask : public FNonAbandonableTask&#123;public: friend class FAutoDeleteAsyncTask&lt;FTestAsyncTask&gt;; int32 RunCount = 0; FTestAsyncTask(FString ThreadName,class AActor1* a1) : MyThreadName(ThreadName), A1(a1) &#123;&#125;; ~FTestAsyncTask(); void DoWork(); FORCEINLINE TStatId GetStatId() const &#123; RETURN_QUICK_DECLARE_CYCLE_STAT(FTestAsyncTask, STATGROUP_ThreadPoolAsyncTasks); &#125; FString MyThreadName; class AActor1* A1; static FCriticalSection CriticalSection;&#125;;///////////////////////////////////////////////////////////////////////// FTestAsyncTask.cpp FCriticalSection FTestAsyncTask::CriticalSection;FTestAsyncTask::~FTestAsyncTask()&#123;&#125;void FTestAsyncTask::DoWork()&#123; UE_LOG(LogTemp, Log, TEXT(&quot;%s------%d&quot;), *MyThreadName, RunCount); while (IsValid(A1)) &#123; // 同步锁 FScopeLock Lock(&amp;CriticalSection); if (A1-&gt;TestCount &lt; A1-&gt;TestTarget) &#123; A1-&gt;TestCount++; RunCount++; // 节约资源 每100次打印一次 if (RunCount % 100 == 0) UE_LOG(LogTemp, Log, TEXT(&quot;%s======%d&quot;), *MyThreadName, RunCount); &#125; else &#123; break; &#125; &#125; &#125; 执行线程类： 12345678// 头文件 int32 TestCount; UPROPERTY(EditAnywhere) int32 TestTarget;// 线程运行 (new FAutoDeleteAsyncTask&lt;FTestAsyncTask&gt;(&quot;thread1&quot;, this))-&gt;StartBackgroundTask(); (new FAutoDeleteAsyncTask&lt;FTestAsyncTask&gt;(&quot;thread2&quot;, this))-&gt;StartBackgroundTask(); 在自定义执行的线程类中 使用 FAutoDeleteAsyncTask 来传入我们刚才写的Task。FAutoDeleteAsyncTask顾名思义就是任务执行完就会自动删除。 还有StartBackgroundTask和StartSynchronousTask的区别： StartBackgroundTask会利用线程池里空闲的线程来执行。 StartSynchronousTask则是主线程执行。 执行结果： LogTemp: thread2======30600 LogTemp: thread1======68000 LogTemp: thread1======68100 LogTemp: thread2======30700 LogTemp: thread2======30800 LogTemp: thread1======68200 LogTemp: thread1======68300 LogTemp: thread2======30900 LogTemp: thread2======31000 LogTemp: thread1======68400 LogTemp: thread1======68500 LogTemp: thread1======68600 LogTemp: thread1======68700 LogTemp: thread1======68800 LogTemp: thread2======31100 PIE: Play in editor total start time 0.055 这里运行次数设置的为100000 缺少一次是因为当满足条件是直接跳出了，没有打印出","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UEC++ 多线程（一） FRunnable","slug":"UE/UEC++ 多线程（一） FRunnable","date":"2025-04-20T09:28:39.000Z","updated":"2025-04-20T09:35:13.502Z","comments":true,"path":"2025/04/20/UE/UEC++ 多线程（一） FRunnable/","link":"","permalink":"http://www.formeasy.cc/2025/04/20/UE/UEC++%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%20FRunnable/","excerpt":"","text":"虚幻官方文档：https://docs.unrealengine.com/5.0/en-US/API/Runtime/Core/HAL/FRunnable/ FRunnable “runnable”对象的接口。 可运行对象是在任意线程上“运行”的对象。调用使用模式是Init()、Run()、Exit()。将要“run”这个对象的线程总是使用那些调用语义。它在创建的线程上执行此操作，以便在这些调用的上下文中可以使用任何特定于线程的使用(TLS等)。“runnable”在Init()中完成所有的初始化。 如果初始化失败，线程将停止执行并返回错误代码。如果成功，则在执行真正的线程工作的地方调用Run()。完成后，调用Exit()以允许正确的清理。 函数 void Exit() 退出可运行对象 bool Init() 初始化可运行对象。 uint32 Run() 运行可运行对象。 void Stop() 停止可运行对象。如果请求线程提前终止，则调用此函数。 FSingleThreadRunnable GetSingleThreadInterface() 获取在禁用多线程时用于勾选此可运行项的单线程接口指针。 代码流程示意： 自定义基于Runnable的类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 头文件#pragma once#include &quot;HAL/Runnable.h&quot;#include &quot;CoreMinimal.h&quot;/** * */class MX_API FTestRunnable:public FRunnable&#123;public: FTestRunnable(FString ThreadName,class AActor1* a1) :MyThreadName(ThreadName), A1(a1) &#123;&#125;; virtual bool Init() override; virtual uint32 Run() override; virtual void Exit() override; FString MyThreadName; class AActor1* A1;protected: int32 RunCount = 0; static FCriticalSection CriticalSection;&#125;;// 源文件FCriticalSection FTestRunnable::CriticalSection;bool FTestRunnable::Init()&#123; UE_LOG(LogTemp, Log, TEXT(&quot;%s 初始化！&quot;), *MyThreadName); //GEngine-&gt;AddOnScreenDebugMessage(-1, 20, FColor::Red, TEXT(&quot;%s 初始化！&quot;), *MyThreadName); return IsValid(A1);&#125;uint32 FTestRunnable::Run()&#123; while (IsValid(A1)) &#123; // 同步锁 如果没有这行代码 最终各个线程运行的总次数将会大于需要的次数 FScopeLock Lock(&amp;CriticalSection); if (A1-&gt;TestCount &lt; A1-&gt;TestTarget) &#123; A1-&gt;TestCount++; RunCount++; // 节约资源 每100次打印一次 if (RunCount % 100 == 0) UE_LOG(LogTemp, Log, TEXT(&quot;%s %d&quot;), *MyThreadName, RunCount); &#125; else&#123;break;&#125; &#125; return 0;&#125;void FTestRunnable::Exit()&#123; UE_LOG(LogTemp, Log, TEXT(&quot;%s 结束运行！执行次数：%d&quot;), *MyThreadName, RunCount);&#125; 执行线程的类： 12345678910111213// 头文件// 定义两个变量用于计数 int32 TestCount; UPROPERTY(EditAnywhere) int32 TestTarget;// 源文件 用于创建和开启线程 这里我放在了BeginPlay中方便测试 FTestRunnable* Runnable1 = new FTestRunnable(TEXT(&quot;线程1&quot;), this); FTestRunnable* Runnable2 = new FTestRunnable(TEXT(&quot;线程2&quot;), this); FTestRunnable* Runnable3 = new FTestRunnable(TEXT(&quot;线程3&quot;), this); FRunnableThread* RunnableThread1 = FRunnableThread::Create(Runnable1, *Runnable1-&gt;MyThreadName); FRunnableThread* RunnableThread2 = FRunnableThread::Create(Runnable2, *Runnable2-&gt;MyThreadName); FRunnableThread* RunnableThread3 = FRunnableThread::Create(Runnable3, *Runnable3-&gt;MyThreadName); 测试结果：这里我设置的线程运行次数为：1000000 LogTemp:线程2 354000 LogTemp:线程2 354100 LogTemp:线程2 354200 LogTemp:线程1 428600 LogTemp:线程1 428700 LogTemp:线程1 428800 LogTemp:线程1 428900 LogTemp:线程3 216400 LogTemp:线程2 354300 LogTemp:线程2 354400 LogTemp:线程2 354500 LogTemp:线程2 结束运行!执行次数：354573 LogTemp:线程1 结束运行!执行次数：428981 LogTemp:线程3 结束运行!执行次数：216446 PIE: Play in editor total start time 0.178 seconds.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":"黎沐不吃香菜"},{"title":"UE5异步实现方式_ue5 asynctask","slug":"UE/UE5异步实现方式_ue5 asynctask","date":"2025-04-20T09:20:44.000Z","updated":"2025-04-20T09:25:44.830Z","comments":true,"path":"2025/04/20/UE/UE5异步实现方式_ue5 asynctask/","link":"","permalink":"http://www.formeasy.cc/2025/04/20/UE/UE5%E5%BC%82%E6%AD%A5%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F_ue5%20asynctask/","excerpt":"","text":"1）、AsyncTask 一套基于线程池的异步任务处理系统。每创建一个AsyncTask，都会被加入到线程池中进行执行 12345678910111213141516171819202122232425262728293031323334353637383940414243// Fill out your copyright notice in the Description page of Project Settings.//MyAsyncTask.h #pragma once#include &quot;Async/AsyncWork.h&quot;class FMyAsyncTask : public FNonAbandonableTask&#123; friend class FAutoDeleteAsyncTask&lt;FMyAsyncTask&gt;;public: FMyAsyncTask(); void DoWork(); FORCENOINLINE TStatId GetStatId() const &#123; RETURN_QUICK_DECLARE_CYCLE_STAT(FMyAsyncTask, STATGROUP_ThreadPoolAsyncTasks); &#125; FORCENOINLINE static const TCHAR* GetTaskName() &#123; return TEXT(&quot;FMyAsyncTask&quot;); &#125;&#125;;// MyAsyncTask.cpp#include &quot;MyAsyncTask.h&quot;FMyAsyncTask::FMyAsyncTask()&#123;&#125;void FMyAsyncTask::DoWork()&#123; UE_LOG(LogTemp, Warning, TEXT(&quot;FMyAsyncTask&quot;)); for (int i = 0; i &lt; 1000000; ++i) &#123; UE_LOG(LogTemp, Warning, TEXT(&quot;i = %d&quot;), i); &#125;&#125;//UE521TESTCharacter.cppvoid AUE521TESTCharacter::TestAsyncTaskClass()&#123; FAutoDeleteAsyncTask&lt;FMyAsyncTask&gt;* MyTask = new FAutoDeleteAsyncTask&lt;FMyAsyncTask&gt;(); MyTask-&gt;StartBackgroundTask();&#125; 总结 主要应用于后台线程上加载资源、进行复杂的计算、或者执行其他可能会阻塞主线程的操作。 2)、Async 最简单创建异步的方式 12345678910111213// UE521TESTCharacter.cpp#include &quot;Async/Async.h&quot;void AUE521TESTCharacter::TestAsync()&#123; Async(EAsyncExecution::ThreadPool, []() &#123; // 这里是在后台线程上运行的代码 for (int i = 0; i &lt; 1000000; ++i) &#123; UE_LOG(LogTemp, Warning, TEXT(&quot;i = %d&quot;), i); &#125; &#125;);&#125; 3）、FRunnable 1234567891011121314151617181920212223242526//MyRunnable.h#pragma onceclass FMyRunnable : public FRunnable&#123;public: virtual uint32 Run() override;&#125;;//MyRunnable.cpp#include &quot;MyRunnable.h&quot;uint32 FMyRunnable::Run()&#123; for (int i = 0; i &lt; 1000000; ++i) &#123; UE_LOG(LogTemp, Warning, TEXT(&quot;i = %d&quot;), i); &#125; return 0;&#125;// UE521TESTCharactervoid AUE521TESTCharacter::TestRunnable()&#123; FMyRunnable* MyRunnable = new FMyRunnable(); FRunnableThread* MyThread = FRunnableThread::Create(MyRunnable, TEXT(&quot;MyThread&quot;));&#125; 4）、三种方式区别 1）、AsyncTask：AsyncTask是一个模板类，用于创建可以在后台线程上运行的任务。AsyncTask可以在任务完成后自动删除自己，它非常适合用于创建一次性的异步任务。例如，你可以使用AsyncTask来异步加载资源，或者进行一次复杂的计算。 2）、Async：Async是一个函数，用于在后台线程上运行一个lambda表达式。Async函数的使用方式非常简单，只需要一个lambda表达式，可以创建一个异步任务。Async函数非常适合用于创建简单的异步任务，例如异步加载资源，或者进行一次复杂的计算。 3）、FRunnable：FRunnable是一个接口，用于创建可以在单独线程上运行的任务。与AsyncTask和Async不同，FRunnable任务需要手动管理线程的生命周期，这使得它更加灵活，但也更难使用。FRunnable非常适合用于创建复杂的异步任务，例如创建一个后台线程，这个线程可以持续运行并处理来自网络的数据。 总的来说，AsyncTask和Async更适合用于创建一次性的异步任务，而FRunnable更适合用于创建需要长时间运行的异步任务","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"测试工具使用心得：Testbed与Klocwork","slug":"TEST/测试工具使用心得：Testbed与Klocwork","date":"2025-04-17T08:40:03.000Z","updated":"2025-04-25T01:44:46.509Z","comments":true,"path":"2025/04/17/TEST/测试工具使用心得：Testbed与Klocwork/","link":"","permalink":"http://www.formeasy.cc/2025/04/17/TEST/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%EF%BC%9ATestbed%E4%B8%8EKlocwork/","excerpt":"","text":"在测评工作中，一般静态分析和逻辑测试使用Testbed工具帮助测试，代码扫描使用Klocwork工具辅助分析，本文是在测试过程中的总结。 一、测试类型的思考 逻辑测试：选取核心代码进行插桩，将插桩后代码替代原代码进行编译，执行用例，使相关功能全部执行完成，通过testbed测试工具对软件的语句/分支覆盖情况进行检查，并对未覆盖的语句进行原因分析： 1） 逻辑测试选定的代码要有针对性的选择关键模块代码，这样会更有说服力； 2） 插装后的程序应按照步骤进行修改，要不会分析不出覆盖率数据； 3） 如果分析的覆盖率数据达不到指标要求，应仔细分析覆盖率报告中那些程序未执行到，针对这些未执行到的代码，有针对性的执行动态测试用例，根据输出的覆盖数据再进行覆盖率分析； 4） 对于确有执行不到、看不明白的代码要和开发人及时沟通，分析原因，针对为执行到的代码进行叠加分析。 代码扫描：使用Klocwork对编程规范性进行检查，包括编程缺陷和安全漏洞等，提交至开发人员确认，使用源码统计专家统计代码注释率不低于20%。 静态分析：用Testbed进行静态分析，分析控制流，检测有无不能运行的单元，有无无效的函数参数，扇入扇出不大于10，圈复杂度小于等于7。 二、工具的测试步骤 逻辑测试 1、选取核心代码进行插桩。（一般为代码总量20%） 2、将插桩后代码更名，替代原代码进行编译，执行功能、接口测试用例，插桩代码的功能全部执行完成。 3、对生成的exh文件进行分析。 进入Set-Select/Create/Delete Set窗口，输入项目名称ceshi0823，点击Create弹出的窗口中选择Group进入Set-List/Add/Remove Files in Set窗口，点击Add，添加需要插桩的代码（插桩代码最好不存在中文路径），点击OK，添加成功。 进入Analysis-Select Analysis窗口，勾选Main Static Analysis（基本静态分析）和Generate Instrumented Program(s)（生成插桩程序），点击Generate Instrumented Program(s)后面的configure。 勾选下图中红框框起来的选项进行插桩配置，点击OK，保存配置信息。 点击Start Analysis ，进行插桩，插桩后生成以inszt_为前缀的文件。此文件夹下的文件不要进行删除、移动、修改操作（对结果进行分析时testbed识别此路径下的文件及时间）将inszt_为前缀的文件复制出来，去掉前缀，原名替换代码中相应的.c文件。进行编译后，打开软件，动态执行功能、接口等测试用例，覆盖插桩的功能。 执行完测试用例后，退出软件。在程序路径下搜索.exh，搜索到的文件为插桩程序生成的文件，格式如下所示：打开后每一行有一个数字（0-255之间，数字越大，说明覆盖率越高），前面空5个格。（当exh文件不符合此格式时，需手动调整为此格式） 进入Analysis-Select Analysis窗口，勾选Dynamic coverage Analysis，点击后面的configure，选择生成的.exh文件存放路径（最好不要用中文路径），点击确定按钮，点击Start Analysis ，进行分析查看分析结果，分支覆盖、语句覆盖率。 代码扫描 K8安装成功后，首先以管理员身份Start Klocwork Severs。 点击file-New Project，输入项目名称、选择需要分析的语言，点击Next。 选择Bulid from Source Root Directories，点击Add，添加源码所在文件夹（不要有中文），点击Finish。 右键点击项目名称，选择Build，在弹出的窗口中选择存放分析结果的路径（路径不要有中文），点击Build，软件开始进行分析，在存放结果路径下查看测试结果，测试结果保存。 对需要扫描的规则进行勾选，点击OK，保存后进行扫描。 静态分析 进入Set-Select/Create/Delete Set窗口，输入项目名称ceshi0803-jt，点击Create，弹出的窗口中选择System。 进入Set-List/Add/Remove Files in Set窗口，点击Add，添加需要分析的代码。 进入Analysis-Select Analysis窗口，勾选Main Static Analysis（基本静态分析）、Complexity Analysis（复杂度分析）和Static Data Flow Analysis（静态数据流分析），点击Start Analysis ，开始进行分析。 分析完后，选择Group Results-Text Results-Quality Review Report，查看质量度量结果。","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":"作者：找到你的天赋了嘛    来源：CSDN"},{"title":"白盒测试工具Testbed 白盒测试 工具","slug":"TEST/白盒测试工具Testbed 白盒测试 工具","date":"2025-04-17T08:36:00.000Z","updated":"2025-04-25T01:44:16.448Z","comments":true,"path":"2025/04/17/TEST/白盒测试工具Testbed 白盒测试 工具/","link":"","permalink":"http://www.formeasy.cc/2025/04/17/TEST/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7Testbed%20%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95%20%E5%B7%A5%E5%85%B7/","excerpt":"","text":"白盒测试又称结构测试、透明盒测试、逻辑驱动测试或基于代码的测试。白盒测试是一种测试用例设计，白盒指的是盒子是可视的，你清楚盒子内部的东西以及里面是如何运作的。&quot;白盒&quot;法全面了解程序内部逻辑结构、对所有逻辑路径进行测试。&quot;白盒&quot;法是穷举路径测试。在使用这一方案时，测试者必须检查程序的内部结构，从检查程序的逻辑着手，得出测试数据。贯穿程序的独立路径数是天文数字。 白盒测试是一种典型的测试方法 • 它是一种按照程序内部逻辑结构和编码结构设计测试数据并完成测试的一种测试方法 • 测试覆盖全部代码、分支、路径和条件 • 它利用查看代码功能和实现方式得到的信息来确定哪些需要测试、哪些不需要、如何展开测试 • 又称为结构测试或逻辑驱动测试 白盒测试特点主要有 •1. 可以构成测试数据使特定程序部分得到测试 •2. 有一定的充分性度量手段 •3. 可获得较多工具支持 •4. 通常只用于单元测试和集成测试(主要是单元测试) 白盒测试的基本测试内容 基本测试内容 •对程序模块的所有独立执行路径至少测试一次 •对所有的逻辑判定，取“真”与取“假”的两种情况都至少测试一次 •在循环的边界和运行的边界限内执行循环体 •测试内部数据结构的有效性 白盒测试所采用的测试方法是 •逻辑覆盖（包括语句覆盖、分支覆盖、条件覆盖、分支-条件覆盖、条件组合覆盖以及路径覆盖） 六种逻辑覆盖标准：语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖和路径覆盖发现错误的能力呈由弱至强的变化。 语句覆盖要求：独立执行路径至少一次。每条语句至少执行一次。 ·它对程序的逻辑覆盖很少，是很弱的逻辑覆盖标准 ·为了更充分地测试程序，需要采用后边讲述的其他逻辑覆盖方法 ·为了暴露程序中的错误，语句覆盖是最起码的测试要求，要求设计足够多的测试用例，使得每一条语句至少被执行一次 ·语句覆盖的优点 • 检查所有语句 • 结构简单的代码的测试效果较好 • 容易实现自动测试 • 代码覆盖率高 • 如果是程序块覆盖，则不用考虑程序块中的源代码 语句覆盖不能检查出的错误有 • 条件语句错误、逻辑运算错误、循环语句错误 判定覆盖要求：逻辑判断至少一次。每个判定的每个分支至少执行一次。 要求设计做够多的测试用例，使得程序中的每一个分支至少通过一次 • 即每一条分支语句的“真”值和“假”值都至少执行一次 • while语句、switch语句、异常处理、跳转语句和三目运算符(a？b：c)等等同样可以使用分支覆盖来测试 • 对多分支语句，如C语言中的case语句，分支覆盖必须对每一个分支的每一种可能的结果都进行测试 判定覆盖要比语句覆盖查错能力强一些： • 执行了分支覆盖，实际也就执行了语句覆盖 判定覆盖与语句覆盖存在同样的缺点 • 不能查出条件语句错误，不能查出逻辑运算错误，不能查出循环次数错误，不能查出循环条件错误 条件覆盖要求：每个判定的每个条件应取到各种可能的值。 不仅每一个语句至少执行一次，使得判定中的每个条件获得各种可能结果 判定覆盖只关心整个判定表达式的结果，条件覆盖关心的则是每个条件各种取值的结果 条件覆盖的利弊 •− 能够检查所有的条件错误 •− 不能实现对每个分支的检查 •− 用例数增加 判定/条件覆盖要求：同时满足判定覆盖条件覆盖。 设计足够多的测试用例，使得判定中每个条件的所有可能取值至少能够获取一次，同时每个判断的所有可能的判定结果至少执行一次 •− 用于解决条件覆盖不一定包括判定覆盖，判定覆盖也不一定包括条件覆盖的问题 分支-条件覆盖的利弊： •− 既考虑了每一个条件，又考虑了每一个分支，发现错误能力强于分支覆盖和条件覆盖 •− 并不能全面覆盖所有路径 •− 用例数量的增加 条件组合覆盖要求：每个判定中各条件的每一种组合至少出现一次。 要求设计足够多的测试用例，使得每个判定中条件的各种组合至少出现一次 满足条件组合覆盖标准的测试用例，也一定满足判定覆盖、条件覆盖和判定/条件覆盖标准 • 条件组合覆盖是前面几种覆盖标准中最强的 • 但是，满足条件组合覆盖要求的测试用例并不一定能使程序中的每条路径都执行到 路径覆盖要求：使程序中每一条可能的路径至少执行一次。 所有出入口测试。(全覆盖) 覆盖率：逻辑与功能覆盖 = 至少一次items/总item数。 程序流程图的各个符号： 程序图 定义：给定一个采用命令式程序设计语言编写的程序，其程序图是一种有向图，其中： •传统定义： • 节点是程序语句，边表示控制流（从节点i到节点j有一条边，当且仅当对应节点j的语句可以立即在节点i对应的语句之后执行）。 •改进后的定义： • 节点要么是整个语句，要么是语句的一部分，边表示控制流（从节点i到节点j有一条边,当且仅当对应节点j的语句或语句的一部分，可以立即在节点i对应的语句或语句的一部分之后执行） 环形复杂度(McCabe度量法)是一种为程序逻辑复杂性提供定量测度的 软件度量，将该度量用于计算程序的基本的独立路径数目，为确保所有语句至少执行一次的测度数量的上界。 范例： 复杂度:6 复杂度:3","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":null},{"title":"使用testbed进行代码静态分析的步骤详解","slug":"TEST/使用testbed进行代码静态分析的步骤详解","date":"2025-04-17T08:32:18.000Z","updated":"2025-04-25T01:45:06.799Z","comments":true,"path":"2025/04/17/TEST/使用testbed进行代码静态分析的步骤详解/","link":"","permalink":"http://www.formeasy.cc/2025/04/17/TEST/%E4%BD%BF%E7%94%A8testbed%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E7%9A%84%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"使用testbed进行代码的静态分析主要有四个步骤： 选择分析对象 分析前的设置 分析项的选择与分析过程 查看分析结果 1、选择分析对象 可通过两种方式选择被分析对象：单个文件分析、以集（set）的形式分析，其中以set形式可一次分析多个文件 进行单个文件分析时，点击testbed菜单file-select file打开要分析的文件点击select即可,可在工具快捷按钮栏下方看见所选择的文件 以set形式进行分析时，点击testbed菜单Set-select/create/delete sets创建一个set 输入set名点击create后会弹出set的属性设置对话框，有两种属性：group和system 创建好set后可看见set名及其属性 接下来向集合中添加文件，点击testbed菜单set-list/add/remove files in sets，在弹出的对话框中点击add添加多个文件到set中 2、分析前的设置 基本静态设置 点击testbed菜单configure-static option，弹出static analysis option对话框 选项卡include files中的内容是对头文件的设置，其中： analysis include files区域设定是否分析头文件，一般选择第二种analysis the first instance of each found include interactive include file analysis 区域设定代码中出现头文件包含语句时，testbed与用户的交互方式，一般选择第三种display dialog only when include file not found include search directories区域设置头文件的查找目录和系统头文件的处理方式，其中search options设置头文件的查找目录，分析前须添加头文件目录，system include search设置系统头文件的展开方式，建议设为don’t expand 选项卡macros设定用户代码编译宏的处理方式 sysppvar区域设置编译宏的定义，对于在编译命令中定义的宏，而在代码中使用此宏影响代码的编译的情况，需要用户把该宏添加到testbed的设置文件中，可点击edit default打开文件sysppvar.dat，在此文件中添加相应的宏定义 interactive conditional preprocessing options区域设置针对代码中未识别的宏的处理及交互方式，选中interactive preprocessing时，出现未识别的宏时会弹出对话框让用户定义此宏，AutoMacro设定宏的自动定义处理方式： Enable-promt for macro vaule弹窗提示并让用户指定宏值 Enable-no promt , use default 不弹窗提示，使用默认值 Disable-stop static analysis 弹窗，并停止分析 代码评审报告设定 点击testbed 菜单configure-quality report options，弹出对话框quality report，在选项卡report based congiguration 中的programming standards model区域选择进行编码规则检查所使用的规则集，在additional detail for each standards violation区域设定分析结果报告是否包含源代码行号和格式化后的代码行号 在选项卡data files中的standards models editor区域点击launch editor可以打开编码规则图形化定制页面实现规则集的定制 质量评审报告设定 点击testbed菜单configure-metrics report options，弹出metrics report对话框，在metpen configuration区域可以设定质量评审报告中每个度量元的上下限阈值，定制质量模型，点击C:\\LDRA_Toolsuite\\metpen.dat后的edit，打开质量模型配置文件，修改此文件中度量元的上下限阈值即可修改质量模型 数据对象分析报告设定 点击configure-data object analysis report options，弹出data object analysis configuration 对话框，设定数据对象分析报告中显示的对象范围 3、分析项的选择与分析过程 点击菜单analysis-select analysis，在弹出的对话框中选择要执行的静态分析项，接着点击start analysis开始分析 4、查看分析结果 单个文件结果查看 点击菜单individual results 可看到下拉项source code 、text results、graphical results分别显示了分析结果，这三个下拉项分别展开可查看详细的分类结果 set的结果查看 点击菜单set results 可看到下拉项text results、graphical results分别显示了分析结果，这两个下拉项分别展开可查看详细的分类结果","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":null},{"title":"软件开发的四大悖论","slug":"Other/软件开发的四大悖论","date":"2025-04-17T08:29:37.000Z","updated":"2025-04-25T01:49:30.721Z","comments":true,"path":"2025/04/17/Other/软件开发的四大悖论/","link":"","permalink":"http://www.formeasy.cc/2025/04/17/Other/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E7%9A%84%E5%9B%9B%E5%A4%A7%E6%82%96%E8%AE%BA/","excerpt":"","text":"Infoworld 特约撰稿人 Nick Hodges 发布了一篇名为 “Four paradoxes of software development” 的文章，阐述了他眼中的软件开发领域的四大悖论。 全文内容如下： 桥梁建设 vs 软件开发：四个令人困惑的悖论 土木工程师可以理直气壮地说，世界上没有两座完全相同的桥梁。然而，桥梁共享许多已知特性，其建筑材料也有明确参数。桥梁建设涉及大量已知的已知项，未知的未知项远比人们想象的少得多。 我并非土木工程师，对设计和建造桥梁的杰出人士充满敬意。但我想通过这种对比说明：编写优秀、可运行的软件极其困难。软件开发团队承接的每个项目都是独一无二的。尽管项目之间存在相似性，但每个软件项目都有其独特的细微差别、需求，以及大量的未知未知项。 或者说，软件开发充满了难以处理的悖论。以下是四个典型案例： 悖论一：无人知晓工期，但客户坚持要交付日期 坦率地说，这可能是软件开发组织面临的最大挑战。我们根本无法确定任何项目需要多长时间。当然，我们可以估算，但结果几乎总是大错特错 —— 有时严重高估，但更多时候是严重低估。 对客户而言，这既神秘又痛苦。由于不理解悖论的第一部分，他们不明白为何无法确定新软件的交付时间。当软件未能如期交付时，挫败感自然产生。 我们尝试使用 story points、planning poker 和其他敏捷方法来预测进度，但始终无法摆脱霍夫施塔特定律（Hofstadter’s Law）的魔咒：即使考虑了霍夫施塔特定律，事情总会比你预期的更久。 悖论二：向延期项目加派人手，只会让项目更晚 这条被称为布鲁克斯定律（Brooks’s Law）的规则，对旁观者而言可能是最诡异的悖论。 通常，如果你发现无法按时完成牙膏管灌装任务，可以通过增加人手来赶上截止日期。如果你想在一年内建造双倍数量的房屋，通常只需双倍投入劳动力和材料即可实现（误差很小）。 然而，正如弗雷德・布鲁克斯（Fred Brooks）在其著作《人月神话》中所揭示的：“向延期的软件项目增加人力，只会让它更晚。” 这是一个悖论，却是软件开发领域最接近定律的真理。布鲁克斯指出，新成员需要时间理解复杂系统的上下文，并增加沟通成本，因此无法立即贡献生产力 —— 这反而会延长项目周期并推高成本。 悖论三：编码能力越强，编码量反而越少 成为一名经验丰富的软件开发者需要多年积累。学习正确的编码方式、设计方法，以及编写整洁可维护代码的规则与技巧，绝非一日之功。 但讽刺的是，随着经验增长，你往往会被推向领导岗位，实际编码量反而减少。你不再写代码，而是参加设计会议、审查他人代码、管理团队。有时，你甚至因晋升而彻底告别编码。 这并不意味着资深开发者的贡献减少。通过规划项目、指导新人、维护编码标准，并确保团队产出优质代码，资深开发者对团队和公司的成功至关重要。 但你的确会写更少的代码。 悖论四：开发工具日益强大，但开发效率并未提升 对比当今使用 React、Astro、Next.js 等强大工具构建的 Web 应用，与 30 年前通过通用网关接口（CGI）处理数据和 HTML 的网站，你会发现我们已经比早期进步了数光年。 然而，尽管工具日益先进、处理器速度飙升，软件开发效率似乎从未真正提高。工作量不仅总是超出时间预算，甚至超出了每个 CPU 周期的负荷。 我们的网站更美观了，但开发效率真的提升了吗？网站运行更快、数据处理更高效了吗？诚然，新框架和库抽象了许多复杂性（还有人想写 jQuery 代码吗？），但它们也带来了构建流程冗长、配置复杂、依赖膨胀等新问题。 与桥梁的终极差异：软件永无 “完工” 之日 这些悖论的存在并不意味着绝望。我指出它们，是为了让我们意识到其存在，学会接受并应对，从而避开潜在的陷阱。我们无法消除软件开发的陌生感和混乱，但可以预见并驾驭它们。我们的使命是：在悖论中交付。 最后一个悖论或许是：软件开发永远没有真正完成之日。总有新功能可以添加。而桥梁工程至少有一个明确的终点 —— 当桥梁建成并按设计运行时，工作便宣告结束。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://www.formeasy.cc/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":null},{"title":"PyPy、Numba 与 Cython，哪个是最佳 Python运算解决方案？","slug":"Python/PyPy、Numba 与 Cython，哪个是最佳 Python运算解决方案？","date":"2025-04-16T06:31:47.000Z","updated":"2025-04-16T06:36:24.945Z","comments":true,"path":"2025/04/16/Python/PyPy、Numba 与 Cython，哪个是最佳 Python运算解决方案？/","link":"","permalink":"http://www.formeasy.cc/2025/04/16/Python/PyPy%E3%80%81Numba%20%E4%B8%8E%20Cython%EF%BC%8C%E5%93%AA%E4%B8%AA%E6%98%AF%E6%9C%80%E4%BD%B3%20Python%E8%BF%90%E7%AE%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F/","excerpt":"","text":"正如Python之父说：“大部分觉得Python慢的应用都是没有正确地使用Python。” 由于Python由于要在运行时编译和解释执行字节码，而且这个过程中参与了很多类似运行时类型检查的操作等一系列其他操作，从而产生了很多额外开销，降低了性能。 为了让这门语言变得完美，PyPy、Numba、Cython解决方案应用而生。 PyPy PyPy是用RPython(CPython的子集)实现的Python，根据官网的基准测试数据，它比CPython实现的Python要快6倍以上。快的原因是使用了Just-in-Time(JIT)编译器，即动态编译器，与静态编译器(如gcc,javac等)不同，它是利用程序运行的过程的数据进行优化。 **适用场景：**PyPy最适合纯Python应用程序，不适用于C扩展 Numba Numba 是 python 的即时（Just-in-time）编译器，即当您调用 python 函数时，您的全部或部分代码就会被转换为“即时”执行的机器码，它将以您的本地机器码速度运行。 python 代码的编译过程包括四个阶段：词法分析 -&gt; 语法分析 -&gt; 生成字节码 -&gt; 将字节码解释为机器码执行, 常见的 python 解释器的类型有 cpython、IPython、PyPy、Jython、IronPython，与其他解释器不同，numba 是使用 LLVM 编译技术来解释字节码的。 代码编译方式 **适用场景：**使用numpy数组做大量科学计算时、使用for循环时 Cython 与Numba不同，所有的Cython代码应该在专门文件中与常规Python代码分开。Cython将这些文件解析并转换成C代码，然后使用提供的C编译器 (例如，gcc)编译它。 编写快速Cython代码需要理解C和Python内部结构。如果你熟悉C，你的Cython代码可以运行得和C代码一样快。 **适用场景：**优化Python脚本性能或Python调用C函数库 总结： 以上三种方法都有各自最适合的使用场景，也有相对的局限性，没法说谁最是优秀的运算解决方案，大家可以根据不同场景选择使用。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":null},{"title":"在你的html页面里执行python","slug":"Python/在你的html页面里执行python","date":"2025-04-15T02:52:51.000Z","updated":"2025-04-15T03:05:09.155Z","comments":true,"path":"2025/04/15/Python/在你的html页面里执行python/","link":"","permalink":"http://www.formeasy.cc/2025/04/15/Python/%E5%9C%A8%E4%BD%A0%E7%9A%84html%E9%A1%B5%E9%9D%A2%E9%87%8C%E6%89%A7%E8%A1%8Cpython/","excerpt":"","text":"💚 pyodide 介绍 Pyodide是CPython到WebAssembly/Emscripten的一个接口，主要在浏览器中使用。 Pyodide在浏览器中使用micropip安装和运行Python包。它附带了一个健壮的Javascript⟺ Python外部函数接口，这样您就可以在代码中自由地混合这两种语言，而不会产生太大的摩擦。这包括对错误处理（用一种语言抛出错误，用另一种语言捕获错误）、异步/等待等的完全支持。在浏览器中使用时，Python可以完全访问Web API。 💚 在浏览器使用python repl 体验地址 http://pyodide.org/en/stable 页面截图如下 首先在你的html代码里加入这行，引入pyodide 1https:///pyodide/v0.20.0/full/pyodide.js pyodide.js文件定义了一个名为loadPyodide的异步函数，该函数设置Python环境并返回Pyodide顶级名称空间。 123456789async function main() &#123; let pyodide = await loadPyodide(); // Pyodide is now ready to use... console.log(pyodide.runPython(` import sys sys.version `));&#125;;main(); 来看一个例子，详细代码如下 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script src=&quot;https:///pyodide/v0.20.0/full/pyodide.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; Pyodide test page &lt;br&gt; Open your browser console to see Pyodide output &lt;script type=&quot;text/javascript&quot;&gt;async function main()&#123; let pyodide = await loadPyodide(); console.log(pyodide.runPython(` import sys sys.version `)); console.log(pyodide.runPython(&quot;print(1 + 2)&quot;)); &#125; main(); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 我们保存到本地执行一下， 打开该页面的控制台，我们看到打印出了python版本和表达式的结果3 💚 在浏览器页面交互执行python 先看一个例子，在页面交互执行计算一个python列表的所有值相加之和 点击run，就在output输入框显示了计算的值 源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;script src=&quot;https:///pyodide/v0.20.0/full/pyodide.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; You can execute any Python code. Just enter something in the box below and click the button. &lt;/p&gt; &lt;input id=&quot;code&quot; value=&quot;sum([1, 2, 3, 4, 5])&quot; /&gt; &lt;button onclick=&quot;evaluatePython()&quot;&gt;Run&lt;/button&gt; &lt;br /&gt; &lt;br /&gt; &lt;div&gt;Output:&lt;/div&gt; &lt;textarea id=&quot;output&quot; style=&quot;width: 100%;&quot; rows=&quot;6&quot; disabled&gt;&lt;/textarea&gt; &lt;script&gt; const output = document.getElementById(&quot;output&quot;); const code = document.getElementById(&quot;code&quot;); function addToOutput(s) &#123; output.value += &quot;&gt;&gt;&gt;&quot; + code.value + &quot;\\n&quot; + s + &quot;\\n&quot;; &#125; output.value = &quot;Initializing...\\n&quot;; // init Pyodide async function main() &#123; let pyodide = await loadPyodide(); output.value += &quot;Ready!\\n&quot;; return pyodide; &#125; let pyodideReadyPromise = main(); async function evaluatePython() &#123; let pyodide = await pyodideReadyPromise; try &#123; let output = pyodide.runPython(code.value); addToOutput(output); &#125; catch (err) &#123; addToOutput(err); &#125; &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 后记 不仅可以在浏览器中使用，也可以在node.js中使用，当然python也可以执行js, 只需import js。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":null},{"title":"前端Cypress自动化测试全网详解","slug":"TEST/前端Cypress自动化测试全网详解","date":"2025-04-09T00:56:03.000Z","updated":"2025-04-25T01:54:36.973Z","comments":true,"path":"2025/04/09/TEST/前端Cypress自动化测试全网详解/","link":"","permalink":"http://www.formeasy.cc/2025/04/09/TEST/%E5%89%8D%E7%AB%AFCypress%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%85%A8%E7%BD%91%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Cypress 自动化测试详解：从安装到实战 Cypress 是一个强大的端到端（End-to-End, E2E）功能测试框架，基于 Node.js 构建，支持本地浏览器直接模拟测试，并具有测试录屏功能，极大地方便了测试失败时的场景重现与问题定位。本文将详细介绍 Cypress 的安装、配置以及一个实际的自动化测试示例。 一、安装 Cypress 安装 Node.js 首先，你需要安装 Node.js。Node.js 的安装包可以从其官方网站（https://nodejs.org/en/download/ ）下载。下载完成后，按照提示进行安装。 安装完成后，打开命令行工具（cmd 或 PowerShell），输入以下命令以确认安装成功： 12node -vnpm -v 安装 Cypress 接下来，我们需要安装 Cypress。首先，在你的工作目录中创建一个新的文件夹 例如 Ui_test，然后使用 cd 命令进入该文件夹。 12mkdir Ui_testcd Ui_test 执行以下命令以安装 Cypress： 12npm init -ynpm install cypress --save-dev 这将创建一个 package.json 文件并安装 Cypress 及其依赖。 配置 Cypress 在项目根目录下，创建一个 package.json 文件（如果 npm init 没有自动生成），并添加以下配置，以便可以通过 npm 命令启动 Cypress： 12345&#123; &quot;scripts&quot;: &#123; &quot;cypress:open&quot;: &quot;cypress open&quot; &#125;&#125; 二、启动 Cypress 现在，你可以通过以下命令启动 Cypress： 1npm run cypress:open 或者，如果你已经全局安装了 Cypress，可以直接使用： 1npx cypress open Cypress 启动后，你将看到一个图形化的界面，其中包含了所有测试用例的列表。 三、编写测试用例 Cypress 的测试用例通常写在 cypress/integration 目录下。在该目录下，你可以创建多个文件夹和 .js 文件来组织你的测试用例。 以下是一个简单的登录测试用例示例： 在 cypress/integration 目录下创建一个新的文件夹，例如 demo。 在 demo 文件夹中创建一个新的文件，例如 login.js。 在 login.js 文件中，编写以下测试代码： 12345678910111213141516171819202122describe(‘Login Test’, function() &#123; beforeEach(function() &#123; // 在每个测试用例之前执行的代码 cy.visit(‘http://your-test-url.com/login’); // 替换为你的登录页面 URL &#125;);it(‘Should login successfully’, function() &#123; // 定位用户名输入框并输入用户名 cy.get(‘#username’).type(‘your-username’); // 替换为你的用户名 // 定位密码输入框并输入密码 cy.get(&#x27;#password&#x27;).type(&#x27;your-password&#x27;); // 替换为你的密码 // 点击登录按钮 cy.get(&#x27;#login-button&#x27;).click(); // 断言登录成功后跳转的页面包含某个特定元素或文本 cy.url().should(&#x27;include&#x27;, &#x27;/dashboard&#x27;); // 替换为登录成功后应该跳转的 URL 路径 &#125;); &#125;); 四、运行测试用例 回到 Cypress 的图形化界面，你将看到刚才创建的 login.js 测试用例。点击它，然后点击界面右上角的 “Run” 按钮来运行测试用例。 你也可以通过命令行来运行测试用例： 1npx cypress run --spec &quot;cypress/integration/demo/login.js&quot; 这将运行指定的测试用例并生成测试报告。 五、生成测试报告 Cypress 支持多种测试报告生成器，例如 Mocha Awesome。要生成 Mocha Awesome 报告，你需要安装以下依赖： 1npm install --save-dev mocha mochawesome mochawesome-merge mochawesome-report-generator 然后，在 cypress.json 文件中添加以下配置： 123456789101112&#123; &quot;env&quot;: &#123; &quot;search&quot;: &quot;Cypress e2e&quot; &#125;, &quot;reporter&quot;: &quot;mochawesome&quot;, &quot;reporterOptions&quot;: &#123; &quot;reportDir&quot;: &quot;cypress/results&quot;, &quot;overwrite&quot;: false, &quot;html&quot;: true, &quot;json&quot;: true &#125;&#125; 再次运行测试用例时，Cypress 将在 cypress/results 目录下生成 HTML 和 JSON 格式的测试报告。 文件夹目录的详解 在Cypress测试框架中，fixtures、integration、plugins、support以及cypress.json是构成其项目结构的核心目录和文件。以下是对这些目录和文件的详细讲解： 1. fixtures 作用：主要用于存储测试用例的外部静态数据。 使用：通常与cy.fixture()命令配合使用，以加载和引用这些静态数据。 文件类型：一般为.json后缀的文件，用于存储如HTTP状态码和返回值等静态数据。 优点： 可以模拟接口返回值，避免实际调用接口，从而提高测试速度。 消除了对外部功能模块的依赖，使测试用例更加稳定可靠。 2. integration 作用：存放集成测试用例。 文件类型：支持多种文件格式，包括.js（普通JavaScript文件）、.jsx（带有扩展的JavaScript文件，可包含处理XML的ECMAScript）、.coffee（JavaScript的转译语言，拥有更严格的语法）以及.cjsx（CoffeeScript中的jsx文件）。 特点：所有位于integration目录下的符合上述文件类型的文件，都将被Cypress识别为测试文件。 3. plugins 作用：存放自定义插件或Cypress提供的现成插件。 功能：允许修改或扩展Cypress的内部行为，如动态修改配置信息和环境变量等。 默认文件：默认情况下，插件位于cypress/plugins/index.js中，但也可以配置到另一个目录。 加载：每个测试文件运行之前，Cypress都会自动加载插件文件。 4. support 作用：存放辅助文件，如命令、配置等。 默认文件：默认情况下，支持文件位于cypress/support/index.js中，但也可以配置到另一个目录。 功能： 可以在其中配置一些辅助函数和命令，以便在测试用例中重复使用。 通过导入命令文件，可以在测试用例中直接使用定义的命令。 5. cypress.json 作用：Cypress的配置文件，用于定义Cypress项目的配置选项。 配置选项： baseUrl：用作cy.visit()或cy.request()命令的前缀URL。 chromeWebSecurity：是否启用Chrome的安全策略。 retries：测试用例的重试次数。 env：设置任意环境变量。 案例地址和官网地址 大家可以自己去下载 因为通过命令去下载可能不会生成integration文件 好像是因为最新版本的缘故 案例地址：https://github.com/TheBrainFamily/cypress-cucumber-example 官网地址：https://www.cypress.io/","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":null},{"title":"为什么要写测试用例，测试用例写给谁看？","slug":"TEST/为什么要写测试用例，测试用例写给谁看？","date":"2025-04-08T07:36:58.000Z","updated":"2025-04-25T01:45:32.439Z","comments":true,"path":"2025/04/08/TEST/为什么要写测试用例，测试用例写给谁看？/","link":"","permalink":"http://www.formeasy.cc/2025/04/08/TEST/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%86%99%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%EF%BC%8C%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E5%86%99%E7%BB%99%E8%B0%81%E7%9C%8B%EF%BC%9F/","excerpt":"","text":"“为什么要编写测试用例，测试用例写给谁看”，这个问题看似简单，但却涵盖了一系列复杂的考虑因素，并不太好回答。 为了向各位学测试的同学们解释清楚“为什么编写测试用例是至关重要的”，我将通过以下5个方面进行展开： 1、为什么要写测试用例？ 2、测试用例写给谁看？ 3、测试用例使用案例分享 4、测试用例在测试工作中的地位分享 5、测试用例学习资源分享 好，现在我们开始。 一、为什么需要编写测试用例？5大原因 测试用例是为特定测试目的设计的测试执行文档，它包括测试输入、执行步骤和预期结果，用于验证软件在不同情景下的行为。 为什么需要测试用例，以下是一些重要原因： 发现问题： 编写测试用例有助于发现潜在的缺陷和错误。它们允许测试人员模拟各种使用情况，确保软件质量。 验证需求： 测试用例可以用来验证软件是否满足规格和需求。它们帮助确保软件功能按照规划和设计的方式工作。 防止漏测： 测试用例可以防止遗漏关键功能或场景，充当了一个详尽的检查清单，确保了对软件各个方面的全面测试。 实施测试的标准： 编写测试用例为测试提供了一种标准化的方法，定义了每个测试情景的输入、预期输出和操作步骤，确保测试一致和可重复。 测试工作的评估：测试用例可以作为一个量化的指标，用于测量测试工作的进展和效率，对项目管理和资源分配至关重要。 二、测试用例写给谁看？5类人群 现在，让我们来看看测试用例的受众是谁。测试用例的受众可以分为以下5类： 测试团队： 最明显的受众是测试团队成员，包括测试工程师和测试经理。他们使用测试用例来规划、执行和报告测试活动，确保软件质量。 开发团队： 开发团队也是测试用例的受众之一。在用例评审时，测试用例可以帮助开发人员理解他们的代码如何应对各种测试情景，帮助他们修复缺陷。 产品经理和业务分析师： 测试用例可以帮助产品经理和业务分析师验证软件是否满足用户需求和规格。它们有助于沟通需求和期望。 高层管理： 在一些情况下，高层管理可能需要了解测试进展和软件质量。测试用例的报告和结果可用于决策制定。 自动化测试工具（看成是个人吧）： 如果你计划自动化测试，测试用例将成为自动化测试工具的输入。这些工具将模拟测试情景并生成测试报告(请看下图)。 三、测试用例使用案例： 1、冒烟测试：所谓冒烟测试，就是完成一个新版本的开发后，对该版本最基本的功能进行测试，保证基本的功能和流程能走通。 所以冒烟测试使用的用例，应该涵盖系统的核心功能和主要使用场景，以检查系统的基本功能是否可用。 如果不通过，则打回开发那边重新开发； 如果通过测试，才会进行下一步的测试(功能测试，集成测试，系统测试等等)。 2、单元测试： 在单元测试阶段，开发人员编写测试用例来验证他们的代码是否按照规格和设计要求工作。这有助于捕获和修复代码中的缺陷。 3、集成测试： 在集成测试中，测试用例用于测试不同模块之间的交互和数据流。这有助于确保整个系统的各个组件协同工作正常。 4、验收测试：在验收测试中，测试用例用于验证软件是否满足最终用户的需求和期望。产品经理和业务分析师可以使用这些用例来确认软件是否满足规格。 5、自动化测试： 所谓自动化测试，是指使用代码或工具代替手工，对项目进行测试。测试用例也可以用于自动化测试，其中测试脚本会执行预定义的测试用例，模拟各种情景。这可以提高测试效率和可重复性。 四、测试用例在测试工作中的地位分享 综上所述，编写测试用例不仅有助于发现问题、验证需求和提高软件质量，还可以防止漏测、提供测试标准和方便测试工作的评估。 这些用例在不同测试阶段和情景下都发挥关键作用，确保软件的可靠性和一致性。 无论你是从事软件测试还是开发，理解测试用例的价值是至关重要的。 这些用例不仅有助于发现问题、验证需求和提高软件质量，还可以防止漏测、提供测试标准和方便测试工作的评估，确保测试工作的有效性和可信度。 所以，测试用例在测试工作中的地位非常高，属于软件测试核心流程。 也因此，测试用例撰写，是软件测试人员的基本功，必须要掌握。","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":null},{"title":"Web前端自动化测试Cypress实践总结","slug":"TEST/Web前端自动化测试Cypress实践总结","date":"2025-04-08T06:49:33.000Z","updated":"2025-04-25T01:43:49.701Z","comments":true,"path":"2025/04/08/TEST/Web前端自动化测试Cypress实践总结/","link":"","permalink":"http://www.formeasy.cc/2025/04/08/TEST/Web%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95Cypress%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/","excerpt":"","text":"Excerpt 本文主要首先主要介绍了什么是自动化测试，接着对常用的自动化测试框架进行了对比分析，最后，介绍了如果将自动化测试框架Cypress运用在项目中。 一、自动化测试概述 为了保障软件质量，并减少重复性的测试工作，自动化测试已经被广泛运用。在开始学习自动化测试之前，我们很有必要先搞清楚这几个问题，什么是自动化测试？为什么要做自动化测试？哪些项目适合做自动化测试？ 1、什么是自动化测试 自动化测试是一种测试方法，是指使用特定的软件，去控制测试流程，并比较实际结果与预期结果之间的差异。通过将测试自动化，可以把人对软件的测试行为转化为由机器自动执行测试的行为，从而替代大量的手工测试操作，使得测试可以快速，反复的进行。 关于自动化测试，有一个测试金字塔模型，该模型把测试从下到上分为了单元测试、集成测试和端到端测试（E2E测试/UI界面测试）。越往金字塔底层，测试成本越低，效率也越高，而越往金字塔的顶层，测试成本会逐渐增高，收益也会越低。 单元测试 单元测试又称为模块测试，主要针对程序中最小可测试单元（一般指方法，类）的测试，具备投入小、收益产出高的特征，可以较早期地发现代码缺陷，适用于公共函数库的测试。 集成测试 集成测试主要包括模块接口测试，子功能模块集成起来的功能模块测试等，目的是为了验证在单元测试的基础上，所有模块集成起来的子系统、子功能是否仍然满足质量目标。 端到端测试 端到端测试的主要目的是从软件使用者角度来检验软件的质量，如打开浏览器，进行一系列的操作，验证界面或功能是否符合预期。 不同类型的项目，具有不同的测试场景，因此也需要采用不同的测试类型。对于开发人员来说，单元测试专注于代码底层，可能是一种比较友好的选择。但是站在产品的角度上，也许端到端测试（E2E）是更好的选择，更能保障产品功能符合预期。 讲完了自动化测试类型，我们再来看看测试中常用的测试模式，一般常用的测试模式包括TDD和BDD两种。 TDD TDD（测试驱动开发，Test Driven Development），TDD是指先写测试用例代码，再写功能代码，并且不断的重复上述步骤直到完成开发工作。TDD一般结合单元测试使用，是白盒测试。 BDD BDD（行为驱动开发，Behavior Driven Development），BDD是指先写功能代码，再写测试用例代码，BDD一般结合集成测试或端到端测试使用，是黑盒测试。 当然，是选择TDD还是BDD，也是需要从项目的实际角度出发考虑，再做选择 2、为什么要做自动化测试 接下来，我们再来聊聊为什么要做自动化测试？在实际的项目开发中，我们常常会遇到以下问题： 产品迭代频繁 迭代过程中不可避免的需要新增功能或修改功能，怎么保障新功能的发布不会影响原有功能呢？ 多人共同参与开发，代码维护难 项目开发过程中多人参与开发，人员变动频繁，开发过程中可能出现误删或误改他人代码逻辑的问题，如何保障代码的质量和可靠性？ 测试人力不足，回归测试耗时耗力 为了解决上面提到的两个问题，其实方法很简单，就是每次新功能发布后，都对原有功能再进行回归测试。但是又可能遇到测试人力不足的情况，自己手动进行回归测试又耗时耗力，如何才能减少重复性工作，提高效率呢？说到这里，自动化测试就派上用场啦~ 那项目引入自动化测试有什么好处呢？自动化测试的好处主要包括了以下几点。 验证代码正确性，保障产品质量 可以验证代码或产品功能的正确性，确保每次产品迭代，新功能和原有功能能够正确集成，保证产品质量。 提高测试效率 编写的测试用例具有一次编写，多次运行的特点，通过执行测试脚本，可以实现使得测试快速，反复的进行，可以替代大量的重复性手动测试工作，提高效率。 起到文档作用 编写的测试用例可以起到文档的作用，有利于项目后续的维护。 3、哪些项目适合引入自动化测试 既然自动化测试有这么多好处，那是不是所有项目都适合引入自动化测试呢？当然不是！自动化测试需要进行测试用例的编写，需要一定的开发成本，我们需要立足于项目本身，再来决定是否适合引入自动化测试。 适合引入自动化测试的项目 1）产品周期较长，需要不断进行迭代/重构的项目。2）公共库类的开发维护。 不适合引入自动化测试的项目 1）产品周期过短的项目。2）需求变动过于频繁的项目。 二、前端自动化测试框架选择 在明确了我们的项目有必要引入自动化测试之后，就需要选择一款自动化测试框架或工具来帮助我们完成自动化测试工作啦~ 1、测试框架对比 下面主要对比了现在常用的Web前端自动化测试框架，如果需要了解更多的框架，可以参考测试框架选型 在上述框架中，由于Cypress能够同时支持单元测试、集成测试和E2E测试，提供了一套完成的测试解决方案，能够满足我们的需求。此外，Cypress支持JS编写测试用例，支持Jquery元素定位选择器，支持Headless和CI持续集成，运行速度快，上手成本低，并且具有可视化调试界面，方便定位问题。因此决定尝试将Cypress运用到项目中。 三、Cypress实践 接下来，主要介绍如何将Cypress运用在项目中。 1、Cypress安装 在安装Cypress时，可以直接在原有的项目上进行安装，也可以另起一个项目安装。 1npm install cypress --save-dev 2、Cypress启动 Cypress主要包含以下两种启动方式： 1）命令行执行npx cypress open：会在浏览器打开测试用例集的界面，需要手动运行。 2）命令行执行npx cypress run：会以无头浏览器模式运行指定的所有测试用例，没有可视化界面，但运行过程中会录制整个测试过程的视频，可在cypress/videos目录下查看。 当然，除了直接在命令行运行上述命令，也可以通过配置package.json的scripts字段来定义启动方式。 1234567&quot;scripts&quot;: &#123; &quot;serve&quot;: &quot;vue-cli-service serve&quot;, &quot;build&quot;: &quot;vue-cli-service build&quot;, &quot;lint&quot;: &quot;vue-cli-service lint&quot;, &quot;cypress:open&quot;: &quot;npx cypress open&quot;, &quot;cypress:run&quot;: &quot;npx cypress run&quot;&#125; 可视化界面运行 如果我们需要在可视化界面进行测试，在配置好package.json后，只需要执行npm run cypress:open，就可以启动Cypress，实现可视化调试，如果在启动的过程中遇到以下错误，可以先执行npx cypress install -force，再重新启动Cypress。 如果成功启动Cypress，将会看到以下界面，examples目录下是cypress自带的测试用例演示代码（如果后面不需要，我们可以将这些测试用例删除），点击其中的某个测试用例，将会自动打开浏览器运行测试用例。 如果我们是第一次启动Cypress，会发现在项目根目录下也自动生成了cypress.json配置文件和cypress目录。其中，integration文件夹就是我们用来存放测试用例的目录，可以在cypress.json中自定义这些默认目录的命名。 无头浏览器模式运行 如果我们想以无头浏览器模式运行，在配置好package.json后，需要执行npm run cypress:run，Cypress就会以无头浏览器的模式运行指定的所有测试用例。 3、编写测试用例 接下来以验证百度页面的搜索功能为例，演示如何编写测试用例，测试用例可以以.spec.js或.js结尾命名，并放入cypress/integration中。 项目目录如下所示，在cypress/integration中创建test.js或test.spec.js测试用例文件。 接着，可以在test.js中开始编写测试用例，Cypress支持Jquery元素选择器及汉字选择器，并且也支持链式操作，此外，由于Cypress拥有自动等待机制，我们无须在测试中添加wait或sleep，Cypress会自动等待元素至可操作状态时才执行命令或断言。 /// &lt;reference types=&quot;cypress&quot; /&gt; context('百度页面测试', () =&gt; &#123; it('访问百度页面，验证搜索功能', () =&gt; &#123; cy.visit('https://www.baidu.com').then(() =&gt; &#123; // 1. 输入搜索内容 cy.get(&quot;.s_ipt&quot;).should(&quot;exist&quot;).type(&quot;Cypress自动化测试&quot;); // 2. 点击百度一下按钮 cy.get(&quot;.s_btn&quot;).contains(&quot;百度一下&quot;).should(&quot;exist&quot;).click(); // 3. 验证搜索内容不为空 cy.get(&quot;#content_left&quot;).find(&quot;div&quot;).then(ele =&gt; &#123; expect(ele.length).gt(0); &#125;); &#125;); &#125;); &#125;); 编写完上述代码，我们就可以直接启动Cypress运行啦，当然，我们也可以根据实际需要在cypress.json进行一些配置，下面给出了一些常用的配置，可以在Cypress文档查看更多配置。 最后，执行npm run cypress:open启动Cypress，启动成功后，我们就可以看到以下界面，点击test.js，就会在浏览器中运行该测试用例。 在测试用例执行的过程中，每一步操作都会被记录下来，可以点击左边的界面对每一步的操作进行回看，可以帮助我们快速定位问题。 4、Cypess文件上传/下载 在实际的使用过程中，我们通常也需要验证文件上传或下载功能，而Cypress也能够满足这些需求。 1）文件上传 首先需要安装cypress-upload-file插件。 1npm install cypress-upload-file --save-dev 将要上传的文件放到cypress/fixtures中。 编写测试用例代码。 /// &lt;reference types=&quot;cypress&quot; /&gt; context('文件上传', () =&gt; &#123; it('验证文件上传功能', () =&gt; &#123; // 访问页面，此处步骤省略 let file = &quot;file/cover.jpg&quot;; cy.get(&quot;input[type='file']&quot;).attachFile(file); // 执行断言，此处步骤省略 &#125;); &#125;); 2）文件下载 若我们在运行测试用例的过程中存在文件下载操作，Cypress会自动在cypress目录下创建一个downloads目录，所下载的文件会自动保存在该目录中。 可以在测试用例中读取并解析下载的文件。 /// &lt;reference types=&quot;cypress&quot; /&gt; const path = require(&quot;path&quot;); context('文件下载', () =&gt; &#123; it('验证文件下载功能', () =&gt; &#123; // 访问页面，执行下载操作，此处步骤省略 const downloadsFolder = Cypress.config(&quot;downloadsFolder&quot;); const downloadedFilename = path.join(downloadsFolder, &quot;下载文件.xls&quot;); // 读取文件 cy.readFile(downloadedFilename).then(data =&gt; &#123; // 执行断言，此处步骤省略 &#125;); &#125;); &#125;); 5、Cypress测试报告 在执行完自动化测试后，我们通常都希望能够得到一份详细的测试报告，而Cypress也能够提供这个功能。Cypress除了内置的测试报告，也支持用户自定义报告格式。 1）内置的测试报告 Cypress内置的测试报告主要包括了spec格式报告（在控制台窗口输出嵌套分级视图），json格式报告（在控制台窗口输出一个大的json对象）和junit格式报告（输出一个xml文件）。以spec格式报告为例，在启动cypress时加上以下参数即可。 2）自定义的测试报告 常用的自定义测试报告有Mochawesome报告，Mochawesome是与Mocha一起使用的自定义报告程序，并与mochawesome-report-generator结合使用以生成独立的HTML/CSS报告。 安装mocha和mochawesome。 12npm install mocha --save-devnpm install mochawesome --save-dev 修改启动参数。 运行npm run cypress:run，执行结束后，会在项目根目录下生成mochawesome-report目录。 在浏览器中打开mochawesome.html，就可以查看可视化测试报告。 四、编写可维护的测试脚本 在实际编写测试用例的过程中，随着页面的增多，我们常常会遇到以下这些问题，而这个时候，如何编写可维护的测试脚本，方便后期维护，也显得非常重要，这里也总结了实际开发中的一些经验。 1、测试用例代码结构组织 在编写测试用例时，我们可以一个页面对应一个测试文件，也可以同个功能模块的页面一起对应一个测试文件，并且和平时开发中所采用的代码组织结构类似，将不同的测试文件划分到对应的目录下进行管理，方便后期的维护。 2、页面选择器统一管理 在E2E测试中，我们通常需要获取页面元素，才能够进行点击等操作。而Cypress支持Jquery选择器，我们可以通过元素的class或id定位元素。但是一旦页面的类名或id发生变化，我们不得不修改对应页面的所有测试用例。 在编写测试用例的过程中，我们可以将页面选择器进行统一管理，实现类名或id选择器和逻辑代码的分离。对于每个页面或者每个测试文件，可以创建一个对应的xxxControl.js文件，在该文件中，将会定义一个json对象并且export出来，其中，key为我们自己定义的选择器名称，而value值对应页面中实际的class或id。 由于目前项目中使用到了iview组件库，因此也提取出了commonControl.js，对iview的选择器进行统一管理。 由于每个页面都采用到了iview组件，因此每个页面或每个测试文件对应的control.js都需要将上面的commonControl.js引入进来。 最后，每个测试文件只需要引入对应的control.js，就可以通过自己定义的key值获取页面真正的class或id。 上面的方法看起来虽然麻烦了点，但是有两个好处，首先，采用自己定义的key值，更容易方便我们记忆，可以减少编写测试用例过程中反复查看页面元素对应的class或id名。其次，当页面的类名或id发生变化时，我们只需要修改页面对应的control.js文件就可以，而不用修改所有的测试用例文件，有利于后续的维护。 3、路径名及接口统一管理 在编写测试用例的过程中，我们通常需要使用cy.visit()去访问某个页面，或者使用cy.request()去调用后台接口以请求数据或创建测试数据，对于页面url或后台接口api，我们也可以放入某个文件中进行统一管理。 4、代码复用 在测试的过程中，我们可能会注意到，不同的页面可能会存在一些相同的功能。比如像目前的项目中，不同的页面都需要对一些操作进行弹框确认或表单输入，而在验证弹框功能是否正确的过程中，我们都需要对弹框执行点击确定按钮、点击取消按钮、点击关闭按钮等操作，而这个时候就可以采用面向对象编程的方法实现代码的封装和复用。 定义一个弹框类，并且定义属性和方法。 在测试文件中，需要实例化对象，并调用相关的方法完成某个操作。 当然，有些方法并不是所有的页面都共有的，但是在某个页面或功能中会反复使用到，因此也可以为每个页面或每个测试文件单独封装相应的方法。比如为课程管理页面封装相应的通用方法。 以上就是关于将Cypress运用在项目中的一些总结，而如何将Cypress和CI/CD结合，并且实现自动化测试的定时执行，也是接下来需要继续完成的内容~","categories":[{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"}],"author":null},{"title":"python虚拟环境venv直接复制迁移的方法","slug":"Python/python虚拟环境venv直接复制迁移的方法","date":"2025-04-08T02:58:46.000Z","updated":"2025-04-08T03:03:21.941Z","comments":true,"path":"2025/04/08/Python/python虚拟环境venv直接复制迁移的方法/","link":"","permalink":"http://www.formeasy.cc/2025/04/08/Python/python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83venv%E7%9B%B4%E6%8E%A5%E5%A4%8D%E5%88%B6%E8%BF%81%E7%A7%BB%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"python虚拟环境venv迁移布署有很多的方法，大家自行搜索。这里只介绍一种：直接复制的方法 1、将整个文件夹复制到新的电脑 2、修改pyvenv.cfg文件内的home为你新电脑python的安装路径。 3、 如果你使用vscode，还需要修改vscode的配置文件launch.json，这样就可以在新的电脑上调试了。 4、修改程序目录下Scripts\\activate文件（可以用记事本打开） VIRTUAL_ENV=&quot;E:\\your_folder&quot;改为你新电脑的位置 5、修改程序目录下Scripts\\activate.bat文件（可以用记事本打开） set VIRTUAL_ENV=E:\\mySourse\\anzhi4改为你新电脑的位置 6、运行程序目录下Scripts\\activate.bat文件，激活虚拟环境。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":null},{"title":"技术人的大模型应用初学指南","slug":"LLM/技术人的大模型应用初学指南","date":"2025-04-05T13:10:24.000Z","updated":"2025-04-25T01:58:12.367Z","comments":true,"path":"2025/04/05/LLM/技术人的大模型应用初学指南/","link":"","permalink":"http://www.formeasy.cc/2025/04/05/LLM/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%88%9D%E5%AD%A6%E6%8C%87%E5%8D%97/","excerpt":"","text":"Excerpt 随着人工智能技术的快速发展，检索增强生成（RAG）作为一种结合检索与生成的创新技术，正在重新定义信息检索的方式。本文深入探讨了 RAG 的核心原理及其在实际应用中的挑战与解决方案。文章首先分析了通用大模型在知识局限性、幻觉问题和数据安全性等方面的不足，随后详细介绍了 RAG 通过 “检索 + 生成” 模式如何有效解决这些问题。具体而言，RAG 利用向量数据库高效存储与检索目标知识，并结合大模型生成合理答案。此外，文章还对 RAG 的关键技术进行了全面解析，包括文本清洗、文本切块、向量嵌入、召回优化及提示词工程等环节。最后，针对 RAG 系统的召回效果与模型回答质量，本文提出了多种评估方法，为实际开发提供了重要参考。通过本文，读者可以全面了解 RAG 技术的原理、实现路径及其在信息检索领域的革命性意义。 前言 人工智能（AI）时代的到来为技术人员提供了丰富的学习和发展机会。对于没有算法背景的技术同学来说，迎接这种新兴机遇与挑战并做好应对准备和知识储备是非常重要的。 结合笔者这一段对于大模型和 AI 技术的一些学习以及对基于 AI 改造的诸多实际应用场景的了解。于是就写了这篇文章。另外，本篇文章不会用过多的篇幅来讲算法基础的内容，而把重点放在 AI 应用的核心技术概念的理解上。 人工智能术语概述 想必大家在刚开始阅读人工智能相关的文章或书籍的时候，总是听到诸如 LLM，chatGPT，RAG，Agent 等等的术语，但是不知道这些术语对应的技术点关联性在哪里，没关系，咱们首先来学习下这些术语的定义： AI：Artificial Intelligence 的缩写，指 “人工智能”，人工智能是指模拟人类智能的计算机系统或软件，使其能够执行诸如学习、推理、问题解决、感知、语言理解等复杂任务。 生成式 AI：是一种人工智能技术，能够自动生成新的内容，如文本、图像、音频和视频等。与传统的 AI 不同，生成式 AI 不仅能分析和理解数据，还能基于其学习到的信息创造出新的内容。 AIGC：AI Generated Content 的缩写，意指由人工智能生成的内容。在算法和数码内容制作领域，AIGC 涉及使用人工智能技术生成各种形式的内容，比如文字、图像、视频、音乐等。 NLP：Natural Language Processing 的缩写，指 “自然语言处理”，自然语言处理是人工智能的一个子领域，主要研究计算机如何理解、解释和生成人类语言。NLP 技术包括文本分析、语言生成、机器翻译、情感分析、对话系统等。 Transformer：一种用于自然语言处理（NLP）任务的深度学习模型，最初由 Vaswani 等人在 2017 年的论文中提出。它引入了一种名为 “自注意力”（self-attention）的机制，能够有效地处理序列数据，且在许多 NLP 任务，如机器翻译、文本生成和语言建模中取得了巨大的成功。 BERT：Bidirectional Encoder Representations from Transformers 的缩写，是一种自然语言处理（NLP）的预训练模型。它由 Google AI 研究团队于 2018 年首次提出。BERT 的主要创新在于它使用了双向（即上下文敏感）的 Transformer 模型来对文本进行编码。 PEFT：Parameter-Efficient Fine-Tuning 的缩写，中文高效参数微调，这是一种微调机器学习模型的方法，旨在减少需要更新的参数数量，从而降低计算成本和存储需求，同时保持模型性能。PEFT 技术在大型预训练模型（如 BERT、GPT 等）的下游任务适配中尤为重要，因为直接微调这些模型可能会耗费大量计算资源和时间。 LoRA：Low-Rank Adaptation 的缩写，一种用于微调大规模语言模型的一种技术。它通过将模型的权重分解成低秩矩阵来显著减少参数数量和计算开销，从而使得模型在资源受限的环境中也能进行高效的适应性调整。 LLM：Large Language Model 的缩写，指 “大语言模型”，这类模型是基于机器学习和深度学习技术，特别是自然语言处理（NLP）中的一种技术。大语言模型通过大量的文本数据进行训练，以生成、理解和处理自然语言。一些著名的 LLM 示例包括 OpenAI 的 GPT（Generative Pre-trained Transformer）系列模型，如 GPT-3 和 GPT-4 RAG：Retrieval-Augmented Generation 的缩写，指 “检索增强生成”，这是一个跨越检索和生成任务的框架，通过先从数据库或文档集合中检索到相关信息，然后利用生成模型（如 Transformer 模型）来生成最终的输出。目前在技术发展趋势和应用落地上，RAG 是工程同学较为值得探索的领域。 Agent：中文叫智能体，一个能独立执行任务和做出决策的实体，在人工智能中，Agent 可以是一个机器人，一个虚拟助手，或是一个智能软件系统，它能够通过学习和推理来完成复杂任务。在多 Agent 系统中，多个独立的 Agents 相互协作或竞争，以共同解决问题或完成任务。 GPT：Generative Pre-trained Transformer 的缩写，指 “生成式预训练变换器”，GPT 模型利用大量文本数据进行预训练，然后可以通过微调来执行特定任务，例如语言生成、回答问题、翻译、文本摘要等。 LLaMA：Large Language Model Meta AI 的缩写，是由 Meta 开发的一系列大型自然语言处理模型。这些模型在处理文本生成和理解任务方面表现出色，类似于其他著名的大型语言模型如 GPT-3 chatGPT：由 OpenAI 开发的一种基于 GPT（生成预训练变换模型）架构的人工智能聊天机器人。它使用自然语言处理技术，能够理解并生成类似人类的文本回复。可以看做是一种 Agent。 Prompt：指的是提供给模型的一段初始文本，用于引导模型生成后续的内容。 Embedding：中文叫嵌入，是一种将高维数据映射到低维空间的技术，但仍尽可能保留原数据的特征和结构。嵌入技术通常用于处理和表示复杂的数据如文本、图像、音乐以及其他高维度的数据类型。 大模型应用发展趋势 ▐ 向量数据库 随着互联网内容化的飞速发展，以音视频等多媒体内容为代表的非结构化数据呈现出高速增长的趋势。图片、音频、视频等非结构化数据的存储和检索需求也变得越来越多。 IDC DataSphere 数据显示，到 2027 年全球非结构化数据将占到数据总量的 86.8%，达到 246.9ZB；全球数据总量从 103.67ZB 增长至 284.30ZB，CAGR 为 22.4%，呈现稳定增长态势。 Link：https://www.idc.com/getdoc.jsp?containerId=prCHC51814824 通常，为了更有效地管理非结构化数据，常见的做法是将其转换为向量表示，并存储在向量数据库中。这种转换过程通常被称为向量化或嵌入（Embedding）。通过将文本、图像或其他非结构化数据映射到高维向量空间，我们可以捕捉数据的语义特征和潜在关系。向量数据库通过在「向量表示」上构建索引，实现快速的相似性搜索。 向量数据库是用于存储和查询高维向量数据的数据库，通常在搜索、推荐系统、图像识别、自然语言处理等领域中广泛使用。随着 AI 创新应用的不断涌现，对于向量数据库需求也大增。 下面是一些常用的向量数据库。 1. Faiss (Facebook AI Similarity Search)： 开发者：Facebook AI Research 特点：高效的相似性搜索和密集向量聚类，支持 CPU 和 GPU 加速。 适用场景：图像相似性搜索、大规模推荐系统等。 2. Annoy (Approximate Nearest Neighbors Oh Yeah)： 开发者：Spotify 特点：基于内存的高效最近邻搜索，使用构建的可持久化树数据结构。 适用场景：音乐推荐、快速搜索等。 3. HNSW (Hierarchical Navigable Small World)： 开发者：Yury Malkov（和其他社区贡献者） 特点：小世界图算法，高效的近似最近邻搜索，支持动态插入和删除。 适用场景：实时搜索和推荐系统。 4. Elasticsearch with k-NN Plugin： 开发者：Elastic 特点：在 Elasticsearch 之上添加 k-NN 搜索功能，结合全文搜索和向量搜索。 适用场景：综合搜索引擎，需要同时支持文本和向量查询的场景。 5. Milvus： 开发者：ZILLIZ 特点：分布式、高性能向量数据库，支持大规模数据管理和检索。 适用场景：图像、视频、文本等大规模向量数据的存储和检索。 6. Pinecone： 开发者：Pinecone 特点：专用于机器学习应用程序的向量数据库，易于集成和扩展。 适用场景：个性化推荐、语义搜索、实时机器学习应用等。 7. Weaviate： 开发者：SeMI Technologies 特点：开源的向量搜索引擎，支持上下文感知的语义搜索，扩展性强。 适用场景：知识图谱构建、语义搜索、推荐系统。 8. Vectara： 开发者：Vectara, Inc. 特点：基于向量的全托管搜索服务，专注于语义搜索和相关性。 适用场景：搜索引擎优化、自然语言处理应用。 上述所提到的目前主流的向量数据库方案，在向量数据的存储成本、召回率等方面都面临较大的挑战。随着非结构化数据的进一步增长，成本和召回率的挑战会变得越来越棘手。在向量数据库的演讲方向上目前有以下发展趋势 1. 存储和索引优化 量化技术：使用向量量化（Vector Quantization, VQ）技术，例如产品量化（Product Quantization, PQ）或乘积量化（Additive Quantization, AQ），可以在保证精度的同时大幅度减少存储和计算资源。 压缩向量：采用哈希方法如局部敏感哈希（Locality-Sensitive Hashing, LSH）来减少存储消耗，并加速相似性搜索。 分布式存储：使用分布式文件系统和数据库（如 Apache Hadoop、Cassandra）可以优化存储和查询的大规模向量数据。 存储器级别调整：利用固态硬盘（SSD）甚至是新兴的持久化内存（Persistent Memory, PMEM）来在内存和磁盘之间找到平衡，优化存储成本。 2. 召回率优化 混合搜索技术：结合粗粒度和细粒度的索引，例如先使用粗滤技术快速缩小搜索范围，然后进行精确查找。 近似最近邻查找（ANN）算法：如 HNSW（Hierarchical Navigable Small World）图、FAISS 中使用的 ANN 算法可以在保证高召回率的基础上优化搜索速度。 多层次检索：分层结构的检索方法，从粗到细进行，逐步提高召回率和精度。 3. 系统架构和基础设施 云计算和弹性扩展：利用云计算平台（如 AWS、Azure、GCP），按需扩展计算和存储资源，并且利用云端的分布式存储和计算技术来管理大规模数据。 边缘计算：部分预处理和向量化工作放到边缘设备进行，减少中心服务器的负担。 4. 专用硬件加速 GPU 和 TPU：使用专门的硬件加速器，如 GPU（图形处理单元）或 TPU（张量处理单元），以加速向量计算和相似性搜索。 FPGA：使用可编程门阵列（FPGA）为特定向量计算任务定制硬件加速，以提高效率和降低延迟。 5. 持续优化和更新模型 动态索引更新：随着非结构化数据的增长和变化，保持索引和向量表示的及时性，使用在线或增量更新的方法管理索引。 自适应模型：利用机器学习和深度学习模型不断优化向量表示的嵌入质量，使得向量检索更加精准有效。 6. 先进的嵌入技术 预训练模型：使用当前的预训练语言模型（如 BERT、GPT-3）进行上下文嵌入，捕捉复杂的语义信息。 多模态嵌入：对于不同类型的数据（如文本、图像、视频），使用多模态嵌入模型来统一表示和处理，提升检索性能。 ▐ Multi-Agent 在软件领域，“分而治之” 是一种常用的设计和开发理念，而在大模型场景中也同样适用。面向复杂任务场景，多 Agent 方法会将复杂任务分解为子任务，让不同的智能体完成不同的子任务，即专业 “人” 做专业 “事”。因为，拆解任务有助于降低单个大模型的输入复杂度以及理解难度，从而有利于大模型专注于 “做” 一件事情，其性能可能会更好。 多 Agent 框架的核心交互流程可以概括如下： controller 更新当前环境的状态，选择下一时刻行动的 agent X agent X 与环境交互，更新自身 memory 信息 agent X 调用 LLM，基于指令执行动作，获取输出 message 将输出 message 更新到公共环境中 目前在多 Agent 协作方面，目前比较有名的是 AutoGen 框架和 MetaGPT 框架。 AutoGen 框架 AutoGen 是一个能让多个 Agent 进行沟通协作的 Python 开源框架。核心解决两个问题： 第一个问题：如何设计用户可定制、可重用的、能够互相协作的 Agent。AutoGen 是要设计为一个通用的能够适用多种场景的框架，在 AutoGen 的官网 Examples 中给出了在多种场景下能够解决问题的例子，此外在 git 仓库中的 notbook 目录中有 50 + 例子。有解决数学问题场景、有通过开发代码进行分析的场景（比如上一章节的列子）、还有通过五六个 Agent 讨论分析开放问题的场景。所以 Agent 的扩展能力是需要重要考虑问题，AutoGen 中通过支持多种外部工具、不同 LLM、支持 human in the loop 的方式，Agent 之间能够通信的方式来解决扩展问题。 第二个问题：如何让 Agent 能灵活支持不同模式的会话方式。不同的场景，根据复杂度、问题的类型需要不同的 Agent 会话模式。这里的 “模式” 包括了单轮对话 or 多轮对话、自动选择每轮的 speaker or 通过规则选择、通过自然语言控制逻辑 or 通过代码控制，此外设计需要考虑多个 Agent 之间如何灵活 “组网”，比如三人一组，每组一个 leader，组内互相通信，leader 能够通信的方式。 为了解决这两个问题，AutoGen 抽象了一些基础概念。 Conversable Agents 旨在用于在复杂任务中进行多轮交互。这些智能体能够理解和处理用户输入，维护上下文，并生成合适的响应。Conversable Agents 通常集成了自然语言处理技术，包括自然语言理解（NLU）和自然语言生成（NLG），以提高对话的流畅性和智能性。 Conversation Programming 旨在通过自然语言与人工智能系统进行交互，来实现编程和任务自动化。这个概念试图简化编程过程，使得用户无需深厚的编程背景也能使用自然语言描述需求，进而生成可执行的代码或自动化脚本。 在 Conversation Programming 中，用户通过与人工智能助手进行对话，将具体任务、算法逻辑或问题描述出来，AI 系统则负责理解这些意图并生成相应的代码。这种方式降低了编程的门槛，同时也加速了从想法到实现的过程。 MetaGPT 框架 MetaGPT 是一个基于多智能体的元编程框架，它通过将不同的角色（如产品经理、架构师、项目经理等）分配给不同的大型语言模型（LLM），实现软件开发流程的自动化。这个框架特别适合于复杂的编程任务，能够自动生成用户故事、需求分析、数据结构、API 和文档等输出。MetaGPT 使用标准操作程序（SOPs）来指导智能体的协作，旨在提高代码生成的质量和效率 。 工作流程 MetaGPT 的主要工作流程和特点包括： 角色定义（Role Definitions）：MetaGPT 通过定义不同的角色（如产品经理、架构师、项目经理等）来封装每个角色的特定技能和业务流程。这些角色类继承自一个基础角色类，具有名称、简介、目标、约束和描述等关键属性。角色定义帮助 LLM 生成符合特定角色要求的行为。 任务分解（Task Decomposition）：MetaGPT 将复杂的软件开发任务分解成更小、更易于管理的部分，然后将这些子任务分配给合适的智能体执行。 流程标准化（Process Standardization）：MetaGPT 定义了一系列标准化操作，每个操作都具有前缀、LLM 代理、标准化输出模式、执行内容、重试机制等属性。这些标准化操作确保了智能体之间的协作是一致的，输出的结果也是结构化的。 知识共享（Knowledge Sharing）：MetaGPT 通过环境日志复制消息，智能体可以根据自己的角色订阅感兴趣的消息类型。这种方式使智能体可以主动获取相关信息，而不是被动地通过对话获取。 端到端开发（End-to-End Development）：从产品需求到技术设计，再到具体编码，MetaGPT 通过多智能体的协作可以完成整个软件开发生命周期。 设计层次 MetaGPT 的设计分为两个主要层次： Foundational Components Layer（基础组件层）： 作用：建立了智能体操作和整个系统范围内信息交流的核心基础构件。这包括了环境（Environment）、记忆（Memory）、角色（Roles）、动作（Actions）和工具（Tools）等元素。 功能： Environment：提供了共享的工作空间和通讯功能。 Memory：用于存储和检索历史消息。 Roles：封装了领域特定的技能和工作流程。 Actions：执行模块化的子任务。 Tools：提供常用服务和工具。 Collaboration Layer（协作层）： 作用：在基础组件层之上，协调各个智能体共同解决复杂问题。它建立了合作的基本机制，包括知识共享和封装工作流程。 功能： Knowledge Sharing（知识共享）：允许智能体有效地交换信息，贡献到共享的知识库中，从而提高协调能力，减少冗余通讯，提高整体操作效率。 Encapsulating Workflows（封装工作流程）：利用 SOP 将复杂任务分解成小而可管理的组件，将这些子任务分配给合适的智能体，并通过标准化的输出来监督其性能，确保其行动符合总体目标。 这两个层次共同构建了 MetaGPT 的框架，为智能体提供了强大的功能，使其能够协作解决复杂任务。 ▐ RAG 2020 年，Facebook（后更名为 Meta）在 “Retrieval-Augmented Generation for Knowledge-Intensive NLPTasks” 一文中首先提出了一种称为检索增强生成 (RAG) 的框架。该框架可以使模型访问超出其训练数据范围之外的信息，使得模型在每次生成时可以利用检索提供的外部更专业、更准确的知识，从而更好地回答用户问题。 在 RAG 系统中，模型可以通过浏览外部知识来回答用户的问题，而不是试图从参数记忆中找到问题相关的答案，就像在考试的时候是开卷考试还是闭卷考试一样。例如：我们可以分别询问 ChatGPT 和 Bing Chat 两个问题：“RAG 是什么？”“为什么大模型都是 Decoder（解码器）结构？” 因为 Bing Chat 可以结合互联网的搜索数据来生成答案，所以答案会更精准并且信息量更足。 ▐ 工作流程 RAG 的工作流程涉及 3 个主要阶段：数据准备、数据召回和答案生成。数据准备阶段包括识别数据源、从数据源提取数据、清洗数据并将其存储在数据库中。数据召回阶段包括根据用户输入的查询条件从数据库中检索相关数据。答案生成阶段则是利用检索到的数据和用户输入的查询条件生成输出结果。输出质量的高低取决于数据质量和检索策略。 数据准备 根据 LLM 需要处理的任务类型，数据准备通常包括识别数据源、从数据源中提取数据、清洗数据并将其存储在数据库中等环节。用于存储数据的数据库类型和准备数据的步骤可能会因应用场景和检索方法的不同而有所变化。例如，如果使用像 Faiss 这样的向量存储库，需要为数据创建嵌入并将其存储在向量存储库中；如果使用像 Elasticsearch 这样的搜索引擎，需要将数据索引到搜索引擎中；如果使用像 Neo4j 这样的图数据库，需要为数据创建节点和边，并将它们存储到图数据库中。 数据召回 数据召回部分的主要任务是从大型文本数据库中检索与输入关的信息。为了尽可能保证正确答案被送入生成器部分，数据召回部分的召回率显得非常重要。一般来说，召回的数量越大，正确答案被召回的概率也就越高，但同时会面临大模型上下文长度限制的问题。 许多开源博客或框架在这部分的流程中都采用向量搜索出最相近的 k 个候选。例如，如果我们正在构建一个问答系统，并使用向量数据库存储相关数据块，可以为用户的问题生成向量，对向量数据库中的向量进行相似性搜索并检索最相似的数据块。除此之外，还可以根据用户问题，对同一数据库进行混合搜索或使用多个数据库进行搜索，并将结果组合起来作为生成器的上下文进行传递。 关于检索这部分，还有许多提高检索效果的技巧，这会引入更多的小模块，例如候选重排、大模型辅助召回等，这些都属于数据检索的范畴。 答案生成 一旦检索到用户问题相关的数据片段，RAG 系统就将其与用户的问题和相关数据一起传递给生成器 (LLM)。LLM 利用检索到的数据和用户的查询或任务生成输出。输出的质量取决于数据的质量和检索策略，同时生成输出的指令也会极大地影响输出的质量。 RAG 的优缺点 RAG 的优点 前面介绍了 RAG 的基础内容，下面来具体梳理一下 RAG 的优点。 高质量的答案生成，降低答案生成的幻觉 RAG 的一个优点是它能够生成高质量的回答。因为在生成过程中，检索器可以从大量文档中检索问题相关的信息，然后基于这些信息生成回答。这使得整个系统能够充分利用现有知识生成更准确、更具深度的回答，也意味着模型出现幻觉答案的概率更小。 可扩展性 RAG 展示了出色的可扩展性，这意味着它能够轻松适应新数据和任务。利用 RAG 的检索 — 生成框架，只需更新检索部分的数据，模型便可适应新的知识领域。这使得 RAG 能够在面对新领域或不断变化的知识库时保持高度的适应性。 模型可解释性 RAG 具有一定程度的可解释性，这意味着我们可以理解模型是如何生成回答的。由于 RAG 的特性，我们可以很容易地追溯模型是从哪些文档中提取信息的。这使得我们可以评估模型的回答是否基于可靠的数据来源，从而提高模型的可信度。 成本效益 由于 RAG 的知识库能够与生成模型解耦，因此只要拥有一定的数据量，企业便可将 RAG 作为微调的替代方法，而微调可能需要大量资源。这种模式对中小企业非常友好。从另一个角度来看，由于企业的数据都是私有的，提供相关文档作为背景信息可以使生成结果更加准确、更具实用性，以满足企业的特定任务需求。 RAG 的缺点 依赖于检索模块 RAG 系统给出的答案极其依赖于检索的质量。如果检索到的文档与问题无关或质量较低，生成的回答也可能质量较低。如果搜索的文档并未覆盖到问题的答案，那模型也基本无法回答用户提出的问题。因此，在实际应用中，我们会利用很多策略来提高文档片段的召回率。在很多场景中，文档片段的时效性也是要考虑的一部分，例如金融场景，用户咨询 10 月份的金股是什么，如果召回片段不包含 10 月份的券商金股研报，甚至召回很多旧的金股研报，那对最后的大模型生成会产生很大的干扰。还有很多其他的召回情况都会影响到模型的结果生成，因此想构建一个好的 RAG 系统，检索部分是极其重要的，需要花费大量的时间来打磨。 依赖于现有的知识库 RAG 依赖于一个现有的文档数据库进行检索。首先，如果没有一个大规模的知识库，就无法发挥 RAG 的优点。其次，如果知识库覆盖面不够，无法召回相应的知识块，那么模型因为需要遵循指令的约束而无法给出答案，这就会影响到整个系统的问题覆盖率。 推理耗时 由于 RAG 系统需要先检索文档，然后生成答案，相比于纯粹的大模型推理，整个系统的推理耗时会更长。在这种情况下，对于一些延时要求高的场景就无法满足需求。不过这个耗时问题属于大模型的通病，在使用网页端 ChatGPT 的时候，它以流式打字机的模式展示并按字来输出结果，所以用户可能不会感觉很慢，但如果统计从问题发送到答案完整生成这个过程，耗时还是非常长的。 上下文窗口限制 召回模块输出的文档片段数量需要考虑到生成模型能处理的最大长度，例如最早的 ChatGPT（GPT-3.5-turbo）的最大上下文长度是 4096 个 token。如果你的文档片段是 512 个 token 的长度，那实际上需要使用 8 个片段（512×8 = 4096），所以召回部分就需要考虑如何在这 8 个片段中把召回率做到最优。不过也有其他的折中方案，可以召回更多的文档片段。例如，可以采用对检索的文档片段进行压缩，借助大模型进行要点总结之类的策略。也可以对生成端的模型应用长度外推技巧，现有的长度外推策略已经比较成熟，有很多非常优秀的外推策略，可以让模型推理的长度远远超过训练阶段的长度。 ▐ 提示词工程 提示词工程（Prompt Engineering）是一种在人工智能和自然语言处理领域中开发和设计提示词（Prompts）以引导大型语言模型（例如 GPT-3 等）产生特定输出的方法。通过精心构建和优化提示词，用户可以更有效地获得所需的答案、生成文本或执行其他自然语言处理任务。 提示词工程的关键在于找到合适的语言和结构来清晰地表达问题或任务，使得模型可以更准确地理解并给出相关的回应。这可能涉及反复试验、调整提示词的细节，以及利用对模型行为的理解来优化结果。接下来通过一些基础案例介绍如何优化 Prompt 使得大模型更好的回答我们的问题。 描述答案的标注 在与 LLM 交互时，最好在提示中清楚地描述所期望的答案标准。不要假设 LLM 具有与人类相似的理解能力，也不要期望它一定会以人类的方式进行回答。与 LLM 交互时使用 prompt 通常会显得有些 “啰嗦”，这是正常的。但要注意每一条关于答案标准的描述都应与所期望实现的目标密切相关，避免冗余信息，以降低 LLM 理解的难度。 比如我们可以在提问 “北京有哪些景点” 时增加 “请不要过多介绍景点” 来简化 ChatGPT 的输出结果。 设置兜底的回答方式 在某些情况下，向量化模型可能无法准确召回与用户问题相关的文本，甚至与用户问题几乎没有任何关联。如果让 LLM 根据这些召回的文本生成答案，可能会得到与问题无关或不符合事实的答案。因此，我们需要明确告知 LLM，如果上下文中没有与用户问题相关的答案，就不要强行生成答案了。这样能够避免产生不准确或不相关的回答。 输入中提供问答实例 有时候，我们很难通过语言准确地描述一项任务。如果任务描述不清楚，或者问题本身很复杂，会导致语言模型产生歧义，进而严重影响回答的效果。遇到这种情况，可以尝试在输入中增加一些问答示例，让语言模型自行领悟接下来应该做的任务。一般情况下，为语言模型提供问答示例是有益的。然而，需要注意的是，示例的数量、顺序以及与真实问题的相关性等因素都会影响语言模型的回答效果，这需要大量实践来确定。在提供示例时，尽量涵盖简单、困难、长尾等各种类型的示例。 标识出 prompt 中不同类型的内容 在撰写 prompt 时，最好能把任务描述、示例、引用文本等不同类型的内容用特殊符号隔开，避免 LLM 在内容理解上有歧义，同时也便于用户对 prompt 进行修改与维护。如果用户下达的指令和 prompt 其他内容是冲突的，使用该技巧就十分重要了。 设定输出格式 ChatGPT 等模型都是经过对话数据微调的。在需要准确输出内容点的场景中，有时可能会出现输出无用信息或过于口语化的情况，这不利于进一步提取输出中所需的内容。一种有效的解决方法是让 LLM 以 json 格式输出内容，如果效果不佳，也可以尝试在提示中增加输出 json 的示例。有时候 LLM 输出的 json 格式可能不够标准（例如，字典的键值没有引号或冒号采用中文格式），不能直接使用 Python 的 json 包进行处理，则可以借助正则表达式进行处理。如果不熟悉正则表达式，可直接向 ChatGPT 询问。 指定大模型的身份 在 prompt 中，告诉 LLM 所扮演的身份是什么，这可以帮助 LLM 确定接下来输出的内容和说话风格。 使用思维链 对 于 LLM 来说，当它进行推理相关的任务时，要求它输出推理过程同样可以减少错误的发生。以计算一个简单的数学题为例，直接输出的答案可能是错误的。只有要求它逐步给出每一步的计算过程，才能得到正确的答案。LLM 不仅在训练时可以通过增加计算量（训练更多数据）来提高效果，而且在推理过程中也可以做到这一点（输出更多内容）。 ▐ 模型微调 目前通用的大语言模型，比如 ChatGPT，Gemini，通义千问等事实上都属于预训练 (Pre-trained) 模型，预训练是指通过互联网上已知的海量的语料对原始大模型进行训练，训练后的大模型具有了通用领域知识的解答和推理能力。而对于拥有特定领域知识的企业来说，想要落地大模型往往需要大模型能够理解企业的领域知识且私有数据不能被泄露。所以在企业落地的实际应用中需要对大模型进行微调。 基于已有开源大模型进行微调训练，如果采用预训练的方式对模型的所有参数都进行训练微调，由于现有的开源模型参数量都十分巨大，如最新千问 72B 模型 (qwen/Qwen1.5-72B-Chat) 有 720 亿参数，对所有的参数都进行处理，那 GPU 资源成本会非常高，可能高达数百万每年，为了解决这个问题，社区提出了大模型微调的概念：PEFT (Parameter-Efficient Fine-Tuning)，即对开源预训练模型的所有参数中的一小部分参数进行训练微调，最后输出的结果和全参数微调训练的效果接近。 PEFT 的基本思想是保持大部分参数不变，通过微调一小部分参数，达到具有竞争力甚至是领先的性能。由于需要更新的参数量小，其所需的数据和算力资源变小，使得微调更加有效率。 下面介绍最常见的高效微调方法 LoRA 以及他的一些变体： LoRA（Low-Rank Adaptation） LoRA 即 LLMs 的低秩适应，是参数高效微调最常用的方法。LoRA 的本质就是用更少的训练参数来近似 LLM 全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。 简单来说，LoRA 在模型参数矩阵的（例如 m*n 维）旁边新增一支旁路，由两个低秩矩阵（m*r, r*n 维，r 远小于 m,n）相乘，前向过程中，同时经过原始矩阵和旁路（LoRA 部分），分别得到各自的输出再相加起来，训练时冻结原始参数，只训练 LoRA，由于 LoRA 部分是两个低秩矩阵，参数量远远小于原始矩阵，因此可以显著减少训练代价。 QLoRA（Quantized LoRA） QLoRA 是模型量化和 LoRA 的结合。除了增加了 LoRA 旁路，QLoRA 在加载时将大模型量化成 4bit 或者 8bit，但在计算时，又将该部分的参数反量化成 16bit 进行计算，其优化了非使用状态模型参数的存储，与 LoRA 相比进一步降低训练时显存消耗。 大模型框架 大型语言模型 (LLM) 如 GPT 系列模型引领了人工智能领域的一场技术革命。开发者们都在利用这些 LLM 进行各种尝试，虽然已经产生了许多有趣的应用，但是单独使用这些 LLM 往往难以构建功能强大的实用应用。 也因此，大模型应用框架可以说是百花齐放，本文挑选了热度和讨论度较高的一些开源应用框架进行介绍。 ▐ LangChain LangChain 是一个开源的应用开发框架，目前支持 Python 和 TypeScript 两种编程语言。它赋予 LLM 两大核心能力：数据感知，将语言模型与其他数据源相连接；代理能力，允许语言模型与其环境互动。结合上述两种能力，LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源。 通过 LangChain 可以实现围绕 LLM 核心快速构建 AI 应用，比如提示词工程、检索增强生成（RAG）、会话式 Agent 构建等。 LangChain 提供了一系列的工具帮助我们更好的使用大语言模型 (LLM)。主要有 6 种不同类型的工具： 模型（models） : LangChain 支持的模型类型包括 LLM、TextEmbedding，模型集成如 GPT-4、Llama 等。 提示（prompts） : 包括 prompt 模板管理、优化。 链（chains） : 链不仅仅是单个 LLM 调用，还包括一系列包含 LLM、工具、业务 api 等的调用。LangChain 提供了标准的链接，以及一些常见的链实现，可快速实现应用程序的端到端的链调用。 索引（indexes） : 索引是连接知识与 LLM 的关键，可构建属于企业、场景、用户个人的专属知识库。主要包括文档加载、分割、向量化、检索，链中使用索引的常见方式是 “检索”，如 RAG 一般都会经过 “检索” 步骤，以获取与用户问题最接近的可靠知识信息。 代理（agents） : 也可以称之为智能体，简而言之是某个人或场景的代理人，相关的任务都可以通过 Agent 完成。LangChain 提供了一个标准的代理接口，模拟人的通用思维链路，从作出决策到执行行动、观察结果，再重复，直至任务完成。开发者为 agent 提供一套工具，agent 根据任务描述自行决策和编排使用何种工具完成目标任务。 记忆（memory） : LLM、chain、agent 默认均是无状态的，即 LLM 会独立的处理每次输入。而记忆是人类智能的必要能力之一，不论长短期记忆，对后续的交互都非常重要。在 LangChain 中，记忆是在链 / 代理调用之间保持状态的概念，其提供了标准的记忆接口及部分实现。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://www.formeasy.cc/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"}],"author":null},{"title":"软件工程的 13 条法则","slug":"Other/软件工程的13条法则","date":"2025-04-05T13:05:36.000Z","updated":"2025-04-25T01:49:15.795Z","comments":true,"path":"2025/04/05/Other/软件工程的13条法则/","link":"","permalink":"http://www.formeasy.cc/2025/04/05/Other/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%9A%8413%E6%9D%A1%E6%B3%95%E5%88%99/","excerpt":"","text":"1、帕金森定律：工作会膨胀以填满可用的时间。 2、霍夫斯塔特定律：事情总是比你预期的要长，即使你已经考虑了霍夫斯塔特定律。 3、布鲁克斯定律：向一个已经延期的软件项目增加人力只会让它更加延期。 4、康威定律（及逆康威定律）：组织做的设计往往是其内部沟通结构的复制品。 5、坎宁安定律：在互联网上获得正确答案的最佳方式不是提问，而是发布一个错误答案。 6、斯特金定律：90% 的东西都是垃圾。 7、扎温斯基定律：每个程序都试图扩展，直到能够读取邮件。那些无法如此扩展的程序会被能够做到的程序所取代。 8、海勒姆定律：当 API 的用户数量足够多时，你在合约中承诺什么并不重要：系统的所有可观察行为都会被某些人所依赖。 9、普赖斯定律：在任何群体中，50% 的工作是由其总人数的平方根数的人完成的。 10、林格尔曼效应：群体中个体成员的生产力随着群体规模的增大而逐渐降低的趋势。 11、古德哈特定律：当一项指标成为目标时，它就不再是一个好的指标。 12、吉尔布定律：任何你需要量化的东西，都可以通过某种方式进行测量，这总比完全不测量要好。 13、墨菲定律：可能出错的事就一定会出错。 来源：https://newsletter.manager.dev/p/the-13-software-engineering-laws","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://www.formeasy.cc/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":null},{"title":"OpenDroneMap：无人机摄影测量入门教程","slug":"OpenDroneMap/OpenDroneMap：无人机摄影测量入门教程","date":"2025-04-04T03:40:23.000Z","updated":"2025-04-04T03:55:42.843Z","comments":true,"path":"2025/04/04/OpenDroneMap/OpenDroneMap：无人机摄影测量入门教程/","link":"","permalink":"http://www.formeasy.cc/2025/04/04/OpenDroneMap/OpenDroneMap%EF%BC%9A%E6%97%A0%E4%BA%BA%E6%9C%BA%E6%91%84%E5%BD%B1%E6%B5%8B%E9%87%8F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"无人机摄影测量简介 无人机摄影测量是一种利用无人机搭载的摄影设备，通过获取地面物体的图像信息，进行测量和分析的技术。它广泛应用于地形测绘、农业监测、灾害评估等领域。 1.1 无人机摄影测量的原理 无人机摄影测量基于光学成像原理，通过无人机上的相机捕捉地表图像，然后利用图像处理技术提取所需信息。这一过程通常包括图像获取、预处理、特征提取和数据分析等步骤。 1.2 无人机摄影测量的应用 无人机摄影测量在多个行业都有显著的应用，例如： 地形测绘：通过无人机摄影获取的高分辨率图像，可以制作出精确的地形图。 农业监测：无人机摄影可以帮助监测作物生长情况，评估病虫害。 灾害评估：在自然灾害发生后，无人机摄影可以快速评估受灾情况，为救援提供数据支持。 12345678910111213141516171819202122232425262728293031323334# 以下是一个简单的无人机摄影测量数据处理示例import cv2import numpy as np# 假设我们已经获取了一张无人机拍摄的图像image_path = &#x27;drone_image.jpg&#x27;image = cv2.imread(image_path)# 对图像进行预处理，比如灰度化gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)# 使用边缘检测算法提取特征edges = cv2.Canny(gray_image, 100, 200)# 使用霍夫变换检测图像中的直线lines = cv2.HoughLines(edges, 1, np.pi/180, 200)# 在图像上绘制检测到的直线for line in lines: rho, theta = line[0] a = np.cos(theta) b = np.sin(theta) x0 = a * rho y0 = b * rho x1 = int(x0 + 1000 * (-b)) y1 = int(y0 + 1000 * (a)) x2 = int(x0 - 1000 * (-b)) y2 = int(y0 - 1000 * (a)) cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)# 显示处理后的图像cv2.imshow(&#x27;Processed Image&#x27;, image)cv2.waitKey(0)cv2.destroyAllWindows() OpenDroneMap 软件安装与配置 OpenDroneMap（ODM）是一个开源的无人机摄影测量软件，它可以从无人机拍摄的照片中生成 3D 地图和模型。下面将介绍 ODM 的安装与配置过程。 2.1 OpenDroneMap 安装 OpenDroneMap 可以在多种操作系统上运行，以下是在 Ubuntu 系统上的安装步骤： 更新系统包列表 安装依赖项 克隆 OpenDroneMap 仓库 安装 Python 依赖 构建 OpenDroneMap 123456789101112131415161718192021# 更新系统包列表sudo apt-get update# 安装依赖项sudo apt-get install -y git build-essential \\ python3 python3-dev python3-pip \\ libgdal-dev libopenexr-dev libboost-all-dev \\ libeigen3-dev libxerces-c-dev libxerces-c3.2-dev \\ libpoppler-dev libpoppler-cpp-dev# 克隆OpenDroneMap仓库git clone https://github.com/OpenDroneMap/ODM.git# 进入ODM目录cd ODM# 安装Python依赖pip3 install -r requirements.txt# 构建OpenDroneMapmake 2.2 OpenDroneMap 配置 安装完成后，需要对 ODM 进行一些基本配置，以确保其能够正确运行。以下是一些基本配置步骤： 设置环境变量 配置 GDAL 测试安装 12345678# 设置环境变量，将ODM的路径添加到PATH变量中export PATH=$PATH:/path/to/ODM# 配置GDAL，确保GDAL数据文件可用export GDAL_DATA=/usr/local/share/gdal# 测试安装，运行ODM的版本命令odm --version 确保以上步骤无误后，OpenDroneMap 就安装配置完成了，可以开始进行无人机摄影测量数据的处理工作了。 2.3 注意事项 在安装过程中，可能会根据系统版本和已安装包的不同，需要调整安装命令。 在配置环境变量时，请确保路径正确无误。 如果在测试安装时遇到问题，请检查依赖项是否全部正确安装。 无人机影像数据准备 在进行无人机摄影测量之前，需要准备高质量的影像数据。这些数据的质量直接影响到最终生成的地图和模型的准确性。 3.1 影像数据获取 影像数据的获取是通过无人机搭载的相机进行航空摄影。在飞行前，需要规划飞行路径，确保覆盖所需区域，并考虑飞行高度、相机参数等因素。 3.2 影像数据预处理 获取的影像数据通常需要经过预处理，以下是预处理的一些基本步骤： 3.2.1 影像数据格式转换 有时需要将影像数据转换为特定的格式，以便于后续处理。 12# 假设原始影像为JPEG格式，需要转换为TIFF格式convert input.jpg -format tiff output.tif 3.2.2 影像数据去噪 去除影像中的噪声，提高图像质量。 1234567891011import cv2import numpy as np# 读取影像image = cv2.imread(&#x27;input.tif&#x27;)# 使用均值滤波去噪denoised_image = cv2.blur(image, (5, 5))# 保存去噪后的影像cv2.imwrite(&#x27;denoised.tif&#x27;, denoised_image) 3.2.3 影像数据校正 对影像进行几何校正，消除镜头畸变等影响。 1234567891011121314151617181920212223# 此处通常需要相机参数和镜头畸变参数来进行校正# 示例代码省略具体参数，因为它们因相机型号和设置而异# 以下是一个通用的校正流程def undistort_image(image, camera_matrix, dist_coeffs): h, w = image.shape[:2] new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h)) # 对图像进行去畸变处理 undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs, None, new_camera_matrix) # 返回校正后的图像 return undistorted_image# 假设已有相机参数和畸变系数camera_matrix = ...dist_coeffs = ...# 读取并校正影像image = cv2.imread(&#x27;denoised.tif&#x27;)corrected_image = undistort_image(image, camera_matrix, dist_coeffs)# 保存校正后的影像cv2.imwrite(&#x27;corrected.tif&#x27;, corrected_image) 3.3 影像数据组织 预处理后的影像数据需要按照一定的组织结构进行存储，以便于软件处理。通常，这些影像会被放置在一个目录中，并且包含相应的元数据文件。 3.4 注意事项 在获取影像数据时，确保光照条件适宜，避免阴影和过曝。 预处理步骤应根据实际影像质量和需求进行调整。 影像数据的质量控制是确保最终成果准确性的关键。 OpenDroneMap 基本操作流程 OpenDroneMap（ODM）提供了一套完整的工具，用于从无人机影像数据生成 3D 地图和模型。以下是 ODM 的基本操作流程。 4.1 影像数据准备 确保你的无人机影像数据已经按照上一节的要求准备好，并且存储在一个目录中。 4.2 创建项目 在 ODM 中创建一个新项目，这通常涉及到指定一个工作目录和输入的影像数据目录。 12# 创建ODM项目odm --project-path /path/to/project --image-path /path/to/images 4.3 影像预处理 在开始处理之前，ODM 会对影像进行预处理，包括去噪、校正等。 12# 执行预处理步骤odm --project-path /path/to/project --step preprocess 4.4 影像拼接 预处理完成后，ODM 将开始拼接影像，生成 orthophoto 和点云数据。 12# 执行影像拼接步骤odm --project-path /path/to/project --step merge 4.5 生成 3D 模型 拼接完成后，可以使用生成的点云数据来创建 3D 模型。 12# 生成3D模型odm --project-path /path/to/project --step model 4.6 导出成果 最后，将生成的地图和模型导出为不同的格式，以便于查看和使用。 12# 导出成果odm --project-path /path/to/project --export 4.7 注意事项 在执行 ODM 命令时，确保已经正确设置了 --project-path 和 --image-path 参数。 根据影像数据的大小和复杂性，ODM 处理过程可能需要较长的时间。 如果处理过程中遇到错误，可以查看 ODM 的日志文件来诊断问题。 以下是一个完整的 ODM 操作流程示例： 1234567891011121314# 创建项目odm --project-path /path/to/project --image-path /path/to/images# 预处理odm --project-path /path/to/project --step preprocess# 影像拼接odm --project-path /path/to/project --step merge# 生成3D模型odm --project-path /path/to/project --step model# 导出成果odm --project-path /path/to/project --export 确保在每一步骤之间检查输出和日志，以确保处理过程按预期进行。 影像处理与 3D 模型生成 在无人机摄影测量中，影像处理是将拍摄的影像数据转换为有用的地理信息，而 3D 模型生成则是利用这些信息创建出三维模型。以下是这两个过程的详细说明。 5.1 影像处理 影像处理包括一系列步骤，从影像的预处理到生成正射影像和点云。 5.1.1 影像预处理 预处理步骤通常包括影像的校正、去噪、增强等，以确保后续处理的准确性。 1234567891011121314# 影像预处理示例（以Python代码表示）import cv2# 读取影像image = cv2.imread(&#x27;input_image.jpg&#x27;)# 影像校正（此处假设已有校正参数）corrected_image = cv2.undistort(image, camera_matrix, dist_coeffs)# 影像去噪denoised_image = cv2.fastNlMeansDenoisingColored(corrected_image, None, 30, 30, 7, 21)# 保存预处理后的影像cv2.imwrite(&#x27;preprocessed_image.jpg&#x27;, denoised_image) 5.1.2 影像拼接 拼接处理是将多张影像合并成一张完整的正射影像。 12# 使用OpenDroneMap进行影像拼接odm --project-path /path/to/project --step merge 5.2 3D 模型生成 在影像拼接完成后，可以利用生成的点云数据生成 3D 模型。 5.2.1 点云生成 点云是 3D 模型的基础，它由一系列的点组成，每个点在空间中都有唯一的坐标。 12# 使用OpenDroneMap生成点云odm --project-path /path/to/project --step pointcloud 5.2.2 3D 模型构建 从点云数据中构建 3D 模型，通常使用三角网或表面重建算法。 12# 使用OpenDroneMap构建3D模型odm --project-path /path/to/project --step model 5.3 导出成果 处理完成后，可以将正射影像、点云和 3D 模型导出为不同的格式。 12# 导出成果odm --project-path /path/to/project --export 5.4 注意事项 影像处理和 3D 模型生成是资源密集型任务，可能需要高性能的计算机硬件。 在处理大量影像时，考虑使用分布式计算或云计算资源。 导出的成果格式取决于具体的应用需求，常见的格式包括 TIFF、PDF、OBJ 等。 通过以上步骤，可以从无人机影像数据中提取有价值的信息，并生成高质量的 3D 模型。 数据分析与优化 在无人机摄影测量中，数据分析与优化是关键步骤，它们确保了从无人机影像数据中提取的信息是准确和有用的。以下是数据分析与优化的一些基本方面。 6.1 数据分析 数据分析涉及对生成的正射影像、点云和 3D 模型进行评估，以确定它们的质量和适用性。 6.1.1 质量控制 质量控制是确保数据满足特定标准的过程。 12345678910# 假设有一个函数来评估正射影像的质量def evaluate_orthophoto_quality(orthophoto_path): # 评估正射影像的质量，返回评估结果 # 这里只是一个示例，实际评估过程可能更复杂 quality_score = ... # 计算质量分数 return quality_score# 调用函数评估正射影像质量quality_score = evaluate_orthophoto_quality(&#x27;path/to/orthophoto.tif&#x27;)print(f&#x27;Orthophoto quality score: &#123;quality_score&#125;&#x27;) 6.1.2 特征提取 特征提取是从影像中识别和提取特定信息的过程。 12345678910# 假设有一个函数来从正射影像中提取特定特征def extract_features(orthophoto_path): # 使用影像处理库来提取特征 # 这里只是一个示例，实际特征提取过程可能更复杂 features = ... # 提取的特征 return features# 调用函数提取特征features = extract_features(&#x27;path/to/orthophoto.tif&#x27;)print(f&#x27;Extracted features: &#123;features&#125;&#x27;) 6.2 数据优化 数据优化包括对原始数据和生成结果进行改进，以提高其精度和实用性。 6.2.1 参数调整 在数据处理过程中，可能需要根据结果的质量来调整参数。 12# 调整OpenDroneMap的参数以优化结果odm --project-path /path/to/project --step merge --parameter &quot;orthophoto_resolution=5&quot; 6.2.2 误差校正 校正数据中的误差，以提高地图和模型的准确性。 1234567891011# 假设有一个函数来校正点云中的误差def correct_point_cloud_errors(point_cloud_path): # 读取点云数据 point_cloud = ... # 加载点云 # 校正误差 corrected_point_cloud = ... # 校正后的点云 # 保存校正后的点云 save_point_cloud(corrected_point_cloud, &#x27;corrected_point_cloud.ply&#x27;)# 调用函数校正点云correct_point_cloud_errors(&#x27;path/to/point_cloud.ply&#x27;) 6.3 注意事项 数据分析应基于具体的应用场景和需求进行。 优化过程可能需要多次迭代，以获得最佳结果。 在调整参数和校正误差时，应记录所做的更改，以便于跟踪和回溯。 通过细致的数据分析和优化，可以确保无人机摄影测量结果的最大价值，并为各种应用提供可靠的数据基础。 实际案例分析 在无人机摄影测量领域，实际案例分析有助于我们理解理论如何应用于实践，并从真实世界的项目中学习经验。以下是一个简化的实际案例分析。 7.1 项目背景 假设我们有一个农业监测项目，目的是通过无人机影像分析农田的健康状况。项目位于一片开阔的农田，无人机需要覆盖整个区域以收集数据。 7.2 影像数据获取 使用无人机进行航空摄影，确保影像覆盖整个农田，并且具有足够的重叠度以便于后续处理。 7.3 数据处理 将无人机收集的影像数据导入 OpenDroneMap 进行处理。 123456789101112# 创建ODM项目odm --project-path /path/to/agriculture_project --image-path /path/to/collected_images# 执行预处理odm --project-path /path/to/agriculture_project --step preprocess# 影像拼接和点云生成odm --project-path /path/to/agriculture_project --step merge# 生成正射影像和3D模型odm --project-path /path/to/agriculture_project --step orthophotoodm --project-path /path/to/agriculture_project --step model 7.4 数据分析 分析生成的正射影像和 3D 模型，以评估农田的健康状况。 12345678910# 假设有一个函数来分析正射影像def analyze_orthophoto(orthophoto_path): # 使用影像处理和分析技术 # 这里只是一个示例，实际分析过程可能更复杂 health_scores = ... # 计算农田健康分数 return health_scores# 调用函数分析正射影像health_scores = analyze_orthophoto(&#x27;path/to/orthophoto.tif&#x27;)print(f&#x27;Farm health scores: &#123;health_scores&#125;&#x27;) 7.5 结果优化 根据分析结果，可能需要对数据处理流程进行优化，以提高数据的准确性。 12# 调整参数以优化正射影像质量odm --project-path /path/to/agriculture_project --step orthophoto --parameter &quot;orthophoto_resolution=10&quot; 7.6 成果应用 将分析结果应用于实际的农业管理决策中，例如调整灌溉计划或施肥策略。 7.7 注意事项 实际项目可能面临各种挑战，如天气条件、无人机飞行限制等。 数据处理和分析需要专业知识，以及对特定领域的理解。 结果的准确性和可靠性取决于整个数据处理流程的质量控制。 通过这个案例，我们可以看到无人机摄影测量在实际应用中的价值，以及从数据获取到结果应用的全过程。 高级功能与扩展应用 OpenDroneMap 不仅提供了基本的无人机影像处理功能，还拥有一些高级功能和扩展应用，这些功能可以进一步扩展 ODM 的能力，满足不同用户的需求。 8.1 高级功能 以下是一些 OpenDroneMap 的高级功能： 8.1.1 多源数据融合 OpenDroneMap 支持将无人机影像与其他数据源（如卫星影像、地面测量数据）融合，以提供更全面的信息。 123# 假设已经有一个卫星影像文件satellite_image.tif# 将其与无人机影像融合odm --project-path /path/to/project --image-path /path/to/collected_images --additional-image-path /path/to/satellite_image.tif 8.1.2 大规模数据处理 对于大规模的数据集，OpenDroneMap 提供了分块处理的能力，允许用户将大型区域分成小块进行处理。 1234567891011121314 # 分块处理大型区域 odm --project-path /path/to/project --image-path /path/to/collected_images --split 5```P### 8.2 扩展应用OpenDroneMap 的扩展应用可以涵盖多个领域：#### 8.2.1 灾害响应在灾害响应中，无人机可以快速收集受灾地区的影像，OpenDroneMap 可以用来生成紧急地图和 3D 模型，以支持救援行动。```PYTHON # 灾害响应中的快速制图 odm --project-path /path/to/disaster_response_project --image-path /path/to/disaster_images --step orthophoto --fast 8.2.2 建筑监测 在建筑行业，OpenDroneMap 可以用于监测建筑进度，通过定期生成的 3D 模型来评估施工质量。 12# 建筑监测中的3D模型生成odm --project-path /path/to/construction_project --image-path /path/to/construction_images --step model 8.2.3 环境监测 OpenDroneMap 可用于环境监测，例如通过分析无人机影像来监测植被变化或水污染。 12345678910# 假设有一个函数来分析植被指数def analyze_vegetation_index(orthophoto_path): # 使用影像处理和分析技术 # 这里只是一个示例，实际分析过程可能更复杂 vegetation_index = ... # 计算植被指数 return vegetation_index# 调用函数分析正射影像vegetation_index = analyze_vegetation_index(&#x27;path/to/orthophoto.tif&#x27;)print(f&#x27;Vegetation Index: &#123;vegetation_index&#125;&#x27;) 8.3 注意事项 使用高级功能可能需要更多的计算资源和专业知识。 扩展应用通常需要定制化的数据处理和分析流程。 在实际应用中，应考虑数据隐私和安全问题，特别是在敏感区域进行无人机飞行和影像采集时。 通过利用 OpenDroneMap 的高级功能和扩展应用，用户可以更好地适应各种复杂场景的需求，并将无人机摄影测量的价值最大化。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"OpenDroneMap","slug":"OpenDroneMap","permalink":"http://www.formeasy.cc/tags/OpenDroneMap/"}],"author":null},{"title":"OpenDroneMap(ODM)使用","slug":"OpenDroneMap/OpenDroneMap(ODM)使用","date":"2025-04-04T03:29:08.000Z","updated":"2025-04-25T01:46:38.213Z","comments":true,"path":"2025/04/04/OpenDroneMap/OpenDroneMap(ODM)使用/","link":"","permalink":"http://www.formeasy.cc/2025/04/04/OpenDroneMap/OpenDroneMap(ODM)%E4%BD%BF%E7%94%A8/","excerpt":"","text":"前言 最近调查一个项目，要求把无人机航拍到的图片拼成一个地图底图，了解了一下，有个开源软件OpenDroneMap可以实现这个需求，在其基础上略作封装完成了这个项目。这里记录下ODM的使用。 下载安装 ODM官网地址：https://opendronemap.org 有三个版本，ODM CLI是命令行调用，NodeODM在CLI基础上封装了Node的Web界面，还有一个WebODM，这里没有具体了解。我们是要在Windows工作站上运行，正好ODM CLI有Windows编译好的版本，下载地址：https://github.com/OpenDroneMap/ODM/releases 选择ODM_Setup_xxx.exe，直接下载安装即可。 图像拼接 安装好后，打开ODM Console，打开ODM的命令行界面，如下图 默认输出帮助内容，使用很简单，建立一个工程文件夹，里面再建立一个images文件夹，存放要拼接的图片，若图片没有自带GPS信息，还需要准备一个geo.txt文件，里面第一行是使用的坐标系，后面每一行对应一张图片的经纬度和高度信息，如下图 一定要确保图片的GPS信息对应正确，将直接影响最终生成的图片质量 准备好图片和geo.txt后，在ODM Console中运行如下命令启动拼接 1run --feature-type=sift --matcher-type=flann --skip-3dmodel D:\\odm_test 其中D:\\odm_test是我的工程目录，内容包含images文件夹和geo.txt文件，生成成功后的目录结构如下，红框框起来的是启动任务所必须的文件。 拼接的TIFF文件在odm_orthophoto目录下 以下是原图和拼接好的图片 可以看到最终效果还不错，除了边缘区域有些毛刺，其他地方看不到拼接痕迹，叠加到天地图上也能与地图重合的很好。 拼接进度获取 还有个需求是要在拼接时在我们的软件界面显示拼接百分比进度，研究了下ODM源码，其控制流程的代码写得也比较简洁易懂， 如上图，可以不进入ODM Console，也可以由winrun直接启动python的虚拟环境，此时由winrun调用run.py，将命令参数传入，run.py再调用stages下的odm_app.py，odm_app.py初始化各个stage，并连接起来使其顺序执行。 其中每一个stage都继承了一个叫ODM_Stage的基类，ODM_Stage类在opendm目录下的types.py文件中定义。 这一部分使用了模板方法模式，ODM_Stage中实现了诸如日志、进度等功能，主要的处理功能process方法由子类实现，在ODM_Stage类中，更新进度的方法为update_progress，此方法还额外调用了一个叫progressbc.send_update的方法，如下图。 查找此方法，发现其已经实现了一个汇报进度的功能，在opendm目录下的progress.py文件中。 该方法使用udp向127.0.0.1:6367发送进度信息，分析到这就够了，对这块稍作改造，将单例模式改为每个任务实例化一个Broadcaster，再加入标记任务的UUID，进度这块的功能就算是实现了。 总结 因为之前没有做过GIS相关的项目，对这块一点都不懂，ODM这个软件应该还有很多强大的功能，不过应该不会再深入去了解了，之前还担心拼出来的图无法叠加到地图上，没想到这在这个领域只是个基础功能，拼好后的TIFF直接就带有经纬度信息。 最后贴一下使用的ODM参数吧。 --feature-type=sift特征类型，还有好几种类型，区别没去了解 --feature-quality=ultra特征质量，ultra是最高等级 --matcher-type=flann应该是比对类型，有个阶段会对图片的特征两两比对，不同类型之间区别不了解 --mesh-octree-depth=12 不知道啥意思 --skip-3dmodel 跳过3D模型生成，我们只需要正射投影，这个关掉可以快一点 --orthophoto-resolution=2 正射分辨率，默认5，按甲方要求改成2，单位好像是厘米或像素 --fast-orthophoto 快速生成正射投影 --pc-quality=ultra 不知道啥意思 --pc-filter=1.5 不知道啥意思 按上面的参数，100张左右图片最终合成的TIFF在5个G左右，14700K+4070的机器需要半个小时。还是停耗性能的。 补充：如果使用docker运行 1docker run -ti --rm -v D:/datasets:/datasets opendronemap/odm --project-path /datasets 解释 D:/datasets:/datasets :前的部分是要处理的图片地址，其中图片存放在images 中，图片的地址是 D:/datasets/images :后的部分就是自动的，不用动","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"OpenDroneMap","slug":"OpenDroneMap","permalink":"http://www.formeasy.cc/tags/OpenDroneMap/"}],"author":null},{"title":"分享14个实用360WebVr全景视图框架大全","slug":"Other/分享14个实用360WebVr全景视图框架大全","date":"2025-04-04T03:09:18.000Z","updated":"2025-04-25T01:53:22.074Z","comments":true,"path":"2025/04/04/Other/分享14个实用360WebVr全景视图框架大全/","link":"","permalink":"http://www.formeasy.cc/2025/04/04/Other/%E5%88%86%E4%BA%AB14%E4%B8%AA%E5%AE%9E%E7%94%A8360WebVr%E5%85%A8%E6%99%AF%E8%A7%86%E5%9B%BE%E6%A1%86%E6%9E%B6%E5%A4%A7%E5%85%A8/","excerpt":"","text":"一、Theasys 地址：https://www.theasys.io/samples/ 二、Panoraven 地址：panoraven.com/en 三、360-image-viewer 地址：renderstuff.com/tools/360-p… 360-image-viewer 也是一个类似于上面的库，可以帮助您显示图像的全景图。各种设备屏幕上的照片、视频和响应能力。仅约 46kb（压缩后）的大小。使用此库时可以轻松优化站点的性能。 四、Kaleidoscope 地址：github.com/thiagopnts/… Kaleidoscope 是一个开源的 Javascript 库，它可以轻松地为照片或视频构建 360 度方便的方法查看器。 如果你需要一个紧凑的库，不要使用额外的库，它能满足显示视频和全景图像的基本元素，我认为这个库是您不错的选择 五、JS Cloudimage 360 View 地址：scaleflex.github.io/js-cloudima… JS Cloudimage 360 View 是一个用Javascript编写的紧凑型开源库，可以轻松实现360度显示图像，并提供更多功能帮助用户更便捷的交互。 如全屏显示、lazyload功能、图像放大镜。此外，它还提供您可以通过非常简单的设置直接用于网站的 CDN 只需将它提供的属性调用到我们想要显示 360 的 HTML 对象图像中。 六、Three.js 地址：threejs.org/ Threejs 是基于WebGL封装的3D引擎框架，降低了前端开发3D效果的难度，很容易就可以Web3D效果。 七、2VR 地址：www.2vr.in/ 八、Panolens.js 地址：pchen66.github.io/Panolens/ 基于Threejs封装的全景框架，只需要引用three.min.js 和 panolens.min.js 九、Pannellum 地址：pannellum.org/ 一个轻量级的Web全景查看器，Pannellum是一个轻量级、免费、开源的网络全景查看器。它使用HTML5、CSS3、JavaScript和WebGL构建，不含插件。 十、view360 地址：naver.github.io/egjs-view36… 十一、A-Frame 地址：aframe.io/ 十二、VR View 地址：developers.google.com/vr/develop/… 十三、Photo Sphere Viewer 地址：photo-sphere-viewer.js.org/ 十四、Marzipano 地址：www.marzipano.net/ 本文收录于以下专栏","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"}],"author":null},{"title":"MCP极简入门：超快速上手运行简单的MCP服务和MCP客户端","slug":"MCP/MCP极简入门：超快速上手运行简单的MCP服务和MCP客户端","date":"2025-03-26T07:24:09.000Z","updated":"2025-06-24T01:10:36.089Z","comments":true,"path":"2025/03/26/MCP/MCP极简入门：超快速上手运行简单的MCP服务和MCP客户端/","link":"","permalink":"http://www.formeasy.cc/2025/03/26/MCP/MCP%E6%9E%81%E7%AE%80%E5%85%A5%E9%97%A8%EF%BC%9A%E8%B6%85%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E8%BF%90%E8%A1%8C%E7%AE%80%E5%8D%95%E7%9A%84MCP%E6%9C%8D%E5%8A%A1%E5%92%8CMCP%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"MCP是什么？ 首先我们快速过一下MCP的基本概念，接着我们会通过一个简单的天气服务的教程，来上手学会使用MCP服务和在主机运行服务。本文根据官方教程改编。 1. MCP的基本概念 MCP（Model Context Protocol，模型上下文协议）是一个开放协议，旨在标准化应用程序如何向大型语言模型（LLM）提供上下文。它允许LLM与外部数据源和工具无缝集成，从而使AI模型能够访问实时数据并执行更复杂的任务。 官方MCP Github主页 官方文档Introduction 支持MCP特性的客户端列表 2. MCP的架构 MCP的核心组件包括： 主机（Host）：运行LLM的应用程序（如Claude Desktop），负责发起与MCP服务器的连接。 客户端（Client）：在主机应用程序内部运行，与MCP服务器建立1:1连接。 服务器（Server）：提供对外部数据源和工具的访问，响应客户端的请求。 LLM：大型语言模型，通过MCP获取上下文并生成输出。 工作流程： 主机启动客户端。 客户端连接到MCP服务器。 服务器提供资源、提示或工具。 LLM使用这些信息生成响应。 3. MCP的原语 MCP通过三种主要原语（Primitives）增强LLM的功能，理解这些原语是编写MCP的关键： 提示（Prompts）：预定义的指令或模板，指导LLM如何处理输入或生成输出。 资源（Resources）：提供额外上下文的结构化数据，例如文件或数据库内容。 工具（Tools）：可执行的函数，允许LLM执行操作（如查询API）或检索信息。 关键点：这些原语是MCP的核心，决定了服务器能为LLM提供什么能力。 MCP Server 构建一个简单的MCP服务器 在我们的示例中，使用 Claude for Desktop 作为客户端，自己编写python文件作为服务端，在 Claude Desktop 里调用server.py。 先决条件 已安装 python 3.10 或更高 已安装 Claude for Desktop 1. 安装uv，设置环境变量 打开 Powershell，输入如下命令： 1powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot; 打开系统高级环境变量，在 Path 将uv路径添加进去： 1C:\\Users\\windows\\.local\\bin 重启 Powershell 。 在命令行输入 uv --version ， 能返回版本信息就算安装成功了: 2. 创建和设置项目 打开 Powershell ， cd 到你想要创建项目的目录位置，如: 接着依次输入以下命令： 12345678910111213# Create a new directory for our projectuv init weathercd weather# Create virtual environment and activate ituv venv.venv\\Scripts\\activate# Install dependenciesuv add mcp[cli] httpx# Create our server file。new-item 是powershell 命令，用于创建文件new-item weather.py 3. 添加代码 将以下代码整个复制到 weather.py： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293from typing import Any import httpx from mcp.server.fastmcp import FastMCP # Initialize FastMCP server mcp = FastMCP(&quot;weather&quot;) # Constants NWS_API_BASE = &quot;https://api.weather.gov&quot; USER_AGENT = &quot;weather-app/1.0&quot; async def make_nws_request(url: str) -&gt; dict[str, Any] | None: &quot;&quot;&quot;Make a request to the NWS API with proper error handling.&quot;&quot;&quot; headers = &#123; &quot;User-Agent&quot;: USER_AGENT, &quot;Accept&quot;: &quot;application/geo+json&quot; &#125; async with httpx.AsyncClient() as client: try: response = await client.get(url, headers=headers, timeout=30.0) response.raise_for_status() return response.json() except Exception: return None def format_alert(feature: dict) -&gt; str: &quot;&quot;&quot;Format an alert feature into a readable string.&quot;&quot;&quot; props = feature[&quot;properties&quot;] return f&quot;&quot;&quot; Event: &#123;props.get(&#x27;event&#x27;, &#x27;Unknown&#x27;)&#125; Area: &#123;props.get(&#x27;areaDesc&#x27;, &#x27;Unknown&#x27;)&#125; Severity: &#123;props.get(&#x27;severity&#x27;, &#x27;Unknown&#x27;)&#125; Description: &#123;props.get(&#x27;description&#x27;, &#x27;No description available&#x27;)&#125; Instructions: &#123;props.get(&#x27;instruction&#x27;, &#x27;No specific instructions provided&#x27;)&#125; &quot;&quot;&quot; @mcp.tool() async def get_alerts(state: str) -&gt; str: &quot;&quot;&quot;Get weather alerts for a US state. Args: state: Two-letter US state code (e.g. CA, NY) &quot;&quot;&quot; url = f&quot;&#123;NWS_API_BASE&#125;/alerts/active/area/&#123;state&#125;&quot; data = await make_nws_request(url) if not data or &quot;features&quot; not in data: return &quot;Unable to fetch alerts or no alerts found.&quot; if not data[&quot;features&quot;]: return &quot;No active alerts for this state.&quot; alerts = [format_alert(feature) for feature in data[&quot;features&quot;]] return &quot;\\n---\\n&quot;.join(alerts) @mcp.tool() async def get_forecast(latitude: float, longitude: float) -&gt; str: &quot;&quot;&quot;Get weather forecast for a location. Args: latitude: Latitude of the location longitude: Longitude of the location &quot;&quot;&quot; # First get the forecast grid endpoint points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot; points_data = await make_nws_request(points_url) if not points_data: return &quot;Unable to fetch forecast data for this location.&quot; # Get the forecast URL from the points response forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;] forecast_data = await make_nws_request(forecast_url) if not forecast_data: return &quot;Unable to fetch detailed forecast.&quot; # Format the periods into a readable forecast periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;] forecasts = [] for period in periods[:5]: # Only show next 5 periods forecast = f&quot;&quot;&quot; &#123;period[&#x27;name&#x27;]&#125;: Temperature: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125; Wind: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125; Forecast: &#123;period[&#x27;detailedForecast&#x27;]&#125; &quot;&quot;&quot; forecasts.append(forecast) return &quot;\\n---\\n&quot;.join(forecasts) if __name__ == &quot;__main__&quot;: # Initialize and run the server mcp.run(transport=&#x27;stdio&#x27;) 如果代码里提示依赖错误，安装对应的包就好。 4. 运行服务 打开 Claude for Desktop , 点击左上角菜单 —— File —— Settings —— Developer 点击 Edit Config ，就会在 C:\\Users\\windows\\AppData\\Roaming\\Claude 目录下自动创建 claude_desktop_config.json 文件。 打开 claude_desktop_config.json , 添加如下代码： 12345678910111213&#123; &quot;mcpServers&quot;: &#123; &quot;weather&quot;: &#123; &quot;command&quot;: &quot;uv&quot;, &quot;args&quot;: [ &quot;--directory&quot;, &quot;T:\\\\PythonProject\\\\weather&quot;, &quot;run&quot;, &quot;weather.py&quot; ] &#125; &#125;&#125; 其中路径为在上一步创建的weather目录, 使用绝对路径。 这会告诉 Claude for Desktop ， 我们的服务名叫 weather , 通过 uv --directory T:\\\\PythonProject\\\\weather run weather 来启动服务。 保存文件。 5. 在Claude中使用服务 打开任务管理器，将 Claude 结束任务，彻底关掉。 重新打开 Claude for Desktop 。 如果在Claude的对话框下看到了一把锤子，说明我们的MCP服务配置成功了。 点击锤子能看到： 在设置页显示如下： 下面测试服务： 在对话框输入：what’s the weather in NY 服务配置成功啦！ MCP Client 要使用Claude API, 需要充值购买credits 否则请求会报Error: Error code: 403 - {‘error’: {‘type’: ‘forbidden’, ‘message’: ‘Request not allowed’}} 1. 创建和设置项目 前期的步骤与上文介绍的一致，先决条件和uv的安装看 MCP Server 部分。 打开Powershell , cd 到python项目的目录下，依次输入如下命令： 123456789101112131415161718# Create project directoryuv init mcp-clientcd mcp-client# Create virtual environmentuv venv# Activate virtual environment# On Windows:.venv\\Scripts\\activate# On Unix or MacOS:source .venv/bin/activate# Install required packagesuv add mcp anthropic python-dotenv# Create our main filenew-item client.py 2. 配置API_KEY 1new-item .env 打开.env文件，复制以下代码： 1ANTHROPIC_API_KEY=&lt;your key here&gt; 在Claude控制台创建KEY（需充值才能用），将API Key复制到.env （确保key的安全，不要分享出去！） 将.env文件添加到.gitignore , 在 powershell 输入以下命令： 1echo &quot;.env&quot; &gt;&gt; .gitignore 3. 添加代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155import asyncio from typing import Optional from contextlib import AsyncExitStack from mcp import ClientSession, StdioServerParameters from mcp.client.stdio import stdio_client from anthropic import Anthropic from dotenv import load_dotenv load_dotenv() # load environment variables from .env class MCPClient: def __init__(self): # Initialize session and client objects self.session: Optional[ClientSession] = None self.exit_stack = AsyncExitStack() self.anthropic = Anthropic() # methods will go here async def connect_to_server(self, server_script_path: str): &quot;&quot;&quot;Connect to an MCP server Args: server_script_path: Path to the server script (.py or .js) &quot;&quot;&quot; is_python = server_script_path.endswith(&#x27;.py&#x27;) is_js = server_script_path.endswith(&#x27;.js&#x27;) if not (is_python or is_js): raise ValueError(&quot;Server script must be a .py or .js file&quot;) command = &quot;python&quot; if is_python else &quot;node&quot; server_params = StdioServerParameters( command=command, args=[server_script_path], env=None ) stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params)) self.stdio, self.write = stdio_transport self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write)) await self.session.initialize() # List available tools response = await self.session.list_tools() tools = response.tools print(&quot;\\nConnected to server with tools:&quot;, [tool.name for tool in tools]) async def process_query(self, query: str) -&gt; str: &quot;&quot;&quot;Process a query using Claude and available tools&quot;&quot;&quot; messages = [ &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query &#125; ] response = await self.session.list_tools() available_tools = [&#123; &quot;name&quot;: tool.name, &quot;description&quot;: tool.description, &quot;input_schema&quot;: tool.inputSchema &#125; for tool in response.tools] # Initial Claude API call response = self.anthropic.messages.create( model=&quot;claude-3-5-sonnet-20241022&quot;, max_tokens=1000, messages=messages, tools=available_tools ) # Process response and handle tool calls tool_results = [] final_text = [] assistant_message_content = [] for content in response.content: if content.type == &#x27;text&#x27;: final_text.append(content.text) assistant_message_content.append(content) elif content.type == &#x27;tool_use&#x27;: tool_name = content.name tool_args = content.input # Execute tool call result = await self.session.call_tool(tool_name, tool_args) tool_results.append(&#123;&quot;call&quot;: tool_name, &quot;result&quot;: result&#125;) final_text.append(f&quot;[Calling tool &#123;tool_name&#125; with args &#123;tool_args&#125;]&quot;) assistant_message_content.append(content) messages.append(&#123; &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: assistant_message_content &#125;) messages.append(&#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [ &#123; &quot;type&quot;: &quot;tool_result&quot;, &quot;tool_use_id&quot;: content.id, &quot;content&quot;: result.content &#125; ] &#125;) # Get next response from Claude response = self.anthropic.messages.create( model=&quot;claude-3-5-sonnet-20241022&quot;, max_tokens=1000, messages=messages, tools=available_tools ) final_text.append(response.content[0].text) return &quot;\\n&quot;.join(final_text) async def chat_loop(self): &quot;&quot;&quot;Run an interactive chat loop&quot;&quot;&quot; print(&quot;\\nMCP Client Started!&quot;) print(&quot;Type your queries or &#x27;quit&#x27; to exit.&quot;) while True: try: query = input(&quot;\\nQuery: &quot;).strip() if query.lower() == &#x27;quit&#x27;: break response = await self.process_query(query) print(&quot;\\n&quot; + response) except Exception as e: print(f&quot;\\nError: &#123;str(e)&#125;&quot;) async def cleanup(self): &quot;&quot;&quot;Clean up resources&quot;&quot;&quot; await self.exit_stack.aclose() async def main(): if len(sys.argv) &lt; 2: print(&quot;Usage: python client.py &lt;path_to_server_script&gt;&quot;) sys.exit(1) client = MCPClient() try: await client.connect_to_server(sys.argv[1]) await client.chat_loop() finally: await client.cleanup() if __name__ == &quot;__main__&quot;: import sys asyncio.run(main()) 如果开头anthropic报错，安装anthropic就好。 4. 运行Client 这里我们使用上文创建的mcp服务weather 在powershell输入： 1uv run client.py T:/PythonProject/weather/weather.py 接着，我们就可以在 Query 输入问题了。 至此，我们的第一个MCP服务端和客户端编写完成。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"MCP","slug":"MCP","permalink":"http://www.formeasy.cc/tags/MCP/"}],"author":null},{"title":"vs code + cline 联手 MCP-server，解锁大模型万物互联新玩法！","slug":"MCP/vs code + cline 联手 MCP-server，解锁大模型万物互联新玩法","date":"2025-03-26T00:43:27.000Z","updated":"2025-08-14T06:40:25.702Z","comments":true,"path":"2025/03/26/MCP/vs code + cline 联手 MCP-server，解锁大模型万物互联新玩法/","link":"","permalink":"http://www.formeasy.cc/2025/03/26/MCP/vs%20code%20+%20cline%20%E8%81%94%E6%89%8B%20MCP-server%EF%BC%8C%E8%A7%A3%E9%94%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%87%E7%89%A9%E4%BA%92%E8%81%94%E6%96%B0%E7%8E%A9%E6%B3%95/","excerpt":"","text":"1.前言 什么是MCP-server？MCP-server（模型上下文协议服务器）是一种遵循 Model Context Protocol (MCP) 的标准化服务，旨在为大型语言模型（LLM）提供安全访问本地或远程资源的能力，从而扩展AI的功能。以下是其核心要点： 1. 基本定义与架构 协议背景：MCP由Anthropic推出，是一种开放协议，用于统一LLM与外部数据源、工具之间的通信，解决数据分散和集成复杂性的问题。 架构设计采用客户端-服务器模型，包含以下组件： MCP Host：运行AI助手（如Claude Desktop、IDE工具）的平台，负责用户交互。 MCP Client：在Host内与Server建立一对一连接，作为LLM与Server的桥梁。 MCP Server：轻量级程序，通过标准化协议提供资源、工具和提示信息，连接本地或远程资源（如数据库、API、云服务）。 2. 核心功能 资源访问：允许LLM读取本地文件、数据库（如SQLite、iMessage）或远程API（如GitHub、Google Drive）。 工具调用：提供预定义工具（如执行脚本、浏览器自动化、金融数据查询），类比于GPTs的Action功能。 提示管理：通过标准化的提示模板指导LLM完成任务，例如生成代码或分析数据。 3. 工作流程 初始化连接：Client向Server发送请求，建立通信通道。 能力协商：Server返回支持的工具和资源列表。 请求处理：Client发送具体操作请求（如查询数据库），Server执行后返回结果。 安全控制：需用户授权敏感操作，确保数据隔离和权限管理。 4. 典型应用场景 本地资源集成：访问文件系统、iMessage数据库、执行本地命令。 云服务交互：集成Cloudflare Workers、GitHub API、Salesforce等平台。 自动化任务：浏览器自动化（通过Playwright）、数据分析、实时监控 5.与类似技术的对比 相较于传统API集成，MCP通过标准化协议减少定制开发，同时限制LLM的可访问范围，增强可控性。 与ChatGPT的GPTs Action类似，但MCP更强调开放性和跨平台复用性 MCP-server作为连接AI模型与真实世界的桥梁，通过统一协议和安全设计，使LLM能够灵活、安全地调用外部能力，推动AI应用向更深层次的实用化发展。开发者可通过丰富的工具链快速构建自定义服务，而用户则能通过标准化接口享受更智能的交互体验。 目前已经支持的MCP-clients 有下面这些工具组件 今天就带大家使用vs code+cline 实现MCP-server 来讲解一下如何实现大模型+MCP 实现万物互联。 2.工具介绍 本地演示我们用了如下几个工具 VSCode 微软免费的代码开发工具，下载地址https://code.visualstudio.com/ 建议使用最新的版本1.97.2 cline 一款集成于 VS Code 的 开源AI编程助手，通过大模型（如Claude 3.5、GPT）生成代码，自动修复语法和逻辑错误。 可以在 VS Code 插件市场上安装，目前最新版本3.5.0 Navicat Premium Navicat Premium 是一款功能强大的数据库管理工具。目前这个软件是收费的，目前可以有14天试用期。关于这个工具我们这里就不详细展开了。 nodejs Node.js 是一个基于 Chrome V8 JavaScript 引擎构建的开源、跨平台的 JavaScript 运行环境，它使 JavaScript 可以在服务器端运行，极大地拓展了 JavaScript 的应用场景。如果你电脑上没有安装这个nodejs 需要把这个软件安装。下载地址https://nodejs.org/zh-cn/download 下载上面windows 版本，安装即可，这里就不详细展开。 安装好后参考上面的额命令保证你命令行能显示node-v npm -v 版本显示成功 3.MCP-server 安装和使用 目前已经有好几个网站收集整理了MCP-server，给大家介绍一下这个网站https://www.pulsemcp.com/ 目前这个网站已经收集到1300MCP-server，而且每天都有增加。 这个网站上有很多MCP-server，比如排名靠前的 Filesystem 它提供通过受控的API读取，编写和操纵本地文件。说白了就是通过大模型可以操控本地文档。 另外还有很多其他的MCP-server 这里我们就不详细展开，下面给大家介绍2个MCP-server 在cline中使用和安装。 1.sleep-mcp 这个sleep功能非常简单和上手，主要功能是大模型调用远程执行时间长的时候可以调用这个组件实现sleep. 我们打开cline,配置好模型厂商API key.目前cline 提供如下几个厂商 这里我们选择openrouter，主要是因为 openrouter提供部分免费和收费的模型。而且国内网络访问它也没有限制。通过它可以使用免费的google gemini. 我们知道google gemini提供免费的gemini2 系列模型，模型能力非常强、模型上下文分成大达到1M，另外最主要是免费。 如果大家没有https://openrouter.ai 可以去网站上开通注册一个。我记得好像QQ邮箱就可以注册一个，然后生成免费的api key 这里关于这个网站注册 创建apikey就不带大家展示了。 选定模型厂商、输入模型key，选择好模型cline 就可以使用了。 目前cline 在3.4.0版本上线了MCP-server 插件市场。点击“+” 号旁边插件市场打开MCP-server 插件市场 这里列举了非常多的插件和分类，有浏览器自动化的、数据库的、开发工具的 大家根据自己的需要安装MCP-server . 我们给大家先安装一个sleep-mcp 点击sleep install cline 会调用大模型自动给你安装。 模型会提示你是否创建生成这个文件夹，点击 run command 模型会提示你是否通过git clone 下载这个代码到C:\\Users\\Administrator\\Documents\\Cline\\MCP\\sleep-mcp 模型下。我们同样点击 run command 这里需要注意的是有的小伙伴电脑上网络可能会受到限制访问https://github.com/Garoth/sleep-mcp.git 访问不了。 如果遇到这问题可以手工下载放到这个目录下。 复制代码到 如果网络没有问题 点击 run command 提示下载的程序使用npm install 命令安装这个代码 安装完成后，会提示你把安装路径写到 cline_mcp_settings.json 点击保存按钮完成设置。返回测试结果 这样我们就确保这个mcp server 组件安装成功 安装完成后，我们可以在 install 查看到显示绿色 这样就按照成功了。 通过上述方法，我们成功完成了一个最简单的 MCP Server 的安装。需要注意的是，不同的 MCP Server 在安装过程中可能会存在一些差异。此外，软件所依赖的第三方软件是否受到网络环境的限制，也会对不同 MCP Server 的安装方法产生影响，从而造成安装上的差异。大家可以依据实际情况进行判断。 2.mysql 目前，通过 marketplace 中的 MCP Server 市场来安装 cline 相关组件相对较为简便，借助大语言模型对话就能完成组件的安装。不过，这个市场的更新可能不太及时。在我使用 MySQL 的过程中，发现市场里并没有针对 MySQL 的 MCP Server。但在 https://www.pulsemcp.com/servers?q=mysql 这个网站上是可以找到相关内容的。接下来，我们就为大家介绍如何通过手工方式将 MySQL MCP Server 整合到 cline 中。 首选我们需要在mcp server 市场上找到mysql mcp server对于开源项目地址，搜索到后点击链接 点击地址 https://github.com/designcomputer/mysql\\_mcp\\_server 文档的下面有安装的说明，我们简单解读一下 第一步安装mysql-mcp-server 组件包 我们需要使用pip 安装 mysql-mcp-server 组件包， 这个代码是python 写的所以我们需要pip 依赖包安装。我们在cmd窗口中执行 1pip install mysql-mcp-server -i https://pypi.tuna.tsinghua.edu.cn/simple/ 安装完成后，我们在windows cmd 命令行窗口输入 1pip show mysql-mcp-server 确保这个组件安装完成。 第二步安装数据库及SQL 脚本 我们使用Navicat Premium 创建数据库student_score，执行如下脚本 student_score.sql -- 创建学生表 CREATE TABLE students ( student_id INT PRIMARY KEY, student_name VARCHAR(50) NOT NULL, gender CHAR(1), class_name VARCHAR(20), admission_date DATE ); -- 创建课程表 CREATE TABLE courses ( course_id INT PRIMARY KEY, course_name VARCHAR(50) NOT NULL, credit DECIMAL(3,1) ); -- 创建成绩表 CREATE TABLE scores ( score_id INT PRIMARY KEY, student_id INT, course_id INT, score DECIMAL(5,2), exam_date DATE, FOREIGN KEY (student_id) REFERENCES students(student_id), FOREIGN KEY (course_id) REFERENCES courses(course_id) ); -- 插入测试数据 -- 1. 插入学生数据 INSERT INTO students (student_id, student_name, gender, class_name, admission_date) VALUES (1001, '张三', 'M', '高一(1)班', '2023-09-01'), (1002, '李四', 'F', '高一(1)班', '2023-09-01'), (1003, '王五', 'M', '高一(2)班', '2023-09-01'), (1004, '赵六', 'F', '高一(2)班', '2023-09-01'), (1005, '孙七', 'M', '高一(3)班', '2023-09-01'); -- 2. 插入课程数据 INSERT INTO courses (course_id, course_name, credit) VALUES (1, '语文', 4.0), (2, '数学', 4.0), (3, '英语', 4.0), (4, '物理', 3.0), (5, '化学', 3.0); -- 3. 插入成绩数据 INSERT INTO scores (score_id, student_id, course_id, score, exam_date) VALUES (1, 1001, 1, 85.5, '2023-12-20'), (2, 1001, 2, 92.0, '2023-12-20'), (3, 1001, 3, 78.5, '2023-12-20'), (4, 1002, 1, 88.0, '2023-12-20'), (5, 1002, 2, 95.5, '2023-12-20'), (6, 1002, 3, 90.0, '2023-12-20'), (7, 1003, 1, 82.5, '2023-12-20'), (8, 1003, 2, 86.0, '2023-12-20'), (9, 1003, 3, 75.5, '2023-12-20'), (10, 1004, 1, 91.0, '2023-12-20'), (11, 1004, 2, 89.5, '2023-12-20'), (12, 1004, 3, 94.0, '2023-12-20'), (13, 1005, 1, 87.5, '2023-12-20'), (14, 1005, 2, 88.0, '2023-12-20'), (15, 1005, 3, 85.5, '2023-12-20'); -- 一些常用查询示例 -- 1. 查询某个学生的所有成绩 SELECT s.student_name, c.course_name, sc.score FROM students s JOIN scores sc ON s.student_id = sc.student_id JOIN courses c ON sc.course_id = c.course_id WHERE s.student_id = 1001; -- 2. 查询某个班级的平均成绩 SELECT s.class_name, c.course_name, AVG(sc.score) as avg_score FROM students s JOIN scores sc ON s.student_id = sc.student_id JOIN courses c ON sc.course_id = c.course_id GROUP BY s.class_name, c.course_name; -- 3. 查询各科成绩排名前三的学生 WITH RankedScores AS ( SELECT c.course_name, s.student_name, sc.score, RANK() OVER (PARTITION BY c.course_id ORDER BY sc.score DESC) as student_rank FROM scores sc JOIN students s ON sc.student_id = s.student_id JOIN courses c ON sc.course_id = c.course_id ) SELECT * FROM RankedScores WHERE student_rank &lt;= 3; 数据库脚本执行完成后，数据库有3个表 分别是students、courses、scores 接下来我们需要记事本记录下数据库连接信息 ： 12345MYSQL_HOST=localhost # Database hostMYSQL_PORT=3306 # Optional: Database port (defaults to 3306 if not specified)MYSQL_USER=your_usernameMYSQL_PASSWORD=your_passwordMYSQL_DATABASE=your_database 第三步cline 手工安装mysql-mcp-server 组件包 我们打开cline mcp server 点击 configure mcp servers 复制下面的代码 12345678910111213141516&quot;mysql&quot;: &#123; &quot;command&quot;: &quot;uv&quot;, &quot;args&quot;: [ &quot;run&quot;, &quot;mysql_mcp_server&quot; ], &quot;env&quot;: &#123; &quot;MYSQL_HOST&quot;: &quot;192.168.1.5&quot;, &quot;MYSQL_PORT&quot;: &quot;3306&quot;, &quot;MYSQL_USER&quot;: &quot;root&quot;, &quot;MYSQL_PASSWORD&quot;: &quot;xxxxxx&quot;, &quot;MYSQL_DATABASE&quot;: &quot;student_score&quot; &#125;, &quot;disabled&quot;: false, &quot;autoApprove&quot;: []&#125;, 到cline_mcp_settings.json 里面，关于cline_mcp_settings.json 我的目录在C:\\Users\\Administrator\\AppData\\Roaming\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings文件夹下 以上就是我添加完成的效果，大家可以发现上面的sleep-mcp 就在mysql 安装的下面。大家知道原理后手工复制也是可以实现mcp server安装的。 这里我们需要用的uv command 命令来执行。 那么什么是uv 呢？ uv 一个非常快速的Python软件包管理工具，使用rust写的 一种替代PIP，PIP-Tools，Pipx，Poetry，Pyenv，Twine，Virtualenv等的一种工具 文档地址 https://docs.astral.sh/uv/ github地址 https://github.com/astral-sh/uv 简单来说它就是个包管理器，我们可以使用pip install uv 安装 1pip install uv -i https://pypi.tuna.tsinghua.edu.cn/simple/ 确保电脑上有uv 运行环境，这样他们就可以执行command 命令了。 以上配置完成后我们就可在cline 聊天对话形式测试它的可用性了。 出现上面绿色 说明这个组件和我们数据库已经实现连接了。 第四步验证测试 我们在cline聊天对话中输入内容，先让大模型告诉我这个数据库有哪些表。 测试返回 显示3个表 和我们上面的 数据库表对应上 通过上面我们已经实现了cline +mysql-mcp-server+大模型实现数据库连接了。接下来我在问几个问题 上面生成的SQL 语句查询返回的结果。 生成的sql 语句 123&#123; &quot;query&quot;: &quot;SELECT s.student_name, c.course_name, sc.score FROM students s JOIN scores sc ON s.student_id = sc.student_id JOIN courses c ON sc.course_id = c.course_id WHERE s.student_name = &#x27;张三&#x27; AND c.course_name IN (&#x27;语文&#x27;, &#x27;数学&#x27;, &#x27;英语&#x27;)&quot;&#125; 数据库执行的语句和返回也一致的。 也就是我们通过自然语音的形式也能帮我生成SQL 语句甚至查询都不用我查询，直接把我的的查询结果给我返回了。 2.File System 此MCP服务可以使大模型访问文件系统 在MCP servers上搜索Fie System并进行安装，步骤上同。 配置 MCP servers: 1234567891011&quot;filesystem&quot;: &#123; &quot;disabled&quot;: false, &quot;timeout&quot;: 60, &quot;type&quot;: &quot;stdio&quot;, &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [ &quot;-y&quot;, &quot;@modelcontextprotocol/server-filesystem&quot;, &quot;D://test&quot; ] &#125; 这也太爽了，数据库开发工程是估计也要偷着乐了，又可以提早下班了。 总结 今天主要带大家深入了解了使用 vs code + cline 实现 MCP - server 来讲解如何实现大模型 + MCP 实现万物互联的相关内容。包括核心要点、工作流程等，还对比了类似技术。随后介绍演示所用工具如 VSCode、cline 等。最后讲 MCP - server 安装使用，推荐网站，着重讲 sleep - mcp和mysql-mcp-server 2个mcp-server安装过程。测试下来感觉这个东西非常强大，感兴趣的下伙伴也可以去尝试。今天的分享就到这里结束了，我们下个文章见。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"MCP","slug":"MCP","permalink":"http://www.formeasy.cc/tags/MCP/"}],"author":"wwwzhouhui 关注"},{"title":"VS Code秒变AI神器！3步免费部署DeepSeek本地编程助手：代码补全/智能问答/隐私保护全搞定","slug":"Editor/VS Code秒变AI神器！3步免费部署DeepSeek本地编程助手：代码补全智能问答隐私保护全搞定","date":"2025-03-25T05:28:41.000Z","updated":"2025-04-25T01:55:45.440Z","comments":true,"path":"2025/03/25/Editor/VS Code秒变AI神器！3步免费部署DeepSeek本地编程助手：代码补全智能问答隐私保护全搞定/","link":"","permalink":"http://www.formeasy.cc/2025/03/25/Editor/VS%20Code%E7%A7%92%E5%8F%98AI%E7%A5%9E%E5%99%A8%EF%BC%813%E6%AD%A5%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2DeepSeek%E6%9C%AC%E5%9C%B0%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%EF%BC%9A%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E5%85%A8%E6%90%9E%E5%AE%9A/","excerpt":"","text":"一、技术选型 以下是VS Code本地部署大模型代码助手的常用插件对比，基于隐私保护、离线使用及功能特性整理，每个人可根据自身需要选择： 插件名称 优点 缺点 适用场景 Continue 支持多模型切换（Ollama/本地模型），支持代码补全/重构/问答，配置灵活度高 需手动修改 JSON 配置文件，新手易出错 企业级复杂项目开发，需同时使用对话和补全功能，重视数据隐私的场景 CodeGPT 一键连接 Ollama 模型，内置 /explain /fix 等快捷指令，学习成本低 仅支持基础问答，代码补全依赖 deepseek-coder 模型 个人开发者快速接入，中小型项目调试，需即时解释代码逻辑的场景 Cline 支持 DeepSeek/Claude 等商用模型，可配置 MCP 服务器扩展功能 需自行购买 API 密钥，部分模型需联网计费 需结合云端高性能模型的混合开发场景，愿意为模型能力付费的团队 Twinny 专为 Ollama 优化，自动检测本地模型，界面交互简洁 功能较单一（仅问答），缺乏代码补全等进阶功能 个人开发者快速验证想法，小型脚本编写，对界面简洁度要求高的场景 Codellm 低显存优化（最低 4GB），支持代码片段自动续写，响应速度快 逻辑推理能力较弱，复杂需求需多次迭代 教育/培训场景，硬件配置较低的设备，编写模板化代码（如 CRUD 接口） ChatMoss 内置 15+ 国内可用模型，支持快捷注释和代码优化 部分模型需兑换码（如 ZXCODE），依赖国内服务节点 国内企业内网环境，需适配国产化开发流程，规避国际模型合规风险的场景 选型建议 隐私优先：选择 Continue 或 CodeGPT，通过 Ollama 完全本地运行 硬件受限：使用 Codellm + deepseek-r1:1.5b 量化版（显存占用 ≤4GB） 国内环境：ChatMoss 或 Cline（需自备代理），规避网络限制 企业定制：Continue + 自研模型微调，通过 config.json 对接内部知识库 部署验证技巧 终端运行 ollama list 确认模型已加载 在 VS Code 中按 Ctrl+Shift+P → 输入 Continue: Open Config File 检查模型连接状态 输入测试指令（如“用 Python 实现快速排序”）观察响应速度和代码质量 二、核心工具准备（5分钟） 1. Ollama 部署 12# Windows/Mac/Linux 通用命令（自动识别系统）curl -fsSL https://ollama.com/install.sh | sh 验证安装： 1ollama --version # 显示版本 ≥0.5.7 即为成功 2. 拉取 DeepSeek 模型 123# 根据显存选择模型（推荐组合）：ollama pull deepseek-r1:1.5b # 基础问答（4GB+显存）ollama pull deepseek-coder:1.3b # 代码补全（6GB+显存） 3. VS Code 安装 Continue 扩展 扩展商店搜索 Continue → 安装官方版本（≥v0.3.2） 三、关键配置实战（含避坑指南） 步骤1：激活本地模型连接 打开 Continue 侧边栏 → 点击齿轮图标进入 config.json，替换为： 123456789101112&#123; &quot;models&quot;: [&#123; &quot;title&quot;: &quot;DeepSeek-Local&quot;, &quot;provider&quot;: &quot;ollama&quot;, &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;, &quot;apiBase&quot;: &quot;http://localhost:11434&quot; &#125;], &quot;tabAutocompleteModel&quot;: &#123; &quot;provider&quot;: &quot;ollama&quot;, &quot;model&quot;: &quot;deepseek-coder:1.3b&quot; &#125;&#125; 💡 避坑提示： 若配置不生效，按 Ctrl+Shift+P 输入 Reload Window 重启 VS Code 终端运行 curl http://localhost:11434 检查 Ollama 服务状态 步骤2：代码补全优化 在 VS Code 设置文件（settings.json）中添加： 123&quot;continue.tabAutocompleteEnabled&quot;: true,&quot;continue.showContextButton&quot;: false,&quot;continue.maxTokens&quot;: 128 // 控制补全长度 步骤3：快捷键绑定（效率翻倍） 123456// keybindings.json 添加：&#123; &quot;key&quot;: &quot;ctrl+alt+l&quot;, &quot;command&quot;: &quot;continue.quickEdit&quot;, &quot;when&quot;: &quot;editorTextFocus&quot;&#125; 现在选中代码后按 Ctrl+Alt+L 即可触发智能重构！ 四、实战场景演示 场景1：代码自动补全 输入 function reverseString( 时，Continue 会自动补全： 123function reverseString(str) &#123; return str.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;);&#125; 场景2：错误代码修复 选中问题代码 → 输入 /fix： 12345678# 原代码（错误）list = [1,2,3]print(list[-4]) # IndexError# AI修复后list = [1,2,3]index = -4 if -4 &gt;= -len(list) else Noneprint(list[index] if index is not None else &quot;Index out of range&quot;) 场景3：技术文档查询 在聊天框输入： 1/ask 如何在React中实现动态路由？给出代码示例 Continue 将返回： 12345678910// 使用react-router-dom v6+import &#123; Routes, Route &#125; from &#x27;react-router-dom&#x27;;function App() &#123; return ( &lt;Routes&gt; &lt;Route path=&quot;/users/:userId&quot; element=&#123;&lt;UserProfile /&gt;&#125; /&gt; &lt;/Routes&gt; );&#125; 五、部署总结（本地化核心优势） 优势 说明 数据隐私 所有计算在本地完成，代码/文档永不外传 离线可用 断网环境仍可正常使用AI功能 零成本 无需API密钥，免费部署 低延迟 本地响应速度 ≤0.5秒 自定义训练 支持接入自有数据集微调模型 💻 硬件建议： 入门级：CPU i5 + 8GB内存 → 运行 deepseek-r1:1.5b 高性能：GPU RTX 3060 + 16GB显存 → 运行 deepseek-r1:14b 五、常见问题速查 模型加载失败？ 12# 清理缓存后重试ollama rm deepseek-r1:1.5b &amp;&amp; ollama pull deepseek-r1:1.5b 补全不触发？ 检查 Continue 设置中的 tabAutocompleteModel 是否指定代码模型 确认 VS Code 语言模式非纯文本（如.txt文件不会触发） 中文输出异常？ 在 config.json 的模型配置添加： 1&quot;systemMessage&quot;: &quot;你是一个专业的编程助手，使用中文回复&quot; 立即按照本教程部署，让你的 VS Code 获得企业级AI辅助能力！更多深度玩法（自定义知识库/私有模型微调）","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Editor","slug":"Editor","permalink":"http://www.formeasy.cc/tags/Editor/"},{"name":"Ollama","slug":"Ollama","permalink":"http://www.formeasy.cc/tags/Ollama/"}],"author":null},{"title":"pycharm无法安装插件显示网络错误无法安装汉化插件","slug":"Editor/pycharm无法安装插件显示网络错误无法安装汉化插件","date":"2025-03-25T02:50:41.000Z","updated":"2025-04-25T01:51:30.712Z","comments":true,"path":"2025/03/25/Editor/pycharm无法安装插件显示网络错误无法安装汉化插件/","link":"","permalink":"http://www.formeasy.cc/2025/03/25/Editor/pycharm%E6%97%A0%E6%B3%95%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6%E6%98%BE%E7%A4%BA%E7%BD%91%E7%BB%9C%E9%94%99%E8%AF%AF%E6%97%A0%E6%B3%95%E5%AE%89%E8%A3%85%E6%B1%89%E5%8C%96%E6%8F%92%E4%BB%B6/","excerpt":"","text":"【pycharm】pycharm无法安装插件显示网络错误/无法安装汉化插件(报错：Marketplace plugins are not loaded，Check the internet connection and refresh） 【问题描述】 进行pycharm汉化时，无法安装插件，弹出提示：Marketplace plugins are not loaded，Check the internet connection and refresh 尝试： 百度说在settings-&gt; Appearance&amp;Behavior -&gt; System Settings -&gt; Updats 中,取消勾选Use secre Connections 即可 但是我这个版本没有这个选项 【解决方法】 1、进入file-&gt;settings-&gt; Appearance&amp;Behavior -&gt; System Settings -&gt; HTTP Proxy下； 2、勾选 auto-detect proxy seting、automatic proxy configuration URL； 3、将automatic proxy configuration URL其后的网址修改为：https://plugins.jetbrains.com/； 4、保存后重启，即可解决问题。 5、再次进行汉化插件搜索时，即可成功搜索到：","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Editor","slug":"Editor","permalink":"http://www.formeasy.cc/tags/Editor/"},{"name":"python","slug":"python","permalink":"http://www.formeasy.cc/tags/python/"}],"author":null},{"title":"vs code插件Continue + 本地语言模型使用方法","slug":"ollama/vs code插件Continue+本地语言模型使用方法","date":"2025-03-25T02:40:27.000Z","updated":"2025-06-24T01:09:58.464Z","comments":true,"path":"2025/03/25/ollama/vs code插件Continue+本地语言模型使用方法/","link":"","permalink":"http://www.formeasy.cc/2025/03/25/ollama/vs%20code%E6%8F%92%E4%BB%B6Continue+%E6%9C%AC%E5%9C%B0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"ollama如何运行模型，此文不涉及，随便查一查很简单。 1. 在拓展商店中找到Continue 2. 安装好continue插件以后，左侧会多出continue的图标，进去 2.1 现在我们先设置一下对话模型，点右上角加号进入new session，下拉框选择模型，选择add chat model provider选择ollama，model可以自己找，官方推荐用Qwen 2.5 1.5b，我这里用的是7b，根据你自己的条件和个人喜好决定。 添加完json配置里的models列表就会多出一个模型选项，有时候模型名称与你本地跑的有出入，报错的话，你自己到这里改一下。 或者添加表单里，有自动检测模型选项，可以用。 2.2 再设置一下，自动补全 找到configuration，找不到就点右上角设置小圆圈。 在配置json中，models选项下面，就可以看到tabAutocompleteModel，在里面给个名字，provider填ollama，model填qwen2.5-coder:1.5b-base，这个根据你自己的模型来填。如果这里model名字填的有问题，会直接报错。如果不报错，但是补全没任何反应，一般一会儿就会正常。如果一直不行，看看你自己是不是填了base url什么的。因为是本地模型，base url用默认，不需要指定，直接删掉。 正常来讲，每当你进行代码编辑，右下角的Continue都回转圈，然后跳出补全。 桌面右下角，能看到ollama在后台运行，continue就可以与ollama的模型去对话。 你下载的模型参数不同对应的内存不同，ollama会自行判断，如果你的显卡内存足够，会跑在显卡上(nvidia cuda)，否则会运行在cpu上，然后占用cpu的内存，所以个人电脑1.5b是最佳选择。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"ollama模型离线迁移/复制","slug":"ollama/ollama模型离线迁移复制","date":"2025-03-25T02:25:20.000Z","updated":"2025-06-24T01:09:29.893Z","comments":true,"path":"2025/03/25/ollama/ollama模型离线迁移复制/","link":"","permalink":"http://www.formeasy.cc/2025/03/25/ollama/ollama%E6%A8%A1%E5%9E%8B%E7%A6%BB%E7%BA%BF%E8%BF%81%E7%A7%BB%E5%A4%8D%E5%88%B6/","excerpt":"","text":"在ollama中可以使用命令ollama pull deepseek-r1:7b下载模型，但在某些特殊情况下（如：离线环境）需要手动迁移模型，本文详细讲解了ollama中离线迁移模型的方式。 一、下载特定模型 在一个有网的环境中，使用ollama pull命令下载模型，如：deepseek-r1:7b 二、进行离线迁移 迁移之前首先需要确定ollama主目录。在windows系统中，通常是用户主目录下的.ollama文件夹，例如： C:\\Users\\wangk\\.ollama；在Linux系统中，同样的，通常也是用户主目录下的.ollama文件夹，例如：/root/.ollama windows系统下的ollama主目录 linux系统下的ollama主目录 在ollama主目录下，有两部分内容需要迁移 1、blobs文件夹 在blobs文件夹下是一些二进制文件，这时，需要到ollama官网去，找到对应模型的唯一标识，这里以deepseek-r1:7b为例，ollama官网的models中搜索deepseek-r1，并进入主页，如下所示： 点击model，然后拷贝这部分 96c415656d37 在blobs文件夹搜索 96c415656d37 可以定位到一个二进制文件，找到这个文件，并将与这个文件具有相同修改时间的其它文件一起复制到目标主机的对应文件夹下 2、manifests文件夹 这个比较简单，复制manifests文件夹下特定目录到目标主机的对应文件夹下 三、模型离线迁移完成 在目标主机运行ollama list命令，发现deepseekr1:7b模型已经迁移过来了 备注：ollama的模型在windows、linux和mac系统中都是通用的，模型不同系统之间可以进行相互拷贝。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"向量数据库的分类概况_向量库类型","slug":"LLM/向量数据库的分类概况_向量库类型","date":"2025-03-21T09:01:16.000Z","updated":"2025-04-25T01:59:21.033Z","comments":true,"path":"2025/03/21/LLM/向量数据库的分类概况_向量库类型/","link":"","permalink":"http://www.formeasy.cc/2025/03/21/LLM/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%88%86%E7%B1%BB%E6%A6%82%E5%86%B5_%E5%90%91%E9%87%8F%E5%BA%93%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"向量数据库的分类概况 保存和检索矢量数据的五种方法： 像 Pinecone 这样的纯矢量数据库 全文搜索数据库，例如 ElasticSearch 矢量库，如 Faiss、Annoy 和 Hnswlib 支持矢量的NoSQL 数据库，例如 MongoDB、Cosmos DB 和 Cassandra 支持矢量的SQL 数据库，例如 SingleStoreDB 或 PostgreSQL 1.纯矢量数据库 纯向量数据库专门用于存储和检索向量。示例包括 Chroma、LanceDB、Marqo、Milvus/Zilliz、Pinecone、Qdrant、Vald、Vespa、Weaviate 等。 在纯矢量数据库中，数据是根据对象或数据点的矢量表示来组织和索引的。这些向量可以是各种类型数据的数值表示，包括图像、文本文档、音频文件或任何其他形式的结构化或非结构化数据。 纯载体数据库的优点 利用索引技术进行高效的相似性搜索 大型数据集和高查询工作负载的可扩展性 支持高维数据 支持基于 HTTP 和 JSON 的 API 对向量运算的本机支持，包括加法、减法、点积、余弦相似度 纯载体数据库的缺点 仅矢量 纯矢量数据库可以存储矢量和一些元数据，但仅此而已。对于大多数企业人工智能用例，您可能需要包括实体、属性和层次结构（图形）、位置（地理空间）等的描述等数据。 有限或没有 SQL 支持 纯向量数据库通常使用自己的查询语言，这使得很难对向量和相关信息运行传统分析，或者将向量和其他数据类型结合起来。 没有完整的 CRUD 纯向量数据库并不是真正为创建、更新和删除操作而设计的。对于读取操作，数据必须首先进行矢量化和索引以进行持久化和检索。这些数据库专注于提取矢量数据、对其进行索引以进行有效的相似性搜索以及基于矢量相似性查询最近邻居。 建立索引非常耗时 索引矢量数据计算量大、成本高且耗时。这使得很难将新数据用于生成人工智能应用程序。 被迫权衡 根据所使用的索引技术，矢量数据库要求客户在准确性、效率和存储之间进行权衡。例如，Pinecone 的 IMI 索引（反向多重索引，ANN 的一种变体）会产生存储开销，并且计算量很大。它主要针对静态或半静态数据集而设计，如果频繁添加、修改或删除向量，则可能会受到挑战。Milvus 使用称为“产品量化”和“分层可导航小世界”(HNSW) 的索引，这些索引是权衡搜索准确性和效率的近似技术。此外，其索引需要配置各种参数，使用不正确的参数选择可能会影响搜索结果的质量或导致效率低下。 企业特征值得怀疑 许多矢量数据库在基本功能上严重落后，包括 ACID 事务、灾难恢复、RBAC、元数据过滤、数据库可管理性、可观察性等。这可能会导致严重的业务问题 - 类似于丢失所有数据的客户。 对于许多客户来说，矢量数据库的局限性将归结为性价比。鉴于矢量运算的计算量大，OSS矢量数据库或矢量库成为特别大规模应用程序的可行替代方案。 2. 全文检索数据库 此类别包括 Elastic/Lucene、OpenSearch 和 Solr 等数据库。 优点 --高可扩展性和性能，特别是对于非结构化文本文档 --丰富的文本检索功能，例如内置外语支持、可自定义分词器、词干分析器、停止列表和 N 元语法 --基于开源库（Apache Lucene） --大型集成生态系统，包括向量库 矢量数据全文检索数据库的局限性 --未针对向量搜索或相似性匹配进行优化 --专为全文搜索而不是语义搜索而设计，因此基于其构建的应用程序不会具有检索增强生成 (RAG) 和其他用例的完整上下文。为了实现语义搜索功能，这些数据库需要使用其他工具以及大量的自定义评分和相关性模型进行扩充。 --其他数据格式（图像、音频、视频）的应用有限 --缺乏 GPU 支持 3. 向量库 对于许多开发人员来说，Faiss、Annoy 和 Hnswlib 等开源矢量库是一个不错的起点。 Faiss是一个用于密集向量的相似性搜索和聚类的库。Annoy（Approximate Nearest Neighbors Oh Yeah）是一个用于 ANN 搜索的轻量级库。Hnswlib是一个实现 ANN 搜索的 HNSW 算法的库。 开源向量库的优点 --快速最近邻搜索 --专为高维而打造 --支持面向 ANN 的索引结构，包括倒排文件、乘积量化和随机投影 --支持推荐系统、图像搜索和 NLP 的用例 --SIMD（单指令、多数据）和 GPU 支持可加速矢量相似性搜索操作 开源向量库的局限性 --繁琐的维护和集成 --与精确方法相比，牺牲搜索精度 --自带基础设施。矢量库需要大量内存和计算资源，它们需要您构建和维护复杂的基础设施，以便为应用程序需求提供足够的 CPU、GPU 和内存资源。 --对元数据过滤、SQL、CRUD 操作、事务、高可用性、灾难恢复以及备份和恢复的支持有限或不支持 4.支持向量的NoSQL数据库 该类别包括： NoSQL 数据库，例如 MongoDB、Cassandra/DataStax Astra 和 CosmosDB。 键值数据库，例如 Redis 其他特殊用途数据库，例如 Neo4j（图） 几乎所有这些 NoSQL 数据库最近才通过添加矢量搜索扩展而变得支持矢量。 优点 对于其特定的数据模型，NoSQL 数据库提供高性能和规模。Neo4j（图形数据库）可以与社交网络或知识图的法学硕士结合使用。具有矢量功能的时间序列数据库（例如 kdb）也许能够将矢量数据与金融市场数据结合起来。 局限性 NoSQL 数据库的向量功能是基本的/新生的/未经测试的。许多 NoSQL 数据库今年才添加了向量支持。五月，Cassandra 宣布计划添加矢量搜索。4 月份，Rockset 宣布支持基本向量搜索，Azure Cosmos DB于 5 月份宣布支持 MongoDB vCore 的向量搜索。DataStax和MongoDB就在本月宣布了矢量搜索功能（均为预览版）！ NoSQL 数据库的矢量搜索性能差异很大，具体取决于支持的矢量函数、索引方法和硬件加速。 5. 支持向量的 SQL 数据库 该类别由一组非常小的数据库组成——SingleStoreDB、PostgreSQL 的 pgvector/Supabase Vector（测试版）、Clickhouse、Kinetica 和 Rockset。我们预计更多流行的数据库会出现在这个列表中，因为向已建立的数据库添加基本矢量功能并不是一件繁重的工作。事实上，矢量数据库 Chroma 是从 ClickHouse 中诞生的。 更新：2023 年 9 月，Oracle 也宣布了矢量搜索功能。 支持矢量的 SQL 数据库的优点 --具有点积、余弦相似度、欧氏距离和曼哈顿距离等功能的幂向量搜索。 --使用相似度分数查找 K 最近邻 --多模型 SQL 数据库提供混合搜索，并且可以将向量与其他数据结合起来以获得更有意义的结果 --大多数 SQL 数据库可以部署为服务，并在任何主要云上完全管理。 SQL 数据库用于矢量数据处理的局限性 --SQL 数据库是为结构化数据而设计的。生成式人工智能应用程序背后的语料库主要包含非结构化数据，例如图像、音频和文本。虽然关系数据库通常可以存储文本和 blob，但大多数数据库不会对这种非结构化数据进行矢量化以用于机器学习。 --大多数 SQL 数据库尚未针对矢量搜索进行优化。关系数据库的索引和查询机制主要是为结构化数据设计的，而不是高维向量数据。虽然用于矢量数据处理的 SQL 数据库的性能可能并不出色，但支持矢量的 SQL 数据库可能会添加扩展或新功能来支持矢量搜索。例如，虽然 SingleStoreDB 支持精确的 k-NN 搜索，但我们打算添加 ANN 搜索来提高非常大、高维数据集的性能。 --传统的 SQL 数据库无法横向扩展，因此其性能会随着数据的增长而下降。使用 SQL 数据库处理高维向量的大型数据集可能需要您进行额外的优化，例如对数据进行分区或采用专门的索引技术来保持高效的查询性能。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"}],"author":null},{"title":"软件为UDP服务却收不到数据问题解析","slug":"UDPTCP/软件为UDP服务却收不到数据问题解析","date":"2025-03-20T03:21:13.000Z","updated":"2025-04-25T02:02:02.314Z","comments":true,"path":"2025/03/20/UDPTCP/软件为UDP服务却收不到数据问题解析/","link":"","permalink":"http://www.formeasy.cc/2025/03/20/UDPTCP/%E8%BD%AF%E4%BB%B6%E4%B8%BAUDP%E6%9C%8D%E5%8A%A1%E5%8D%B4%E6%94%B6%E4%B8%8D%E5%88%B0%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/","excerpt":"","text":"问题：软件为UDP服务却收不到数据问题解析 【问题描述】安装了一软件，基础UDP服务，用来接收UDP数据协议，但软件启动后，就是收不到任何UDP数据。 【原因分析】 1.安装wireshark或UDP测试工具，正常能接收UDP数据，说明发送端没有问题。 2.启动此软件，查看是否占用端口，查看到: 12netstat -ano | findstr :9999 UDP 192.168.110.1:9999 *:* 3934 说明软件正常启动，但是其中的192.168.110.1并不是我主网卡的网卡。 本机有三个网卡（WMware Network Adapter VMnet1、WMware Network Adapter VMnet8和以太网） 其中安装虚拟机软件WMware后，安装了前两块网卡，其中WMware Network Adapter VMnet8网段是192.168.110.1 也就是说，软件默认的用的是WMware Network Adapter VMnet8网卡而不是本机的以太网网卡 【解决方案】通过跃点数（Metric）设置优先级 1.打开网络连接设置： 按 Win + R 输入 ncpa.cpl 回车。 或依次点击：控制面板 → 网络和Internet → 网络连接。 2.调整网卡跃点数： 右键点击要设为“主网卡”的适配器 → 属性 → 双击 “Internet协议版本4（TCP/IPv4）”。 点击 “高级” → 切换到 “自动跃点” 标签。 取消勾选 “自动跃点”，输入一个较小的数值（如 10），跃点数越低优先级越高。 对其他网卡设置更高的跃点数（如 20、30）。 3.重启网络服务或重启电脑： 按 Win + R 输入 cmd，右键选择“以管理员身份运行”。 123ipconfig /flushdnsnetsh int ip resetnetsh winsock reset","categories":[{"name":"网络通讯","slug":"网络通讯","permalink":"http://www.formeasy.cc/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"UDPTCP","slug":"UDPTCP","permalink":"http://www.formeasy.cc/tags/UDPTCP/"}]},{"title":"UE4&5 C++类创建后重启项目C++类不显示并且其蓝图子类丢失父类等问题原因及解决方法","slug":"UE/UE4&5 C++类创建后重启项目C++类不显示并且其蓝图子类丢失父类等问题原因及解决方法","date":"2025-03-19T03:21:13.000Z","updated":"2025-03-19T04:48:51.307Z","comments":true,"path":"2025/03/19/UE/UE4&5 C++类创建后重启项目C++类不显示并且其蓝图子类丢失父类等问题原因及解决方法/","link":"","permalink":"http://www.formeasy.cc/2025/03/19/UE/UE4&5%20C++%E7%B1%BB%E5%88%9B%E5%BB%BA%E5%90%8E%E9%87%8D%E5%90%AF%E9%A1%B9%E7%9B%AEC++%E7%B1%BB%E4%B8%8D%E6%98%BE%E7%A4%BA%E5%B9%B6%E4%B8%94%E5%85%B6%E8%93%9D%E5%9B%BE%E5%AD%90%E7%B1%BB%E4%B8%A2%E5%A4%B1%E7%88%B6%E7%B1%BB%E7%AD%89%E9%97%AE%E9%A2%98%E5%8E%9F%E5%9B%A0%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"问题一：UE4&amp;5 C++类创建后编辑器不显示 【问题描述】：C类创建后，在电脑资源管理器中显示存在.h和.cpp文件，VS正常打开其.h和.cpp文件，实时编译也不报错，但是在UE编辑器中C类文件夹下不见踪影。 【原因】C类文件路径错误，属于C1083错误的变种。C类只能存放在源文件夹下项目同名文件夹下的Private和Public文件夹内，C类创建时需要勾选是公共或私有，公共的C类的.h文件会放在Public文件夹内，.cpp文件会放在Private文件夹内；私有的C++类的.h和.cpp都会被放在Private文件夹内。 【解决方案】创建C++类的时候点选上面的公共或私有，查看.h和.cpp文件保存路径是否在源文件夹下的项目同名文件夹内的Private和Public文件夹内。 【特别注意】选择创建C++空类的时候无论是否点选公共与私有都不会被UE编辑器识别显示。这是因为需要在空类中定义受UE支持的类的类型才可以被识别。简单来说就是空类不是类。 问题二：UE4&amp;5 C类创建后重启项目C类也不显示并且其蓝图子类丢失父类 【问题描述】通过正常方式创建C++类会正常显示在UE编辑器中，但关闭项目重启之后 ，C类依然不显示，而且基于C类的蓝图子类也会提示丢失父类。 C++不显示Private和Public文件夹内，其蓝图子类也显示不正常 【原因】这是因为实时编译的保护。 【解决方案】 方案一：关闭实时编译，启用热重载与VS生成。（不建议） 方案二：打开项目用Ctrl+alt+F11运行一次实时编译。这样c类就出来了，然后蓝图子类也就会显示c父类了。（注意打开项目后不可以先打开蓝图子类，不然运行一次实时编译之后蓝图还是会提示无父类）（不建议） 开启项目后运行实时编译 方案三：去编辑器偏好设置里左侧加载和保存中勾选上启动时强制编译。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}]},{"title":"UE5（虚幻5）解决The following modules are missing or built with a different engine version","slug":"UE/UE5（虚幻5）解决The following modules are missing or built with a different engine version","date":"2025-03-18T03:21:13.000Z","updated":"2025-03-18T02:51:28.238Z","comments":true,"path":"2025/03/18/UE/UE5（虚幻5）解决The following modules are missing or built with a different engine version/","link":"","permalink":"http://www.formeasy.cc/2025/03/18/UE/UE5%EF%BC%88%E8%99%9A%E5%B9%BB5%EF%BC%89%E8%A7%A3%E5%86%B3The%20following%20modules%20are%20missing%20or%20built%20with%20a%20different%20engine%20version/","excerpt":"","text":"最近正在用UE5开发项目，创建了一个C++项目或加一个C++类后，重新打开后会报以下错误： The following modules are missing or built with a different engine version: XXXX Would you like to rebuild them now? 出现以上提示是让重新编译， 原因是C++项目程序或插件没有正确编译，或者项目文件路径名是中文。 点击“是”后，进行重新编译，如何编译过程中还是报错，从以下分析： 1.C++类工程是否有错误，使用VS打开工程重新编译，直到无错误 2.插件是否有错误，或者插件是否拷贝到项目下的Plugins目录中 以上都没问题后，可正确编译。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}]},{"title":"Windows下Docker环境的安装部署教程（以Win10为例）","slug":"Docker/Windows下Docker环境的安装部署教程（以Win10为例）","date":"2025-03-18T01:13:08.000Z","updated":"2025-05-09T05:38:30.947Z","comments":true,"path":"2025/03/18/Docker/Windows下Docker环境的安装部署教程（以Win10为例）/","link":"","permalink":"http://www.formeasy.cc/2025/03/18/Docker/Windows%E4%B8%8BDocker%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B%EF%BC%88%E4%BB%A5Win10%E4%B8%BA%E4%BE%8B%EF%BC%89/","excerpt":"","text":"Docker 是一个轻量级的容器虚拟化平台，能够帮助开发者快速构建、测试和部署应用程序，本文以 Windows 10 为例，详细讲解 Windows 系统下 Docker 环境的安装与配置步骤。 一、系统虚拟化 1，启用虚拟化 打开任务管理器（CTRL + Shift + Esc），选择性能，查看 CPU 虚拟化，确认是否已启用（默认启用）。 2，启用 Hyper-v 并开启虚拟任务 （1）打开“控制面板”-&gt;“程序” （2）然后点击“启用或关闭 Windows 功能” （3）然后勾选下面红框标注的 4 个功能组件，点击确定开始安装。安装完毕后根据提示重启电脑。 二、安装 WSL 提示：Windows Subsystem for Linux（简称 WSL）是一个在 Windows 10\\11 上能够运行原生 Linux 二进制可执行文件（ELF 格式）的兼容层。 1，检验安装 （1）再终端中输入如下命令，查看是否有安装 wsl。 1wsl （2）若没有安装，则会显示如下信息： 2，安装 WSL （1）安装 WSL 2 之前，必须启用“虚拟机平台”可选功能。 计算机需要虚拟化功能才能使用此功能。以管理员身份打开 PowerShell 并运行下面命令： 1dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart （2）然后我们直接下载下方的安装包，然后双击安装。 https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi （3）最后执行如下命令将 WSL 2 设置为默认版本： 1wsl --set-default-version 2 三、安装 Docker 1，下载安装包 （1）下面分别是官网下载地址和阿里云的下载地址，根据需求选择下载： 官方下载地址：https://docs.docker.com/desktop/setup/install/windows-install/ 阿里云下载地址：https://mirrors.aliyun.com/docker-toolbox/windows/docker-for-windows/ （2）接着双击安装包进行安装即可。安装完成后，任务栏会出现一个小鲸鱼图标（注意安装完成后可能会重启系统） 2，检查是否安装成功 （1）我们在 CMD 终端中输入如下命令： （2）如果成功返回版本信息，则说明 Docker 安装成功了。 四、Docker 配置 1，打开 Docker 配置中心 右键点击 docker 图标，然后选择弹出菜单中的“Settings”菜单项。 2，配置 Docker 国内镜像 （1）在弹出的窗口中，点击左侧的 Docker Engine （2）然后在右侧的 registry-mirrors 节点中添加国内的镜像地址，加快镜像拉取速度。 1234&quot;registry-mirrors&quot;:[ &quot;https://hub.rat.dev&quot;， &quot;https://docker.1panel.live/&quot;], （3）最后点击下方的 Apply &amp; Restart 按钮保存重启即可。 五、使用测试 1，拉取并运行容器 （1）我们执行如下命令启动一个基于 docker/getting-started 镜像的 Docker 容器，该镜像是 Docker 官方的一个示例镜像，包含了入门教程和一些展示内容。 1docker run -d -p 80:80 docker/getting-started （2）容器启动后，我们可以使用浏览器访问 http://localhost 访问我们启动的服务了： 2，查看状态 （1）我们可以通过如下命令查看当前运行的所有容器： 1docker ps （2）返回结果如下：","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}],"author":null},{"title":"Qt中的QByteArray和自定义结构体之间的相互转换","slug":"Qt/Qt中的QByteArray和自定义结构体之间的相互转换","date":"2025-03-15T03:32:43.000Z","updated":"2025-03-15T03:35:58.307Z","comments":true,"path":"2025/03/15/Qt/Qt中的QByteArray和自定义结构体之间的相互转换/","link":"","permalink":"http://www.formeasy.cc/2025/03/15/Qt/Qt%E4%B8%AD%E7%9A%84QByteArray%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%93%E6%9E%84%E4%BD%93%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"在Qt项目开发中，经常会碰到自定义结构体和字符数组之间的转换问题，不妨假设结构体名字为custom_struct, 字符数组名字为array_data 1.QByteArray转换为自定义结构体 1custom_struct *struct_data = reinterpret_cast&lt;custom_struct *&gt;(array_data.data()); 2.自定义结构体转换为QByteArray 12QByteArray array_data;array_data.append((char*)&amp;struct_data, sizeof(struct_data));","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}],"author":null},{"title":"Win10中docker的安装与使用","slug":"Docker/Win10中docker的安装与使用","date":"2025-03-09T06:44:43.000Z","updated":"2025-04-25T00:44:43.708Z","comments":true,"path":"2025/03/09/Docker/Win10中docker的安装与使用/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/Docker/Win10%E4%B8%ADdocker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/","excerpt":"","text":"0.虚拟化环境 开启虚拟化重启后，进入任务管理器看虚拟化是否已启用。 然后再是进入电脑的控制面板-&gt;程序-&gt;启用或关闭Windows功能-&gt;把Hyper-v勾上，启用后电脑会重启，后面就可以下载并安装Docker for Windows了。 1.下载安装 进入网址https://docs.docker.com/docker-for-windows/install/#download-docker-for-windows 下载并安装。我安装的是稳定版。安装过程没什么要注意的。 启动以后会出现在桌面的右下角区域，鼠标放上去以后显示Docker is running表示启动成功，第一次安装启用好像是会弹出个Docker Cloud登录界面，去注册然后登录，使用和git有点类似，可以pull图像等等 2.docker的入门 开始使用 检查Docker，Compose和Machine的版本 检查版本信息，并确保docker命令正常工作 运行docker run hello-world以测试从Docker Hub中拉取图像并启动容器 使用命令docker run -it ubuntu bash运行一个Ubuntu容器，我之前已经拉取过这个容器了，大概是几十兆吧，所以直接启用了，输入exit命令停止容器 运行命令docker run -d -p 80:80 –name webserver nginx 启动一个Dockerized webserver 会下载nginx容器图像并启动它，然后再打开浏览器键入http://localhost 运行docker ps 命令，检查容器的详细信息 停止或移除容器和图像。如果你想停止网络服务器，输入：docker stop webserver然后重新启动docker start webserver。要使用单个命令停止并删除正在运行的容器，请键入： docker rm -f webserver。这将删除容器，但不是 nginx图像。您可以列出本地图像docker images。你可能想要保留一些图片，这样你就不必再从Docker Hub中取出它们了。要删除不再需要的图像，请使用docker rmi后跟图像ID或图像名称。例如docker rmi nginx 3.docker的常用配置 在PowerShell中设置 tab键自动补全（其实用的都是cmd.exe） 启动一个的PowerShell（即以管理员身份运行）。搜索PowerShell，右键单击，然后选择以管理员身份运行。在PowerShell提示符下键入： Set-ExecutionPolicy RemoteSigned 检查策略设置是否正确，运行：get-executionpolicy 应该返回RemoteSigned。 安装posh-dockerPowerShell模块以自动完成Docker命令，键入：Install-Module posh-docker或者，要仅为当前用户安装模块，键入： Install-Module -Scope CurrentUser posh-docker 安装完成后，只能为当前PowerShell启用自动完成功能，输入：Import-Module posh-docker 为了在所有PowerShell会话中保持Tab完成状态$PROFILE，请在PowerShell提示符处输入： if (-Not (Test-Path $PROFILE)) { New-Item $PROFILE –Type File –Force } Add-Content $PROFILE “`nImport-Module posh-docker” 这将创建一个$PROFILE如果不存在，并将此行添加到文件中： Import-Module posh-docker 要检查文件是否已正确创建，或只需手动编辑，请在PowerShell中键入以下内容： Notepad $PROFILE 打开一个新的PowerShell会话。现在，当你键入的前几个字母后按Tab键，Docker命令（如开始，停止，运行及其选项）以及容器和映像名称现在都应该自动完成。 Settings 找到右下角的docker图标，右击选择settings进去 General：这里是设置docker开机自启，应用程序启动时检查更新，发布使用情况统计信息 Advanced：分配cpu数量与内存量 Daemon：Docker for windows10 可以配置阿里云镜像，到https://cr.console.aliyun.com/ 注册一个账户，登录进去后再列表选择加速器，把你的专属加速器地址复制粘贴到Daemon的Registry mirrors中 4.用Dockerfile定义一个镜像 在过去，如果你要开始编写一个Python应用程序，你的第一步就是在你的机器上安装一个Python运行库。但是，这会造成您的机器上的环境必须满足一定条件以使您的应用程序可以运行。 使用Docker，你可以将一个可移植的Python运行库作为一个映像，不需要安装。然后，您的构建可以将基础Python镜像与应用程序代码一起包括在内，确保您的应用程序，依赖项和运行时都一起运行。 这些可移植的镜像是由一个叫做Dockerfile的东西来定义的 新建目录文件 创建一个空目录，我取名叫docker，然后分别在里面新建三个文件：Dockerfile，app.py，requirements.txt 三个文件中的内容分别设计为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950511.Dockerfile：# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;]2.app.py：from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \\ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \\ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;\\_\\_main\\_\\_&quot;: app.run(host=&#x27;0.0.0.0&#x27;, port=80)3. requirements.txt：FlaskRedis 构建镜像 在docker目录下打开cmd.exe运行命令（确保能够找到Dockerfile文件，镜像取名叫friendlyhello）： docker build -t friendlyhello . ps：千万不要落了上面那行后面的那个点，曾经入过坑的。。命令包括后面的那个点 然后再执行命令： docker images 运行镜像程序： docker run -p 4000:80 friendlyhello 可以看到Python正在为应用程序提供消息的http://0.0.0.0:80。但是，这个消息来自容器内部，它不知道我们将该容器的端口80映射到4000，从而打开URL： http://localhost:4000 停止容器运行 首先在接着上面的操作步骤后按下ctrl+c在终端退出，这并不意味着镜像停止运行了 键入docker container ls 列出正在运行的容器 运行命令： docker container stop &lt;Container NAME or ID&gt; 停止容器。否则，在下一步中重新运行容器时，将会收到错误响应。 5.联系Docker Hub的常用操作 登录到Docker Hub 前面已经说过了，docker和git的操作有类似之处，所以docker也 有远程仓库，如果前面已经注册过并登录了docker cloud，那么 访问网址：https://hub.docker.com 在里面创建存储库，否则先 注册吧。 push镜像 前面在本地创建了一个friendlyhello的镜像，现在要把它push到 自己的docker hub的存储库中去，首先： 登录docker hub （我已经登录过了。。再登录一次吧） 标记镜像： 把镜像放入wangliguo存储库并标记为test 查看镜像： 发布镜像（推送镜像） Docker Hub上查看镜像： 从远程存储库中提取并运行镜像：现在当远程存储库有了镜像后，就可以从远程存储库提取并运行了 6.服务 在分布式应用程序中，应用程序的不同部分被称为“服务”。例如，想象一个视频共享站点，它可能包括用于将应用程序数据存储在数据库中的服务，用于用户上传东西的视频转码服务，为前端服务等等。 服务实际上只是“生产中的容器”。服务只运行一个镜像，但它编码镜像运行的方式 - 应该使用哪个端口，容器应该运行多少个副本，以便服务具有所需的容量，以及等等。缩放服务会更改运行该软件的容器实例的数量，从而为流程中的服务分配更多的计算资源。 使用Docker平台定义，运行和扩展服务非常简单 - 只需编写一个docker-compose.yml文件即可。 创建一个docker-compose.yml文件 键入： 12345678910111213141516171819version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: 15433/wangliguo:test deploy: replicas: 5 resources: limits: cpus: &quot;0.1&quot; memory: 50M restart_policy: condition: on-failure ports: - &quot;80:80&quot; networks: - webnetnetworks: webnet: 拉取的是上个步骤中的存储库的tag。 运行该镜像的5个实例作为一个服务调用web，限制每个使用，最多10％的CPU（跨所有核心）和50MB的RAM。 如果一个失败，立即重新启动容器。 将主机上的端口80映射到web端口80。 指导web容器通过一个负载平衡的网络共享80端口webnet。（在内部，容器本身将web在临时端口上发布到 端口80）。 webnet使用默认设置（这是一个负载平衡覆盖网络）定义网络。 运行新的负载均衡应用程序 先运行命令：docker swarm init 然后再运行命令：docker stack deploy -c docker-compose.yml getstartedlab 给它取名叫getstartedlab 服务堆栈在这台主机上运行了5个部署镜像的容器实例 运行命令查看：docker service ls 在服务中运行的单个容器称为任务，可以看到上面有个getstartedlab_web的服务 运行命令docker service ps getstartedlab_web 查看此服务下的任务： 如果只列出系统中的所有容器，也会显示任务，但不会被服务过滤： 运行命令：docker container ls -q 然后打开浏览器，键入http://localhost 点击刷新多次，可以发现Hostname的更改，以循环方式选择5个任务中的一个来响应。容器ID将与前一个命令（docker container ls -q）的输出相匹配。 更改应用程序 比如更改docker-compose.yml中的replicas值，保存更改并重新运行docker stack deploy命令来更新应用程序： 运行命令： docker stack deploy -c docker-compose.yml getstartedlab Docker会做一个就地更新，然后重新运行docker container ls -q以查看重新配置的已部署实例 可以看到之前是6个，现在是7个，刚好多了一个任务 ps:电脑中还运行这之前步骤中从docker hub中拉取并运行着的那个任务，所以会看到6个和7个 关闭应用程序和群 关闭应用程序docker stack rm getstartedlab 关闭群docker swarm leave –force 现在服务中的任务都关闭了以后再运行命令： docker container ls -q 这就是上面说的那个之前步骤中从docker hub中拉取并运行着的那个任务 7.集群 了解集群 swarm是运行Docker并加入到一个集群中的一组机器。但是现在它们将由群集管理器在群集上执行。群体中的机器可以是物理的或虚拟的。加入群体后，他们被称为节点。 Swarm管理人员可以使用多种策略来运行容器，比如“最空的节点”（emptiest node） - 它使用容器填充最少使用的机器。或“全局”，这确保了每台机器只能得到指定容器的一个实例。您可以指示swarm manager在Compose文件中使用这些策略。 群体管理者是群体中唯一可以执行你的命令的机器，或者授权其他机器作为工作者加入群体。工人提供能力，并没有权力告诉任何其他机器可以做什么和不可以做什么。 到目前为止，之前都是在本地机器上以单主机模式使用Docker。但是Docker也可以切换到群集模式，这就是使用群集的原因。启用群模式使当前机器成为群管理器。则Docker将运行您正在管理的群集上执行的命令，而不仅仅是在当前的机器上。 创建一个集群 一个群由多个节点组成，可以是物理机或虚拟机。基本的概念很简单：运行docker swarm init启用群模式，使当前的机器成为群管理器，然后docker swarm join在其他机器上运行 ，让它们作为工人加入群体。下面将使用虚拟机快速创建一个双机群集，并将其变成群集。 步骤： 以管理员运行cmd.exe 这里必须是管理员运行，不然后续操作权限不够 运行docker swarm init启用群模式，使当前的机器成为群管理器，然后docker swarm join在其他机器上运行 ，让它们作为工人加入群体。 启动Hyper-V管理器 点击开始windows管理工具Hyper-V管理器 单击右侧菜单中的虚拟交换机管理器 单击创建类型为外部网络的虚拟交换机，给它的名称myswitch，并检查框共享您的主机的活动网络适配器 使用节点管理工具创建几个虚拟机docker-machine： docker-machine create -d hyperv –hyperv-virtual-switch “myswitch” myvm1 docker-machine create -d hyperv –hyperv-virtual-switch “myswitch” myvm2 之前我已经创建过了，所以我现在再新建两个：myvm3 和 myvm4 docker-machine create -d hyperv –hyperv-virtual-switch “myswitch” myvm3 docker-machine create -d hyperv –hyperv-virtual-switch “myswitch” myvm4 现在创建了两个虚拟机，分别命名为myvm3和myvm4。使用命令 docker-machine ls 列出机器并获取其IP地址。 初始化群并添加节点 先使用命令docker-machine ssh myvm3 然后让myvm3 成为一个管理员：docker swarm init 注意红框中的内容，这是后面的myvm4 加入集群要执行的命令 运行命令：docker node ls 可以看到myvm3 已经成为管理员了 以管理员身份再运行一个cmd.exe.然后运行命令：docker-machine ssh myvm4 然后再运行命令：（这就是上一页中图片里红框中的内容，下面的token是我这里的，正常运行到这里的时候是去myvm3的docker swarm init命令中把红框框位置里的命令复制粘贴过来执行） docker swarm join --token SWMTKN-1-0csyw4yz6uxob90h0b8ejoimimrgisiuy9t2ugm8c1mxfvxf99-7q7w5jw1mrjk1jlri2bcgqmu8 10.211.106.194:2377 然后再切换到myvm3 的cmd.exe中执行命令：docker node ls 可以看到，我们已经创建了一个简单的集群。、 附离开群命令：docker swarm leave 在集群上部署应用程序 docker-machine为swarm管理器配置一个shell 运行命令：docker-machine env myvm3 注意最后一行的内容 我这里是@FOR /f &quot;tokens=*&quot; %i IN ('docker-machine env myvm3') DO @%i 复制粘贴运行它 再运行docker-machine ls以验证它myvm3 是否为活动机器 在swarm管理器上部署应用程序 以部署我们之前docker-compose.yml服务为例 首先在这个以管理员身份打开的cmd中进入到docker-compose.yml文件的所在的目录中去，我的因为在D/docker中，如果不过来，那么执行命令： docker stack deploy -c docker-compose.yml getstartedlab会出现： 进入目录后执行上面那条命令： 再执行命令docker stack ps getstartedlab 查看服务详情： 如果发现state存在shutdown的情况（也有可能出现你的图片上的实例数量大于你在服务文件中定义的数量的情况，这都是我爬过的坑，现在我这里定义的是6，图片上也是6，），那应该是你在之前服务哪一章运行过命令： docker stack deploy -c docker-compose.yml getstartedlab 而没有把getstartedlab移除掉 这时应该执行命令：docker stack rm getstartedlab 把getstartedlab移除掉 Ps：我是d，c盘都执行了这个命令，因为之前运行docker stack deploy -c docker-compose.yml getstartedlab命令是在d盘的时候 然后重新运行：docker stack deploy -c docker-compose.yml getstartedlab 和 docker stack ps getstartedlab 就好了 浏览器访问集群的网址","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}],"author":null},{"title":"proxmox的安装及配置_proxmox安装教程","slug":"proxmox/proxmox的安装及配置_proxmox安装教程","date":"2025-03-09T06:32:31.000Z","updated":"2025-06-24T01:07:42.089Z","comments":true,"path":"2025/03/09/proxmox/proxmox的安装及配置_proxmox安装教程/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/proxmox/proxmox%E7%9A%84%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE_proxmox%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","excerpt":"","text":"Proxmox全称Proxmox Virtual Environment简称PVE是基于Debian的虚拟机平台。以利用它安装任何你想要的系统，如：Win系统、linux系统、centos、ubuntu等）、软路由（LEDE、OpenWRT、ROS、高恪、爱快、等），而且是开源永久免费，要求硬件配置低，系统运行稳定等特点。 一、安装前准备 1、Proxmox 几乎可以在所有x86硬件上运行，需要准备一台可以开机的PC。 2、一个大于1G的U盘。 3、软碟通UltraISO软件。 4、到Proxmox官网 https://pve.proxmox.com/wiki/Downloads 下载最新版的PVE。 5、下载后用ultraiso打开下载的ISO文件，菜单-启动-写入硬盘映像。 6、驱动器选择U盘盘符，映像文件选择下载的PVE安装文件，写入方式选择RAW，最后点写入开始写盘。 7、写入U盘后关闭ultraiso，拔下U盘插到要安装PVE的PC上。开始设置启动顺序选择U盘启动。 二、PVE的安装 1、U盘启动后进入安装界面选择install Proxmox VE 2、出现安装协议，同意协议，选择“I agree” 4、选择安装的硬盘 5、国家、地区和键盘的选择 随后，输入服务器的国家china、选择区域和键盘布局，然后再次单击“下一步”。 6、设置root登陆密码和邮箱 7、分配IP、掩码、网关 Hostname：主机名，我这里写 pve.com IP Address：IP地址，默认分配的，也可以自己设定 Netmask：子网掩码，写255.255.255.0 Getway：网关，默认，也可以自己设定 DNS Server：DNS服务器，默认，也可以自己设定 8、点Next继续，确认输入无误后点Install安装 9、安装 根据PC性能，几分种便完成。 10、重启 重启前请拔掉U盘，点reboot 11、重启后自动默认选择第一项 12、最后进入PVE的登录界面，PVE的安装全部完成 打开控制端浏览器地址栏输入设定的IP地址和端口（https://192.168.1.250:8006） 三、PVE配置 安装后即可进行基本设置 删除订阅通知 通过 SSH 连接到 Proxmox 机器或通过 PVE Web 界面使用控制台，输入以下命令，然后清除浏览器缓存： sed -i.bak “s/data.status !== ‘Active’/false/g” /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service systemctl restart pveproxy重启网页服务 更改软件源 将/etc/apt/sources.list.d/pve-enterprise.list 文件内的唯一一条记录注释掉： #deb https://enterprise.proxmox.com/debian/pve stretch pve-enterprise wget -q -O- ‘http://download.proxmox.com/debian/pve/dists/stretch/proxmox-ve-release-5.x.gpg’ | apt-key add - echo “deb http://download.proxmox.com/debian/pve stretch pve-no-subscription” &gt; /etc/apt/sources.list.d/pve-no-subscription.list apt update &amp;&amp; apt dist-upgrade 国内源： echo “deb https://mirrors.ustc.edu.cn/proxmox/debian/pve stretch pve-no-subscription” &gt; /etc/apt/sources.list.d/pve-no-subscription.list 2、常用的设置几命令 ●磁盘映射 添加新硬盘 装好硬盘启动后查看下硬盘的名称 ls /dev/sd* 查看硬盘及硬盘分区（SATA硬盘） 也可以在节点-磁盘中查看 如果硬盘不带 SD_1/SD_2/SD*3 类数字表示未分区，使用以下命令进行分区； fdisk /dev/sdb 给sdb分区 输入 n 新建分区，输入 p 建立主分区，输入 1 创建一个分区 分区的扇区结束位置，默认，直接回车，w保存，到此就分区完成了，输入 p 查看一下 Select (default p): p Partition number (1-4, default 1): (分几个区 直接按下 enter) First sector (2048-167772159, default 2048): (直接按下 enter) Last sector, +sectors or +size {K,M,G} (2048-967772159, default 967772159): (直接按下 enter) Command (m for help): w 注保存并退出 fdisk 工具 输入m后字母对应表 Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition 注：这是删除一个分区的动作； l list known partition types 注：l 是列出分区类型，以供我们设置相应分区的类型； m print this menu 注：m 是列出帮助信息； n add a new partition 注：添加一个分区； o create a new empty DOS partition table p print the partition table 注：p 列出分区表； q quit without saving changes 注：不保存退出； s create a new empty Sun disklabel t change a partition’s system id 注：t 改变分区类型； u change display/entry units v verify the partition table w write table to disk and exit 注：把分区表写入硬盘并退出； x extra functionality (experts only) 注：扩展应用，专家功能； 如果已存在分区，可直接使用 mkfs -t ext4 /dev/sd_1 进行格式化分区；式化好了！之后我们要挂载到 pve 上面，先新建一个挂载目录 mkdir -p /mnt/sd_1输入后无任何提示已执行成功，然后把硬盘挂载信息写入/etc/fstab； echo /dev/sd_1 /mnt/sd_1 ext4 defaults 1 2 &gt;&gt; /etc/fstab 无提示表示已挂载成功； PVE 数据中心，储存，点击添加目录，全部勾选，点击添加后，就可以看到了； 1、创建分区 先查看是否有未分区的硬盘存在 在 shell 中输入 mkdir /mnt/sda 创建 sda 文件夹用来给磁盘挂载 输入 mount /dev/sda1 /mnt/sda 进行挂载 ●开启硬件直通 在 shell 里输入 nano /etc/default/grub 找到：GRUB_CMDLINE_LINUX_DEFAULT=“quiet” 修改为：GRUB_CMDLINE_LINUX_DEFAULT=“quiet intel_iommu=on” 如果是 AMD cpu 修改为：GRUB_CMDLINE_LINUX_DEFAULT=“quiet amd_iommu=on” 保存退出后输入 update-grub ●移除 LVM-Thin，并将空间并入 local 中 释放 LVM-Thin 对应空间 pve/data Shell 中输入代码： lvremove pve/data 扩展 local 对应空间 pve/root Shell 输入代码： lvextend -l +100%FREE -r pve/root 手动删除左列显示的 LVM-Thin 选中 “数据中心” 点选中间列的 “存储” 删除 “LVM-Thin” 编辑 “local”，在 “内容” 中增加原本 LVM-Thin 的 “磁盘映像”、“容器” ●源加速，关闭订阅 1，关闭企业版更新源 mv /etc/apt/sources.list.d/pve-enterprise.list /etc/apt/sources.list.d/pve-enterprise.list.bak 2，更新 debian 国内加速及 pve 非订阅版更新源 nano /etc/apt/sources.list #deb http://ftp.debian.org/debian buster main contrib #deb http://ftp.debian.org/debian buster-updates main contrib security updates #deb http://security.debian.org buster/updates main contrib debian aliyun source deb https://mirrors.aliyun.com/debian buster main contrib non-free deb https://mirrors.aliyun.com/debian buster-updates main contrib non-free deb https://mirrors.aliyun.com/debian-security buster/updates main contrib non-free proxmox source #deb http://download.proxmox.com/debian/pve buster pve-no-subscription #deb https://mirrors.ustc.edu.cn/proxmox/debian/pve buster pve-no-subscription deb http://download.proxmox.wiki/debian/pve buster pve-no-subscription ●关闭订阅提醒 sed -i.bak “s/data.status !== ‘Active’/false/g” /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service ●软路由 img 文件转换 chmod +x img2kvm ./img2kvm &lt;img_name&gt; &lt;vm_id&gt; vm-&lt;vm_id&gt;-disk-1 [storage] ●把镜像转成虚拟磁盘并导入到虚拟机 方法一 使用WinSCP把解压出来的synoboot.img上传到根目录 img磁盘转换，选择Shell，输入 qm importdisk 101 /synoboot.img local-lvm 会看到vm-101-disk-0正在创建，101是虚拟机编号，synoboot.img是刚才上传的引导镜像 方法二 查看上传镜像的目录：点击网页下端的任务选项卡 &gt; 双击最新的“数据拷贝”任务 &gt; “target file”后面就是刚刚上传的镜像文件完整目录： target file: /var/lib/vz/template/iso/syboboot.img 把镜像转成虚拟磁盘并导入到虚拟机：选择“pve”节点 &gt; shell &gt; 输入以下命令并回车： qm importdisk 103 /var/lib/vz/template/iso/syboboot.img local-lvm shell会显示vm-103-disk-0虚拟磁盘创建的进度，最后显示‘Successfully imported disk as 'unused0:local-lvm:vm-103-disk-0’就是添加成功了。 qm importdisk是PVE导入磁盘到虚拟机的工具，后面的参数‘103’是DSM虚拟机的编号，‘/var/lib/vz/template/iso/syboboot.img’是刚才上传群晖引导镜像的完整目录，‘local-lvm’是PVE储存虚拟磁盘的存储空间。 导入成功后在虚拟机的“硬件”选项卡就能看到一个“未使用的磁盘0”。 apt-get update为升级为最新的版本 123apt-get install lshw #安装磁盘直通的工具 ls –l /dev/disk/by-id/ #查看所有硬盘的信息（包含硬盘id）qm set 101 –sata1 /dev/disk/by-id/硬盘id #为直通硬盘的命令 这里讲一下磁盘ID怎么找，你必需选择的是整个硬盘（物理硬盘）而不是分区，比如sda、sdb、sdc对应的id，而不是（sda1、sda2…） 比如：qm set 100 -sata1 /dev/disk/by-id/ata-ST8000VN0022-2EL112_ZA1F8YX4","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"proxmox","slug":"proxmox","permalink":"http://www.formeasy.cc/tags/proxmox/"}],"author":null},{"title":"史上最全安装proxmox教程（基于vmware workstation）","slug":"proxmox/史上最全安装proxmox教程（基于vmware workstation）","date":"2025-03-09T06:24:04.000Z","updated":"2025-06-24T01:07:57.213Z","comments":true,"path":"2025/03/09/proxmox/史上最全安装proxmox教程（基于vmware workstation）/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/proxmox/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%AE%89%E8%A3%85proxmox%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8Evmware%20workstation%EF%BC%89/","excerpt":"","text":"安装Proxmox 使用vmware workstation新建虚拟机 选择install Proxmox VE 选择【ok】 选择【iagree】 选择系统安装的磁盘，可以选择【option】分区，新手不建议。 修改时区，然后选择【Next】 输入密码和邮箱，选择【Next】 设置网络信息，选择【Next】 确认信息，然后选择【install】 安装完成后，选择【reboot】 选择第一个选项引导 输入用户名密码登录 创建一个集群 root@shaonian:~# pvecm create yunwei-clusterCorosync Cluster Engine Authentication key generator.Gathering 1024 bits for key from /dev/urandom.Writing corosync key to /etc/corosync/authkey.Writing corosync config to /etc/pve/corosync.confRestart corosync and cluster filesystemroot@shaonian:~# 查看集群状态 root@shaonian:~# pvecm statusQuorum information------------------Date: Mon May 20 16:23:08 2019Quorum provider: corosync_votequorumNodes: 1Node ID: 0x00000001Ring ID: 1/8Quorate: YesVotequorum information----------------------Expected votes: 1Highest expected: 1Total votes: 1Quorum: 1 Flags: Quorate Membership information---------------------- Nodeid Votes Name0x00000001 1 192.168.108.200 (local)root@shaonian:~# 查看集群节点 root@shaonian:~# pvecm nodesMembership information---------------------- Nodeid Votes Name 1 1 192.168.108.200 (local)root@shaonian:~# 修改apt源 vi /etc/apt/source.listdeb http://mirrors.163.com/debian/ stretch main non-free contribdeb http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.163.com/debian/ stretch main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb http://mirrors.163.com/debian-security/ stretch/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib 更新apt源 root@shaonian:/etc/apt# apt-get -y update 安装net-tools apt-get install net-tools -y 打开网页（注意是https），然后输入用户名密码（用户名root，密码是安装时设置的） 登录后","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"proxmox","slug":"proxmox","permalink":"http://www.formeasy.cc/tags/proxmox/"}],"author":null},{"title":"open-webui+ollama搭建自己的RAG服务","slug":"ollama/open-webui+ollama搭建自己的RAG服务","date":"2025-03-09T02:56:11.000Z","updated":"2025-04-25T01:31:19.898Z","comments":true,"path":"2025/03/09/ollama/open-webui+ollama搭建自己的RAG服务/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/ollama/open-webui+ollama%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84RAG%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"一、RAG是什么 检索增强生成(RAG, Retrieval-Augmented Generation）。该架构巧妙地整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精准的答案，从而显著提升了回答的准确性。 RAG可以简单的总结为数据处理、检索、增强和生成四个阶段： 数据处理阶段：对原始数据进行清洗和处理，并转换为检索模型可用的格式，然后写入到向量数据库中。 检索阶段：将用户的问题输入到检索系统中，并从数据库中搜索相关信息。 增强阶段：将搜索的相关信息进行处理和增强，以便可以更好的理解和使用。 生成阶段：将增强后的信息输入到生成模型中，生成模型根据这些信息生成答案。 RAG方法使得我们不需要为每个特定任务都重新训练一个大模型，仅仅挂上知识库，即可以为模型提供额外的知识，提高回答的准确性。 可扩展性：减少模型大小和训练成本，仅仅更新特定领域的知识，即可提升回答效果 准确性：引用我们自己的知识库，增强人们对模型输出结果的信任 可控性：允许更新和定制知识库 及时性：通过更新我们的知识库，从而使我们可以在不重新训练模型的前提下，保证回答问题的准确性。 安全性：通过在数据库中设置不同的角色和权限，保证数据的保密性。 虽然RAG在一定程度上可以增强其生成的结果，但它仍有一些弊端，如： 检索效果依赖embedding和检索算法 LLM如何利用检索到的信息仍是黑盒 对所有任务都无差别检索K个文本片段，效率不高 二、搭建自己的RAG服务 1.准备自己的知识库文件 常见的文档格式一般为txt、doc、PDF等，这里我将选择最简单的txt文档进行导入，需要注意以下几点： 由于目前LLM均有token的限制，所以在写入向量库时会对我们上传的文档进行分割、切块，将较长的文本切分成较小的文本，每段文本即为一个单位的知识。 当PDF、doc中设计到表格、图片时，需要特殊处理，现有框架如open-webui或者lang chain等在加载该类文档时，仅仅会处理文字部分，图片和表格部分均会忽略，如果图片内容对你来说也非常重要的话，需要自己转换下，如OCR识别或者WPS转换（效果针对与具体文档而言，这里不给评价） 这里，我以一个最简单的txt来作为参考，为了方便演示，内容相对简单且简洁，具体如下： 2.open-webui 前期准备工作 文档准备完成后，写入向量库之前，我们需要先在open-web ui中进行一些前置设置，open-webui的搭建指南可参考“系列文章三”。 首先，我们需要选择选择我们的词向量模型，如m3e,bge等，这里我们拿ollama支持的向量模型，如nomic-embed-text、mxbai-embeded-large来作为示例，模型需要提前在自己的o llama服务中下载，下载方式可参考“系列文章一”。 其次，我们进入我们open-webui的界面，点击“文档”栏，如下： 点击文档之后，再点击右上角的文档设置，会出现如下图的设置页面： 点击红框中的箭头，然后会看到我们当前ollama下载的所有模型，如下图： 如果没有列出模型，说明你的ollama中没有模型，可以结合我的往期文章来看看自己少了哪一步。这里我以mxbai-embeded-large为例，选择好模型之后，按照下方指示进行保存设置。如下图： 注意：这里的块参数表示将你的文档切块的大小以及块和块之间文本的重叠度，相关介绍见末尾扩展知识，这个参数按照自己的需求进行设置。因为上方我提供的知识库文字较少，所以这里的块大小我设置为30，块重叠设置为5。 3.导入知识库并写入向量库 经历了前边几步的配置，我们的所需的基础建设就基本搭建完成了，现在我们便可以导入我们的文档并写入向量数据库。 导入：首先我们在“文档”界面点击“+”，以上传自己的文档，如图： 选择我们要上传的文档即可，如图： 查看：上传成功后，等段时间我们的文档会显示在当前界面里，如图： 注意：你上传完文档后，会等一段时间（耗时根据文档的大小而定）才会显示出来，这段时间是embedding的过程 另外，我们还可以在“系列文章三中”设置的open-webui挂载的宿主机目录下的vector_db里查看是否有新生成的文件，如图： 如上所示，正常写入向量库时，会在这里生成文件，如果没有，先确定自己查看的目录有没有问题，其次再去查看embedding的过程中是否出现了问题。 4.搭建并使用自己的RAG服务 经历如上几步，我们的知识库便挂载进去了，现在我们便可以利用我们的知识库进行聊天。 如上图所示，我们新建个聊天窗口并选择所要用的模型，这里以qwen2:1.5b为例，当不使用知识库时间，大模型回答如下： 当使用知识库时，只需要在输入问题之前输入“#”，然后选择要挂载的文档即可，如： 这里选择我门要使用的知识库，然后再输入问题即可，如下： 可以看到，挂了知识库后，大模型的回答和我们想要的基本一致，如此，我们便可以使用自己的知识库来搭建自己的RAG服务了。 三、扩展知识 1.词向量 在机器学习和自然语言处理（NLP）中，词向量（Embeddings）是一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。如图所示： 它的优势主要包括以下两点： 词向量比文字更适合检索。当我们在数据库检索时，如果数据库存储的是文字，主要通过检索关键词（词法搜索）等方法找到相对匹配的数据，匹配的程度是取决于关键词的数量或者是否完全匹配查询句的；但是词向量中包含了原文本的语义信息，可以通过计算问题与数据库中数据的点积、余弦距离、欧几里得距离等指标，直接获取问题与数据在语义层面上的相似度； 词向量比其它媒介的综合信息能力更强，当传统数据库存储文字、声音、图像、视频等多种媒介时，很难去将上述多种媒介构建起关联与跨模态的查询方法；但是词向量却可以通过多种向量模型将多种数据映射成统一的向量形式。 2.向量数据库 向量数据库是用于高效计算和管理大量向量数据的解决方案。向量数据库是一种专门用于存储和检索向量数据（embedding）的数据库系统。它与传统的基于关系模型的数据库不同，它主要关注的是向量数据的特性和相似性。 在向量数据库中，数据被表示为向量形式，每个向量代表一个数据项。这些向量可以是数字、文本、图像或其他类型的数据。向量数据库使用高效的索引和查询算法来加速向量数据的存储和检索过程。 常见的向量数据库如下： Chroma:一个轻量级、易用的向量数据库，专注于提供高效的近似最近邻搜索（ANN）。它支持多种向量数据类型和索引方法，使得用户可以轻松集成到现有的应用程序中。Chroma特别适用于小型到中型数据集，是初学者和小型项目的理想选择 Pinecone:一个实时、高性能的向量数据库，专为大规模向量集的高效索引和检索而设计。 Weaviate:结合了向量搜索和图数据库特性的多模态语义搜索引擎。它支持多模态数据（文本、图像等）的语义搜索，让用户能够以前所未有的方式探索和理解数据。 Milvus:支持多种索引类型和查询优化策略，提供卓越的查询性能和扩展性。它特别适用于大规模内容检索、图像和视频搜索等场景 Faiss:提供高效的相似度搜索和稠密向量聚类能力，支持多种索引构建方法和查询策略优化。Faiss易于与深度学习框架集成（如PyTorch），使得用户可以轻松将向量检索功能嵌入到深度学习应用中 3.文档切割 在二.2中我们提到了两个概念，一个是“块大小”，一个是“块重叠”。这里我们简单介绍下这两个的由来及作用。 由来：由于单个文档的长度往往会超过模型支持的上下文，导致检索得到的知识太长超出模型的处理能力，因此，在构建向量知识库的过程中，我们往往需要对文档进行分割，将单个文档按长度或者按固定的规则分割成若干个块，然后将每个块转化为词向量，存储到向量数据库中。在检索时，我们会以块作为检索的元单位，也就是每一次检索到 k 个块作为模型可以参考来回答用户问题的知识，这个 k 是我们可以自由设定的。 块大小：每个块包含的字符或 Token （如单词、句子等）的数量 块重叠：两个块之间共享的字符数量，用于保持上下文的连贯性，避免分割丢失上下文信息。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"史上最简单open-webui安装方式","slug":"ollama/史上最简单open-webui安装方式","date":"2025-03-09T02:44:24.000Z","updated":"2025-06-24T01:10:20.123Z","comments":true,"path":"2025/03/09/ollama/史上最简单open-webui安装方式/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/ollama/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95open-webui%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/","excerpt":"","text":"史上最简单open-webui安装方式 一、安装python3.11 这里需要注意，不要用python3.11以上的版本，否则不兼容 1、到python官网下载python3.11 链接：https://www.python.org/ftp/python/3.11.9/python-3.11.9-amd64.exe 2.双击安装包，开始安装，注意勾选[Add python 3.11 to Path]选项！！ 3.选择Customize install选项，建议把安装路径改为其他盘（注意！安装路径中不能有中文） 二、测试python 1、按下win+r打开运行框，输入cmd，回车 2、在命令提示符中输入python 3、自动显示： 3、输入exit()退出python 4、输入pip list，显示： 三、pip换源 在cmd中输入： pip config set global.index-url https://mirrors.aliyun.com/pypi/simple 四、安装open-webui 1、打开cmd，输入： pip install open-webui 等待安装完成~~ 2、等待过程结束后，输入： open-webui serve 不出意外的话，就要出意外了： ERROR: can not connect to &quot;http://hf-com.co&quot; is your computer offline? 五、解决can not connet问题 1、出现以上问题是因为国内访问国外网站信号不好 2、解决方案： 打开cmd，输入： pip install open-webui==0.2.0 3、安装完成后，打开cmd输入： open-webui serve 自动显示： 安装成功后，出现Open-Webui界面： 打开Open-Webui网页 六、升级open-webui 打开cmd，输入： pip install open-webui --upgrade 七、运行ollama+open-webui 1、打开cmd，输入： ollama serve 2、打开另一个cmd，输入： open-webui serve 3、访问链接： open-webui 网站截图： 登陆界面截图： 八、docker安装open-webui 1.如果您的计算机上安装了Ollama，可以使用以下命令： docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.nju.edu.cn/open-webui/open-webui:main 2.如果Ollama在另一台服务器上，请使用以下命令： 连接到另一台服务器上的Ollama时，请将OLLAMA_BASE_URL更改为服务器的URL： docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.nju.edu.cn/open-webui/open-webui:main 要使用Nvidia GPU支持运行Open WebUI，请使用以下命令： docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.nju.edu.cn/open-webui/open-webui:cuda 3.带有捆绑Ollama支持的Open WebUI安装 此安装方法使用一个单独的容器映像，将Open WebUI与Ollama捆绑在一起，通过单个命令实现简化设置。根据您的硬件设置选择适当的命令： 使用GPU支持：通过运行以下命令利用GPU资源 docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.nju.edu.cn/open-webui/open-webui:ollama 4.如果内存&gt;16GB,推荐使用docker，如果内存&lt;=16GB,推荐使用python+open-webui","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"Python虚拟环境创建和使用方法(使用自带的venv模块)","slug":"Python/Python虚拟环境创建和使用方法(使用自带的venv模块)","date":"2025-03-09T02:24:29.000Z","updated":"2025-03-09T02:34:15.088Z","comments":true,"path":"2025/03/09/Python/Python虚拟环境创建和使用方法(使用自带的venv模块)/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/Python/Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95(%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B8%A6%E7%9A%84venv%E6%A8%A1%E5%9D%97)/","excerpt":"","text":"概要 这篇文章主要如何在Python中使用虚拟环境,包括创建、激活、使用、生成requirements.txt文件、卸载包和删除虚拟环境,虚拟环境有助于隔离项目依赖,避免版本冲突,并便于部署,需要的朋友可以参考下 1. 安装虚拟环境工具 从 Python 3.3 开始，Python 自带了 venv 模块，无需额外安装。你可以直接使用它来创建虚拟环境。 2. 创建虚拟环境 2.1 使用 venv 创建虚拟环境 使用以下命令创建虚拟环境。这里我使用了 venv 来创建虚拟环境，并且命名为 venv，你也可以选择任何其他名称。 python -m venv myvenv python -m venv myvenv：这条命令会在当前目录下创建一个名为 myvenv 的虚拟环境和文件夹。 如果你有多个 Python 版本，你可能需要指定 Python 版本，如 python3.8 或 python3，以确保使用正确的版本。 2.2 查看虚拟环境文件 虚拟环境创建后，会在当前目录下生成一个 myvenv 文件夹。里面包含了虚拟环境所需的文件和目录结构： bin：包含虚拟环境的可执行文件（如 python）。 lib：包含虚拟环境的库文件。 include：包含用于编译 C 扩展模块的头文件。 Scripts（Windows）：包含 activate.bat 等脚本。 3. 激活虚拟环境（Windows下） .\\myvenv\\Scripts\\activate 执行后，你会看到命令行前面出现虚拟环境的名称 (myvenv)，表示虚拟环境已经被激活。 激活后，你会看到命令行前面加上 (myvenv)，这表示当前已经进入虚拟环境。 或者进入myvenv目录，运行Scripts\\activate 4. 使用虚拟环境 当虚拟环境激活后，你可以在虚拟环境中安装和管理 Python 包。所有通过 pip 安装的包只会影响当前虚拟环境，而不会影响全局的 Python 安装。 4.1 安装依赖包 你可以在虚拟环境中使用 pip 来安装你需要的依赖包： pip install &lt;package_name&gt; 4.2 查看安装的包 你可以使用 pip list 查看虚拟环境中安装的所有包： 4.3 卸载包 如果你不再需要某个包，可以使用 pip uninstall 卸载它： pip uninstall &lt;package_name&gt; 5. 生成 requirements.txt requirements.txt 文件是记录项目依赖包的常见方式，通常用于分享和复现环境。 5.1 创建 requirements.txt 你可以使用 pip freeze 命令生成当前虚拟环境的依赖包列表，并将其保存到 requirements.txt 文件中： pip freeze &gt; requirements.txt 该命令会将虚拟环境中所有已安装的包及其版本记录到 requirements.txt 文件中。 5.2 安装 requirements.txt 中的依赖 当其他人获取到你的项目代码时，他们可以使用 requirements.txt 安装项目所需的所有依赖： pip install -r requirements.txt 提示： 可以通过在命令行中指定镜像源来安装 requirements.txt 中的依赖包。例如，使用清华大学的镜像源，你可以这样运行： pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 6. 退出虚拟环境 当你完成工作后，可以通过以下命令退出虚拟环境： deactivate 退出后，你的命令行会回到系统的默认 Python 环境。 7. 删除虚拟环境 如果你不再需要某个虚拟环境，可以删除它。只需要删除包含虚拟环境的文件夹即可（通常是 venv 文件夹）。 8. 使用虚拟环境的好处 隔离依赖：每个项目都有自己的依赖包，避免版本冲突。 干净的工作环境：不同项目之间的库版本不会互相影响。 便于部署：通过 requirements.txt 文件，你可以轻松地为其他开发者或生产环境部署项目。 9.Python IDLE Shell 使用虚拟环境 Python IDLE Shell 可以使用虚拟环境，但设置起来稍微有点不同，因为 IDLE 默认启动的是系统 Python 环境。要在 IDLE 中使用虚拟环境，你需要手动指定虚拟环境中的 Python 解释器。 myenv\\Scripts\\python.exe -m idlelib.idle 这样，IDLE 将会启动，并使用虚拟环境中的 Python 解释器。你可以在 IDLE 中执行代码，并确保它使用的是虚拟环境中安装的依赖，而不是全局 Python 环境中的库。 注意：在IDLE没有关闭之前，不能安装其他包。因为显示IDLE的时候，命令还在执行。 检查 IDLE 是否使用虚拟环境 在 IDLE 中，你可以通过运行以下命令来检查当前 Python 环境是否是虚拟环境： import sys print(sys.executable)","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":null},{"title":"python的venv环境迁移","slug":"Python/python的venv环境迁移","date":"2025-03-09T02:07:06.000Z","updated":"2025-03-09T02:35:01.305Z","comments":true,"path":"2025/03/09/Python/python的venv环境迁移/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/Python/python%E7%9A%84venv%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB/","excerpt":"","text":"前言 使用Python内置的venv模块管理python环境，怎么实现环境迁移。 方案一 拷贝老环境下的Lib目录 1、在新设备上新建与原始环境相同python版本的venv环境 1python -m venv my_venv 2、将原始环境.venv 下的Lib文件拷贝到新环境中 1cp -r old/venv/Lib new/my_venv/ 3、然后就可以在新的环境下激活使用了。 方案二 直接复制虚拟环境文件夹 1、将整个虚拟环境文件夹（通常命名为 venv 或其他名称）从一台电脑复制到另一台电脑。 2、修改 pyvenv.cfg 文件中的 home 配置为新电脑上 Python 的安装路径。 注意：这种方法迁移确保迁移前后环境的python版本尽量一致，和架构必须一致。 使用此种方式迁移到新机器后，确保解压后虚拟环境bin目录下python软连接文件指向本地的python路径是正确的。否则会报文件不存在： bad interpreter: No such file or directory 方案三 导出和导入依赖项 在原始电脑上，使用以下命令导出项目的依赖项到一个文件中： 1pip freeze &gt; requirements.txt 将生成的 requirements.txt 文件复制到新电脑。 在新电脑上，使用相同版本的 Python 创建一个虚拟环境。 运行以下命令，将依赖项从 requirements.txt 安装到新的虚拟环境 1pip install -r requirements.txt 如果新机器中没有互联网访问权限，则可以通过以下步骤完成: 在第一台计算机的venv中运行pip wheel -w wheels -r packages.txt.这将为您所需的所有软件包下载并构建*.whl软件包.请注意，这是假设两台机器的操作系统和体系结构都相似！ 将wheel文件复制到新机器上. 在新计算机上创建一个新的virtualenv并输入它. 通过轮子在新的venv中安装软件包:pip install -r packages.txt (这个文件需要自己创建反，把所有whl文件列出） 提示： 可以通过在命令行中指定镜像源来安装 requirements.txt 中的依赖包。例如，使用清华大学的镜像源，你可以这样运行： pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 方案四 用Docker镜像 创建一个 Docker 镜像，将 Python 环境和项目一起打包。 在新电脑上运行该 Docker 镜像，即可获得相同的 Python 环境。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"}],"author":null},{"title":"Ollama + Open WebUIChatbox本地Windows部署","slug":"ollama/Ollama + Open WebUIChatbox本地Windows部署","date":"2025-03-09T01:52:04.000Z","updated":"2025-04-25T01:33:22.129Z","comments":true,"path":"2025/03/09/ollama/Ollama + Open WebUIChatbox本地Windows部署/","link":"","permalink":"http://www.formeasy.cc/2025/03/09/ollama/Ollama%20+%20Open%20WebUIChatbox%E6%9C%AC%E5%9C%B0Windows%E9%83%A8%E7%BD%B2/","excerpt":"","text":"一、安装Ollama 访问 Ollama 下载页面。 选择（Windows、Linux 或 macOS）并下载相应的版本。 按指引流程安装 Ollama。 验证 win+r打开cmd命令行工具，输入 ollama --version 二、下载deepseek-r1模型 访问 deepseek-r1模型下载页面。 根据硬件条件选择模型，复制命令在cmd执行 3.安装完成即可在cmd开始使用（下次运行模型仍在cmd中执行上述命令，例ollama run deepseek-r1:1.5b） 当前即可本地使用deeseek-r1，以下为添加对话UI，可选 三、安装open-webui（可选） 准备 安装Python 3.11或更高版本。 安装Node.js和npm 备注：安装完成后pip、npm记得先设置镜像源 1. 打开Git Bash或终端，输入以下命令克隆open-webui项目到本地： 1git clone https://github.com/open-webui/open-webui ps: 如果未安装Git，可直接下载压缩包 或 2.安装依赖并构建项目 cmd下进入项目目录。 执行npm install命令安装所有依赖。 执行npm run build命令构建项目。 ps: 构建项目可能出现内存溢出问题：# FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - J，cmd执行setx NODE_OPTIONS --max_old_space_size=10240后重新执行build命令 3、启动open-webui 进入项目目录下的backend目录，双击执行start_windows.bat脚本启动服务 浏览器输入http://localhost:8080 进入Open WebUI 界面 提示注册用户，输入注册进入 4、配置ollama连接 open-webui页面，点击右上角头像进入设置-管理员设置-外部连接，点击ollama连接地址右上的设置图标，将ollama默认连接地址localhost修改为127.0.0.1，点击刷新按钮测试连接（连接失败无法加载到ollama安装的本地模型） 可以选择模型开始对话了 四、安装Chatbox（可选） 访问 Chatbox 下载页面。 选择（Windows、Linux 或 macOS）并下载相应的版本。 按指引流程安装 Chatbox。 打开Chatbox，选择本地模型，即可开始对话","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"解决Docker Desktop错误：安装kubernetes时一直在StartingKubernetes failed to start","slug":"Docker/解决Docker Desktop错误：安装kubernetes时一直在StartingKubernetes failed to start","date":"2025-02-13T08:00:23.000Z","updated":"2025-04-25T00:46:49.158Z","comments":true,"path":"2025/02/13/Docker/解决Docker Desktop错误：安装kubernetes时一直在StartingKubernetes failed to start/","link":"","permalink":"http://www.formeasy.cc/2025/02/13/Docker/%E8%A7%A3%E5%86%B3Docker%20Desktop%E9%94%99%E8%AF%AF%EF%BC%9A%E5%AE%89%E8%A3%85kubernetes%E6%97%B6%E4%B8%80%E7%9B%B4%E5%9C%A8StartingKubernetes%20failed%20to%20start/","excerpt":"","text":"安装kubernetes时一直在StartingKubernetes 错误原因：由于墙的问题，导致拉取国外的K8s镜像失败。 解决办法1：科学上网 解决办法2： 步骤1：克隆k8s-for-docker-desktop代码 步骤2：选中自己的kubernetes 版本 下载zip包 步骤3：PowerShell运行load_images.ps1文件 在 Mac 上执行如下脚本 1./load_images.sh 在Windows上，使用 PowerShell 1.\\load_images.ps1 说明: 如果因为安全策略无法执行 PowerShell 脚本，请在 “以管理员身份运行” 的 PowerShell 中执行 Set-ExecutionPolicy RemoteSigned 命令。 如果需要，可以通过修改 images.properties 文件自行加载你自己需要的镜像 步骤4：重启docker","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}],"author":null},{"title":"如何在本地部署Ollama大模型并使用Python进行简单访问","slug":"ollama/如何在本地部署Ollama大模型并使用Python进行简单访问","date":"2025-02-12T02:18:37.000Z","updated":"2025-04-25T01:34:06.968Z","comments":true,"path":"2025/02/12/ollama/如何在本地部署Ollama大模型并使用Python进行简单访问/","link":"","permalink":"http://www.formeasy.cc/2025/02/12/ollama/%E5%A6%82%E4%BD%95%E5%9C%A8%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B9%B6%E4%BD%BF%E7%94%A8Python%E8%BF%9B%E8%A1%8C%E7%AE%80%E5%8D%95%E8%AE%BF%E9%97%AE/","excerpt":"","text":"如何在本地部署Ollama大模型并使用Python进行简单访问 简介 Ollama是一个强大的大型语言模型平台，它允许用户轻松地下载、安装和运行各种大型语言模型。在本文中，我将指导你如何在你的本地机器上部署Ollama，并展示如何使用Python进行简单的API调用以访问这些模型。 步骤1：下载和安装Ollama 首先，访问Ollama官网下载Ollama。安装过程非常简单，只需遵循安装向导的指示即可。默认情况下，Ollama会安装在系统的默认路径下。 更改模型保存路径 如果你想更改模型的保存路径，可以通过设置系统环境变量来实现。创建一个名为OLLAMA_MODELS的环境变量，并将其值设置为你希望保存模型的路径。 步骤2：验证Ollama安装 安装完成后，打开命令提示符（cmd）并输入ollama来验证Ollama是否安装成功。如果安装成功，你将看到Ollama的启动界面。 步骤3：选择并下载模型 接下来，访问Ollama模型库来浏览和选择你需要的模型。在这个例子中，我选择了llama3.2模型。复制模型页面上提供的代码ollama run llama3.2，并将其粘贴到cmd中运行。Ollama将开始下载模型文件，并在下载完成后自动运行。你可以通过输入/bye来退出对话。 步骤4：使用Python访问本地Ollama 为了使用Python访问本地运行的Ollama模型，首先需要启动Ollama的服务器模式。在cmd中输入ollama serve并运行。Ollama服务器将启动，并在日志中显示访问路径，通常类似于http://localhost:11434/api/chat。 Python访问代码示例 以下是一个Python代码示例，展示了如何使用requests库向Ollama服务器发送请求，并获取响应。 12345678910111213141516171819202122232425262728293031import requestsimport json# API的URLurl = &#x27;http://localhost:11434/api/chat&#x27;input_text = &quot;穿山甲（汤浸透，取甲锉碎，同热灰铛内慢火炒令黄色）五钱 红色曲（炒） 川乌（一枚，灰火中带焦炮）各二钱半&quot;# 要发送的数据data = &#123; &quot;model&quot;: &quot;llama3.2&quot;, &quot;messages&quot;: [ &#123;&quot;role&quot;:&quot;system&quot;,&quot;content&quot;: &quot;你是一个中药药材提取工具，只知道药材名字，你的工作是从字符串中提取药材名字，并用英文逗号隔开。&quot;&#125;, &#123;&quot;role&quot;: &quot;user&quot;,&quot;content&quot;: &quot; &quot;&#125; ], &quot;stream&quot;: False&#125;# 找到role为user的messagefor message in data[&quot;messages&quot;]: if message[&quot;role&quot;] == &quot;user&quot;: # 将输入文本添加到content的开头 message[&quot;content&quot;] = input_text# 将字典转换为JSON格式的字符串json_data = json.dumps(data)# 发送POST请求response = requests.post(url, data=json_data, headers=&#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;)# 打印响应内容print(response.text) 这段代码首先设置了API的URL和输入文本，然后定义了要发送的数据结构，包括模型名称、消息列表和是否流式传输。在消息列表中，我们特别关注角色为user的消息，并将其内容设置为我们的输入文本。然后，我们将数据结构转换为JSON格式，并使用requests库发送POST请求。最后，我们打印出服务器的响应内容。 通过以上步骤，你可以轻松地在本地部署Ollama大模型，并使用Python进行简单的API调用。这为开发基于大型语言模型的应用提供了一个强大的平台。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"使用Docker搭建Ollama DeepSeek和Open Web UI的步骤","slug":"Docker/使用Docker搭建Ollama DeepSeek和Open Web UI的步骤","date":"2025-02-12T02:12:15.000Z","updated":"2025-03-09T01:59:01.192Z","comments":true,"path":"2025/02/12/Docker/使用Docker搭建Ollama DeepSeek和Open Web UI的步骤/","link":"","permalink":"http://www.formeasy.cc/2025/02/12/Docker/%E4%BD%BF%E7%94%A8Docker%E6%90%AD%E5%BB%BAOllama%20DeepSeek%E5%92%8COpen%20Web%20UI%E7%9A%84%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"一、准备工作 安装Docker： 确保你的系统中已经安装了Docker。如果尚未安装，可以从Docker官方网站下载并安装适合你操作系统的Docker版本。 拉取镜像： 从Docker Hub或其他镜像仓库中拉取Ollama、DeepSeek（通常作为Ollama的一个模型存在）和Open Web UI的镜像。 对于不同操作系统，重启命令可能有所不同。 例如，在Ubuntu/Debian系统上，可以使用systemctl daemon-reload和systemctl restart ollama命令；在CentOS系统上，则可能需要使用sudo yum update、sudo yum install lsof、stop ollama、lsof -i :11434、kill 和ollama serve等命令组合。 二、部署Ollama 拉取Ollama镜像： 1docker pull ollama/ollama 或者，如果你需要特定版本的Ollama，可以使用带版本的标签，如ollama/ollama:0.3.0。 运行Ollama容器： 1docker run -d -v /path/to/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama -d：后台运行容器。 -v：将本地文件夹挂载到容器内，用于存储模型和数据。 -p：映射端口，方便外部访问。 –name：指定容器名称。 启动DeepSeek模型（在Ollama容器中）： 1docker exec -it ollama ollama run deepseek-r1:1.5b 或者，根据你下载的DeepSeek模型版本进行调整。 三、部署Open Web UI 拉取Open Web UI镜像： 1docker pull ghcr.io/open-webui/open-webui:main 运行Open Web UI容器： 1docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=http://localhost:11434 -v /path/to/open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main -p：将容器的8080端口映射到宿主机的3000端口。 -e：配置Ollama服务的基础URL地址。 -v：挂载本地目录到容器，用于存储Open Web UI的数据。 –name：指定容器名称。 –restart always：容器异常退出后自动重启。 注意：OLLAMA_BASE_URL应该设置为Ollama服务的实际访问地址。如果你的Ollama服务部署在远程服务器上，那么这里应该填写远程服务器的IP地址或域名。如果部署在本机，可以使用localhost或127.0.0.1。但是，在Docker容器中访问宿主机时，可能需要使用宿主机的实际IP地址或host.docker.internal（在某些Docker版本中支持）。 四、访问和使用 访问Open Web UI： 打开浏览器，访问http://localhost:3000（或你设置的其他端口）。 你应该能够看到Open Web UI的界面，并通过它与DeepSeek模型进行交互。 使用Open Web UI： 在Open Web UI界面中，选择DeepSeek模型。 输入你想让模型回答的问题或文本。 点击“生成”或类似的按钮，查看模型的输出结果。 注意：也可以使用ChatBox桌面客户端访问 下载ChatBox(https://chatboxai.app/zh) 在设置中，设置API域名为 http://localhost:11434 也可以查看模型的输出结果 五、注意事项 硬件配置： Ollama和DeepSeek对硬件配置有一定的要求。确保你的服务器或计算机有足够的CPU、内存和存储空间来运行这些服务。 网络配置： 如果你的Ollama服务部署在远程服务器上，确保你的服务器能够访问外部网络（特别是如果你需要从外部下载模型或更新）。 同时，确保你的Open Web UI能够访问Ollama服务的基础URL地址。 安全性： 在生产环境中部署时，请注意安全性问题。例如，使用HTTPS来保护你的Web界面和数据传输；限制对Ollama服务的访问权限；定期更新和备份你的数据和模型等。 性能优化： 根据你的实际需求和硬件配置，调整Ollama和DeepSeek的运行参数以优化性能。例如，调整模型的批量大小、并发请求数等。 Docker Compose： 为了简化部署和管理过程，你可以使用Docker Compose来一次性启动整个应用栈。编写一个docker-compose.yml文件来定义Ollama和Open Web UI的服务和配置，然后使用docker-compose up命令来启动所有服务。 通过以上步骤，你应该能够成功使用Docker搭建Ollama、DeepSeek和Open Web UI，并通过Open Web UI与DeepSeek模型进行交互。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"},{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"大模型ollama命令详解大全","slug":"ollama/大模型ollama命令详解大全","date":"2025-02-12T02:12:15.000Z","updated":"2025-03-09T01:59:22.720Z","comments":true,"path":"2025/02/12/ollama/大模型ollama命令详解大全/","link":"","permalink":"http://www.formeasy.cc/2025/02/12/ollama/%E5%A4%A7%E6%A8%A1%E5%9E%8Bollama%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%E5%A4%A7%E5%85%A8/","excerpt":"","text":"一、启动与停止服务 启动Ollama服务 ollama serve：启动Ollama服务器，以便运行模型和处理请求。首次启动可能会生成ssh私钥文件，并提示服务端口状态。如果服务已在运行中，可以通过netstat -tulpn | grep 11434命令进行确认。 重启Ollama服务 对于不同操作系统，重启命令可能有所不同。例如，在Ubuntu/Debian系统上，可以使用systemctl daemon-reload和systemctl restart ollama命令；在CentOS系统上，则可能需要使用sudo yum update、sudo yum install lsof、stop ollama、lsof -i :11434、kill 和ollama serve等命令组合。 二、模型管理 创建模型 ollama create [Modelfile路径]：使用包含模型信息的Modelfile来创建一个新模型。 显示模型信息 ollama show：显示特定模型的详细信息，如模型名称、版本等。 列出模型 ollama list：列出本地所有可用的模型。 从注册表拉取模型 ollama pull [模型名称]：从模型注册表中拉取一个模型到本地使用。 推送模型到注册表 ollama push [模型名称]：将本地模型推送到模型注册表中，以便他人或其他系统使用。 复制模型 ollama cp [原模型名称] [新模型名称]：复制一个模型到另一个位置或给定名称的地方。 删除模型 ollama rm [模型名称]：删除一个已安装的模型。 三、运行模型 ollama run [模型名称]：运行一个已安装的模型，执行某些任务。可以根据需要指定模型的参数和配置。 四、会话管理 Ollama还提供了一些与会话管理相关的命令，这些命令可以帮助更好地控制和管理与模型的交互： 加载会话或模型 /load &lt;model&gt;：加载一个特定的模型或会话。可以指定一个模型的名称或路径来加载它。 保存会话 /save &lt;model&gt;：保存当前的会话状态或模型。可以将当前会话或模型的配置保存为一个文件，以便以后使用。 清除会话上下文 /clear：清除会话上下文。这将删除当前会话中的所有历史记录或对话内容。 退出会话 /bye：退出会话。这个命令将结束当前与模型的对话，并退出程序。 五、其他命令 查看帮助信息 ollama help [命令名称] 或 ollama --help：获取有关Ollama任何命令的帮助信息。如果指定了命令名称，则显示该命令的详细帮助信息。 查看版本信息 ollama version：显示当前Ollama工具的版本信息。 设置会话参数和配置 /set：用于设置会话参数和配置。例如，设置消息格式、启用或禁用历史记录等。具体参数包括/set system&lt;string&gt;、/set template&lt;string&gt;、/set history、/set nohistory、/set wordwrap、/set nowordwrap、/set format json、/set noformat、/set verbose和/set quiet等。 显示键盘快捷键 /?shortcuts 或 /help shortcuts：显示键盘快捷键的帮助信息，帮助更快速地进行操作。 六、示例：安装qwen 1、安装Ollama 打开终端或命令提示符。 输入以下命令以安装Ollama： 1curl -fsSL https://ollama.com/install.sh | sh 该命令会从Ollama的官方网站下载并安装Ollama。 2、下载并运行qwen2.5模型 安装完成后，可以使用以下命令来拉取（下载）qwen2.5模型： 1ollama pull qwen2.5-coder:7b 这里以qwen2.5-coder的7b版本为例。如果想下载其他版本的qwen2.5模型，请将7b替换为相应的版本号。 下载完成后，可以使用以下命令来运行qwen2.5模型： 1ollama run qwen2.5-coder:7b 该命令会启动Ollama服务，并加载qwen2.5-coder:7b模型。之后，可以通过Ollama提供的API接口与模型进行交互。 3、测试qwen2.5模型 可以使用curl命令或Python脚本来测试qwen2.5模型是否正常工作。以下是一个使用curl命令测试qwen2.5模型的示例： 123curl http://localhost:11434/v1/chat/completions \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123; &quot;model&quot;: &quot;qwen2.5-coder:7b&quot;,&quot;stream&quot;:true, &quot;messages&quot;: [ &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好&quot; &#125; ] &#125;&#x27; 该命令会向Ollama服务发送一个包含用户消息的请求，并等待模型返回回答。如果模型正常工作，应该能够看到模型返回的“你好”对应的回答。 请注意，随着Ollama的更新和发展，可能会有新的命令和功能被添加或修改。因此，建议定期查看Ollama的官方文档或GitHub仓库以获取最新的命令和功能信息。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"}],"author":null},{"title":"Windows11下安装Docker","slug":"Docker/Windows11下安装Docker","date":"2025-02-11T08:16:39.000Z","updated":"2025-04-25T00:49:05.304Z","comments":true,"path":"2025/02/11/Docker/Windows11下安装Docker/","link":"","permalink":"http://www.formeasy.cc/2025/02/11/Docker/Windows11%E4%B8%8B%E5%AE%89%E8%A3%85Docker/","excerpt":"","text":"一、准备工作 先下载以下资源，暂时不要安装： Docker安装包 Wsl2安装包 二、开始安装 1.打开主板BIOS的虚拟化选项，可以在任务管理器中确实是否已经打开 2.勾上虚拟机平台所有选项（建议完成这一步骤重启） 3.用管理员身份打开PowerShell，执行下面命令启动wsl 1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 4.执行下面命令启动虚拟机给功能 1dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 5.安装之前下载的安装包【wsl_update_x64.msi】（建议完成这一步骤重启） 6.将WSL2设置为默认版本 1wsl --set-default-version 2 7.安装docker安装包【Docker Desktop Installer.exe】 三、docker配置 1.修改docker默认镜像下载目录 Windows11 Docker镜像存储路径更改（非C盘路径） 基于WSL2安装docker后，在使用过程中会发现大量的docker镜像文件，使系统C盘容量激增，对电脑后续使用造成不便，所以需要在安装的时候，手动修改docker的镜像地址，使得镜像文件保存到另外的非系统盘中。 最新的windows提供了新的虚拟化技术（WSL/WSL2），所以设置页面不能镜像的存储位置进行修改了。 修改方案 退出Docker Desktop step 01 cmd 查看WSL应用 1wsl --list -v 确保所有wsl应用都停止 step 02 导出docker镜像文件 12wsl --export docker-desktop-data &quot;D:\\docker\\docker-desktop-data.tar&quot;wsl --export docker-desktop &quot;D:\\docker\\docker-desktop.tar&quot; step 03 注销docker-desktop-data、docker-desktop 12wsl --unregister docker-desktop-datawsl --unregister docker-desktop step 04 指定文件夹重新导入 12wsl --import docker-desktop-data D:\\docker\\data &quot;D:\\docker\\docker-desktop-data.tar&quot; --version 2wsl --import docker-desktop D:\\docker\\desktop &quot;D:\\docker\\docker-desktop.tar&quot; --version 2 step 05 重启Docker 2.配置docker阿里镜像仓库 &quot;registry-mirrors&quot;: [ &quot;https://r32otmli.mirror.aliyuncs.com&quot; ] 四、安装后图片展示 本文作者：jory 本文链接：https://www.cnblogs.com/jory/p/18375482 版权声明：本作品采用知识共享署名-非商业性使用-禁止演绎 2.5 中国大陆许可协议进行许可。","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}],"author":"jory"},{"title":"Qt中手动配置MSVC2017环境","slug":"Qt/Qt中手动配置MSVC2017环境","date":"2025-02-06T01:31:11.000Z","updated":"2025-04-24T06:25:05.821Z","comments":true,"path":"2025/02/06/Qt/Qt中手动配置MSVC2017环境/","link":"","permalink":"http://www.formeasy.cc/2025/02/06/Qt/Qt%E4%B8%AD%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AEMSVC2017%E7%8E%AF%E5%A2%83/","excerpt":"","text":"1. 安装MSVC2017 首先安装VS2017（过程略） 2. 安装Qt 5.14.2 下载Qt 5.14.2，点击安装包，勾选MSVC 2017 64-bit、MinGW 7.3.0 64-bit，点击下一步进行安装。 3. 通过Visual Studio安装MSVC2017编译器以及window10 SDK工具 1）下载Visual studio 2022安装包：下载地址 勾选C桌面开发以及Windows 10 SDK、MSVC 2017 C，然后下一步开始安装。 2）配置Windows10调试工具包： 在应用程序中找到Windows kit 右键更改，再点击Repair，将图中的选项勾选 配置成功后退出，并重启qtcreator。 3）在qtcreator中配置msvc2017编译器： 按照上面步骤安装完成后，进入到qtcreator配置Kit界面，会发现新增加了编译器： 点击右边添加按钮，再点击MSVC，选择C++： 新建一个MSVC，依次配置相关参数，下图中红色方框中参数为： 64位系统 SDK版本号 -vcvars_ver= MSVC版本号 此处为x64 10.0.20348.0 -vcvars_ver=14.16 以上版本号全部可以在第二步的安装工具中查到 配置完成后点击应用，然后选择构建套件(Kit)选项界面： 点击下图中的序号1，然后在第二个红色方框中选择上一步配置好的MSVC编译器，最后点击应用，MSVC2017手动配置完成。 MSVC2017手动配置完成后，重新构建项目，选择MSVC2017 debug运行即可.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"}],"author":null},{"title":"QT5构建套件检测不到MSVC2017解决方法","slug":"Qt/QT5构建套件检测不到MSVC2017解决方法","date":"2025-02-06T01:24:38.000Z","updated":"2025-04-24T06:25:41.823Z","comments":true,"path":"2025/02/06/Qt/QT5构建套件检测不到MSVC2017解决方法/","link":"","permalink":"http://www.formeasy.cc/2025/02/06/Qt/QT5%E6%9E%84%E5%BB%BA%E5%A5%97%E4%BB%B6%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0MSVC2017%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"前言 记录一下 QT5构建套件检测不到 MSVC2017 解决方法 。Qt Creator + MSVC开发环境搭建（Qt Creator 集成工具 + MSVC编译） 一、本地环境 电脑操作系统：Win11 Qt 版本：Qt 5.14.2 二、现象 如下图所示，MSVC2017 32bit 和 MSVC2017 64bit 的前面都有一个黄色的感叹号 将鼠标移至黄色感叹号的位置，可以看到警告信息为：工具包中没有设置编译器 三、解决办法 1、打开 Visual Studio Installer 2、点击修改 3、选择单个组件，勾选 MSVC v141-VS 2017 C++ x64/x86 Spectre 缓解库(v14.16) 和 MSVC v141-VS2017 C++ x64/x86生成工具(v14.16)，选择修改 4、安装 msvc 调试器 下载地址：https://download.microsoft.com/download/4/2/2/42245968-6A79-4DA7-A5FB-08C0AD0AE661/windowssdk/winsdksetup.exe 直接全部下一步就好了，等待安装完成…（此过程不能断网） 5、打开 Qt Creator，选择 工具-&gt;选项 ①、添加 msvc2017 32bit 编译器 Kit -&gt; 编译器 -&gt; 添加 -&gt; MSVC -&gt; C++ 名称：Microsoft Visual C++ Compiler MSVC2017_32 初始化：D:\\VS2022\\VC\\Auxiliary\\Build\\vcvarsall.bat（这个和你的安装路径有关系） 和 x86 ABI：自定义、x86、windows、msvc2017、pe、32bit 点击 Apply。 继续添加 ②、添加 msvc2017 64bit 编译器 Kit -&gt; 编译器 -&gt; 添加 名称：Microsoft Visual C++ Compiler MSVC2017_64 初始化：D:\\VS2022\\VC\\Auxiliary\\Build\\vcvarsall.bat（这个和你的安装路径有关系） 和 x86_amd64 ABI：自定义、x86、windows、msvc2017、pe、64bit 点击 Apply 6、点开 Debuggers 确认一下存在下图红框内这两个 7、配置 kits 内 MSVC2017 32bit 和 64bit 点 MSVC2017 32 bit，修改 C++ 和 Debugger，再点击 Apply 点 MSVC2017 64 bit，修改 C++ 和 Debugger，再点击 Apply 8、创建项目 创建的时候，记得选 MSVC 2017 编译运行成功","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"}],"author":null},{"title":"Windows搭建Docker+K8s","slug":"kubernetes/Windows搭建Docker+K8s","date":"2025-01-24T08:18:15.000Z","updated":"2025-05-31T09:40:57.831Z","comments":true,"path":"2025/01/24/kubernetes/Windows搭建Docker+K8s/","link":"","permalink":"http://www.formeasy.cc/2025/01/24/kubernetes/Windows%E6%90%AD%E5%BB%BADocker+K8s/","excerpt":"","text":"修改 Docker Desktop 的默认安装路径（Optional） 确保 C:\\Program Files 路径中没有 Docker 文件夹 在想要的安装路径中新建 Docker 文件夹 管理员模式打开 Windows Terminal 创建目录链接，其中 F:\\Docker 为想要安装的位置 1mklink /j &quot;C:\\Program Files\\Docker&quot; &quot;F:\\Docker&quot; 下载并运行安装包 安装完成后，可以发现 C 盘占用没有发生变化 安装Docker Desktop 从官网下载，然后直接安装即可，过程很简单，一直Next就行。 有一点需要注意就是要看好对应的版本，因为后边涉及到版本的问题。 https://www.docker.com/products/docker-desktop 安装完成，双击图标，打开桌面程序，就可以看到左下角有一个绿色的鲸鱼标识，注意，这个时候只有一个： 中间的打马赛克的默认也是没有的，这是我已经安装好的。 修改本地镜像的存储位置（Optional） 原存储路径：C:\\Users\\GCH\\AppData\\Local\\Docker\\wsl 1、停止运行中的容器 查询是否有运行中的容器 1docker ps 2、右键图标，点击 Quit Docker Desktop，退出 Docker Desktop Docker Desktop 安装了两个特殊用途的内部 Linux 发行版: docker-desktop 和 docker-desktop-data（两者都不能用于一般开发） 第一个（docker-desktop）用于运行 Docker engine 第二个（docker-desktop-data）用于存储 containers 和 images 12# 查询 Docker Desktop 运行状态wsl -l -v 3、导出，注销，然后导入 只迁移 docker-desktop-data 即可，若已有的 images 较大，这个过程会耗点时间。 wsl --export docker-desktop-data F:\\docker-desktop-data.tar wsl --unregister docker-desktop-data wsl --import docker-desktop-data &quot;F:\\\\docker_images&quot; &quot;F:\\\\docker-desktop-data.tar&quot; --version 2 4、重新启动 Docker Desktop 5、pull 一个镜像，测试一下 没问题的话，就可以把 docker-desktop-data.tar 压缩文件删掉了 配置镜像加速 1234&quot;https://registry.docker-cn.com&quot;,&quot;http://hub-mirror.c.163.com&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://xxxx.mirror.aliyuncs.com&quot; //阿里云镜像加速，登录自己的阿里云账号获取 安装好Docker服务和配置镜像加速以后，K8s默认是关闭状态的，需要我们手动打开： 请注意！ 这个时候不要轻易的打开它，除非你有VPN，且网速比较好。 因为开启K8s，主要是启动对应的服务，大概有七八个服务，镜像是很麻烦的，特别是没有配置本地加速的情况下（加速可以用阿里云或者中科大的地址，百度即可）。所以需要从远程仓库把镜像拉下来，过程很慢，即便我用VPN了，也一个小时未成功，无奈只能重装，换了第二种方案。 安装K8s服务 上边直接手动启动的方式已经放弃，换成了阿里的本地镜像： https://github.com/AliyunContainerService/k8s-for-docker-desktop 直接clone代码，切换到当前Docker Desktop对应版本的分支，然后根据他们的README操作即可，比较简单，镜像拉取完成后，就可以看到多了一些镜像： 注意Docker Desktop的k8s版本要求 Docker -&gt; About Docker Desktop 阿里云README操作在PowerShell，都是基于克隆下来的目录进行 步骤 克隆代码 1git clone https://github.com/AliyunContainerService/k8s-for-docker-desktop.git 在Windows上，使用 PowerShell,进来克隆的代码目录 1.\\load_images.ps1 说明: 如果因为安全策略无法执行 PowerShell 脚本，请在 “以管理员身份运行” 的 PowerShell 中执行 Set-ExecutionPolicy RemoteSigned 命令。 如果需要，可以通过修改 images.properties 文件自行加载你自己需要的镜像 开启 Kubernetes，并等待 Kubernetes 开始运行 开启 Kubernetes，并等待 Kubernetes 开始运行 配置 Kubernetes 控制台 部署 Kubernetes dashboard 1kubectl apply -f kubernetes-dashboard.yaml 检查 kubernetes-dashboard 应用状态 1kubectl get pod -n kubernetes-dashboard 开启 API Server 访问代理 1kubectl proxy 通过如下 URL 访问 Kubernetes dashboard http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 配置控制台访问令牌 授权kube-system默认服务账号 1kubectl apply -f kube-system-default.yaml 对于Windows环境 123$TOKEN=((kubectl -n kube-system describe secret default | Select-String &quot;token:&quot;) -split &quot; +&quot;)[1]kubectl config set-credentials docker-desktop --token=&quot;$&#123;TOKEN&#125;&quot;echo $TOKEN 登录dashboard的时候 选择 令牌 输入上文控制台输出的内容 或者选择 Kubeconfig 文件,路径如下： 1Win: %UserProfile%\\.kube\\config 点击登陆，进入Kubernetes Dashboard 参考：https://www.bilibili.com/video/BV1m5411J7Q6?p=1&amp;vd_source=10332ffe931de86faa42900544751c8c","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":null},{"title":"K8s的资源组件介绍","slug":"kubernetes/K8s的资源组件介绍","date":"2025-01-24T07:53:46.000Z","updated":"2025-05-31T09:40:16.020Z","comments":true,"path":"2025/01/24/kubernetes/K8s的资源组件介绍/","link":"","permalink":"http://www.formeasy.cc/2025/01/24/kubernetes/K8s%E7%9A%84%E8%B5%84%E6%BA%90%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"引言 这篇重点介绍K8s的资源组件和相关配置使用。 1. Node &amp; Pod Node: 是 Pod 真正运行的主机，可以是物理机，也可以是虚拟机。为了管理 Pod，每个 Node 节点上至少要运行 container runtime（比如 docker, rkt, containerd）、kubelet 和 kube-proxy 服务。 Pod: 是一组紧密关联的容器集合（也可以是单个容器），它们共享 IPC（进程间通信） ， Network namespace 和 文件存储（需挂载到容器），是 Kubernetes 调度的基本单位。 Node和Pod的关系如下图所示： 上图中的Node中共有4个Pod，分别为： 2. Namespaces 是对一组资源和对象的抽象集合，相当于给k8s系统内部的对象划分一些命名空间。常见的 pods, services, replication controllers 和 deployments 等都是属于某一个 namespace 的（默认是 default）。 创建命名空间的配置示例： 1234apiVersion: v1kind: Namespace # 表示要创建的资源类型为命名空间metadata: name: test # 命名空间名称为test 命名空间的使用则是通过Pod或Service中的metadata.namespace字段来声明。 3. Service 是应用服务的抽象，为应用提供负载均衡和服务发现。它通过将多个 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。 每个 Service 都会自动分配一个 cluster IP（仅在集群内部可访问的虚拟地址）和 DNS 名，其他容器可以通过该地址或 DNS 来访问服务，而不需要了解后端容器的运行。 Service模型如下所示： 创建Service的配置： 12345678910111213kind: Service # 创建的资源类型为服务apiVersion: v1metadata: # 资源的元数据 name: &#123;&#123;name&#125;&#125; # 服务名称 namespace: &#123;&#123;namespace&#125;&#125; # 所属namespacespec: # 指定服务的规格，包括选择器和端口 selector: # 用于指定服务所选择的Pod的标签 k8s-app: &#123;&#123;name&#125;&#125; # 选择具有标签k8s-app且值为占位符&#123;&#123;name&#125;&#125;的Pod ports: # 指定服务的端口映射规则 - name: serviceport # 定义了一个名为serviceport的端口映射，将容器内的8081端口映射到服务的端口8081上 protocol: TCP port: 8081 # 服务对外开放的访问端口 targetPort: 8081 # 容器内端口 4. Ingress 为进入集群的请求提供路由规则的集合，类似于反向代理Nginx的作用，它可以按规则将请求路由到具体的Service上。 Ingress模型如下图示例： 创建Ingress的配置规则： 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingress # 创建的资源类型为Ingressmetadata: name: testspec: # 指定Ingress的规格，包括规则（rules) rules: - host: foo.bar.com # 请求的主机名，会用于Request中的Host头过滤 http: # 使用http协议 paths: # 请求路径配置 - backend: # 指定要请求的后端服务 serviceName: s1 # 后端服务名称 servicePort: 80 # 后端服务端口 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 5. Deployment 用于无状态 Pod 部署声明，这些Pod对部署顺序没有要求（如nginx)，可以定义 Pod 的副本数量，调度策略等，是最常用的一种部署方式，一般将 Pod 的定义内置在 Deployment 中。 Deployment的配置规则示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960apiVersion: apps/v1kind: Deployment # 创建的资源类型为Deploymentmetadata: name: &#123;&#123;name&#125;&#125; namespace: &#123;&#123;namespace&#125;&#125;spec: # Deployment的规格，包括副本数（replicas）、选择器（selector）、模板（template）等。 replicas: 2 # 创建2个pod副本 selector: # 选择Pod的条件配置 matchLabels: k8s-app: &#123;&#123;name&#125;&#125; # 选择具有标签k8s-app且值为占位符&#123;&#123;name&#125;&#125;的Pod template: # 用于定义Pod的模板 metadata: labels: # 设置Pod的标签 k8s-app: &#123;&#123;name&#125;&#125; spec: terminationGracePeriodSeconds: 10 # Pod的优雅终止期限为10秒 nodeSelector: k8s-meeting: true # 按需调整 volumes: # 定义了两个存储卷log和conf - name: log hostPath: # 使用主机磁盘路径/var/log/quanshi/&#123;&#123;name&#125;&#125;进行挂载， 类型为目录或创建目录 path: /var/log/quanshi/&#123;&#123;name&#125;&#125; type: DirectoryOrCreate - name: conf configMap: # 使用名称为&#123;&#123;name&#125;&#125;的ConfigMap配置数据进行挂载 name: &#123;&#123;name&#125;&#125; containers: # 容器定义，名称和镜像均使用占位符表示 - name: &#123;&#123;name&#125;&#125; # 容器名称 image: &#123;&#123;image&#125;&#125; # 容器使用的镜像名称 env: # 注入到系统的环境变量，程序能读到，每个Pod可以不同 - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP resources: limits: # 指定容器可以使用的最大资源空间 cpu: 2000m # 2个CPU核心 memory: 4000Mi # 4000Mi=4GB requests: # 表示容器部署需要的最小资源 cpu: 100m # 占用一个CPU核心的1/10, 1C=1000m memory: 150Mi # 150MB securityContext: # 容器特权配置，有一些特殊的场景需要配置，例如syslog privileged: false volumeMounts: # 指定容器中的挂载卷和挂载路径 - name: log # 卷log（上面有指定）挂载到容器的/var/log/quanshi目录下 mountPath: /var/log/quanshi - name: conf # 卷conf（上面有指定）挂载到容器的/mnt/conf目录下 mountPath: /mnt/conf 6. StatefulSet 为了解决有状态服务的部署问题，能做到有序部署，有序扩展，即 Pod 是有顺序的。在部署或者扩展的时候要依据定义的顺序依次依序进行（即从 0 到 N-1，在下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态）。 典型场景有： 数据库部署（如MySQL），每个Pod都有一个稳定的网络标识和唯一的持久化存储卷，可以确保数据的持久性和一致性； 消息队列（如Kafka）每个Pod都有一个唯一的网络标识和持久化存储卷，确保消息的可靠性和持久化存储； 分布式缓存（如Redis)，每个Pod都有一个唯一的网络标识和持久化存储卷，可以确保缓存数据的可靠性和一致性。 创建StatefulSet的配置示例： 123456789101112131415161718192021222324252627282930apiVersion: v1kind: Service # 先定义一个Service，供下文的StatefulSet使用metadata: name: nginxspec: ports: - port: 80 name: web clusterIP: None # None表示不分配集群IP selector: # 选择具有标签app: nginx的Pod与该Service关联 app: nginx---apiVersion: apps/v1kind: StatefulSet # 创建的资源类型为StatefulSetmetadata: name: webspec: serviceName: &quot;nginx&quot; # 指定StatefulSet关联的Service名称为nginx replicas: 2 # StatefulSet的副本数为2，即创建2个Pod。 selector: matchLabels: # 通过标签选择器来选择要关联的Pod。 app: nginx template: # StatefulSet创建Pod时的模板 metadata: labels: # 设置Pod的标签为app: nginx app: nginx spec: containers: # 定义Pod中的容器名称和镜像名称 - name: nginx image: nginx 7. DaemonSet 保证在每台 Node 上都运行一个容器实例，供主机上的所有Pod共用。常用来部署一些集群的日志、监控或者其他系统管理应用，如syslog-ng, filebeat等。 12apiVersion: apps/v1kind: DaemonSet 8. ConfigMap 用于保存配置数据的键值对，可以用来保存单个属性，也可以用来保存配置文件。 典型使用场景： 配置注入：将应用程序的配置信息注入到容器中。通过将ConfigMap挂载到容器的文件系统中，应用程序可以读取ConfigMap中的配置数据并应用到运行时环境中。 动态配置更新：当应用程序的配置信息发生更改时，可以通过更新ConfigMap来实现动态配置更新。这样，无需重新构建和重新部署应用程序，就可以更新应用程序的配置。 环境变量注入：通过将ConfigMap的值设置为环境变量，可以将配置信息传递给应用程序作为环境变量。 共享配置：多个应用程序可以共享同一个ConfigMap，以便它们可以使用相同的配置信息。 创建ConfigMap的配置示例： 123456789101112131415161718apiVersion: v1kind: ConfigMap # 创建的资源类型为ConfigMapmetadata: name: special-config # ConfigMap的名称为special-config namespace: default # ConfigMap所属的命名空间为defaultdata: special.how: very # 定义了一个键值对，键为special.how，值为very special.type: charm # 定义了一个键值对，键为special.type，值为charm。 game.properties: | # 定义了一个键值对，键为game.properties，值为多行文本。 enemies=aliens # game.properties内部定义一个配置项，键为enemies，值为aliens lives=3 secret.code.allowed=true secret.code.lives=30 ui.properties: | # 定义了一个键值对，键为ui.properties，值为多行文本。 color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice 9. HPA 全称为Horizontal Pod Autoscaling，可以根据 CPU 使用率或应用自定义 metrics 自动扩展 Pod 数量。 CA（Cluster AutoScaler）用于提供Node级扩容，支持更高效的扩缩容。 CA可以和 HPA配合使用：","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"}],"author":null},{"title":"ROS2简介与基本使用","slug":"ROS/ROS2简介与基本使用","date":"2025-01-24T02:57:48.000Z","updated":"2025-04-25T01:27:40.075Z","comments":true,"path":"2025/01/24/ROS/ROS2简介与基本使用/","link":"","permalink":"http://www.formeasy.cc/2025/01/24/ROS/ROS2%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1. ROS2 介绍与安装 1.1 ROS2 的历史 ROS（Robot Operating System，机器人操作系统），但 ROS 本身并不是一个操作系统，而是可以安装在现在已有的操作系统上（Linux、Windows、Mac）的软件库和工具集 ROS 出生于 2007 年，ROS 的出现解决了机器人各个组件之间的通信问题，同时基于 ROS 完善的通信机制，越来越多的优秀的机器人算法集成到了 ROS 中来 现在的 ROS 功能已经变得非常的丰富和强大。但随着对 ROS 功能上要求越来越多，一些原始的架构和设计不能够满足目前的使用需求，这也是 ROS2 出现的原因 1.1.1 ROS 的作用 做一个机器人需要涉及到多个部分，而且这些部分之间还要进行通信，如果想要整个机器人可以跑起来，那么必须要有一个东西将下面的几个部分合理的连接到一起，这个东西就是 ROS 感知部分：激光雷达、深度相机、IMU、里程计、碰撞感知、建图 决策部分：路径规划（navigation）算法、定位算法 控制部分：轮子驱动 1.1.2 为什么需要 ROS2 2007 年 ROS 开发人员设计和制作 ROS 时，当时只想着简化机器人的开发，并没有想到过今天那么多的功能需求，比如商业化要求的稳定性、生命周期管理、多机协同、数据加密等 ROS 发展的后几年里，机器人对 ROS 的功能要求越来越多，ROS 开发人员只能在原有的 ROS 上修修补补。随着 ROS 不断的添加新功能，ROS 变得越来越臃肿，祖传代码也越来越多。ROS 开发人员发现在原有的 ROS 架构上修修补补十分消耗头发，于是 ROS 官方重新设计制作了 ROS2 1.1.3 ROS2 版本对照表 ROS2 是在 ROS 的基础上设计开发的第二代机器人操作系统，可简化机器人开发任务，加速机器人落地的软件库和工具集 1.2 ROS 和 ROS2 对比 1.2.1 ROS 存在的问题 ROS 的设计目标是简化机器人的开发，ROS 为此设计了一整套通信机制（话题、服务、参数、动作） 通过这些通信机制，ROS 实现了将机器人的各个组件给的连接起来，在设计这套通信机制的时候就设计了一个叫做 ROS Master 的东西，所有节点（可以理解为某一个组件，比如：激光雷达）的通信建立必须经过这个主节点 一旦 ROS Master 主节点挂掉后，就会造成整个系统通信的异常，ROS 的不稳定这个问题，如果是想基于 ROS 做商业化机器人（比如无人驾驶汽车），就会造成非常严重的后果 ROS 还存在以下问题：1、通信基于 TCP 实现，实时性差、系统开销大；2、对 Python3 支持不友好，需要重新编译；3、消息机制不兼容；4、没有加密机制、安全性不高 网络传输可靠性对比 ROS1 是基于 TCP/IP 构建的，TCP/IP 很难在无线通信中传输数据，因为中断可能会导致回退、重传和延迟 ROS2 中的 DDS 使用 UDP 传送数据，不会尝试重新传输数据，相反，DDS 决定在不可靠的条件下何时以及如何重新传输，DDS 引入了服务质量 (QoS) 来公开这些设置，以优化可用带宽和延迟 1.2.2 ROS 与 ROS2 架构对比 OS 层 ROS：只支持 linux 平台 ROS2：支持 windows、mac 甚至是嵌入式 RTOS 平台 中间件层（中间件就是介于某两个或者多个节点中间的组件，提供多个节点间通信用的） 去中心化 master：ROS 和 ROS2 中间件不同之处在于，ROS2 取消了 master 节点，去中心化后，各个节点之间可以通过 DDS 的节点相互发现，各个节点都是平等的，且可以 1 对 1、1 对 n、n 对 n 进行互相通信 不造通信的轮子：通信直接更换为 DDS 进行实现，采用 DDS 通信，使得 ROS2 的实时性、可靠性和连续性上都有了增强 应用层 Python2 到 Python3 的支持 编译系统的改进（catkin 到 ament） C++ 标准更新到 C++11 可以使用相同 API 的进程间和进程内通信 什么是 DDS？ DDS（Data Distribution Service，数据分发服务），是 OMG（Object Management Group，对象管理组织）发布的分布式通信规范/协议，采用订阅发布模型，以中间件的形式提供通信服务，并提供 QoS（Quality of Service）策略，保障数据实时、高效、灵活的分发 DDS 协议大致流程是多对多的单向数据交互，通信模型为分布式结构，没有中心节点，同一个数据空间任何两个节点之间都能直接通信，DDS 采用以数据为中心的发布-订阅模型 DCPS（Data-Centric Publish-Subscribe） 分布式实时通信-DDS 概述 1.3 安装 ROS2 一键安装 ROS2 1wget http://fishros.com/install -O fishros &amp;&amp; . fishros 卸载 12sudo apt remove ros-galactic-*sudo apt autoremove 安装位置查询 12cd /opt/ros/galactic(根据安装版本替换)/ls 1.4 ROS2 初体验 启动乌龟模拟器节点 1ros2 run turtlesim turtlesim_node 启动乌龟遥控器节点 1ros2 run turtlesim turtle_teleop_key 1.5 ROS2 系统架构 1.5.1 操作系统层 ROS2 本身就是基于 Linux、Windows 或者 macOS 系统建立的，驱动计算机硬件、底层网络通信等实现都是交由操作系统来实现的 1.5.2 DDS实现层 DDS实 现层其实就是对不同常见的 DDS 接口进行再次的封装，让其保持统一性，为 DDS 抽象层提供统一的 API 1.5.3 抽象 DDS 层（RMW） 这一层将 DDS 实现层进一步的封装，使得 DDS 更容易使用：原因在于 DDS 需要大量的设置和配置（分区，主题名称，发现模式，消息创建,…），这些设置都是在 ROS2 的抽象层中完成的 1.5.4 ROS2 客户端库（RCL） RCL（ROS Client Library，ROS 客户端库），其实就是 ROS 的一种 API，提供了对 ROS 话题、服务、参数、Action 等接口，不同语言对应不同 RCL，但基本功能都是相同的 Python 语言提供了 rclpy 来操作 ROS2 的节点话题服务等 C++ 则使用 rclcpp 提供 API 操作 ROS2 的节点话题和服务等 GUI 和 CLI GUI（Graphical User Interface，图形用户界面），Windows 是就是可视化的，通过鼠标点击按钮等图形化交互完成任务 CLI（Command-Line Interface，命令行界面），终端（黑框框）就是命令行界面 什么是 API？ API（ Application Programming Interface，应用程序编程接口），比如你写了一个库，里面有很多函数，如果别人要使用这个库，但并不知道每个函数内部是怎么实现的。使用的人需要看你的文档或者注释才知道这个函数的入口参数和返回值或者这个函数是用来做什么的。对于使用者来说来说，你的这些函数就是 API API 在不同语言中的表现形式不同，在 C/C++ 表现为头文件，在 Python 中表现为 Python 文件 1.5.5 应用层 应用层就是写代码以及 ROS2 开发的各种常用的机器人相关开发工具所在的层 1.6 中间件 DDS 架构 1.6.1 什么是中间件 中间件就是介于某两个或者多个节点中间的组件，就是提供多个节点中间通信用的 中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源 中间件位于客户机/服务器的操作系统之上，管理计算机资源和网络通讯，是连接两个独立应用程序或独立系统的软件 ROS1 的中间件是 ROS 组织自己基于 TCP/UDP 机制建立的 ROS2 采用了第三方的 DDS 作为中间件，将DDS服务接口进行了一层抽象，保证了上层应用层调用接口的统一性。基于 DDS 的互相发现协议，ROS2 终于干掉了 ROS1 中的 Master 节点 1.6.2 DDS 和 ROS2 架构 ROS2 为每家 DDS 供应商都开发了对应的 DDS_Interface 即 DDS 接口层，然后通过 DDS Abstract 抽象层来统一 DDS 的 API 1.6.3 DDS 通信模型 DDS 通信模型：可以定义话题的数据结构（类似于 ROS2 中的接口类型） Pos：一个编号 id 的车的位置 x,y DDS 的参与者（Participant）通过发布和订阅主题数据进行通信 DDS 的应用层通过 DDS 进行数据订阅发布，DDS 通过传输层进行数据的收发 1.6.4 DDS 优缺点 优势 发布/订阅模型 简单解耦，可以轻松实现系统解耦 性能 在发布/订阅模式中，与请求/回复模式相比，延迟更低，吞吐量更高 远程参与者的自动发现 此机制是 DDS 的主要功能之一。通信是匿名的、解耦的，开发者不必担心远程参与者的本地化 丰富的 Qos 参数集 允许调整通信的各个方面：可靠性、持久性、冗余、寿命、传输设置、资源 实时发布/订阅协议 (RTPS) 该协议几乎可以通过任何传输实现，允许在 UDP、TCP、共享内存和用户传输中使用 DDS，并实现不同 DDS 实现之间的真正互操作性 劣势 API 复杂，DDS 的灵活性是以复杂性为代价的 系统开销相对较大 社区支持问题，ROS2 近两年来使用 DDS 后社区表现还是不错的 使用 DDS 的理由 DDS 已经应用在军事、潜艇各个领域，稳定性、实时性经过实际检验 使用 DDS 需要维护的代码要少得多，可以让 ROS2 开发人员腾出手专注机器人开发 DDS 有定义好的行为和规范并且有完善的文档 DDS 提供了推荐的用例和软件 API，有较好的语言支持 2. ROS2 第一个节点 2.1 使用 CMakeList.txt 编译 ROS2 的节点 2.1.1 动态链接库 程序编译一般需要经预处理、编译、汇编和链接几个步骤 在实际应用中，有些公共代码需要反复使用，就把这些代码编译成为“库”文件 静态库：在链接步骤中，链接器将从库文件取得所需的代码，复制到生成的可执行文件中，这种库称为静态（链接）库，其特点是可执行文件中包含了库代码的一份完整拷贝，缺点是被多次使用就会多份冗余拷贝 动态库：还有一种库，就是程序在开始运行后调用库函数时才被载入，这种库独立于现有的程序，其本身不可执行，但包含着程序需要调用的一些函数，这种库称为动态（链接）库（Dynamic Link Library） 在 widows 平台下，静态链接库是 .lib 文件，动态库文件是 .dll 文件。在 linux 平台下，静态链接库是 .a 文件，动态链接库是 .so 文件 2.1.2 编译 ROS2 的 C++ 节点 创建工作空间并编写节点 打开终端，创建 d2lros2/chapt2/basic 工作空间目录并用 VSCode 打开 12mkdir -p d2lros2/chapt2/basiccode d2lros2 1234567891011121314// 在 basic 目录下创建 first_ros2_node.cpp#include &quot;rclcpp/rclcpp.hpp&quot;#include &lt;iostream&gt;int main(int argc, char **argv) &#123; // 调用 rclcpp 的初始化函数 rclcpp::init(argc, argv); std::cout &lt;&lt; &quot;Hello World!&quot; &lt;&lt; std::endl; // 调用 rclcpp 的循环运行创建的 first_node 节点 rclcpp::spin(std::make_shared&lt;rclcpp::Node&gt;(&quot;first_node&quot;)); return 0;&#125; 1234567# 在 basic 目录下创建 CMakeList.txtcmake_minimum_required(VERSION 3.16)project(first_node)find_package(rclcpp REQUIRED)add_executable(first_node first_ros2_node.cpp)target_link_libraries(first_node rclcpp::rclcpp) 编译与运行 123456cd ~/d2lros2/chapt2/basicmkdir buildcd buildcmake ..make./first_node 1Hello World! 2.2 CMake 依赖查找流程 find_package 查找路径对应的环境变量如下 12345&lt;package&gt;_DIRCMAKE_PREFIX_PATHCMAKE_FRAMEWORK_PATHCMAKE_APPBUNDLE_PATHPATH 打开终端，输入指令 echo $PATH 12echo $PATH/opt/ros/galactic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin PATH 中的路径如果以 bin 或 sbin 结尾，则自动回退到上一级目录，接着检查这些目录下的 123&lt;prefix&gt;/(lib/&lt;arch&gt;|lib|share)/cmake/&lt;name&gt;*/ (U)&lt;prefix&gt;/(lib/&lt;arch&gt;|lib|share)/&lt;name&gt;*/ (U)&lt;prefix&gt;/(lib/&lt;arch&gt;|lib|share)/&lt;name&gt;*/(cmake|CMake)/ (U) cmake 找到这些目录后，会开始依次找 Config.cmake 或 Find.cmake 文件，找到后即可执行该文件并生成相关链接信息 打开 /opt/ros/humble/share/rclcpp/cmake 会发现 rclcppConfig.cmake 就在其中 2.3 ROS2 节点介绍 ROS2 中每一个节点也是只负责一个单独的模块化的功能（比如一个节点负责控制车轮转动、一个节点负责从激光雷达获取数据、一个节点负责处理激光雷达的数据、一个节点负责定位等等） ROS2 一共有四种通信方式实现节点之间的交互 话题 - topics 服务 - services 动作 - Action 参数 - parameters ROS2 节点常用指令 1234567891011121314# 启动功能包下的节点，格式：ros2 run &lt;package_name&gt; &lt;executable_name&gt;ros2 run turtlesim turtlesim_node# 查看节点列表ros2 node list# 查看节点信息ros2 node info &lt;node_name&gt;# 重映射节点名称ros2 run turtlesim turtlesim_node --ros-args --remap __node:=my_turtle# 运行节点时设置参数ros2 run example_parameters_rclcpp parameters_basic --ros-args -p rcl_log_level:=10 2.4 ROS2 工作空间和功能包 一个工作空间下可以有多个功能包，一个功能包可以有多个节点存在 工作空间是包含若干个功能包的目录，一开始大家把工作空间理解成一个文件夹就行了。这个文件夹包含下有 src，所以一般新建一个工作空间的操作就像下面一样 12cd ~/d2lros2/chapt2/mkdir -p chapt2_ws/src 功能包可以理解为存放节点的地方，ROS2 中功能包根据编译方式的不同分为三种类型 ament_python，适用于 python 程序 cmake，适用于 C++ ament_cmake，适用于 C++ 程序，是 cmake 的增强版 功能包获取的两种方式 1. 安装获取 1sudo apt install ros-&lt;version&gt;-package_name 2. 手动编译获取 需要下载源码然后进行编译生成相关文件 一般能安装的功能包都是作者编译好程序将可执行文件上传到仓库中，然后才能够通过 apt 进行安装，如果作者还没来得及测试上传，或者忘记了测试上传，就会找不到对应的包，这时候就需要手动编译安装了 手动编译之后，需要手动 source 工作空间的 install 目录 与功能包相关的指令 ros2 pkg 创建功能包 1ros2 pkg create &lt;package-name&gt; --build-type &#123;cmake,ament_cmake,ament_python&#125; --dependencies &lt;依赖名字&gt; 列出可执行文件 12ros2 pkg executables # 列出所有ros2 pkg executables turtlesim # 列出 turtlesim 功能包的所有可执行文件 列出所有的包 1ros2 pkg list 输出某个包所在路径的前缀 12# ros2 pkg prefix &lt;package-name&gt;ros2 pkg prefix turtlesim 列出包的清单描述文件 123# 每个功能包都有一个标配的 manifest.xml 文件，用于记录这个包的名字、构建工具、编译信息、拥有者和作用等信息# 通过这个信息，就可以自动为该功能包安装依赖，构建时确定编译顺序等ros2 pkg xml turtlesim 2.5 ROS2 构建工具之 colcon 什么是 colcon colcon 其实是一个功能包构建工具，用来编译代码的，ROS2 默认是没有安装 colcon 的，colcon 相当于 ROS1 中的 catkin 工具 安装 colcon 1sudo apt-get install python3-colcon-common-extensions 编译测试 12cd ~/d2lros2/chapt2/mkdir colcon_test_ws &amp;&amp; cd colcon_test_ws 12git clone https://github.com/ros2/examples src/examples -b galacticcolcon build 构建完成后，在 src 同级目录应该会看到 build、install 和 log 目录 build 目录存储的是中间文件，对于每个包，将创建一个子文件夹，在其中调用例如CMake install 目录是每个软件包将安装到的位置，默认情况下，每个包都将安装到单独的子目录中 log 目录包含有关每个 colcon 调用的各种日志信息 运行测试 1234# 运行一个订者节点cd ~/d2lros2/chapt2/colcon_test_wssource install/setup.bashros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 123# 打开一个新的终端，先source，再运行一个发行者节点source install/setup.bashros2 run examples_rclcpp_minimal_publisher publisher_member_function 总结 1234567891011# 只编译一个包colcon build --packages-select YOUR_PKG_NAME# 不编译测试单元colcon build --packages-select YOUR_PKG_NAME --cmake-args -DBUILD_TESTING=0# 运行编译的包的测试colcon test# 允许通过更改 src 下的部分文件来改变 installcolcon build --symlink-install 2.6 使用 RCLCPP 编写节点 创建工作空间 12cd ~/d2lros2/chapt2/mkdir -p chapt2_ws/src/ 创建 example_cpp 功能包 12345cd chapt2_ws/src# pkg create 是创建包的意思# --build-type 用来指定该包的编译类型，一共有三个可选项 ament_python、ament_cmake、cmake# --dependencies 指的是这个功能包的依赖，这里是 ros2 的 C++ 客户端接口 rclcppros2 pkg create example_cpp --build-type ament_cmake --dependencies rclcpp 12345678910tree # 查看 src 下的目录结构.└── example_cpp ├── CMakeLists.txt ├── include │ └── example_cpp ├── package.xml └── src 4 directories, 2 files 创建节点 在 example_cpp/src 下创建一个 node_01.cpp 文件 12345678910111213#include &quot;rclcpp/rclcpp.hpp&quot;int main(int argc, char **argv) &#123; /* 初始化rclcpp */ rclcpp::init(argc, argv); /*产生一个node_01的节点*/ auto node = std::make_shared&lt;rclcpp::Node&gt;(&quot;node_01&quot;); // 打印一句自我介绍 RCLCPP_INFO(node-&gt;get_logger(), &quot;node_01节点已经启动.&quot;); /* 运行节点，并检测退出信号 Ctrl+C*/ rclcpp::spin(node); /* 停止运行 */ rclcpp::shutdown(); return 0;&#125; 修改 CMakeLists.txt 123456789# 在 CMakeLists.txt 末尾添加下述代码add_executable(node_01 src/node_01.cpp)ament_target_dependencies(node_01 rclcpp)install(TARGETS node_01 DESTINATION lib/$&#123;PROJECT_NAME&#125; ) 编译运行 12cd ~/d2lros2/chapt2/chapt2_wscolcon build 12source install/setup.bashros2 run example_cpp node_01 1[INFO] [1711876723.907901312] [node_01]: node_01 start 12ros2 node list # 当节点运行起来后，查看现有的节点/node_01 2.7 面向对象编程思想 计算机编程三种编程思想 面向过程编程思想。缩写：POP 面向对象编程思想。缩写：OOP 函数式思想。缩写：FP 2.7.1 三种编程思想对比 用三种思想把大象装进冰箱 面向过程的思想 把大象塞进去 关上冰箱门 面向对象的思想 把冰箱理解为一个对象，就可以研究你家冰箱由哪些部分（指令装置等）组成，冰箱能干什么（制冷、调温等）？对象的行为其实是对其属性的操作：对象 = 属性 + 行为 采用 OOP 的方法把大象装进冰箱 调用：冰箱-&gt;打开门(行为) 调用：冰箱-&gt;装东西(行为) 调用：冰箱-&gt;关闭门(行为) 函数式编程 定义关进（冰箱，大象）函数 实现函数：关门(放入(开门(冰箱)，大象)) 2.7.2 面向对象编程 类与对象（抽象与具体） 通过调用容声（具体冰箱品牌）冰箱的开门、装东西和关门三个行为来把大象装进冰箱，这时可以把容声冰箱（具体的）称之为一个对象，而冰箱（抽象的）就称为一个类 在 ROS2 中的 DDS 是有很多厂家的，ROS2 为了匹配不同厂家的 DDS，就设计除了 DDS 抽象层，而每一个具体的 DDS 厂家，可以称之为一个 DDS 的对象，是具体的 封装、继承与多态 2.8 使用面向对象方式编写 ROS2 节点 在 d2lros2/chapt2/chapt2_ws/src/example_cpp/src 下新建 node_02.cpp 1234567891011121314151617181920212223242526#include &quot;rclcpp/rclcpp.hpp&quot;// 创建一个类节点，名字叫做Node03,继承自Node.class Node03 : public rclcpp::Node &#123;public: // 构造函数,有一个参数为节点名称 Node03(std::string name) : Node(name) &#123; // 打印一句 RCLCPP_INFO(this-&gt;get_logger(), &quot;大家好，我是%s.&quot;,name.c_str()); &#125;private:&#125;;int main(int argc, char **argv) &#123; rclcpp::init(argc, argv); /*产生一个node_03的节点*/ auto node = std::make_shared&lt;Node03&gt;(&quot;node_03&quot;); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0;&#125; 修改 CMakeLists.txt 123456789# 在 CMakeLists.txt 末尾添加下述代码add_executable(node_02 src/node_02.cpp)ament_target_dependencies(node_02 rclcpp)install(TARGETS node_02 DESTINATION lib/$&#123;PROJECT_NAME&#125;) 编译运行 123colcon build --packages-select example_cppsource install/setup.bashros2 run example_cpp node_02 2.9 colcon 使用进阶 2.9.1 构建系统与构建工具 两者的区分点在于针对的对象不同，构建系统之针对一个单独的包进行构建，而构建工具重点在于按照依赖关系依次调用构建系统完成一系列功能包的构建 ROS 中用到的构建系统：CMake、ament_cmake、catkin、Python setuptools ROS 中用到的构建工具：colcon、catkin_make、catkin_make_isolated、catkin_tools colcon 作为构建工具，通过调用 CMake、Python setuptools 等构建系统完成构建 常见构建系统 CMake：是一个跨平台构建系统生成器。项目使用独立于平台的文件指定其生成过程。用户通过使用 CMake 为其平台上的本机工具生成构建系统来构建项目 Python setuptools：Python 包的打包常用工具。Python 包使用文件来描述依赖项，以及如何构建和安装内容。在 ROS2 中，功能包可以是“普通” Python 包，而在 ROS1 中，任何 Python 功能都是从 CMake 文件触发 setup.py 进行打包 catkin：基于 CMake，并提供了一组方便的函数，使编写 CMake 包更容易。它自动生成 CMake 配置文件以及 pkg 配置文件。它还提供了注册不同类型测试的函数 常见构建工具 catkin_make：该工具仅调用 CMake 一次，并使用 CMake 的函数在单个上下文中处理所有包。虽然这是一种有效的方法，因为所有包中的所有目标都可以并行化，但它具有明显的缺点：由于所有函数名称、目标和测试都共享一个命名空间，并且规模更大，这很容易导致冲突 colcon：colcon 是一个命令行工具，用于改进构建，测试和使用多个软件包的工作流程。它自动化了流程，处理了订购并设置了使用软件包的环境 ament_tools：由用于构建 ROS2 包的独立 Python3 包提供。它是为引导 ROS2 项目而开发的，因此仅针对 Python3，并且可以在 Linux，MacOS 和 Windows 上运行 2.9.2 colcon 构建进阶之 build 参数解析 构建指令 123--packages-select，仅生成单个包（或选定的包）--packages-up-to，构建选定的包，包括其依赖项--packages-above，整个工作区，然后对其中一个包进行了更改。此指令将重构此包以及（递归地）依赖于此包的所有包 指定构建后安装的目录 可以通过 --build-base 参数和 --install-base，指定构建目录和安装目录 合并构建目录 –merge-install，作为所有软件包的安装前缀，而不是安装基中的软件包特定子目录 --install-base 如果没有此选项，每个包都将提供自己的环境变量路径，从而导致非常长的环境变量值 使用此选项时，添加到环境变量的大多数路径将相同，从而导致环境变量值更短 符号链接安装 启用 --symlink-install 后将不会把文件拷贝到 install 目录，而是通过创建符号链接的方式 错误时继续安装 启用 --continue-on-error，当发生错误的时候继续进行编译 CMake 参数 –cmake-args，将任意参数传递给 CMake。与其他选项匹配的参数必须以空格为前缀 控制构建线程 –executor EXECUTOR 用于处理所有作业的执行程序。默认值是根据所有可用执行程序扩展的优先级选择的。要查看完整列表，请调用 colcon extensions colcon_core.executor --verbose sequential [colcon-core]：一次处理一个包 parallel [colcon-parallel-executor]：处理多个作业平行 –parallel-workers NUMBER 要并行处理的最大作业数。默认值为 os.cpu_count() 给出的逻辑 CPU 内核数 开启构建日志 使用 --log-level 可以设置日志级别，比如 --log-level info 2.10 ROS2 节点发现与多机通信 ROS2 用于通讯的默认中间件是 DDS，在 DDS 中，不同逻辑网络共享物理网络的主要机制称为域 (Domain) ID 同一域上的 ROS2 节点可以自由地相互发现并发送消息，而不同域上的 ROS2 节点则不能 所有 ROS2 节点默认使用域 ID 为 0 为避免在同一网络上运行 ROS2 的不同计算机组之间互相干扰，应为每组设置不同的域 ID 选择域 ID（短版本） 只需选择一个介于 0 和 101 之间的安全的域 ID (包括 0 和 101) 选择域 ID（长版本） DDS 使用域 ID 计算将用于发现和通讯的 UDP 端口，网络中 UDP 端口是无符号 16 位整型，因此可以分配的最大端口号是 65535 特定平台的约束： 为了实现最大的兼容性，在选择域账号时应遵循一些特定于平台的附加约束。特别是，最好避免在操作系统的临时端口范围中分配域 ID，避免 ROS2 节点使用的端口与计算机上的其他网络服务之间可能的冲突 参与者约束 对于计算机上运行的每个 ROS2 进程，将创建一个 DDS “participant”。由于每个 DDS 参与者占用计算机上的两个端口，因此在一台计算机上运行 120 个以上的 ROS2 进程可能会溢出到其他域 ID 或临时端口 域ID到UDP端口号计算器 http://dev.ros2.fishros.com/doc/Concepts/About-Domain-ID.html#domain-id-to-udp-port-calculator","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"ROS","slug":"ROS","permalink":"http://www.formeasy.cc/tags/ROS/"}],"author":null},{"title":"c++之组合、继承、聚合及依赖","slug":"C/c++之组合、继承、聚合及依赖","date":"2025-01-23T07:34:52.000Z","updated":"2025-01-23T09:08:32.272Z","comments":true,"path":"2025/01/23/C/c++之组合、继承、聚合及依赖/","link":"","permalink":"http://www.formeasy.cc/2025/01/23/C/c++%E4%B9%8B%E7%BB%84%E5%90%88%E3%80%81%E7%BB%A7%E6%89%BF%E3%80%81%E8%81%9A%E5%90%88%E5%8F%8A%E4%BE%9D%E8%B5%96/","excerpt":"","text":"在学习c++的过程中相信大家对这几个概念都不陌生。 c++中一些常用的设计模式都是由这几种特性组合而成。本文再从整体对这个概念或者特性进行简要的介绍。 组合 c++中类之间的一种关系叫做&quot;has-a&quot;的关系。这种关系表示的是一个类中包含另一类的对象，体现了“有一个”的关系。这个被包含的类一般以实例对象的形式存在，而非指针对象的形式存在。请看下面的示例: 12345678910111213141516171819class Engine&#123; public: void start() &#123; cout&lt;&lt;&quot;引擎启动&quot;&lt;&lt;endl; &#125;&#125;class car&#123;private: Engine engine; //这里以实例的形式存在，而非指针，在类关系中是组合的关系public: void startCar() &#123; engine.start(); //启动引擎 &#125;&#125; 组合特点 组合关系下被包含的类无法独立存在，即部分不能脱离整体存在 被包含的类实例生命周期与包含类实例绑定 这两个类是强拥有关系，个人理解是通过实例对象实现这个隐含的作用的，如果是指针对象的那么就不能理解为强拥有关系。 继承 继承关系是c++中特别重要的一种关系，它同样是用于描述两个类关系。用一个英文描述继承的就是&quot;is-a&quot;，核心含义是一个类是另外一个类的特殊类型，即“是一个”的关系。具体示例如下： 1234567891011121314151617class Animal&#123;public: virtual void makeSound() //虚函数 &#123; cout&lt;&lt;&quot;动物的叫声&quot;&lt;&lt;endl; &#125;&#125;class Dog: class Animal //继承关系，狗也是动物的一种，Dog类是Animal的一种特殊类型&#123; public: void makeSound() &#123; cout&lt;&lt;&quot;汪汪&quot;&lt;&lt;endl; &#125;&#125; 继承特点 强耦合关系 子类继承父类的所有特性 支持多态，在继承中这个多态是运行时多态；同样有编译时多态，即一个同一个函数或者方法可以定义不同的参数，这是编译时多态，也叫静态多态。 聚合 聚合也是c++中类之间关系的一种，这种关系与组合类似，也是&quot;has-a&quot;关系的一种。区别是在聚合关系下被包含对象的存在是以指针对象的形式存在的。请看下面的示例： 123456789101112131415161718class Student&#123; public: std::string name; ...&#125;class School //学校类&#123; private: std::vector&lt;Student*&gt; students; //学生对象的集合,聚合关系，注意这里描述学生的类型是Student* public: void addStudent(Student* stu) &#123; students.push_back(stu); &#125;&#125; 聚合特点 松耦合的关系，比组合的松耦合还要送，也可以叫做弱拥有关系 被包含的类可以独立存在，即部分可以脱离整体存在 生命周期独立 依赖关系 除了上面的3中关系外，还有一种依赖关系，那怎么叫做依赖关系呢？相信大家也有到类似的情况，一个类使用另外一个类时仅在函数参数中使用。这种情况明显不属于上面的3种关系，所以这里就有了依赖关系。那都有哪些情况属于依赖关系呢？ 函数参数 作为返回类型 在成员函数中以局部变量出现 静态方法调用 具体示例如下： 123456789101112131415class Printer &#123;public: void print(Document doc) &#123; //参数依赖 // 使用 Document 对象 &#125; Report createReport() &#123; // 返回类型依赖 Report report; // 局部变量依赖 return report; &#125; void process() &#123; Logger::log(&quot;Processing&quot;); // 静态方法调用依赖 &#125;&#125;; 依赖关系特点 这是一种最弱的关系，关系强度如下:依赖关系&lt;聚合关系&lt;组合关系&lt;继承关系。 设计原则 优先使用组合而非继承 合理使用继承 总结 c++中非常重要的设计模式，就是对上面的几种关系的组合运用。","categories":[{"name":"设计","slug":"设计","permalink":"http://www.formeasy.cc/categories/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"}],"author":null},{"title":"用Enterprise Architect画类图和顺序图","slug":"EA/用Enterprise Architect画类图和顺序图","date":"2025-01-23T07:26:21.000Z","updated":"2025-04-25T01:26:05.214Z","comments":true,"path":"2025/01/23/EA/用Enterprise Architect画类图和顺序图/","link":"","permalink":"http://www.formeasy.cc/2025/01/23/EA/%E7%94%A8Enterprise%20Architect%E7%94%BB%E7%B1%BB%E5%9B%BE%E5%92%8C%E9%A1%BA%E5%BA%8F%E5%9B%BE/","excerpt":"","text":"新建一个Project 没什么好说的，“文件-新建项目”，然后选择保存位置就好了，模式的话由于我喜欢一个包一张图所以一般都选择“新建包的时候同时新建图”。 会弹出一个模型向导的对话框， 是给你导入模板的，我不需要，所以都不选直接点确定。 在项目浏览器里新增包，一个图一个包比较舒服： UML的图就主要在UML Structural和UML Behavioral两个包里： 有时候你新建在图里的元素删除了只是在图里删除而没有在包里删除，作为一个强迫症，总是要多动手删一次= = EA还提供一些像Word那样的操作，比如这两个按钮可以修改元素的层次关系： 类图 类图挺好画的，从工具箱里拖一个“Class”进去，会自动弹出一个设置Class的界面。 在“Class1”那个位置写类的名称： 右下方的“详细”选项卡里可以设置类的属性的操作，后期如果想设置可以在类上“右键-功能与属性”里也可以修改： 类之间的关联在工具箱子的这个位置： 添加两个类的关联的方法是：选中相应关联工具，然后按住鼠标在一个类和另一个类之间拖出一条线 双击关联的线或者**选中线后“右键-特性”**都可以设置关联的属性： 在“角色”选项卡里可以设置多重性： 不过EA12的类图有一个特点，如果一个类没有属性或者没有操作，它就会显示成二栏或者一栏而不是标准的三栏……对于要考试的还是EA新手的人来说TAT……只好加一个叫“…”的属性和操作顶上= = 顺序图 EA的顺序图的每个对象的生命线都是从相同的高度开始的，反正我试图拖的时候不能把某个对象拖下来Orz Actor和Lifeline是两个有生命线的东西，先要新建它们，拖到图里就好了 Fragment是用于表示结构化控制的 消息传递在Interaction Relationship里，一共有4个，1是对象之间传递的消息，2是自传递的消息，3和4我目前发现没有太大的区别——如果想要表示自调用就在单一对象的生命线上点一下，如果表示两个对象之间的调用就在调用者和被调用者之间拖一条线…… 用Lifeline新建一个对象，双击它或者右键-特性可以设置属性，对象的名称貌似是要自己写“：”来符合UML规范。 消息就是点击一下单一对象的生命线或者在调用者和被调用者之间拖一条线产生出来的对象，同样是双击或者右键就可以设置属性，具体如下： 有时候消息需要在特定条件下才能发出，也可以设置： 新建一个如下设置的自调用，可以规定条件： 还有结构化控制，用Fragment实现，拖一个到图里，然后可以双击设置属性： 最后的结果： 导出 Ctrl+T或者在菜单栏里“图-保存图到文件”就可以把图导出为图片。","categories":[{"name":"设计","slug":"设计","permalink":"http://www.formeasy.cc/categories/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"EA","slug":"EA","permalink":"http://www.formeasy.cc/tags/EA/"}],"author":null},{"title":"Enterprise Architect类图的绘制","slug":"EA/Enterprise Architect类图的绘制","date":"2025-01-23T05:54:01.000Z","updated":"2025-04-25T01:26:28.505Z","comments":true,"path":"2025/01/23/EA/Enterprise Architect类图的绘制/","link":"","permalink":"http://www.formeasy.cc/2025/01/23/EA/Enterprise%20Architect%E7%B1%BB%E5%9B%BE%E7%9A%84%E7%BB%98%E5%88%B6/","excerpt":"","text":"1.新建类图 新建图，弹出的窗口如下 2.绘制类图 常用类之间的关系 上方菜单栏找到图，找到并打开工具箱的视图， 鼠标悬浮就会显示元素对应的信息功能，拖到元素到工作区就会对应生成，新建一个类， 在类上鼠标右键添加其他信息，常用的是功能与属性的属性和操作， 其中属性是成员变量，操作是方法， 类之间的关系，可以在工具箱里添加，也可以在类的 箭头样式的那个图标 上拖动 3.多种类的关系的类图绘制 有时候，类的关系不止一种，两个类之间可能有多种关系，如下 两个类之间有聚合、依赖两种关系，使用Enterprise Architect，先画聚合关系， 然后在连接线上，右键选择高级–&gt;改变方向,目标到起始 结果如下：","categories":[{"name":"设计","slug":"设计","permalink":"http://www.formeasy.cc/categories/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"EA","slug":"EA","permalink":"http://www.formeasy.cc/tags/EA/"}],"author":null},{"title":"Cursor使用介绍","slug":"Editor/Cursor使用介绍","date":"2025-01-23T03:39:22.000Z","updated":"2025-04-25T01:52:24.715Z","comments":true,"path":"2025/01/23/Editor/Cursor使用介绍/","link":"","permalink":"http://www.formeasy.cc/2025/01/23/Editor/Cursor%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"Cursor是一款AI代码编辑器，官网地址为https://www.cursor.com/ 直接在官网下载安装即可，基于VS Code二次开发而来，之所以没有采用插件方式，在官方网站上给出的答案是某些功能插件无法实现，产品专注在使用AI来进行编程方面，价格方面还不便宜，Pro单月20刀，企业版单月单个用户40刀，但某些功能确实好用啊，有找外包替你完成部分工作的感觉，不付费的话使用次数有限制。 最基本功能：Tab键代码自动补全。在写代码时，后面会有代码提示，官网上说是一个更强大的 Copilot（Github出品的代码补全工具），Copilot我只体验过，没有深度使用，不能给出比较准确的对比评价。 第二个特色功能：根据提示修改代码或生成命令。快捷键Ctrl/Cmd + k，比如下图，找到需要优化问题代码片段，选中需要优化一段代码，快捷键Ctrl/Cmd + k，输入提示“优化一下”，就会生成新代码，比较有特色是可以分段部分接受修改，根据右侧图中红框内快捷键操作即可，如果有错误，还可以继续进行AI Fix修复，用来重构代码效率会大大提高。 如果在终端中按快捷键Ctrl/Cmd + k，同样会出现提示框，输入“构建命令”，就会在命令行中生成要执行的命令，命令稍加修改就能执行，感觉已经非常厉害了，理论上可以在这个终端里连接上远程服务器，通过提示生成要执行的命令，这对于终端命令不太熟悉的同学非常有帮助。 第三个特色功能：聊天功能。快捷键Ctrl/Cmd + L，会单独打开右侧窗口，同样是输入“优化一下”，生成代码后点击右上角Apply应用到代码中，下面还会总结改进的内容，也可用继续问，进行多轮聊天，直到感觉可以后再应用，也可以闲聊，问一些和代码无关的问题也没有问题。 Cursor会对代码进行索引，会计算代码库中的每个文件的嵌入向量，并将使用这些嵌入向量来提高代码库答案的准确性。如果在聊天时，使用快捷键Ctrl/Cmd + Enter，会使用这项功能来搜索项目下代码内容来提高答案的准确性，也是特色功能之一。 第四个特色功能：AI Review代码 Review功能目前还是Beta测试中，需要现在设置中启用，如需要长文本功能的也在这里启用，目前聊天中token限制为20000个，快捷提示中为10000个。 根据提示，Ctrl/Cmd + Shift + P，输入Reload Window，重载窗口，就能看到聊天窗口右边出现Review标签页了。 重载窗口后，同样是输入提示，下面也提供了四项对应的Review功能，Review Working State可以对未提交的工作空间内代码进行Review，Review Last Commit也挺方便的，在开发分支提交代码后直接进行Review，Review后再合并到上层分支。 Cursor可以配置使用其他AI，发送任意数量的 AI 消息 可以对使用的模型进行设置，选择使用哪些模型，可以同时使用多个模型，GPT-4, GPT-4o, and Claude 3.5 Sonnet都是收费的高级模型 总结Cursor使用，编写代码中可以使用tab键补全代码，使用提示（Ctrl/Cmd + k）生成、修改或重构代码，同样可以使用聊天（Ctrl/Cmd + L）方式生成、修改或重构代码，在聊天时使用Ctrl/Cmd + Enter发送信息会索引本地代码提高回答准确率，Beta测试中的Review代码功能非常好用。 以上为Cursor使用总结，Cursor是非常有创新的产品，不管是否是在计算机行业都应该体验一下。","categories":[{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"Editor","slug":"Editor","permalink":"http://www.formeasy.cc/tags/Editor/"}],"author":null},{"title":"Qt5.14.2与VS2022配置","slug":"Qt/Qt5.14.2与VS2022配置","date":"2025-01-23T03:21:13.000Z","updated":"2025-04-24T06:26:11.869Z","comments":true,"path":"2025/01/23/Qt/Qt5.14.2与VS2022配置/","link":"","permalink":"http://www.formeasy.cc/2025/01/23/Qt/Qt5.14.2%E4%B8%8EVS2022%E9%85%8D%E7%BD%AE/","excerpt":"","text":"1.qt6要在线安装，安装时间比较长，要求网络要稳定，不适合快速安装 2.使用qt5.14.2离线安装包，安装速度快，可以快速安装。 3.安装完qt.5.14.2后打开QtCreate4.0.1，打开 工具-&gt;选项-&gt;Kits,发现如下图: 没有找到MSVC2017,安装qt时选择安装MSVC2017的， 4.打开Visual Studio Installer，确保VS2022已经安装MSVC2017 5.确保WindowSDK有安装 6.到qtcreate中 工具-&gt;选项-&gt;Debuggers，查看有没有调试器 如果没有,到控制面板-&gt;程序卸载，查找 右击-&gt;更改，勾选如下图 等待安装完成。 7.安装完成后，在qtcreate-&gt;工具-&gt;选项-&gt;kits-&gt;Debuggers中看到cdb.exe调试器 8.重新添加编译器 9.重新配置Kits中构建套件(Kit) 10.如果报错 原因 解决","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"}]},{"title":"Ubuntu添加用户增加sudo授权","slug":"Ubuntu/Ubuntu添加用户增加sudo授权","date":"2025-01-21T05:43:13.000Z","updated":"2025-01-21T05:57:12.898Z","comments":true,"path":"2025/01/21/Ubuntu/Ubuntu添加用户增加sudo授权/","link":"","permalink":"http://www.formeasy.cc/2025/01/21/Ubuntu/Ubuntu%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%A2%9E%E5%8A%A0sudo%E6%8E%88%E6%9D%83/","excerpt":"","text":"1.安装sudo 1apt install sudo 2.创建用户 123sudo useradd -m usernamesudo passwd usernamesudo usermod -s /bin/bash username 3.让用户拥有sudo权限 在Linux系统中，如果你想让一个名为username的用户拥有sudo权限，你需要编辑/etc/sudoers文件或者使用usermod命令将该用户添加到sudo组中（假设你的系统使用sudo组来管理sudo权限）。下面是两种方法的详细步骤： 方法一:编辑/etc/sudoers文件 在打开的编辑器中，添加以下行来给予username用户sudo权限： 1username ALL=(ALL:ALL) ALL 这行配置的意思是：用户username可以从任何主机（ALL）以任何用户（第一个ALL）和任何组（第二个ALL）的身份执行任何命令（最后一个ALL）。 方法二:使用usermod命令将用户添加到sudo组 1）确保存在sudo组： 在大多数基于Debian的系统（如Ubuntu）中，sudo组是默认存在的。但在某些系统中，可能需要手动创建或确认该组的存在。 2）将用户username添加到sudo组 使用usermod命令的-aG选项将用户添加到sudo组，同时保留用户原有的其他组成员资格。 1sudo usermod -aG sudo username","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"}]},{"title":"UE5和VS2022下载安装","slug":"UE/UE5和VS2022下载安装","date":"2025-01-12T02:56:13.000Z","updated":"2025-04-21T02:50:45.121Z","comments":true,"path":"2025/01/12/UE/UE5和VS2022下载安装/","link":"","permalink":"http://www.formeasy.cc/2025/01/12/UE/UE5%E5%92%8CVS2022%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/","excerpt":"","text":"先看一下UE和VS的兼容性 为了让VS更好兼容UE5，因此这里下载VS2022版本 步骤 一、Visual Studio下载安装 1. 进入Visual Studio 官网，点击下载 下载社区版即可 下载后点击应用程序开始安装 2. 在安装程序的“工作负荷”面板，先勾选“使用C++”的游戏开发，然后勾选“Windows 10 SDK”和“Unreal Engine 安装程序” 在安装程序的“单个组件”面板，保证如下选项已被勾选： 3. 可以再设置一下安装位置 4. 点击安装 5. 其它注意 1.UE5.4不支持VS2022之前的版本 2.VS2022安装选项要有 .NET 桌面开发 使用 C++ 进行桌面开发 使用 C++ 进行游戏开发 C++ profiling tools C++ AddressSanitizer Windows 10 SDK (10.0.18362 or Newer) Unreal Engine installer 在单个组件中 选择 .netcore3.1(不受支持) .net6.0运行时(长期支持） .netframework4.6.2 .netframework4.7.2 默认勾中的不用取消 二、Visual Studio Integration Tool插件安装 “Visual Studio Integration Tool”插件可与Visual Studio协同工作，以在C++代码中显示有关蓝图资产的信息。 在虚幻商城中搜索“Visual Studio Integration Tool”插件并安装到引擎 在虚幻编辑器中的插件中搜索“Visual Studio Integration Tool”并勾选","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"},{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"}],"author":null},{"title":"Linux下安装navicat_navicat","slug":"Navicat/Linux下安装navicat","date":"2025-01-02T05:33:11.000Z","updated":"2025-04-25T02:04:46.899Z","comments":true,"path":"2025/01/02/Navicat/Linux下安装navicat/","link":"","permalink":"http://www.formeasy.cc/2025/01/02/Navicat/Linux%E4%B8%8B%E5%AE%89%E8%A3%85navicat/","excerpt":"","text":"1.在https://www.navicat.com.cn/download/navicat-premium下载navicat安装包 2.在终端执行命令 给navicat16-premium-cs.AppImage赋予可执行的权限 1chmod +x navicat16-premium-cs.AppImage 启动Navicat16 1./navicat16-premium-cs.AppImage 3.点击连接——mysql——输入连接名以及密码，点击确定。 其中， 连接名：为这次连接起个名字，可以随意填写 主机：mysql数据库所在的主机的ip 端口：mysql服务所在的端口号 用户名、密码：登录mysql时的用户名、密码 其实就是在终端执行mysql -h192.168.110.112 -P3306 -uroot -p命令所写的参数 点击测试连接可以测试能否正常连接指定的数据库 4.navicat 需要注册，如不注册只有14天的使用时间，执行下面两个命令，即可无限使用： 关闭Navicat程序，删除如下2个文件 12rm -rf ~/.config/navicatrm -rf ~/.config/dconf/user 再次重新启动navicat即可。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Navicat","slug":"Navicat","permalink":"http://www.formeasy.cc/tags/Navicat/"}],"author":null},{"title":"容器技术-docker swarm（一）","slug":"Docker/容器技术-docker swarm（一）","date":"2024-12-31T00:58:13.000Z","updated":"2025-04-25T00:51:21.127Z","comments":true,"path":"2024/12/31/Docker/容器技术-docker swarm（一）/","link":"","permalink":"http://www.formeasy.cc/2024/12/31/Docker/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF-docker%20swarm%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"1. 集群的基本概念 我们的应用随着业务的扩展，从开始的单体架构，到分布式架构，再到微服务架构，其中的核心理念就是用资源换取性能。单台服务器的性能是由瓶颈的，随着业务的扩展、访问量的增大、计算量的增大，IO读写需求的增大，逐渐无法支撑，于是便通过集群技术将多台机器构成集群，调度集群内的多台服务器协同进行工作，以满足应用运行的需要，提升应用的性能。这是分布式架构的基本思想。 这里的关键技术就是集群技术。集群是一组相互独立的、通过高速网络互联的计算机构成了一个组，并以单一系统的模式加以管理。每个集群节点都是运行其自己进程的一个独立服务器，但是对于用户来讲，集群却像是一个独立的服务器、一个单一的系统，集群框架就像是多台电脑的操作系统，它将各个节点协同起来向用户提供系统资源，系统服务，通过网络连接形成一个个组合来共同完一个个任务。集群系统最核心的技术就是调度技术，就像一台电脑最核心的就是cpu的调度能力一样. 构建集群的目的： 1 提高性能 一些计算密集型应用，如：天气预报、核试验模拟等，需要计算机要有很强的运算处理能力，现有的技术，即使普通的大型机器计算也很难胜任。这时，一般都使用计算机集群技术，集中几十台甚至上百台计算机的运算能力来满足要求。提高处理性能一直是集群技术研究的一个重要目标之一。 2 降低成本 通常一套较好的集群配置，其软硬件开销要超过100000美元。但与价值上百万美元的专用超级计算机相比已属相当便宜。在达到同样性能的条件下，采用计算机集群比采用同等运算能力的大型计算机具有更高的性价比。 3 提高可扩展性 用户若想扩展系统能力，不得不购买更高性能的服务器，才能获得额外所需的CPU 和存储器。如果采用集群技术，则只需要将新的服务器加入集群中即可，对于客户来看，服务无论从连续性还是性能上都几乎没有变化，好像系统在不知不觉中完成了升级。 4 增强可靠性 集群技术使系统在故障发生时仍可以继续工作，将系统停运时间减到最小。集群系统在提高系统的可靠性的同时，也大大减小了故障损失。 集群根据应用场景和侧重点的不同有不同的分类，包括高性能计算集群(侧重并行计算)、负载均衡集群、高可用性集群。集群是通过集群框架组织起多台机器形成的，集群框架相当于集群的操作系统，除了组成集群的机器的性能影响外，影响集群能力就是集群框架的调度算法了。如我在平常工作中经常接触曙光超算就是高性能计算机集群（HPC）。 现如今，很多应用都支持集群化部署，如侧重数据存储的mysql集群、ElasticSearch集群等，侧重大数据处理的Hadoop集群、spark集群等，侧重任务调度的Jenkins集群、chronos集群等，集群化应用的调度算法注重应用自身的任务，根据应用不同有各自的侧重点。 而我们的应用在微服务架构下，随着业务的扩展，服务越来越多，总不能一直将所有服务及其依赖的容器全部部署在一台机器上，这样服务器撑不住，也失去了分布式架构的意义。要将docker容器部署到不同机器上，又要让它们协调工作，并且能够对这些容器对进行敏捷的生命周期的管理，就需要构建容器集群了。能实现docker容器集群构建和管理的工具也有多种，其中最基础的就是Docker Swarm。 2. Docker Swarm Swarm 是 Docker 官方提供的一款集群管理工具，内置在docker之中，通过docker引擎的SwarmKit成为 Docker 的一个子命令，是原生的docker集群编排工具，是曾经的Docker三剑客项目之一。通过Swarm可以用几条简单的命令就将若干台 Docker 主机抽象为一个整体，快速的创建一个docker集群，并且通过一个入口统一管理集群各个机器上的各种 Docker 资源。 提起容器集群管理就绕不开k8s，现在主流的容器管理工具就是k8s，但是Swarm项目也是一个经典，和k8s对比，Swarm更轻量级，是了解容器集群技术的入门工具，对于一些小型的容器集群应用场景是很简单而有效的解决方案。 一个 Swarm 集群由一个或多个 Docker 节点组成，这些节点可以是物理服务器、虚拟机或云实例，唯一的前提就是所有节点通过可靠的网络相连。节点在加入集群的时候会被配置为管理节点（Manager）或工作节点（Worker），后续还能进行升级或降级。 管理节点负责执行容器的编排和集群的管理工作，集群编排管理指令在manger节点下达。由于Swarm实际上是通过agent调用了本地的Docker daemon来运行容器，当Swarm集群服务出现故障时，无法接受新的请求，但已经运行起来的容器将不会受到影响。在生产环境中，为避免单点故障，swarm可以部署多个manager节点，docker官方建议使用奇数个节点，最好是3到5个，不能大于7个，这些管理节点采用主从模式，分为leader和follower，follwer接收到命令时会转发给leader，它们会通过Raft协议进行状态同步，并在Leader节点发生故障时分布式选举出另一个Leader继续执行编排任务。 工作节点接收来自管理节点的任务并执行，并且默认manager node也是一个work node，不过可以将它设置为Drain模式，让它只负责编排和管理工作。 服务是要在集群节点上执行的任务的定义，它是swarm系统的中心结构，是用户与swarm交互的主要根源。创建服务时，指定在运行的容器中使用的容器映像和执行的命令，服务中还有诸如扩缩容、滚动升级以及简单回滚等特性。 服务分为两种类型：全局服务（global）和复制服务（replicated）。 复制服务：swarm manager会根据指令设置的规模在节点之间分配特定数量的副本任务。 全局服务：会在集群中的每个可用节点上为该服务运行一个任务。 任务包含一个Docker容器和容器运行的命令，它是swarm的最小调度单元，似于调度器放置容器的“槽”。管理器节点根据服务规模中设置的副本数将任务分配给工作节点，由工作节点去执行。任务一旦分配给节点，就不能移动到另一个节点。它只能在指定的节点上运行或失败。一旦容器处于活动状态，调度程序就会识别出任务处于运行状态。如果容器未通过运行状况检查或终止，则任务将终止。 swarm manager默认使用 ingress 负载均衡来暴露需要让外部访问的服务。我们可以为服务配置一个外部端口，如果没有显式指定端口的话，那么swarm manager会自动分配30000-32767之间的任意一个端口给到service。 swarn模式有一个内部的DNS组件，Swarm manager节点会为集群中的每个服务分配唯一的DNS记录和负载均衡VIP，通过Swarm内置的DNS服务器可以查询到集群中每个运行的容器，实现对服务的各个副本容器的服务发现，使用内部负载均衡机制来接受集群中节点的请求，基于DNS名字解析来实现。 3. 集群节点准备 在搭建集群之前需要先准备节点机器，这里我使用以下三台机器来构建集群。 操作系统 主机名 ip地址 centOS7.6 server 192.168.137.200 centOS7.6 woker1 192.168.137.201 centOS7.6 woker2 192.168.137.202 对于节点机器需要做以下准备： 安装 Docker 确保能与其他节点通信，防火墙放行，或者至少开放以下端口 2377/tcp：用于客户端与 Swarm 进行安全通信。 7946/tcp 与 7946/udp：用于控制面 gossip 分发。 4789/udp：用于基于 VXLAN 的覆盖网络。 配置主机名称以区分不同机器 确保节点机器之间时间同步 集群机器比较少的时候我们可以手动进行配置。 整理的shell脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116SERVER_NAME=(server worker1 worker2)SERVER_IP=(192.168.137.201 192.168.137.202 192.168.137.203)# 配置本地hostssed -i &#x27;3,$d&#x27; /etc/hostsecho -e &quot;# swarm cluster&quot; &gt;&gt; /etc/hostslet SER_LEN=$&#123;#SERVER_IP[@]&#125;-1for ((i=0;i&lt;=$SER_LEN;i++)); do echo &quot;$&#123;SERVER_IP[i]&#125; $&#123;SERVER_NAME[i]&#125;&quot; &gt;&gt; /etc/hostsdone# 同步server的密钥到其他节点SSH_RROT_PASSWD=123456bash &lt;(curl -sSL https://gitee.com/yx571304/olz/raw/master/shell/ssh-key-copy.sh) &quot;$(echo $&#123;SERVER_IP[@]&#125;)&quot; root $SSH_RROT_PASSWD# 同步 hosts 到其他节点for node in $&#123;SERVER_IP[@]&#125;; do echo &quot;[INFO] scp hosts -----&gt; $node&quot; scp /etc/hosts $node:/etc/hostsdone# 手动指定网卡 eth0(此网卡为 SERVER_IP 变量中的IP网卡)for node in $&#123;SERVER_IP[@]&#125;; do ssh -T $node &lt;&lt;&#x27;EOF&#x27; HOST_IF=eth0 HOST_IP=$(ip a|grep &quot;$HOST_IF$&quot;|awk &#x27;&#123;print $2&#125;&#x27;|cut -d&#x27;/&#x27; -f1) hostnamectl set-hostname $(grep $HOST_IP /etc/hosts | awk &#x27;&#123;print $2&#125;&#x27;)EOFdonefor node in $&#123;SERVER_IP[@]&#125;; do echo &quot;[INFO] Config -----&gt; $node&quot; ssh -T $node &lt;&lt;&#x27;EOF&#x27; # 优化ssh连接速度 sed -i &quot;s/#UseDNS yes/UseDNS no/&quot; /etc/ssh/sshd_config sed -i &quot;s/GSSAPIAuthentication .*/GSSAPIAuthentication no/&quot; /etc/ssh/sshd_config systemctl restart sshd # 配置阿里云yum源 rm -f /etc/yum.repos.d/*.repo curl -so /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo curl -so /etc/yum.repos.d/Centos-7.repo http://mirrors.aliyun.com/repo/Centos-7.repo sed -i &#x27;/aliyuncs.com/d&#x27; /etc/yum.repos.d/Centos-7.repo /etc/yum.repos.d/epel-7.repo # 防火墙 firewall-cmd --set-default-zone=public firewall-cmd --complete-reload firewall-cmd --zone=public --add-port=2377/tcp --permanent firewall-cmd --zone=public --add-port=7946/tcp --permanent firewall-cmd --zone=public --add-port=7946/udp --permanent firewall-cmd --zone=public --add-port=4789/udp --permanent firewall-cmd --reload # 文件/进程 限制 if [ ! &quot;$(grep &#x27;# My Limits&#x27; /etc/security/limits.conf)&quot; ]; then echo -e &quot;# My Limits&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* soft nofile 65535&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* hard nofile 65535&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* soft nproc 65535&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* hard nproc 65535&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* soft memlock unlimited&quot; &gt;&gt; /etc/security/limits.conf echo &quot;* hard memlock unlimited&quot; &gt;&gt; /etc/security/limits.conf fi # 启用路由转发 echo &#x27;net.ipv4.ip_forward = 1&#x27; &gt;&gt; /etc/sysctl.conf echo &#x27;net.bridge.bridge-nf-call-iptables = 1&#x27; &gt;&gt; /etc/sysctl.conf echo &#x27;net.bridge.bridge-nf-call-ip6tables = 1&#x27; &gt;&gt; /etc/sysctl.conf # 同时同一用户可以监控的目录数量 echo &#x27;fs.inotify.max_user_watches=524288&#x27; &gt;&gt; /etc/sysctl.conf # 进程拥有VMA(虚拟内存区域)的数量 echo &#x27;vm.max_map_count=655360&#x27; &gt;&gt; /etc/sysctl.conf # TIME_WAIT echo &#x27;net.ipv4.tcp_syncookies = 1&#x27; &gt;&gt; /etc/sysctl.conf echo &#x27;net.ipv4.tcp_tw_reuse = 1&#x27; &gt;&gt; /etc/sysctl.conf echo &#x27;net.ipv4.tcp_tw_recycle = 1&#x27; &gt;&gt; /etc/sysctl.conf modprobe br_netfilter sysctl -p -w /etc/sysctl.conf # stop/disable selinux setenforce 0 sed -i &#x27;s#SELINUX=.*#SELINUX=disabled#&#x27; /etc/selinux/configEOFdone# 设置时间同步for node in $&#123;SERVER_IP[@]&#125;; do echo &quot;[INFO] Install ntpdate -----&gt; $node&quot; ssh -T $node &lt;&lt;&#x27;EOF&#x27; yum install -y ntpdate ntpdate ntp1.aliyun.com hwclock -w crontab -l &gt; /tmp/crontab.tmp echo &quot;*/20 * * * * /usr/sbin/ntpdate ntp1.aliyun.com &gt; /dev/null 2&gt;&amp;1 &amp;&amp; /usr/sbin/hwclock -w&quot; &gt;&gt; /tmp/crontab.tmp cat /tmp/crontab.tmp | uniq &gt; /tmp/crontab crontab /tmp/crontab rm -f /tmp/crontab.tmp /tmp/crontabEOFdone# 安装docker, 从安装源获取最新稳定版本并安装(二进制版)for node in $&#123;SERVER_IP[@]&#125;; do echo &quot;[INFO] Install docker -----&gt; $node&quot; ssh -T $node &lt;&lt;&#x27;EOF&#x27; bash &lt;(curl -sSL https://gitee.com/yx571304/olz/raw/master/shell/docker/install.sh) -i docker sed -i &#x27;s/&quot;live-restore&quot;: true/&quot;live-restore&quot;: false/g&#x27; /etc/docker/daemon.json systemctl daemon-reload systemctl restart docker.serviceEOFdone 以上脚本将把集群机器的环境配置好，并且为每台机器安装好docker，使用的时候注意修改ERVER_NAME、SERVER_IP、SSH_RROT_PASSWD以及HOST_IF。 Ps: 测试环境下也可以利用docker machine快速创建docker虚拟主机用作集群节点，或者通过以下网站https://labs.play-with-docker.com/，免费创建几台机器进行测试，这里提供的在线虚拟机地址只能使用四个小时。 4. 集群构建 不包含在任何 Swarm 中的 Docker 节点，称为运行于单引擎（Single-Engine）模式。一旦被加入 Swarm 集群，则切换为 Swarm 模式。第一步我们要做的就是初始化 Swarm。 4.1 初始化swarm集群 这里我将server机器作为manager节点，执行以下命令 1docker swarm init --advertise-addr 192.168.137.201 docker swarm init 会通知 Docker 来初始化一个新的 Swarm，并将自身设置为第一个管理节点，同时也会使该节点开Swarm 模式。 --advertise-addr 参数配置当前管理节点的发布地址，其他节点必须能连接这个地址。在机器只有一个ip的情况下可以省略，如果由多个ip则必须手动指定。 看到以上输出就代表这swarm集群初始化成功。输出信息中还包含了将其他节点作为管理节点或者工作节点加入到集群的提示。 可以通过以下命令查看集群和节点的状态： 1docker info 1docker node ls 可以看到当前机器已经作为管理节点中的leader加入到集群中了。 4.2 节点加入集群 其他节点可以以工作节点或管理节点的方式加入集群。如果是作为工作节点，只需要复制集群初始化后的提示命令在节点机器上执行即可。 1docker swarm join --token SWMTKN-1-0hm7th9vtv18f3s41x1wb6ddcgwxv9yx54333bovht7vajykgx-780i8mbd9pfza43jl0gl564ef 192.168.137.201:2377 我们也可以根据需要新增的节点的类型，使用以下命令重新获取加入机器的命令： 1docker swarm join-token worker # 查看工作节点加入集群的指令和令牌 1docker swarm join-token manager # 查看管理节点加入集群的指令和令牌 远程连接到worker1机器，将其加入到集群中 再远程连接到worker2机器，将其加入到集群中 之后在manager节点，也就是server机器，就可以看到集群的节点信息了(只能是manager身份才可查看)。 以上是手动加入集群的过程，如果在需要快速加入集群的话，可以在上面配置节点机器的shell脚本的基础上进行修改，在机器配置完成之后自动构建集群 4.3 刷新令牌 token是一个节点加入swarm集群的唯一必要条件，非常重要，特别是管理器令牌，因为它们允许新的管理器节点加入并获得对整个进程的控制。token不应该给和应用源码那些存放在一起，官方推荐至少6个月对token进行一次刷新。 刷新令牌命令如下，可以指定刷新worker节点令牌还是manager节点令牌： 1docker swarm join-token --rotate worker token刷新对已加入集群的节点不会有影响，但是后续想加入集群的节点必须使用新的token。 4.4 集群锁定 尽管swarm内置有很多的原生安全机制，但是重启一个旧的管理节点或进行备份恢复仍有可能对集群造成影响。 一个旧的管理节点重新接入 Swarm 会自动解密并获得 Raft 数据库中长时间序列的访问权，这会带来安全隐患。 进行备份恢复可能会抹掉最新的 Swarm 配置。 为了规避以上问题，Docker 提供了自动锁机制来锁定 Swarm，这会强制要求重启的管理节点在提供一个集群解锁码之后才有权从新接入集群。 我们可以在集群初始化的时候启用swarm集群的自动锁定功能： 1docker swarm init --autolock --advertise-addr 192.168.137.201 对于已经存在的集群，可以在管理节点上通过以下方式启动或禁用自动锁定功能： 1docker swarm update --autolock=true 启用了自动锁定功能之后输出的密钥非常重要，后续集群里的管理节点重启等操作需要用到，请妥善保存。 下面我将两个工作节点都先升级到管理节点 启用了自动锁定功能之后，管理节点将重启之后将无法直接加入到集群中，在worker1上重启docker 尝试使用docker node命令 从server机器上可以看到worker1节点处于 unreachable 状态 在worker1上执行 docker swarm unlock 命令来为解锁 Swarm，需要提供解锁码，也就是刚才配置 --autolock=true 时生产的密钥。 解锁之后，worker1就重新接入 Swarm，再次执行 docker node ls 命令可以看到显示 ready 和 reachable状态了 有些时候我们可能会忘记解锁码，这时候我们可以通过以下命令来查看现用的解锁码 1docker swarm unlock-key 为了保证解锁码的安全，避免泄露，我们可以定期的刷新更换解锁码 1docker swarm unlock-key --rotate 当刷新解锁钥匙时，我们将旧解锁码的记录保存一段时间，因为解锁码在管理节点之间同步需要一小段时间，如果其他管理节点在拿到新解锁码之前宕机，那么它仍可能用旧解锁码解锁。 5. swarm集群管理基本命令 5.1 docker swarm docker swarm 命令用于集群管理，常用的命令如下，可用–help查看详细说明： 5.1.1 docker swarm init [OPTION] 初始化集群，常用参数有： –advertise-addr: 多网卡的情况下，指定需要使用的ip，或者指定一个节点上没有的 IP，比如一个负载均衡的 IP –listen-addr: 指定监听的 ip 与端口，通常与 --advertise-addr 相匹配，如果 --advertise-addr 设置了一个远程 IP 地址（如负载均衡的IP地址），该属性也是需要设置的 –autolock: 指定集群启用自动锁定功能 –availability: 节点的有效性(“active”|“pause”|“drain”) Active：集群中该Node可以被指派Task Pause：集群中该Node不可以被指派新的Task，但是其他已经存在的Task保持运行 Drain：集群中该Node不可以被指派新的Task，Swarm Scheduler停掉已经存在的Task，并将它们调度到可用的Node上 5.1.2 docker swarm join-token [OPTION] (worker | manager) 管理集群令牌，可查看、刷新令牌，只能在管理节点执行，参数如下： -q:只输出令牌 –rotate: 刷新令牌 5.1.3 docker swarm join [OPTIONS] HOST:PORT 将一个节点机器加入集群，需要在节点机器上执行，常用参数如下： –advertise-addr: 多网卡的情况下，指定需要使用的ip –listen-addr: 指定监听的 ip 与端口，通常与 --advertise-addr 相匹配 –availability: 节点的有效性(“active”|“pause”|“drain”) –token：集群令牌 5.1.4 docker swarm update [OPTIONS] 更新集群状态，只能在管理节点执行，常用参数如下： –autolock：修改管理节点的自动锁定功能配置，可用值有: true、false –cert-expiry：验证节点之间的通讯令牌的间隔，默认时2160小时，可用单位: ns|us|ms|s|m|h –dispatcher-heartbeat：心跳包间隔时长，默认5秒，可用单位：ns|us|ms|s|m|h –task-history-limit：任务历史记录保留限制 5.1.5 docker swarm leave [OPTIONS] 脱离集群，在需要退出的节点执行，如果只有一个管理节点的情况下，管理节点退出集群，集群解散。参数如下： -f: 强制退出集群 一个节点退出集群之后，docker node ls命令还可以看到该节点信息，只是处于down状态。 5.1.6 docker swarm unlock-key [OPTIONS] 管理解锁码，可查看、刷新解锁码 -q：只输出解锁码 –rotate：刷新解锁码 5.1.7 docker swarm unlock 解锁一个管理节点 5.2 docker node docker node 命令用于节点管理，常用的命令如下： 5.2.1 docker node ls [OPTIONS] 列出集群中的节点，只能在管理节点操作 5.2.2 docker node inspect [OPTIONS] self|NODE [NODE…] 查看节点的详细信息，只能在管理节点操作 –pretty：格式化输出信息 可以使用self查看当前节点，也可以使用节点名称查看其他节点，可以通过多个节点名称一次性查看多个节点 5.2.3 docker node demote NODE [NODE…] 对节点进行降级，从管理节点降级到工作节点，通过节点名称一次性可以对多个几点进行操作，尽量多个节点进行操作，保持管理节点是奇数个，只能在管理节点操作 5.2.4 docker node promote NODE [NODE…] 对节点进行升级，从工作节点升级到管理节点，通过节点名称一次性可以对多个几点进行操作，尽量多个节点进行操作，保持管理节点是奇数个，只能在管理节点操作 5.2.5 docker node ps [OPTIONS] [NODE…] 查看节点上正在执行的任务，可以通过节点名称查看某一节点的任务，默认是当前节点，只能在管理节点操作 5.2.6 docker node update [OPTIONS] NODE 更改一个节点的配置，只能在管理节点操作 –availability：更改节点的状态，可用状态有：“active”、“pause”、“drain” –label-add：为节点添加或更新标签，以key=value的形式 –label-rm：移除节点标签 –role：设置节点角色，可用值：“worker”、“manager”，相当于升降级 5.2.7 docker node rm [OPTIONS] NODE [NODE…] 通过节点名称移除节点，只能在管理节点操作，可以一次移除多个节点，一个节点使用docker swarm leave命令脱离集群之后还可以用docker node ls命令看到，使用docker node rm移除的节点将彻底不再集群中。 -f：强制移除 ———————————————— 原文链接：https://blog.csdn.net/weixin_37648525/article/details/125346643","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"xargs命令用法","slug":"Ubuntu/xargs命令用法","date":"2024-12-30T05:38:13.000Z","updated":"2025-04-25T01:19:48.519Z","comments":true,"path":"2024/12/30/Ubuntu/xargs命令用法/","link":"","permalink":"http://www.formeasy.cc/2024/12/30/Ubuntu/xargs%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95/","excerpt":"","text":"事例1：把文件结果做为参数，查看文件大小 cat 1.txt | xargs -i ls -hl {} -i 用 {} 代替传递的数据 {} 作为cat的结果，在xargs作为一个参数 ls : 此处不支持命令别名，使用ll会报错 事例2：把find出来的文件复制到指定目录下 思路： 1）把需要查找的文件名称存放到1.txt文件里面 2）通过for循环找到文件 3）通过xargs -i 复制找到的文件 cat 1.txt for i in `cat 1.txt`; do find . -name “$i” |xargs -i cp {} /tmp/`date +%Y%m%d` ;done ll /tmp/`date +%Y%m%d` -i 和-I 的区别，-I 要加一个{} -i : xargs -i cp {} /tmp/ -I : xargs -I {} cp {} /tmp/ [root@localhost ~]# for i in `cat 1.txt`; do find . -name “$i” |xargs -i cp {} /tmp/`date +%Y%m%d` ;done [root@localhost ~]# rm -f /tmp/20220811/* [root@localhost ~]# for i in `cat 1.txt`; do find . -name “$i” |xargs -I {} cp {} /tmp/`date +%Y%m%d` ;done [root@localhost ~]# ll /tmp/20220811/ 总用量 8 -rw-r–r-- 1 root root 2656 8月 11 17:54 nginx.conf -rw-r–r-- 1 root root 744 8月 11 17:54 ping-test.sh 事例3：批量删除docker容器 删除容器：docker ps -aq | xargs docker rm 删除镜像：docker images -q | xargs docker rmi -f 强制删除","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"}]},{"title":"容器技术-docker swarm（二）","slug":"Docker/容器技术-docker swarm（二）","date":"2024-12-30T01:01:13.000Z","updated":"2025-04-25T00:51:57.967Z","comments":true,"path":"2024/12/30/Docker/容器技术-docker swarm（二）/","link":"","permalink":"http://www.formeasy.cc/2024/12/30/Docker/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF-docker%20swarm%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"本篇是 docker swarm 技术点的第二篇，在上一篇 容器技术—docker swarm（一）的基础上继续往下讲。 6. 部署服务 6.1 基本部署操作 基于docker swarm的docker集群已经搭建完成，我们的目的是要在集群中部署应用。swarm集群部署应用最基本的命令是docker service，它的使用方式类似于docker container（也就是我们一直用的docker命令，docker命令是docker container的简写），也和docker container命令一样适合部署单个应用，不能进行编排，只不过一个是用于单机，一个用于集群。 下面以在swarm集群中部署nginx为例： 默认的情况下，管理节点也是一个工作节点，服务也会部署在了管理节点上，如果我们不希望服务部署在管理节点上的话，可以将管理节点设置为darin状态。 之后执行以下命令部署nginx应用： 1docker service create --name nginx-test --replicas 2 -p 8080:80 nginx:1.21.6 swarm集群中进行应用部署使用docker swarm create命令，该命令与熟悉的 docker container run 命令的许多参数是相同的，上面的命令中声明基于nginx:1.21.6镜像部署应用，服务名称为nginx-test，将容器内部的80端口映射到集群网络的8080端口，在集群节点之中保持2个服务副本(即两个容器)。从上面的输出还可以看出，管理节点首先会根据版本获取镜像摘要，如果管理节点获取不到，则还有在各个节点分别尝试获取，然后拉取镜像。 命令执行完成之后，可以通过docker service ls查看服务的状态 1docker service ls 可以看到服务已经部署成员，2/2表示两个服务副本都正常。我们创建的所有服务都会被 Swarm 持续监控，Swarm 会在后台进行轮训检查（Reconciliation Loop），来持续比较服务的实际状态和期望状态是否一致。如果一致，则无须任何额外操作；如果不一致，Swarm 会使其一致。换句话说，Swarm 会一直确保实际状态能够满足期望状态的要求。 例如这里的两个nginx的容器其中一个宕机了，swarm会重新启动一个副本，让正常运行的nginx容器始终保持在两个，这使得服务在面对节点宕机等问题时具有自愈能力。 通过docker service ps nginx-test查看服务的详细信息 可以看到，两个nginx容器分别启动在server节点和worker1节点。 我们可以通过swarm集群中的任意一个节点的ip加上开放出来的8080端口访问到nginx应用。 这里我通过192.168.137.201这个ip进行访问，也能访问得通。192.168.137.201对于的节点是server，而启动的nginx容器并没法在server上，这是因为在默认的情况下swarm集群采用ingress模式发布端口，通过路由网格模式让我们发布的端口在集群每一个节点上口都可以访问，再通过内部的负载均衡自动转发到实际的运行的容器之中。 我们的应用在实际的应用中可能会根据访问量进行扩容、缩容，即根据实际情况调整容器启动的数量，通过docker service scale命令可以很方便得进行操作。例如下面将nginx容器扩展到4个。 1docker service scale nginx-test=4 再对其进行niginx-test服务进行缩容 有些时候我们会对服务的配置进行修改，例如增加一个映射端口： 1docker service update --publish-add 8081:80 nginx-test 可以看到8080、8081都映射到了容器内部的80端口。在使用docker service update命令更新服务时，docker会停止现有的容器并且用新的配置启动新的容器。 我们也可以通过docker service update命令来更新容器镜像，实现日常工作中的版本迭代，还可以通过配置实现滚动更新。 1docker service update --image nginx:latest --update-parallelism 1 --update-delay 20s nginx-test 这里我们指定对nginx-test服务进行更新，采用 nginx:latest新镜像, --update-parallelism 声明每次使用新镜像更新两个副本，–update-delay 声明每次更新期间有 20s 的延迟。 通过一个新的xshell窗口连接server服务器，用docker service ps nginx-test可以看到，两个正在运行的容器一个已经更新到latest版本，一个还没有。其他那些已经shutdown的容器是执行update命令之后关闭掉的容器。 更新完成之后，两个服务副本都已经是lastes版本了。 服务更新时，还可以配置更新失败回滚策略。如： 1docker service update --image nginx:latest --update-parallelism 1 --update-delay 20s --rollback-parallelism=2 --rollback-monitor=20s --rollback-max-failure-ratio=.2 nginx-test 其中–rollback-parallelism=2 声明更新失败时每次回滚两个任务，–rollback-monitor声明回滚后，任务将被监视20秒，以确保它们不会退出，–rollback-max-failure-ratio 声明允许最大失败率为20%，这是一个0到1之间的浮点数。 除此之外，我们还可以手动回滚： 1docker service update --rollback nginx-test 以上我们在update命令声明的更新策略、回滚策略，在声明之后都会被保存，下次更新、回滚时会按照这次策略执行无需再配置。通过docker service inspect命令查看服务详细信息可以看到。 1docker service inspect nginx-test 这些策略也可以在创建服务的时候就设置好。 如果需要移除某个服务，可以用docker service rm 命令，需要注意的是这个服务使用要谨慎，它不会做二次提醒的。 1docker service rm nginx-test 6.2 配置文件管理 docker cli中有一个docker config命令，这个命令用于管理docker配置文件，主要用于swarm模式创建服务时进行配置文件统一管理。 为什么需要这个呢？还是以nginx为例，nginx下有个nginx.conf文件用于配置代理信息，我们以服务的方式部署nginx，启动了多个容器，正常情况下一个服务的多个副本应该保持一致，统一修改，如果把这些存放在容器中后续修改会很不方便，而且容易出错导致副本容器不一致。 docker config 的创建： (1) 创建文件： (2) 创建config 1docker config create nginx-conf ./default.conf 查看config 1docker config ls 查看config的详细信息： 1docker config inspect nginx-conf 默认情况下文件内容是通过base64算法加密的，可以在查看的时候对其进行解密 1docker config inspect -f &#x27;&#123;&#123;json .Spec.Data&#125;&#125;&#x27; nginx-conf | cut -d &#x27;&quot;&#x27; -f2 | base64 -d 删除config 1docker config rm nginx-conf 这里我就不删除了，接下来就是在服务创建的时候使用配置文件了，通过–config参数设置配置文件，通过source参数指定配置文件，使用docker config的名称，通过target指定要替换的容器内部的文件 1docker service create --name nginx-test --replicas 2 --config source=nginx-conf,target=/etc/nginx/conf.d/default.conf -p 8080:8000 nginx:latest 这里将容器映射端口改为8000是与配置文件的监听端口对应，验证配置是否生效，通过其中一个节点访问nginx，如下： 进入worker2节点看一下，可以看到我们设置的配置文件确实存在 对于配置文件，我们不能通过修改原文件的方式直接进行更新，只能够创建新的配置文件，然后通过docker service update命令来对服务进行更新。为了更容易地更新或回退 Config，可以考虑在 Config Name 中添加版本号或日期。 swarm对配置文件的管理机制是这样的： 在 Swarm 中添加一个 Config 时，Docker 通过 TLS 连接把 Config 发送给 Swarm Manager。这个 Config 经过加密后，存储在 Raft 日志中，而且整个 Raft 日志会被复制到其他 Manager 中，确保 Config 的高可用性。 在新创建的或正在运行的服务添加 Config 时，Config 将作为文件安装到容器中，文件路径默认为 linux 容器中的 /&lt;config-name&gt; 可以在任何时候通过更新服务的方式授权其他的 Config 或移除已有的Config 访问权。 如果节点是 Swarm Manager，或者正在运行服务任务已被授权访问这个 Config，那么这个节点才能访问这个配置。当容器任务停止运行时，共享给它的 Config 将从该容器的内存文件系统中卸载，并从节点的内存刷新。 如果一个节点运行了一个带 Config 的任务容器，在它失去与 Swarm 的连接后，这个任务容器仍然可以访问其 Config，但只有在节点重新连接到 Swarm 时才能接收更新。 正在运行的服务正在使用的 Config 不能删除。想要在不中断正在运行的服务的情况下删除配置可以参考 《Rotate a config》。 6.3 卷映射 卷映射是docker容器一个非常基本也非常有用的功能，能够保证就算容器挂了，数据依旧保留在宿主机上，不会丢失，同时也保证了容器的可移植性，只要重要数据还在，我们只要重新启动一个容器即可。 在swarm集群下一样可以做卷映射，通过卷映射来管理容器中的重要数据。集群服务中的卷映射参数和单机模式下有所不同，可以在创建服务时通过–mount参数配置，或者通过update命令中的–mount-add 和–mount-rm来管理。 集群服务中卷映射有两种模式，分别是volume和bind，默认是volume。 6.3.1 volumes模式 如果指定的卷在主机上已经存在，则使用指定的卷，如果在特定主机上执行容器启动任务时这些卷不存在，则会根据服务上的卷规范自动创建卷，默认路径为 /var/lib/docker/volumes/{your_custom_volume}/_data 还是以nginx服务部署为例，执行以下命令创建服务，将容器中/usr/share/nginx/html目录映射到nginx_data，nginx_data是卷名。 1docker service create --replicas 1 --mount type=volume,src=nginx_data,dst=/usr/share/nginx/html --name nginx-test2 nginx 可以看到服务副本运行在 worker1节点上，ssh到worker1节点，可以看到映射出来的卷已经创建了，实际路径为/var/lib/docker/volumes/nginx_data/_data 默认的情况下，自动创建的卷使用的驱动是 local，可以在–mount参数中使用更具体的配置进行设置，格式如下： 1docker service create --mounttype=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=&lt;DRIVER&gt;,volume-opt=&lt;KEY0&gt;=&lt;VALUE0&gt;,volume-opt=&lt;KEY1&gt;=&lt;VALUE1&gt; --name myservice &lt;IMAGE&gt; 6.3.2 bind模式 将宿主机某个目录映射到docker容器，目录必须已经存在，如果节点初始化任务容器时路径不存在，则会报错，服务任务执行失败。很适合用于部署网站，可以宿主机的这个目录作为git版本目录，每次update代码的时候，容器就会更新。 1docker service create --replicas 1 --mount type=bind,src=/home/yyl/nginx,dst=/usr/share/nginx/html --name nginx-test3 nginx 在worker1、worker2两个节点预先创建对应的目录后，启动就正常了。 bind模式的卷映射必须保证节点上已经存在对应的路径，比较麻烦。官方推荐使用volume模式，如果需要使用bind模式的话，可以通过节点标签指定服务任务在某些具备映射目录的节点上运行，但是这样也可能导致问题，如果你的副本容器挂掉了，swarm调度器会调度在其他节点重新启动，以保证存在足够的副本，但是由于节点条件的限制可能导致没有合适的节点可以指派。 6.3.3 NFS模式 以上两种方式都是单机docker上数据共享方式，使用的卷都是在节点机器上的，多个任务副本的情况下每个节点都会有相应的卷，在集群中这可能不适用，我们可以使用NFS来实现共享存储或网络存储。 NFS是一种基于TCP/IP传输的网络文件系统协议。通过使用NFS协议，客户机可以像访问本地目录一样访问远程服务器中的共享资源。对于大多数负载均衡群来说，使用NFS协议来共享数据存储是比较常见的做法，NFS也是存储设备必然支持的一种协议。但是由于NFS没有用户认证机制，且数据在网络上的明文传输，所以安全性很差，一般只在局域网中使用 NFS服务的实现依赖于RPC机制，已完成远程到本地的映射过程。所以需要安装nfs-utils、rpcbind软件包来提供NFS共享服务，前者用于NFS共享发布和访问，后者用于RPC的支持。 下面可以简单演示怎么配置NFS服务 1、先配置主机 首先安装nfs-utils、rpcbind软件包 1yum -y install nfs-utils rpcbind 然后配置配置共享目录，并赋予相应的权限 修改/etc/exports文件，添加规则。 ()中的是添加的权限，这里选择的是可读可写，同时写入磁盘和内存，root用户不隐 藏。此外，我这边选择的是这个137.0网段的用户都可以使用这个NFS服务 然后开启nfs、rpcbind服务 通过端口查看是否已经运行服务。111是rpcbind，接着nfs是2049端口 exportfs -rv ；是用来查看本NFS共享服务器发布了哪些目录和地址 通过rpcinfo -p 查看nfs需要用到的端口，防火墙开放相应的端口，或者直接关闭防火墙 2、配置客户机 首先安装nfs-utils、rpcbind服务 1yum install -y nfs-utils rpcbind 通过 showmount -e ip 命令获取共享目录 创建一个本地目录，并将其挂载到nfs服务 详细使用方式请参考以下文章：NFS共享存储 nfs服务已经部署完毕，接下来通过swarm集群实现卷共享 swarm 集群使用nfs卷挂载，在不用docker stack的情况下需要先在各个节点创建nfs数据卷，这里先使用使用以下命令在各个节点上创建nfs数据卷，docker stack方式之后再讲。 1docker volume create --driver local --opt type=nfs --opt o=addr=192.168.137.202,rw --opt device=:/home/yyl/shared nfs-share 这里需要注意的是，创建nfs卷时，device 参数是指nfs服务端共享目录的路径 之后，再管理节点上使用以下命令创建服务 1docker service create --replicas 2 --mount type=volume,src=nfs-share,dst=/usr/share/nginx/html --name nginx-nfs nginx 可以看到服务的两个任务已经分别运行在两个工作节点上了，接下来到worker2服务器上，找到卷对应的路径，在路径下创建一个文件 再到worker1服务器上，可以看到worker1下也有了我们刚刚创建的文件，两边内容是会保持同步的 6.4 私有库使用 日常工作中对于私有库的搭建和使用是必不可少的，swarm集群中通过私有库镜像创建服务，如果私有仓库使用http协议，需要在各个节点的docker主机中先设置信任私有库地址。 修改各个节点的/etc/docker/daemon.json文件，在insecure-registries节点中添加私有镜像仓库地址，之后重启docker服务： 注意管理节点重启docker之后，需要通过解锁码进行解锁。在生产环境下，节点比较多的情况下一个一个去配置daemon.json文件比较麻烦，可以在上面的集群初始化脚本中添加一些命令，在集群初始化的时候将私有仓库地址添加进去。 123456789101112# 安装docker, 从安装源获取最新稳定版本并安装(二进制版)for node in $&#123;SERVER_IP[@]&#125;; do echo &quot;[INFO] Install docker -----&gt; $node&quot; ssh -T $node &lt;&lt;&#x27;EOF&#x27; bash &lt;(curl -sSL https://gitee.com/yx571304/olz/raw/master/shell/docker/install.sh) -i docker sed -i &#x27;s/&quot;live-restore&quot;: true/&quot;live-restore&quot;: false/g&#x27; /etc/docker/daemon.json # 设置私有仓库 sed -i &#x27;s/&quot;insecure-registries&quot;: [&quot;127.0.0.1&quot;]/&quot;insecure-registries&quot;: [&quot;127.0.0.1&quot;, &quot;xx.xx.xx.xx:8082&quot;]/g&#x27; /etc/docker/daemon.json systemctl daemon-reload systemctl restart docker.serviceEOFdone 由于我部署的私有库拉取docker镜像需要认证，所以还得在管理节点登录私有仓库。 之后通过–with-registry-auth参数使用加密的WAL日志将登录令牌从本地客户端传递到部署服务的swarm节点，就可以通过指定镜像来源仓库进行服务创建了。 1docker service create --with-registry-auth --publish 8005:80 --name dockersample xx.xx.xx.xx:8082/dockersample 可以看到已经通过发布在私有仓库的镜像创建了服务，两个任务分别运行在两个节点。 在两个工作节点中查看镜像，也可以看到工作节点上拉取了镜像，启动了容器。 通过集群中的任意一个ip和8005端口可以访问到启动起来的服务 7. 服务管理基本命令 docker service 命令用于swam集群中对服务进行部署和管理，常用的命令如下，可用–help查看详细说明： 7.1 docker service create [OPTIONS] IMAGE [COMMAND] [ARG…] 按照指定的参数创建服务，后面可以命令和参数，类似docker run，常用的选项有： –name: 指定服务名称 –label：设置服务标签 –mode：设置服务模式，可用值：global、replicated，默认值是replicated global：全局模式，会在每一个可用节点都创建一个服务副本，而且每个节点有且只有一个 replicated：复制模式，可以指定复制个数，默认是1，swarm调度器会调度可以节点创建指定数量的副本，一个节点可以同时有多个副本 –replicas: 任务副本个数，与–mode=replicated，搭配使用 –replicas-max-per-node：每个节点可以运行的任务的最大个数，默认是0，表示没有限制 –env：设置运行时环境变量 –workdir：设置工作目录 –user：设置用户 –publish: 端口映射，默认使用 ingress 网络模式，使用swarm集群的负载均衡，会在每一个节点上都开放配置的端口，并且自动转发到容器内部。如果不想使用swarm集群负载均衡，想要自己更加灵活地做路由策略，可以设置为mode=host模式，这种模式下swarm集群只会在任务运行的节点上开放配置的端口，你需要知道任务副本运行在哪个几点上，一般情况下–publish mode=host 模式和 --mode=global一起使用。 示例： 123docker service create --publish 8000:80 nginxdocker service create --publish published=8080,target=80 nginxdocker service create --mode global --publish mode=host,target=80,published=8080 --name=nginx nginx:latest –mount：配置卷挂载，常用的两种挂载方式是volume和bind，区别在于一个会自动创建卷，一个必须节点上已经存在相应的卷 示例： 12docker service create --mount src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt; --name myservice &lt;IMAGE&gt;docker service create --mount type=bind,src=&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt; --name myservice &lt;IMAGE&gt; volume模式可以根据实际情况设置卷驱动和各种参数，默认卷驱动是local，不同的卷驱动程序按照以下方式配置： 1docker service create --mount type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=&lt;DRIVER&gt;,volume-opt=&lt;KEY0&gt;=&lt;VALUE0&gt;,volume-opt=&lt;KEY1&gt;=&lt;VALUE1&gt; --name myservice &lt;IMAGE&gt; bind模式可以讲目标路径装载为只读： 1docker service create --mount type=bind,src=&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt;,readonly --name myservice &lt;IMAGE&gt; –network：配置网络，不同的swarm服务可以共有一个覆盖网络，这样不同的服务之间就可以通讯，网络有可以做很多的配置，最基本的用法如下： 12docker network create --driveroverlay my-networkdocker service create \\--replicas3 \\--networkmy-network \\--namemy-web \\nginx –config: 设置配置文件 –secret：设置机密信息，与–config类似 –reserve-memory：配置服务启动需要最少的内存，如果没有满足要求的节点，则服务将保持挂起状态，直到合适的节点可以运行其任务为止 –reserve-cpu：配置服务启动需要最少的cpu个数，如果没有满足要求的节点，则服务将保持挂起状态，直到合适的节点可以运行其任务为止 –constraint：设置任务节点约束，只有满足约束的节点会被调度运行任务副本，需要配置集群内的节点的标签使用，用于调度任务在合适的节点上运行，避免调度到一些不符合服务运行条件的节点，导致服务运行失败 –placement-pref：配置放置首选项，与–constraint类似，可以结合–constraint、–reserve-cpu、–reserve-memory一起使用，筛选合适的节点。要注意的是，不要做出无法达到的条件筛选。 –update-delay：更新策略，两次更新任务之间间隔多长，默认0s，可用时间单位：ns、us、ms、s、m、h –update-failure-action：更新失败时的操作，默认为pause，可用值：pause、continue、rollback –update-max-failure-ratio：可以容忍的更新失败比例，默认时0，可用值为0到1的浮点数，表示更新失败的百分比，1为100% –update-monitor：更新之后需要监控容器正常运行多长时间，默认是5s –update-parallelism：每次同时根据的任务副本个数，默认是1 –rollback-delay：回滚策略，两次回滚任务之间间隔多长，默认0s，可用时间单位：ns、us、ms、s、m、h –rollback-failure-action：回滚失败时的操作，默认为pause，可用值：pause、continue、rollback –rollback-max-failure-ratio：可以容忍的回滚失败比例，默认时0，可用值为0到1的浮点数，表示更新失败的百分比，1为100% –rollback-monitor：回滚之后需要监控容器正常运行多长时间，默认是5s –rollback-parallelism：每次同时根据的任务副本个数，默认是1 –restart-condition：配置重启策略，可用值有:“none”、“on-failure”、“any”，默认是any –restart-delay：尝试重启的时间间隔 –restart-max-attempts：尝试重启的最大次数 –with-registry-auth：服务创建的时候，各个工作节点同步管理节点的私有仓库登录凭证，从而各个节点可用拉取私有仓库镜像 create 命令是docker service很重要的一个命令，涉及的相关选项非常多，这里没有列全，也没有讲解得很详细，大家实际用到的时候再具体了解。 7.2 docker service ls [OPTIONS] 列出所有服务，命令常用选项如下： -f：对服务进行过滤 -q：只展示id 7.3 docker service ps [OPTIONS] SERVICE [SERVICE…] 列出一个或多个服务的详细任务信息，可以查看服务对于的任务副本的状态，具体在哪个节点等，命令常用选项如下： -f：对任务进行过滤 -q：只展示id 7.4 docker service inspect [OPTIONS] SERVICE [SERVICE…] 查看一个或多个服务的元信息，能够了解到服务内部的很多配置和一些原理，常用选项如下： –pretty：对服务信息进行格式化 7.5 docker service logs [OPTIONS] SERVICE|TASK 通过服务或任务的名称、id，输出服务或者任务的日志信息，对于排查错误有用，常用选项如下： –since：给定一个时间戳，输出从给定时间之后的日志 -n：输出最后多少行 -t：显示每行日志的时间 7.6 docker service scale SERVICE=REPLICAS [SERVICE=REPLICAS…] 设置服务的副本个数，选项如下： -d：后台运行命令 7.7 docker service update [OPTIONS] SERVICE 按照新的配置更新服务，update命令的大部分参数配置会关闭原有的副本容器，重新启动新的容器。常用选项如下： –image：更新服务使用的镜像，一般用于对服务进行迭代升级，指定新的镜像标签重启容器 –replicas：更新服务的副本数量，用于扩容缩容，和docker service scale功能相同 –replicas-max-per-node：单个节点最多可部署多少个副本 –env-add：添加或更新环境变量 –env-rm：移除环境变量 –workdir：更改工作目录 –user：更改用户 –publish-add：添加或更新端口映射，与create命令中的格式一样 –publish-rm：通过目标端口删除已发布的端口 –mount-add：新增或更新卷映射配置 –mount-rm：移除卷映射配置 –network-add：添加网络 –network-rm：移除网络 –config-add：添加或者更新服务配置文件 –config-rm：删除服务配置文件 –secret-add：添加或更新机密数据 –secret-rm：删除机密数据 –reserve-memory：配置服务启动需要最少的内存 –reserve-cpu：配置服务启动需要最少的cpu个数 –constraint-add：添加或更新约束 –constraint-rm：删除约束 –placement-pref-add：添加或更新首选项 –placement-pref-rm：删除首选项 –rollback：回滚到之前的版本，不能和update除回滚配置之外的其他命令一起使用，相当于docker service rollback命令 –force：强制更新，update命令有一些参数不会导致启动新的容器，通过这个参数可以强制启动新的容器 update命令也是docker service很重要的命令之一，这里可用的选项没有列全，也没有讲的很详细，但是update命令相关选项可以分布三类，一些是update特有的，如–force、–rollback等，一些是和create命令中的参数配置对于，但是存在更新和移除两种情况的，如–publish-add、–publish-rm等，一些是和create命令中的参数一样的，如–rollback-delay、–update-delay等，这一部分就没有列出来了。 7.8 docker service rollback [OPTIONS] SERVICE 按照回滚配置回滚一个服务，选项如下： -d：后台运行命令 7.9 docker service rm SERVICE [SERVICE…] 移除一个或者多个服务，需要注意的是，该命令不会二次确认，使用的时候请小心。 ———————————————— 原文链接：https://blog.csdn.net/weixin_37648525/article/details/125347670","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"修改MySQL8的密码","slug":"MySQL/修改MySQL8的密码","date":"2024-12-29T02:54:52.000Z","updated":"2024-12-23T02:38:19.335Z","comments":true,"path":"2024/12/29/MySQL/修改MySQL8的密码/","link":"","permalink":"http://www.formeasy.cc/2024/12/29/MySQL/%E4%BF%AE%E6%94%B9MySQL8%E7%9A%84%E5%AF%86%E7%A0%81/","excerpt":"","text":"要在 MySQL8(中修改密码，通常推荐使用 ALTER USER 语句。MySQL8 在安全性和权限管理上进行了改进，因此推荐使用这个方法。下面是详细步骤： 步骤 1: 使用管理员账户登录 MySQL 首先，使用具有足够权限的管理员账户（通常是 root）登录到 MySQL。你可以通过以下命令进入 MySQL 命令行客户端： 1mysql -u root -p 然后输入当前的密码。 步骤 2: 修改密码 在 MySQL 8 中，可以使用 ALTER USER 语句来修改密码。例如，要修改 root 用户的密码，使用以下命令： 1ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;new_password&#x27;; root 是用户名。 localhost 是允许访问的主机名，可以是 localhost 或者是 %（表示允许从任何主机登录）。 'new_password' 是你想要设置的新密码。 步骤 3: 刷新权限 执行完 ALTER USER 命令后，为了确保密码修改立即生效，运行以下命令刷新权限： 1FLUSH PRIVILEGES; 步骤 4: 退出 MySQL 修改密码后，退出 MySQL 命令行： 1exit; 步骤 5: 使用新密码登录 重新登录 MySQL 时，使用你刚刚设置的新密码： 1mysql -u root -p 输入你设定的新密码，应该就能成功登录了。 其他常见情况 1. 修改其他用户的密码 如果你需要修改其他用户的密码，只需将用户名和主机名替换为目标用户。例如，修改 user1 用户的密码： 1ALTER USER &#x27;user1&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;new_password&#x27;; 2. 忘记密码 如果你忘记了 MySQL root 用户的密码，可以通过以下步骤进行重置。这里的步骤假设你拥有操作 MySQL 数据目录和系统权限： 2.1 停止 MySQL 服务 首先，停止 MySQL 服务。 Windows： 1net stop mysql Linux： 1sudo systemctl stop mysql 2.2 启动 MySQL 无密码模式 然后，启动 MySQL 并跳过授权表来允许不需要密码登录。 Windows： 1mysqld --skip-grant-tables Linux： 1sudo mysqld_safe --skip-grant-tables &amp;amp; 2.3 登录 MySQL 接下来，使用以下命令登录 MySQL（不需要密码）： 1mysql -u root 2.4 修改密码 登录 MySQL 后，执行以下命令修改 root 用户的密码： 1ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;new_password&#x27;; 2.5 退出并重启 MySQL 完成密码修改后，退出 MySQL，然后重启 MySQL 服务。 Windows： 1net start mysql Linux： 1sudo systemctl start mysql 2.6 使用新密码登录 现在你应该能够使用新密码登录 MySQL。 1mysql -u root -p 总结 推荐方法：使用 ALTER USER 语句修改密码。 其他用户：修改其他用户密码时，只需替换用户名。 忘记密码：通过跳过授权表重置密码。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"}]},{"title":"【Docker】Dockerfile 文件编写","slug":"Docker/【Docker】Dockerfile 文件编写","date":"2024-12-23T02:18:13.000Z","updated":"2024-12-23T02:37:59.061Z","comments":true,"path":"2024/12/23/Docker/【Docker】Dockerfile 文件编写/","link":"","permalink":"http://www.formeasy.cc/2024/12/23/Docker/%E3%80%90Docker%E3%80%91Dockerfile%20%E6%96%87%E4%BB%B6%E7%BC%96%E5%86%99/","excerpt":"","text":"编写 Dockerfile 是创建 Docker 镜像的核心步骤。Dockerfile 是一个文本文件，其中包含了构建镜像所需的一系列指令和配置。在本文中，我们将详细介绍 Dockerfile 的编写，包括其基本结构、常用指令、优化技巧和示例。 Dockerfile 基本结构 一个典型的 Dockerfile 由一系列指令组成，每个指令定义了镜像构建过程中的一个步骤。常见的指令包括 FROM、RUN、COPY、CMD、EXPOSE 等。 123456789101112131415161718192021222324# 使用的基础镜像FROM ubuntu:20.04# 维护者信息LABEL maintainer=&quot;yourname@example.com&quot;# 设置环境变量 ENV DEBIAN_FRONTEND=noninteractive# 安装依赖和软件包RUN apt-get update &amp;&amp; apt-get install -y curl \\ vim \\ git # 复制文件到镜像COPY . /app# 设置工作目录WORKDIR /app# 暴露端口EXPOSE 8080# 容器启动时运行的命令CMD [&quot;python3&quot;, &quot;app.py&quot;] 常用指令详解 1. FROM FROM 指令用于指定基础镜像。每个 Dockerfile 必须以 FROM 开头。 1FROM &lt;image&gt;[:&lt;tag&gt;] &lt;image&gt;：基础镜像的名称。 &lt;tag&gt;：可选，指定镜像的版本号或标签。 示例 12345# 使用最新版本的 Ubuntu 作为基础镜像FROM ubuntu:latest# 使用 Python 3.9 的官方镜像FROM python:3.9 2. LABEL LABEL 指令用于添加元数据，如维护者信息、版本号等。 1LABEL &lt;key&gt;=&lt;value&gt; [&lt;key&gt;=&lt;value&gt; ...] 示例 123456# 添加维护者信息LABEL maintainer=&quot;yourname@example.com&quot;# 添加版本信息LABEL version=&quot;1.0&quot;LABEL description=&quot;This is a sample application.&quot; 3. ENV ENV 指令用于设置环境变量。 1ENV &lt;key&gt;=&lt;value&gt; 示例 123# 设置环境变量ENV APP_ENV=productionENV DEBUG=false 4. RUN RUN 指令用于在镜像构建过程中执行命令。通常用于安装软件包、执行脚本等。 1RUN &lt;command&gt; &lt;command&gt;：要执行的命令，可以是任何 shell 命令。 示例 12345678# 安装 nginxRUN apt-get update &amp;&amp; apt-get install -y nginx# 运行脚本RUN /path/to/script.sh# 安装 Python 包RUN pip install -r requirements.txt 注意：对于安装多个软件包的情况，通常会将多个命令合并成一条 RUN 指令，以减少构建层数。例如： 12RUN apt-get update &amp;&amp; \\ apt-get install -y nginx curl vim 5. COPY COPY 指令用于将文件或目录从主机复制到镜像中。 1COPY &lt;src&gt; &lt;dest&gt; &lt;src&gt;：要复制的文件或目录的路径。 &lt;dest&gt;：镜像中的目标路径。 示例 12345# 复制当前目录下的所有文件到 /app 目录COPY . /app# 复制特定文件COPY config.yml /etc/myapp/config.yml 6. ADD ADD 指令与 COPY 类似，但支持更多功能，如自动解压 tar 文件和从 URL 下载文件。 1ADD &lt;src&gt; &lt;dest&gt; 示例 12345# 解压文件并复制ADD myapp.tar.gz /usr/src/app# 从 URL 下载文件ADD http://example.com/file.txt /path/in/container 注意：ADD 指令功能强大，但通常推荐使用 COPY 指令，除非需要 ADD 的特殊功能。 7. WORKDIR WORKDIR 指令用于设置工作目录。后续指令（如 RUN、CMD、COPY 等）将在此目录中执行。 1WORKDIR &lt;path&gt; 示例 1# 设置工作目录为 /app WORKDIR /app 8. EXPOSE EXPOSE 指令用于声明容器运行时监听的端口。该指令仅用于文档说明，不会真正地打开端口。 1EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...] &lt;port&gt;：要暴露的端口号。 &lt;protocol&gt;：可选，指定协议（默认是 tcp）。 示例 12345# 暴露端口 80EXPOSE 80# 暴露端口 8080，使用 TCP 协议EXPOSE 8080/tcp 9. CMD CMD 指令用于指定容器启动时执行的命令。每个 Dockerfile 只能有一个 CMD 指令，若有多个 CMD 指令，只有最后一个生效。 1CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 示例 12345678# 使用 shell 形式CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]# 使用 shell 格式CMD nginx -g &quot;daemon off;&quot;# 使用默认命令启动CMD [&quot;python3&quot;, &quot;app.py&quot;] 注意：CMD 指令的内容会被 docker run 命令行参数覆盖。如果需要确保命令执行，可以使用 ENTRYPOINT 指令。 10. ENTRYPOINT ENTRYPOINT 指令用于配置容器启动时运行的主程序。与 CMD 不同，ENTRYPOINT 指令会保持其设置的命令行参数，并将 docker run 命令行参数附加在后面。 1ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 示例 12345# 设置 entrypoint 为 /bin/bashENTRYPOINT [&quot;/bin/bash&quot;]# 使用 exec 格式ENTRYPOINT [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 11. VOLUME VOLUME 指令用于声明挂载点，使数据卷在容器和主机之间共享。 1VOLUME [&quot;&lt;path&gt;&quot;] 示例 12345# 设置 /data 为数据卷VOLUME [&quot;/data&quot;]# 指定多个挂载点VOLUME [&quot;/data&quot;, &quot;/var/lib/mysql&quot;] 12. USER USER 指令用于设置运行后续指令的用户。 1USER &lt;username&gt;[:&lt;group&gt;] 示例 12345# 使用特定用户运行指令USER myuser# 指定用户和组USER myuser:mygroup 13. ARG ARG 指令用于定义构建参数，这些参数在构建时可被传递给 Docker。 1ARG &lt;name&gt;[=&lt;default value&gt;] 示例 12345# 定义构建参数ARG VERSION=1.0# 使用构建参数RUN echo &quot;Building version $VERSION&quot; 构建时可以通过 --build-arg 传递参数： 1docker build --build-arg VERSION=2.0 . 14. HEALTHCHECK HEALTHCHECK 指令用于定义容器内应用的健康检查机制。 1HEALTHCHECK [OPTIONS] CMD &lt;command&gt; CMD &lt;command&gt;：执行检查的命令。 [OPTIONS]：配置检查的选项。 常用选项 --interval=&lt;duration&gt;：设置检查间隔（默认 30s）。 --timeout=&lt;duration&gt;：设置超时时间（默认 30s）。 --retries=&lt;count&gt;：设置失败重试次数（默认 3）。 --start-period=&lt;duration&gt;：初始化启动时间，避免启动初期的检查失败（默认 0s）。 示例 123456# 设置健康检查HEALTHCHECK --interval=30s --timeout=10s --retries=3 \\ CMD curl -f http://localhost/ || exit 1 # 禁用健康检查HEALTHCHECK NONE 15. ONBUILD ONBUILD 指令用于定义一个触发器，当以此镜像为基础构建新的镜像时执行特定指令。 1ONBUILD &lt;instruction&gt; 示例 12# 定义一个触发器，当以此镜像为基础构建时自动执行ONBUILD COPY . /app Dockerfile 示例 示例 1：简单的 Python 应用 下面是一个简单的 Python 应用 Dockerfile 示例： 1234567891011121314151617# 使用官方 Python 3.9 镜像作为基础镜像FROM python:3.9# 设置工作目录WORKDIR /app# 复制当前目录下的所有文件到工作目录COPY . .# 安装依赖RUN pip install -r requirements.txt# 暴露应用端口EXPOSE 5000# 设置容器启动命令CMD [&quot;python&quot;, &quot;app.py&quot;] 示例 2：Node.js 应用 这是一个 Node.js 应用的 Dockerfile 示例： 1234567891011121314151617181920# 使用官方 Node.js 镜像FROM node:14# 设置工作目录WORKDIR /usr/src/app# 复制 package.json 和 package-lock.jsonCOPY package*.json ./# 安装依赖RUN npm install# 复制应用代码COPY . .# 暴露端口EXPOSE 3000# 启动应用CMD [&quot;node&quot;, &quot;server.js&quot;] 示例 3：Nginx 反向代理 这是一个使用 Nginx 作为反向代理的 Dockerfile 示例： 123456789101112# 使用官方 Nginx 镜像FROM nginx:alpine# 复制自定义配置文件到 Nginx 的默认配置目录COPY nginx.conf /etc/nginx/nginx.conf# 暴露 HTTP 和 HTTPS 端口EXPOSE 80EXPOSE 443# 启动 NginxCMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 示例 4：多阶段构建 多阶段构建用于优化镜像体积和构建效率，以下是一个多阶段构建的示例： 1234567891011121314151617181920212223242526# 第一阶段：构建应用FROM golang:1.16 as builder# 设置工作目录WORKDIR /app# 复制源码COPY . .# 编译应用RUN go build -o myapp# 第二阶段：创建最小镜像FROM alpine:latest# 安装必要的依赖RUN apk --no-cache add ca-certificates# 复制编译好的应用COPY --from=builder /app/myapp /usr/local/bin/myapp# 暴露应用端口EXPOSE 8080# 启动应用CMD [&quot;myapp&quot;] Dockerfile 优化技巧 1. 减少镜像体积 使用轻量级基础镜像（如 alpine）。 合并 RUN 指令，减少镜像层数。 删除不必要的文件和缓存。 123456# 使用轻量级镜像FROM node:14-alpine# 合并命令RUN apk add --no-cache curl &amp;&amp; \\ rm -rf /var/cache/apk/* 2. 使用缓存 利用 Docker 缓存加快构建速度。 将不常更改的命令放在 Dockerfile 的上方，以便缓存层次。 12345678# 先复制 package.jsonCOPY package.json ./# 然后安装依赖RUN npm install# 最后复制应用代码COPY . . 3. 安全性 使用非 root 用户运行应用。 定期更新基础镜像和软件包。 12345# 创建非 root 用户RUN groupadd -r myuser &amp;&amp; useradd -r -g myuser myuser# 切换到非 root 用户USER myuser 结论 编写 Dockerfile 是创建 Docker 镜像的核心步骤，了解每个指令的作用和用法可以帮助你更好地构建和优化 Docker 镜像。在实际应用中，你可以根据需求选择合适的基础镜像，合理使用指令，结合优化技巧，构建出高效、安全的 Docker 镜像。希望这篇文章能帮助你更好地理解和编写 Dockerfile。","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"MySQL8启用远程连接","slug":"MySQL/MySQL8启用远程连接","date":"2024-12-19T02:49:43.000Z","updated":"2024-12-23T02:37:16.747Z","comments":true,"path":"2024/12/19/MySQL/MySQL8启用远程连接/","link":"","permalink":"http://www.formeasy.cc/2024/12/19/MySQL/MySQL8%E5%90%AF%E7%94%A8%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"要在 MySQL 8 中启用远程连接，需要执行以下步骤： 1.在 MySQL 8 服务器上，打开 MySQL 配置文件以进行编辑。通常，MySQL 的配置文件位于 /etc/mysql/mysql.conf.d/mysqld.cnf。 使用文本编辑器（例如 nano 或 vim）打开配置文件： sudo nano /etc/mysql/mysql.conf.d/mysqld.cnf 如果 MySQL 配置文件位于不同的位置，请相应地修改路径。 2.找到并编辑 bind-address 选项。将 bind-address 更改为 MySQL 服务器的 IP 地址，或者将其更改为 0.0.0.0 以允许任何 IP 地址连接到服务器。例如： bind-address = 0.0.0.0 这将允许来自任何 IP 地址的远程连接。如果想要限制到特定 IP 地址，请将其替换为相应的 IP 地址。 3.保存并关闭文件。 4.重新启动 MySQL 服务，以便新配置生效： sudo systemctl restart mysql 5.接下来，登录到 MySQL 并掇一个允许远程访问的用户，并为其分配适当的权限。例如，创建一个名为 remoteuser 的用户，分配权限： 123CREATE USER &#x27;remoteuser&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123321&#x27;; GRANT ALL PRIVILEGES ON *.* TO &#x27;remoteuser&#x27;@&#x27;%&#x27; WITH GRANT OPTION;FLUSH PRIVILEGES; 请将 'remoteuser' 替换为希望创建的用户名，'%' 允许从任何主机远程连接，'password' 替换为用户的密码。 6.最后，确保防火墙不阻止 MySQL 的连接请求。根据操作系统和防火墙配置，可能需要更新防火墙规则以允许 MySQL 3306 端口的流量。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"}]},{"title":"Ubuntu20.04版本的NVIDIA显卡驱动程序安装","slug":"NVIDIA/Ubuntu20.04版本的NVIDIA显卡驱动程序安装","date":"2024-12-19T02:43:13.000Z","updated":"2025-04-25T01:08:11.412Z","comments":true,"path":"2024/12/19/NVIDIA/Ubuntu20.04版本的NVIDIA显卡驱动程序安装/","link":"","permalink":"http://www.formeasy.cc/2024/12/19/NVIDIA/Ubuntu20.04%E7%89%88%E6%9C%AC%E7%9A%84NVIDIA%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E5%AE%89%E8%A3%85/","excerpt":"","text":"前言 我在学习深度学习时，在Ubuntu系统下安装NVIDIA显卡驱动踩过了一些坑，浪费了很多的时间，现在想出一个宝宝级的攻略，希望能够帮助大家节约时间，规避一些毒教程的糟粕。 如果大家通过我的攻略安装成功，请在评论区打出“好用“希望能够帮助到更多人。 1.下载NVIDIA官方驱动 官方链接如下: NVIDIA显卡驱动 提醒： 1.由于是外国网站没有“vip”可能会慢一点请耐心等待。 2.这里要准备一个U盘在Windows系统下载后传入Ubuntu的系统，主要是操作方便，避免一些不必要的麻烦。当然你也可以尝试从Ubuntu系统里下载（不建议啊） 1.进入官网 1.查看配置： 控制面板-&gt;硬件和声音-&gt;设备管理器-&gt;显示适配器 查看相关配置。 2.选择配置： 其中前三个选项根据自己的显卡型号来。 后三个选项要根据下方图片进行选择。 开始搜索。 2.下载安装包 1.获取下载 下载最新的版本即可 2.立即下载 3.移动至U盘 将下载后的安装包移至U盘传入到Ubuntu系统的主目录下。 2.安装NVIDIA官方驱动 1.设置BIOS 将电脑重启，重启过程中一直按住F2键进入bios界面（联想拯救者是这个按键，若是不同品牌要先查询一下对应按键） 找到Security将secure boot关闭（一定要进行这一步）否则在后续的安装时会要求咱们对驱动程序进行签名之类的操作，大大增加了安装的繁琐程度和失败的可能性。（不过我相信安装双系统的时候大家已经将该设置关闭了，不过为了以防万一请大家再次进入确认一下） 按F10保存并退出。 进入Ubuntu系统。 2.执行相关操作 1.找到传入ubuntu的驱动文件 右键在终端进行打开。 添加执行权限。 1chmod +x (该文件名) 输入NV之后按下Tab键它会自动补齐。输入密码开始安装。 2.运行安装程序 在目标文件夹下打开终端输入： 1sudo bash （对应的软件包名称）(NV.....用Tab键自动补齐) 3.执行相关权限 continue-&gt;yes-&gt;ok 3.重启电脑确认驱动是否安装 打开终端输入命令： 1nvidia-smi 进入如下界面代表您已经安装成功了。 ———————————————— 原文链接：https://blog.csdn.net/2301_76831056/article/details/143232570","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://www.formeasy.cc/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"},{"name":"NVIDIA","slug":"NVIDIA","permalink":"http://www.formeasy.cc/tags/NVIDIA/"}]},{"title":"Ubuntu20.04安装docker教程(在线)","slug":"Docker/Ubuntu20.04安装docker教程(在线)","date":"2024-12-16T08:16:23.000Z","updated":"2024-12-23T02:45:00.427Z","comments":true,"path":"2024/12/16/Docker/Ubuntu20.04安装docker教程(在线)/","link":"","permalink":"http://www.formeasy.cc/2024/12/16/Docker/Ubuntu20.04%E5%AE%89%E8%A3%85docker%E6%95%99%E7%A8%8B(%E5%9C%A8%E7%BA%BF)/","excerpt":"","text":"在 Ubuntu20.04 上安装 Docker Engine 的详细步骤如下： 1. 卸载旧版本 首先，卸载可能与 Docker Engine 冲突的非官方包： 1for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done 2. 设置 Docker 的 apt 仓库 更新包列表： 1sudo apt-get update 安装依赖包： 1sudo apt-get install ca-certificates curl 添加 Docker 官方 GPG 密钥： 123sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.asc 添加 Docker 仓库到 apt 源： 1234echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 更新包列表： 1sudo apt-get update 3. 安装Docker包 安装最新版本的 Docker Engine： 1 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 如果安装过程中有部分下载失败，可以手动在hosts文件中添加download.docker.com的IP地址，并配置resolv.conf文件。 4.配置镜像加速器 打开daemon.json文件 1sudo nano /etc/docker/daemon.json 更改为以下内容并保存（ctrl+o保存，ctrl+x退出）： 123456789101112131415&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub.rat.dev&quot;, &quot;https://docker.1panel.live&quot;, &quot;https://docker.m.daocloud.io&quot;, &quot;https://dockerproxy.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://docker.nju.edu.cn&quot;, &quot;https://iju9kaj2.mirror.aliyuncs.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://cr.console.aliyun.com&quot;, &quot;https://hub.docker.com&quot;, &quot;http://mirrors.ustc.edu.cn&quot; ]&#125; 重启docker服务 12sudo systemctl daemon-reloadsudo systemctl restart docker 5. （可选）可以避免每次都添加sudo 创建 docker用户组（如果尚未创建）： 1sudo groupadd docker 将当前用户添加到 `docker` 组： 1sudo usermod -aG docker $USER 重新加载用户组： 1newgrp docker 6. 验证安装 运行 `hello-world` 镜像： 12sudo docker pull hello-worldsudo docker run hello-world 也可以直接sudo docker run hello-world，此命令会自动下载测试镜像并在容器中运行它。 出现以下内容即成功: 1234567891011121314151617181920xxx@xxxx:~$ docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub(amd64) 3.The Docker daemon created a new container from that image which runs theexecutable that produces the output you are currently reading. 4.The Docker daemon streamed that output to the Docker client, which sent itto your terminal.To try something more ambitious, you can run an ubuntu container with:S docker run it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas,visit: https://docs.docker.com/get-started/","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"}]},{"title":"Ubuntu20.04系统中安装Docker(离线)","slug":"Docker/Ubuntu20.04系统中安装Docker(离线)","date":"2024-12-16T05:38:13.000Z","updated":"2025-04-25T00:55:34.697Z","comments":true,"path":"2024/12/16/Docker/Ubuntu20.04系统中安装Docker(离线)/","link":"","permalink":"http://www.formeasy.cc/2024/12/16/Docker/Ubuntu20.04%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%AE%89%E8%A3%85Docker(%E7%A6%BB%E7%BA%BF)/","excerpt":"","text":"一、更换源 从软件更新中设置，自行选择最佳服务器，完成后执行：sudo apt-get update 二、Nvidia驱动安装 检查驱动安装 1nvidia-smi 如果显示以下界面，则驱动状态正常。 若没有安装驱动则首先需要安装。输入以下指令，可以查看支持的驱动版本。 1ubuntu-drivers devices ubuntu系统显卡的驱动安装是比较容易出问题的地方，一般有三种方式。 （1）从软件更新中选择驱动安装 选择合适的驱动，应用更改，等待下载安装即可。需要一段时间。 （2）使用指令安装，假设选择上图中可用的 nvidia-utils-470 驱动，执行 1sudo apt install nvidia-utils-470 （3）驱动文件包安装 通过 Nvidia驱动官网： 下载 NVIDIA 官方驱动 | NVIDIA 选择下载适配自己显卡的驱动。 下载后执行指令安装 1sudo sh NVIDIA-Linux-x86_64-470.256.02.run 三、Docker安装 Docker Engine安装参考：https://docs.docker.com/engine/install/ubuntu/ （1）配置Docker的apt仓（需要科学上网，如果无法科学上网，还有离线安装的方法） 1234567891011121314# Add Docker&#x27;s official GPG key:sudo apt-get updatesudo apt-get install ca-certificates curlsudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.asc# Add the repository to Apt sources:echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update （2）安装Docker包 1sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin （3）hello-world验证，完成安装 1sudo docker run hello-world 如果在第（1）步的最后执行 sudo apt-get update 时报 download.docker.com 443 无法连接，则可以离线下载这些安装包安装： （1）去网址：https://download.docker.com/linux/ubuntu/dists/ （2）在列表中选择你的Ubuntu版本，以Ubuntu 20.04为例，输入查看指令后选择 focal 1lsb_release -a （3）进入到 /pool/stable 路径下，确定你的应用架构。我选 amd64 （4）需要下载的以下几个deb安装文件，版本（可选最新）和架构（不能错）都确认好。 12345containerd.io_&lt;version&gt;_&lt;arch&gt;.debdocker-ce_&lt;version&gt;_&lt;arch&gt;.debdocker-ce-cli_&lt;version&gt;_&lt;arch&gt;.debdocker-buildx-plugin_&lt;version&gt;_&lt;arch&gt;.debdocker-compose-plugin_&lt;version&gt;_&lt;arch&gt;.deb （5）下载到一个文件夹下后，终端进入该文件夹，执行安装 1sudo dpkg -i *.deb （6）hello-world验证，完成安装 12sudo service docker startsudo docker run hello-world 四、安装Nvidia容器工具包 1、通过Apt安装 （1）配置下载仓 1234curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed &#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list （2）执行更新 1sudo apt-get update （3）安装Nvidia容器工具包 1sudo apt-get install -y nvidia-container-toolkit 2、配置Docker （1）使用 nvidia-ctk 指令配置容器 1sudo nvidia-ctk runtime configure --runtime=docker （2）重启Docker进程 1sudo systemctl restart docker 五、docker去掉sudo docker刚安装完，执行指令时都是需要sudo docker，去除如下： 1234567891011121314#（1）查看用户组及成员sudo cat /etc/group | grep docker #（2）添加docker组sudo groupadd docker #（3）添加用户到docker组sudo gpasswd -a $&#123;USER&#125; docker #（4）增加读写权限sudo chmod a+rw /var/run/docker.sock #（5）重启dockersudo systemctl restart docker","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"Ubuntu 20.04 系统安装Docker及nvidia-docker2","slug":"Docker/Ubuntu 20.04 系统安装Docker及nvidia-docker2","date":"2024-12-16T02:14:42.000Z","updated":"2024-12-23T02:47:04.662Z","comments":true,"path":"2024/12/16/Docker/Ubuntu 20.04 系统安装Docker及nvidia-docker2/","link":"","permalink":"http://www.formeasy.cc/2024/12/16/Docker/Ubuntu%2020.04%20%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85Docker%E5%8F%8Anvidia-docker2/","excerpt":"","text":"Excerpt Ubuntu 20.04 系统安装Docker及nvidia-docker2安装Docker卸载之前的Docker环境如果之前已经安装了老版本 Docker，那么在安装新版本Docker之前需要将其先卸载。sudo apt-get remove docker docker-engine docker.io… 安装Docker 卸载之前的Docker环境 如果之前已经安装了老版本Docker，那么在安装新版本Docker之前需要将其先卸载。 1sudo apt-get remove docker docker-engine docker.io containerd runc 需要注意的是，用这种方法不能把之前存在的镜像、容器及其他数据清理。如果想完全清理掉之前的数据，可以执行下面的几行命令： 123sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-pluginsudo rm -rf /var/lib/dockersudo rm -rf /var/lib/containerd 安装Docker 配置apt仓库 1234567sudo apt-get updatesudo apt-get install ca-certificates curl gnupg lsb-releasesudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 安装最新版本Docker 12sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 验证Docker环境是否安装成功 1sudo docker run hello-world 如果显示以下信息，则表示安装成功： 1234567891011121314151617181920212223Unable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world2db29710123e: Pull completeDigest: sha256:94ebc7edf3401f299cd3376a1669bc0a49aef92d6d2669005f9bc5ef028dc333Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps:1. The Docker client contacted the Docker daemon.2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64)3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading.4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with:$ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID:https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 安装nvidia-docker2 安装Docker环境 如果还没有安装Docker环境，那么需要先安装一下，可以使用下面的命名通过官方的便捷脚本进行安装，也可以通过上文的方法用apt命令安装。 12curl https://get.docker.com | sh \\&amp;&amp; sudo systemctl --now enable docker 安装nvidia-docker2 配置apt仓库 12345distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\ &amp;&amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\ sed &#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list 安装nvidia-docker2包 12sudo apt-get updatesudo apt-get install -y nvidia-docker2 安装完成后需要重启Docker: 1sudo systemctl restart docker 验证是否安装成功 1sudo docker run --rm --gpus all nvidia/cuda:11.6.2-base-ubuntu20.04 nvidia-smi 执行上面的命令，如果显示跟下面类似的内容，说明nvidia-docker2已经安装成功。 12345678910111213141516171819Fri Jan 6 01:20:11 2023 +-----------------------------------------------------------------------------+| NVIDIA-SMI 470.129.06 Driver Version: 470.129.06 CUDA Version: 11.6 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA GeForce ... Off | 00000000:01:00.0 Off | N/A || N/A 45C P8 1W / N/A | 376MiB / 3911MiB | 19% Default || | | N/A |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|+-----------------------------------------------------------------------------+","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"MySQL、PostgreSQL、ClickHouse、MongoDB区别，适用场景","slug":"MySQL/MySQL、PostgreSQL、ClickHouse、MongoDB区别，适用场景","date":"2024-12-15T07:32:25.000Z","updated":"2025-04-25T01:01:45.953Z","comments":true,"path":"2024/12/15/MySQL/MySQL、PostgreSQL、ClickHouse、MongoDB区别，适用场景/","link":"","permalink":"http://www.formeasy.cc/2024/12/15/MySQL/MySQL%E3%80%81PostgreSQL%E3%80%81ClickHouse%E3%80%81MongoDB%E5%8C%BA%E5%88%AB%EF%BC%8C%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"关于数据库，大学时候我们只知道MySQL，稍微深入点再加上Redis、MongoDB等非关系型数据库。然而，进入公司接手一个项目，发现其中用到多种数据库，每种数据库都有自身的优势和局限性，故在此梳理下日常常用数据库、对应区别以及各自的适用场景。 mysql、postgresql、clickhouse、mongodb有什么区别，各自适合在什么场景下使用 一、常用数据库概览 1.1 关系型数据库 关系型数据库通常是业务型项目的主力数据库，原因以下： 方便业务建模，表的关系和业务之间的关联是类似的 数据一致性，关系型数据库一般支持ACID特性，可用于核心业务场景的数据持久化 关系型数据库的基本单位是表，表与表之间通过键关联，比如学生表和班级表，可以通过班级ID，把学生和班级关联起来。 关系型数据库的经典代表：MySQL、Orcle、PostgreSQL、SQLite等。 1.2 非关系型数据库 非关系型数据库其实只是一个比较笼统的叫法，实际分类下有非常多，这里只介绍键值对、文档、列式存储、图形结构等几种。 1.2.1 KV数据库 KV数据库以键值对的形式存储数据，常见底层数据结构实现是哈希表，读数据复杂度是O(1)。 key value name jw score {chinese:90, math:99} key-value存储的数据通常单个key-value就是一个条独立的数据，很方便水平扩展，可以根据key散列到不同的分片，且读的性能极好，因此常用于做缓存。 经典代表有Redis、Memcached和LevelDB等。 1.2.2 文档型数据库 文档型数据库的数据以文档的形式存储数据，每个文档类似一个JSON对象。 比于KV存储，文档型数据库同样对水平扩展友好，且具有更好的查询性能，支持复杂查询，而KV存储几乎只通过key来读取数据。 经典的文档型数据库有MongoDB、CouchDB和Elasticsearch等。 1.2.3 列式存储数据库 经典的列式存储数据库有HBase、Druid、ClickHouse等，不同列式数据库的底层实现差别挺大的，它们的共同点是按列存储。 比如说MySQL存一个学生信息，有学号和姓名等，这两个字段在同一行，存放也是在一起的；但是列式数据库会按列划分存储，把学号和姓名分开存储，相同的数据类型有利于进行数据压缩、聚合操作等。 下面是HBase的一条数据组成解析，一个Row Key（行键）下有多个Column Family（列族），列族下面有Column Qualifier（列限定符），最后会根据设置保存若干个版本，形成Timestamp/version: Cell Value的键值对。这里我们只需要知道不同的列族是分开存储的就行了。 1.2.4 图数据库 图数据库的基本单元是点和边，经典的图数据库包括Neo4j、OrientDB、TigerGraph等。 简单来说点表示实体，而边则表示实体间的关系，组成一个整体后，可以形成知识图谱、社交网络、金融风控网络等。 比如存储了上图关系，可以直接查询关注了豆小匠Coding的用户： 1MATCH (user:User &#123;name: &#x27;豆小匠Coding&#x27;&#125;)&lt;-[:FOLLOWS]-(follower:User) RETURN follower.name 上述查询使用了 Neo4j 的图查询语言 Cypher。它首先通过 MATCH 子句找到名为豆小匠的用户节点 user，然后通过 -[:FOLLOWS]-&gt; 关系查找所有关注了该用户的节点 follower。最后，通过 RETURN 子句返回关注者的姓名。 1.3 SQL与NoSQL区别 NoSql是相对于传统关系型数据库而言，有很大差异的一种数据库。 1.3.1 结构化与非结构化 传统关系型数据库是结构化数据，每一张表都有严格的约束信息：字段名、字段数据类型、字段约束等等信息，插入的数据必须遵守这些约束： 而NoSql则对数据库格式没有严格约束，往往形式松散，自由。 可以是键值型： 也可以是文档型： 甚至可以是图格式： 1.3.2 关联和非关联 传统数据库的表与表之间往往存在关联，例如外键： 而非关系型数据库不存在关联关系，要维护关系要么靠代码中的业务逻辑，要么靠数据之间的耦合： 1&#123; id: 1, name: &quot;张三&quot;, orders: [ &#123; id: 1, item: &#123; id: 10, title: &quot;荣耀6&quot;, price: 4999 &#125; &#125;, &#123; id: 2, item: &#123; id: 20, title: &quot;小米11&quot;, price: 3999 &#125; &#125; ] &#125; 此处要维护“张三”的订单与商品“荣耀”和“小米11”的关系，不得不冗余的将这两个商品保存在张三的订单文档中，不够优雅。还是建议用业务来维护关联关系。 1.3.3 查询方式 传统关系型数据库会基于Sql语句做查询，语法有统一标准； 而不同的非关系数据库查询语法差异极大，五花八门各种各样。 1.3.4 事务 传统关系型数据库能满足事务ACID的原则。 而非关系型数据库往往不支持事务，或者不能严格保证ACID的特性，只能实现基本的一致性。 1.3.5 总结 除了上述四点以外，在存储方式、扩展性、查询性能上关系型与非关系型也都有着显著差异，总结如下： 存储方式 关系型数据库基于磁盘进行存储，会有大量的磁盘IO，对性能有一定影响 非关系型数据库，他们的操作更多的是依赖于内存来操作，内存的读写速度会非常快，性能自然会好一些 扩展性 关系型数据库集群模式一般是主从，主从数据一致，起到数据备份的作用，称为垂直扩展。 非关系型数据库可以将数据拆分，存储在不同机器上，可以保存海量数据，解决内存大小有限的问题。称为水平扩展。 关系型数据库因为表之间存在关联关系，如果做水平扩展会给数据查询带来很多麻烦 二、MySQL 类型：关系型数据库管理系统（RDBMS） 特点： 开源：广泛使用，社区支持丰富。任何人都可以获取并使用它的源代码，这为开发者提供了很大的灵活性，因为他们可以按照自己的需求定制数据库系统 成熟稳定：经过长时间的发展，性能和稳定性都非常好。MySQL具有优秀的性能，特别是在读取操作方面。它可以处理大量的数据，并支持高并发用户连接 ACID事务支持：支持事务处理，保证数据的一致性和完整性。 索引优化：支持多种索引类型，查询性能优秀。 可扩展性：MySQL支持各种扩展功能，如分区、复制和分片等，这使得它能够处理大规模的数据和复杂的业务需求 轻量级：资源占用相对较少，适合中小型项目。 支持多种数据类型，如整数、浮点数、字符、日期和时间等；拥有不同的存储引擎，如InnoDB和MyISAM，分别适用于不同的应用场景；支持分区功能，可以优化大数据量的存储和访问性能 适用场景： Web应用：如博客、论坛、电子商务网站等。 中小企业：适合中小企业的数据管理和存储需求。 OLTP系统：在线事务处理系统，需要频繁的读写操作。 MySQL 对于复杂条件查询的支持并不好。MySQL 最多使用一个条件涉及的索引来过滤，然后剩余的条件只能在遍历行过程中进行内存过滤，对这个过程不了解的同学可以先行阅读一下MySQL 复杂 where 语句分析 上述这种处理复杂条件查询的方式因为只能通过一个索引进行过滤，所以需要进行大量的 I/O 操作来读取行数据，并消耗 CPU 进行内存过滤，导致查询性能的下降。 缺点： 写入性能：虽然MySQL在读取操作方面表现出色，但在处理大量写入操作时可能会遇到性能瓶颈。这可能导致在高并发写入场景下性能下降。 复杂查询性能：对于复杂查询，MySQL可能没有一些**专门的数据库系统（如PostgreSQL）**表现得那么出色。这可能会在处理复杂的SQL查询时影响到性能。 功能丰富度：相比一些其他的数据库系统，MySQL的功能丰富度可能稍显不足。例如，它在全文搜索、数据完整性约束等方面可能没有一些专门的数据库系统那么强大。 最大连接数：MySQL的最大连接数相对较小，这可能会限制并发用户连接的数量。 三、PostgreSQL 3.1 特点、适用场景 类型：关系型数据库管理系统（RDBMS） 特点： 高级特性：支持大部分的SQL标准，并提供了很多其他现代特性，如复杂查询、外键、触发器、视图、事务完整性、多版本并发控制等高级特性 扩展性强：支持多种扩展，如全文搜索、地理空间数据处理等。 可定制性：高度可定制，支持用户自定义数据类型和函数。 ACID事务支持：强一致性和事务支持。 开源：社区活跃，文档丰富。 适用场景： 复杂查询：需要执行复杂查询和分析的场景。 大数据量：适合处理大规模数据集。如物联网和大数据场景 企业级应用：需要高可靠性和一致性的企业级应用。适用于金融系统，可以确保数据的一致性和完整性 地理信息系统：支持地理空间数据处理，适合GIS应用。 3.2 MySQL与PostgreSQL对比 MySQL和PostgreSQL是两种常见的关系型数据库管理系统（RDBMS），它们都具有强大的功能和广泛的社区支持，但在某些方面存在一些差异，包括特点、性能、扩展性、安全性以及适用场景等方面。 3.2.1 特点比较 MySQL特点 MySQL 是一个基于客户端-服务器架构的开源数据库管理系统，由 Oracle 公司开发和维护。它以其简单性、易用性和高性能而闻名 MySQL 支持多种存储引擎，包括 InnoDB、MyISAM、MEMORY 等。每个存储引擎都具有不同的特性和优化策略，可以根据需求选择合适的引擎 MySQL 在处理大量读操作时表现良好，并且适用于数据存储和读取需求较高的应用场景 PostgreSQL特点 PostgreSQL 是一个开源对象-关系数据库管理系统，具有强大的功能和高度可扩展性。它以其灵活性、丰富的数据类型和高级特性而受到开发者的青睐。 PostgreSQL 支持复杂的数据类型，如数组、JSON、XML 等，并提供了丰富的内置函数和操作符，使得数据处理更加灵活和方便。 PostgreSQL 采用 MVCC（多版本并发控制）技术来处理并发访问，支持高度并发的应用场景。 PostgreSQL 对完整性约束和事务处理提供了强大的支持，使得数据的一致性和可靠性得到保证。 3.2.2 性能比较 性能是选择数据库的关键因素之一。以下是 MySQL 和 PostgreSQL 在性能方面的比较 MySQL性能 MySQL 在处理大量读操作时表现出色。其存储引擎 InnoDB 提供了行级锁定和高效的事务处理，适用于并发读取的场景 MySQL 通过查询缓存来提高读取性能。查询缓存可以缓存查询结果，避免重复执行相同的查询语句 MySQL 在处理简单查询和大量连接时表现出色，适用于 Web 应用程序和许多小型数据库的场景 PostgreSQL特点 PostgreSQL 在处理复杂查询和大量写操作时表现出色。它通过优化查询执行计划和索引来提高查询性能 PostgreSQL 采用 MVCC 技术，使得并发访问时不会出现阻塞和冲突，从而提供了更好的并发处理性能 PostgreSQL 在处理复杂查询和具有复杂数据类型的操作时表现出色。它的查询优化器可以智能地选择最佳执行计划，并且支持各种索引类型和高级查询功能 需要注意的是，性能比较是一个复杂的主题，受到多个因素的影响，如硬件配置、数据量、查询类型和索引设计等。因此，具体的性能表现可能因实际情况而异。在选择数据库时，建议进行基准测试和性能优化，以确保最佳性能 3.2.3 扩展性比较 扩展性是一个重要的考虑因素，特别是在应对数据量增长和并发访问增加的情况下。以下是 MySQL 和 PostgreSQL 在扩展性方面的比较： MySQL扩展性 MySQL 在水平扩展方面表现良好。它支持主从复制和分片技术，可以将数据分布在多个服务器上，以提高读写性能和容量 MySQL 还支持基于触发器和存储过程的复杂业务逻辑，可以将一些计算任务和业务逻辑转移到数据库服务器上进行处理 PostgreSQL扩展性 PostgreSQL 在水平扩展方面也表现良好。它支持流复制和逻辑复制，可以将数据复制到多个节点上，以实现负载均衡和高可用性 PostgreSQL 还支持分区表和并行查询，可以更好地处理大型数据集和复杂查询 需要注意的是，扩展性是一个综合问题，还需要考虑硬件资源、网络拓扑、负载均衡等因素。选择适当的扩展策略和架构设计对于实现高性能和可扩展的数据库系统至关重要。 3.2.4 安全性比较 安全性是数据库管理的重要方面。以下是 MySQL 和 PostgreSQL 在安全性方面的比较： MySQL安全性 MySQL 提供了基本的安全功能，如用户认证、访问控制和加密传输。可以使用用户名和密码进行身份验证，并根据用户的权限控制数据库和表的访问 MySQL 支持 SSL/TLS 加密协议，可以通过配置 SSL 证书来保护数据传输的安全性 PostgreSQL安全性 PostgreSQL 提供了丰富的安全功能，如强大的身份认证和访问控制机制。它支持基于角色的访问控制 (RBAC) 和细粒度的权限管理，可以为用户和组分配不同的权限级别 PostgreSQL 提供了行级别的安全性，可以在表的行级别上定义访问控制规则，以实现更细粒度的数据保护 PostgreSQL 支持加密存储和传输，可以使用 SSL/TLS 加密协议来保护数据的安全性 PostgreSQL 提供了高级的审计功能，可以记录用户操作和数据库变更的日志，以实现安全审计和故障排除 需要注意的是，无论是 MySQL 还是 PostgreSQL，在安全性方面都需要合理配置和管理。这包括设置强密码、定期更新软件补丁、限制网络访问和备份数据等措施，以保护数据库免受潜在的安全威胁。 3.2.5 适用场景比较 MySQL 和 PostgreSQL 在功能和性能上的差异使得它们在不同的场景下具有不同的优势。以下是它们的适用场景比较 MySQL适用场景 MySQL 适用于需要处理大量读操作的应用，如 Web 应用程序、电子商务网站和博客平台等。它的简单性和高性能使得它成为许多小型和中型项目的首选 MySQL 还适用于需要大规模水平扩展和高可用性的应用场景。它的主从复制和分片技术可以提供更好的性能和容量 PostgreSQL适用场景 PostgreSQL 适用于需要复杂数据类型和高级特性的应用，如地理信息系统 (GIS)、大数据分析和科学研究等。它的灵活性和丰富的功能使得它成为处理复杂数据和查询的首选 PostgreSQL 还适用于需要高度并发和可扩展性的应用场景，如金融交易系统、物联网应用和大型企业解决方案 需要根据具体的业务需求和项目规模来选择适合的数据库。如果对数据库的简单性和性能要求较高，可以选择 MySQL。如果需要更复杂的数据类型和功能，以及高度并发和可扩展性，可以选择 PostgreSQL。 3.2.6 补充 1、数据模型和特性： MySQL：MySQL是一种基于客户端-服务器架构的数据库系统，它采用了主要使用SQL的关系型数据模型。支持ACID（原子性、一致性、隔离性、持久性）事务，并提供了多种存储引擎，如InnoDB、MyISAM等，可以根据需求选择适当的存储引擎。MySQL也具有较好的可扩展性和性能。 PostgreSQL：PostgreSQL也是一种关系型数据库管理系统，支持SQL语言和ACID事务。与MySQL相比，PostgreSQL提供了更丰富的数据类型、更强大的功能和更高效的扩展性。它支持复杂的查询、触发器、视图、存储过程、自定义函数、地理空间数据和全文搜索等。 2、适用场景 MySQL：MySQL通常用于web应用程序、小型到中型规模的数据存储需求，以及需要快速读取和写入的场景。它在处理大量事务和高并发方面表现良好，也适合用于数据驱动型应用程序。 PostgreSQL：PostgreSQL 适用于需要高级功能、复杂查询和更严格数据完整性的场景。它在数据分析、地理信息系统、科学研究和大型企业应用程序等领域广泛使用。 3、扩容成本 MySQL ：在MySQL中，扩容的成本相对较低。可以通过水平扩展（例如，使用主从复制或分片）来增加系统的处理能力和存储容量。MySQL的生态系统非常丰富，有许多工具和解决方案可供选择，支持高可用性和负载均衡。 PostgreSQL：PostgreSQL的扩容成本相对较高。由于其高级功能和复杂性，需要更多的配置和管理工作。扩展PostgreSQL可能涉及到分区、复制、并行查询等技术，需要更多的资源和专业知识。 3.3 小节 MySQL 和 PostgreSQL 都是强大的关系型数据库管理系统，具有各自的特点和优势。MySQL 简单易用、性能优越，适用于处理大量读操作和小型项目；而 PostgreSQL 强大灵活、具备丰富的数据类型和高级特性，适用于处理复杂数据和大型项目。 四、ClickHouse 4.1 特点、适用场景 类型：列式存储数据库 特点： 高性能：专为OLAP（在线分析处理）设计，查询速度非常快。 列式存储：数据按列存储，适合大规模数据分析。 支持水平扩展和分布式部署：支持分布式部署，水平扩展能力强。 实时分析：支持实时数据处理和分析。 开源：社区活跃，文档丰富。 支持快速处理大规模数据并支持高并发查询；具有数据冗余和自动故障转移功能，保证数据的安全性和可靠性 适用场景： 大数据分析、日志分析、实时数据处理和数据仓库等场景 大数据分析：适合处理大规模数据集，进行实时分析和报表生成 日志分析：适合处理日志数据，进行监控和分析 BI系统：商业智能系统，需要快速响应复杂的分析查询。 物联网：处理大量传感器数据，进行实时监控和分析。 适用于需要高性能、高可靠性和低延迟查询的数据处理任务 优异的性能和实时分析能力 ClickHouse的性能特点： 列式存储：ClickHouse采用了列式存储，对于聚合查询和数据分析非常有效。 数据压缩：ClickHouse具有高效的数据压缩机制，可以显著减少存储空间和I/O开销。 分布式处理：ClickHouse支持分布式部署，能够处理大规模数据集。 ClickHouse的数据分析 ClickHouse则专注于数据分析场景，特别是对于在线分析处理（OLAP）任务。它支持SQL查询，具有高效的列式存储和压缩机制，适用于执行复杂的聚合查询 4.2 ClickHouse与MySQL的适用场景对比 ClickHouse和MySQL是两种完全不同的数据库系统。 MySQL的适用场景：MySQL适用于事务处理，如网站后台、订单处理、用户管理等场景。它支持ACID事务、一致性以及丰富的SQL功能。 ClickHouse的适用场景：ClickHouse则更适合于数据分析、报表生成、实时监控等场景。它支持高速的数据导入和查询，适用于处理大规模数据集。 clickhouse 不支持事务、不存在隔离级别，其定位是分析性数据库 OLAP系列，count()有天然优势；MongoDB最初不支持，4.0支持事务 ACID。 五、MongoDB 5.1 特点、适用场景 类型：NoSQL文档数据库（数据模式不固定、结构可以不同） 特点： 文档存储：以JSON-like的二进制文档格式（BSON格式）存储数据，灵活性高。数据模式不固定、结构可以不同 水平扩展：支持分片，容易水平扩展。 高性能：读写性能优秀，适合高并发场景。 动态模式：支持动态模式，无需预先定义表结构。 丰富的查询语言：支持复杂的查询操作，如聚合、排序、分组等。 具备灵活的文档模型、强大的查询能力和水平扩展性；支持数据分片、高可用性和地理空间索引等功能 适用场景： 适用于需要灵活的数据模型、快速开发迭代、大规模数据处理和高可用性需求的应用场景 如内容管理系统（CMS）、大数据应用、实时分析与日志数据处理、电子商务系统、物联网（IoT）应用、社交网络平台和云计算等 内容管理系统：如博客、新闻网站等，需要存储和检索大量非结构化数据。 实时分析：适合处理实时数据流，进行实时分析。 物联网：处理大量传感器数据，存储和检索非结构化数据。 社交媒体：适合存储和检索用户生成的内容，如帖子、评论等。 缓存层：作为缓存层，提高应用性能。 使用 MongoDB 时，数据模式不是固定的。在一个集合内部删除或修改文档的某些属性是可行的，这就提供了很大的灵活性。而且，同一集合内的文档，其结构可以是完全不同的。 在 MongoDB 中，数据是以类似于 JSON 文件的名值对形式存在的，因其模式设计，它对数据的约束条件较少。因此如果数据是快速变化的，MongoDB 就很有优势。另外，MongoDB 还提供了预定义的结构，如果需要也可以使用 5.2 MySQL与MongoDB对比 MongoDB 是一种文档型数据库，由于它不限制数据量和数据类型，它是高容量环境下最合适的解决方案。由于 MongoDB 具备云服务需要的水平可伸缩性和灵活性，它非常适合云计算服务的开发。另外，它降低了负载，简化了业务或项目内部的扩展，实现了高可用和数据的快速恢复。 尽管 MongoDB 有那么多优点，但 MySQL 也在某些方面优于 MongoDB，例如可靠性和数据一致性。另外，如果优先考虑安全性，MySQL 就是安全性最高的 DBMS 之一。 而且，当应用程序需要把多个操作视为一个事务（比如会计或银行系统）时，关系数据库是最合适的选择。除了安全性，MySQL 的事务率也很高。实际上，MongoDB 支持快速插入数据，而 MySQL 相反，它支持事务操作，并关注事务安全性。 六、总结 6.1 四种数据库适用场景 MySQL：适合中小型企业、Web应用、OLTP系统（事务处理，可靠、数据一致性、安全性；复杂条件查询较差） PostgreSQL：适合复杂查询、大数据量、企业级应用、地理信息系统 ClickHouse：适合大数据分析、日志分析、BI系统、物联网（实时分析、高并发查询） MongoDB：适合内容管理系统、实时分析、物联网、社交媒体、缓存层（数据模型灵活，大规模数据处理） 选择哪种数据库取决于你的具体需求，包括数据规模、查询复杂度、性能要求、扩展性等因素。 6.2 场景专用数据库 随着业务的复杂，我们会发现不同场景下对数据库的要求差异会很大： 一致性优先，选用关系型数据库。 高性能全文搜索，使用Elasticsearch。 非关键数据，读多写少，量大，选用列式存储。 离线数据分析，Hive。 6.3 补充——MySQL遇到瓶颈 如果是单机MySQL遭遇性能瓶颈，可以通过主从架构读写分离，堆机器的方式解决，另一个方向是增加缓存，如Redis等，减少打到物理存储的请求量。 如果是数据量太大，单表查询性能下降，可以考虑分库分表，但是分库分表在开发时需要考虑更多分布式事务、水平扩展等因素，对研发效率有影响。因此，这个时候可以考虑使用分布式数据库，如TiDB等。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://www.formeasy.cc/tags/PostgreSQL/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://www.formeasy.cc/tags/ClickHouse/"},{"name":"MongoDB区别","slug":"MongoDB区别","permalink":"http://www.formeasy.cc/tags/MongoDB%E5%8C%BA%E5%88%AB/"}]},{"title":"安装Nvidia-Docker","slug":"Docker/安装Nvidia-Docker","date":"2024-12-13T03:14:25.000Z","updated":"2024-12-23T02:48:07.729Z","comments":true,"path":"2024/12/13/Docker/安装Nvidia-Docker/","link":"","permalink":"http://www.formeasy.cc/2024/12/13/Docker/%E5%AE%89%E8%A3%85Nvidia-Docker/","excerpt":"","text":"Docker 和 NVIDIA Docker（nvidia-docker）可以同时存在于同一系统中，并且通常是这样配置的。 NVIDIA Docker 是在标准 Docker 的基础上添加的一个扩展，使得 Docker 容器可以访问 NVIDIA GPU。 检查 NVIDIA Docker 组件是否已安装 可以使用以下命令来检查 nvidia-container-toolkit 或 nvidia-docker2 是否已安装： 对于Ubuntu，使用: 1dpkg -l | grep nvidia-docker 或者： 1dpkg -l | grep nvidia-container-toolkit 下面是一些关于这两者关系和安装方式的详细解释： NVIDIA Docker 是什么？ NVIDIA Docker（特别是 nvidia-docker2 或 NVIDIA Container Toolkit）不是替代 Docker 的独立应用，而是一套工具和插件，使得 Docker 容器能够以支持 CUDA 和其他 NVIDIA 库的方式，安全地访问宿主机上的 NVIDIA GPU。这是通过特殊的 runtime，即 nvidia-container-runtime 实现的。 安装 NVIDIA Docker 在已有 Docker 的系统上安装 NVIDIA Docker 实际上就是在安装一个额外的组件，而不是替换或移除现有的 Docker 安装。以下是安装步骤的概览： 1.确认 Docker 已安装： 确保 Docker 已经安装并运行在你的系统上。可以通过运行 docker version 来检查。 2.安装 NVIDIA Container Toolkit： 安装 NVIDIA Container Toolkit，以便 Docker 可以使用 NVIDIA GPU。安装命令取决于你的操作系统，一般需要添加 NVIDIA 的仓库并安装 nvidia-docker2 包： 1distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update sudo apt-get install -y nvidia-docker2 sudo systemctl restart docker 3.验证 NVIDIA Docker 安装： 安装完成后，你可以通过运行一个测试命令来验证 NVIDIA GPU 的集成： 1docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi 总结 Docker 和 NVIDIA Docker 是可以并且通常会一起安装在同一个系统上的。NVIDIA Docker 依赖于普通的 Docker 服务，并扩展其功能，使其能够管理 GPU 资源。 独立安装：没有必要单独安装 NVIDIA Docker，因为它是作为 Docker 的一个扩展而存在的。你只需要在已安装 Docker 的基础上添加 NVIDIA Docker 组件。 ———————————————— 原文链接：https://blog.csdn.net/qq_44702930/article/details/138953253","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"docker中图形化界面的转发","slug":"Docker/docker中图形化界面的转发","date":"2024-12-13T02:06:13.000Z","updated":"2024-12-23T02:47:54.668Z","comments":true,"path":"2024/12/13/Docker/docker中图形化界面的转发/","link":"","permalink":"http://www.formeasy.cc/2024/12/13/Docker/docker%E4%B8%AD%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2%E7%9A%84%E8%BD%AC%E5%8F%91/","excerpt":"","text":"在Docker中默认情况下是没有图形化界面的，因为Docker主要是为无头（headless）环境设计的。如果想在Docker容器中运行图形化程序，并且希望这些程序的窗口显示在宿主机上，可以通过以下几种方式实现。 一、 使用X11转发（适用于Linux系统） Linux系统中通常使用X11作为显示服务器，可以通过X11转发来将容器内的图形化程序窗口显示到宿主机上 1.允许宿主机的X11连接： 在宿主机上执行以下命令，允许X11接受来自Docker容器的连接 1xhost + 注意：xhost + 会允许任何客户端访问宿主机的X服务器，可能存在安全风险。为了更安全的操作，可以指定特定的主机，例如： 1xhost +local:docker 2.运行Docker容器并设置DISPLAY变量： 在运行容器时，需要将宿主机的X11 socket目录映射到容器内，并设置DISPLAY变量，指定宿主机的X显示服务 1234docker run -it --rm \\ -e DISPLAY=$DISPLAY \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ my_ros_image 参数说明： -e DISPLAY=$DISPLAY：将宿主机的DISPLAY环境变量传递给Docker容器，使容器内程序知道应该将窗口显示在哪个屏幕上。 -v /tmp/.X11-unix:/tmp/.X11-unix：将宿主机的X11 socket目录映射到容器内，以便容器能够与宿主机的X服务器通信。 3. 启动图形化程序： 进入容器后，启动图形化程序（如rviz、gazebo等），它的窗口将显示在宿主机的桌面上。 注意事项： 容器和宿主机的X服务器之间需要权限匹配，否则可能出现“拒绝连接”的错误。 xhost +允许所有客户端访问X服务器，可能有安全隐患。如果在多用户系统中使用，建议启用xhost +local:这种更安全的方式。 二、使用VNC（适用于所有平台） 如果你使用的是Windows、macOS或你不想依赖X11转发，可以通过VNC（虚拟网络计算）在容器中运行图形化界面，并通过VNC客户端在宿主机上访问图形化界面。 1.在Docker镜像中安装VNC服务： 首先需要在Docker镜像中安装VNC服务器和一个桌面环境，例如XFCE4。可以在Dockerfile中进行如下配置： 12345678910111213FROM ubuntu:18.04RUN apt-get update &amp;&amp; apt-get install -y \\ xfce4 \\ xfce4-goodies \\ tightvncserver \\ &amp;&amp; apt-get clean# 配置VNC启动脚本 RUN mkdir ~/.vnc &amp;&amp; \\ echo &quot;xfce4-session &amp;&quot; &gt; ~/.vnc/xstartup &amp;&amp; \\ chmod +x ~/.vnc/xstartup CMD [&quot;vncserver&quot;, &quot;:1&quot;, &quot;-geometry&quot;, &quot;1280x1024&quot;, &quot;-depth&quot;, &quot;24&quot;] 2.启动Docker容器： 构建镜像并运行容器： 12docker build -t my_vnc_ros_image .docker run -p 5901:5901 my_vnc_ros_image 这样会将容器中的VNC服务映射到宿主机的5901端口。 3.在宿主机上使用VNC客户端连接： 使用VNC客户端（如RealVNC或TigerVNC），连接到宿主机的localhost:5901，你就可以看到容器内的图形化界面。 优点： 这种方式跨平台（Windows、macOS、Linux）都可用，不依赖宿主机的显示系统（如X11）。 VNC可以提供一个完整的虚拟桌面环境。 三、使用Xpra（无缝模式，适用于Linux和macOS） Xpra是一种“无缝”远程桌面工具，它允许将容器内的图形化应用显示为宿主机上的独立窗口，而不需要整个桌面环境。相比VNC，Xpra更轻量，且在Linux和macOS上使用较为方便。 1.在Docker镜像中安装Xpra： 在Dockerfile中添加安装Xpra的指令： 1RUN apt-get update &amp;&amp; apt-get install -y xpra 2.启动Xpra服务器： 运行容器时，启动Xpra服务器并映射端口： 1234docker run -it --rm \\ -e DISPLAY=:14 \\ -p 14500:14500 \\ my_xpra_ros_image xpra start :14 --bind-tcp=0.0.0.0:14500 --no-daemon 3.在宿主机上安装Xpra客户端： 安装Xpra客户端后，运行以下命令连接到容器： 1xpra attach tcp:localhost:14500 此时可以在宿主机上以窗口形式看到容器中的图形化程序。 优点： Xpra是无缝的，不像VNC那样需要虚拟桌面，它可以在宿主机上显示为独立的窗口。 支持Linux和macOS，适合图形化应用的开发和调试。 四、使用X11转发到Windows（适用于Windows系统） 如果你使用的是Windows，可以安装X11服务器（如Xming或VcXsrv）来接收Docker容器的图形化输出。 1.安装Xming或VcXsrv： 下载并安装Xming或VcXsrv，确保其在运行并且监听X11连接。 2.配置环境变量： 在Windows的CMD或PowerShell中，找到Xming/VcXsrv的IP地址，通常是localhost或者172.17.0.1。 将环境变量DISPLAY设置为该IP地址加上:0（例如DISPLAY=172.17.0.1:0）。 3.运行Docker容器并设置DISPLAY： 使用类似于Linux的X11转发方法，将DISPLAY和X11 socket传递给容器：``` 1234docker run -it --rm \\ -e DISPLAY=172.17.0.1:0 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ my_ros_image 4.运行图形化程序： 图形化程序的窗口应该会显示在Windows的桌面上。 总结 X11转发：适合Linux和macOS系统，依赖宿主机的X11服务器。 VNC：跨平台，适合需要完整桌面环境的场景。 Xpra：轻量且无缝显示，适合Linux和macOS，独立窗口显示。 Windows X11转发：需要Xming或VcXsrv等工具。 ———————————————— 原文链接：https://blog.csdn.net/m0_55127902/article/details/142370039","categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"}]},{"title":"Fast DDS入门-Fast DDS介绍","slug":"DDS/Fast DDS入门-Fast DDS介绍","date":"2024-12-06T08:48:52.000Z","updated":"2025-04-25T00:58:55.980Z","comments":true,"path":"2024/12/06/DDS/Fast DDS入门-Fast DDS介绍/","link":"","permalink":"http://www.formeasy.cc/2024/12/06/DDS/Fast%20DDS%E5%85%A5%E9%97%A8-Fast%20DDS%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1 前言 Fast DDS是DDS（数据分发服务）规范的C++实现，DDS是由对象管理组（OMG）定义的协议。Fast DDS库提供应用程序编程接口（API）和通信协议，用于部署以数据为中心的发布-订阅（DCPS）模型，目的是在实时系统之间建立高效可靠的信息分发。Fast DDS在资源处理方面具有可预测性、可扩展性、灵活性和高效性。为了满足这些要求，它使用了类型化接口，并依赖于一个多对多的分布式网络范例，该范例巧妙地允许将通信的发布方和订阅方分离。Fast DDS包括： DDS API实现。 Fast DDS-Gen，一种用于桥接类型化接口和中间件实现的生成工具。 底层RTPS有线协议实现。 除了以上内容，Fast DDS已被选为Robot Operating System 2（ROS 2）在每个长期（LTS）版本和大多数非LTS版本中支持的默认中间件。 2 什么是DDS 数据分发服务（DDS）是一种用于分布式软件应用程序通信的以数据为中心的通信协议。它描述了实现数据提供者和数据使用者之间通信的通信应用程序编程接口（API）和通信语义。 由于它是一个以数据为中心的发布-订阅（DCPS）模型，因此在其实现中定义了三个关键应用程序实体：发布实体，它定义了信息生成对象及其财产；订阅实体，定义信息消费对象及其财产；和配置实体，它们定义作为主题传输的信息类型，并使用其服务质量（QoS）财产创建发布者和订阅者，以确保上述实体的正确性能。 DDS使用QoS来定义DDS实体的行为特征。QoS由各个QoS策略（从QoSPolicy派生的类型的对象）组成。策略中对此进行了描述。 在DCPS模型中，为通信应用程序系统的开发定义了四个基本要素。 发布者是负责创建和配置其实现的DataWriter的DCPS实体。DataWriter是负责实际发布消息的实体。每个人都将有一个指定的主题，在该主题下发布消息。 订阅者是负责接收在其订阅的主题下发布的数据的DCPS实体。它服务于一个或多个DataReader对象，这些对象负责向应用程序传递新数据的可用性。 主题是绑定发布和订阅的实体。它在DDS域中是唯一的。通过TopicDescription，它可以统一发布和订阅的数据类型。 领域这是用于链接属于一个或多个应用程序的所有发布者和订阅者的概念，这些应用程序在不同主题下交换数据。这些参与域的单独应用程序称为DomainParticipant。DDS域由域ID标识。DomainParticipant定义域ID以指定其所属的DDS域。具有不同ID的两个DomainParticipant不知道网络中彼此的存在。因此，可以创建几个通信信道。这适用于涉及多个DDS应用程序的场景，它们各自的DomainParticipant彼此通信，但这些应用程序不得干扰。DomainParticipant充当其他DCPS实体的容器，充当发布者、订阅者和主题实体的工厂，并在域中提供管理服务。 这些元素如下图所示。 DDS域中的DCPS模型实体 3 什么是RTPS 实时发布订阅（RTPS）协议是为支持DDS应用程序而开发的，是一种基于尽力传输（如UDP/IP）的发布订阅通信中间件。此外，Fast DDS还支持TCP和共享内存（SHM）传输。 RTPS设计为支持单播和多播通信。 RTPS继承自DDS，可以找到域的概念，它定义了一个单独的通信平面。多个域可以同时独立共存。域包含任意数量的RTPSP参与者，即能够发送和接收数据的元素。为此，RTPSP参与者使用其端点： RTPSWriter：能够发送数据的端点。 RTPSReader：能够接收数据的端点。 RTPSParticipant可以有任意数量的编写器和读取器端点。 RTPS高级架构 通信围绕主题展开，主题定义和标记正在交换的数据。主题不属于特定参与者。参与者通过RTPSWriter对主题下要发布的数据生成数据更新（Change），通过RTPSReader接收与其订阅主题相关的数据更新。通信单元称为Change，它表示在Topic下写入的数据的更新。RTPSReader/RTPSWriter在其历史记录中注册这些数据更新，历史记录是一种数据结构，用作最近数据更新的缓存。 在eProsima Fast DDS的默认配置中，当您通过RTPSWriter端点发布更改时，会在幕后执行以下步骤： Change将添加到RTPSWriter的历史缓存中。 RTPSWriter将Change发送给它匹配的任何RTPSReader。 接收到数据后，RTPSReader将使用新的Change更新其历史缓存。 Fast DDS支持多种配置，允许您更改RTPSWriter/RTPSReader的行为。RTPS实体的默认配置中的修改意味着RTPSWriter和RTPSReader之间的数据交换流发生了变化。此外，通过选择服务质量（QoS）策略，可以以多种方式影响这些历史缓存的管理方式，但通信循环保持不变。 4 DDS API DDS采用的通信模型是多对多的单向数据交换，其中产生数据的应用程序将数据发布到订阅方的本地缓存。信息流由负责数据交换的实体之间建立的服务质量（QoS）策略来调节。 作为一个以数据为中心的模型，DDS建立在所有感兴趣的应用程序都可以访问的“全局数据空间”的概念之上。希望贡献信息的应用程序声明其成为发布者的意图，而希望访问部分数据空间的应用程序则声明其成为订阅者的意图。每当发布者向这个空间发布新数据时，中间件就会将信息传播给所有感兴趣的订阅者。 通信发生在域之间，即连接所有能够相互通信的分布式应用程序的隔离抽象平面。只有属于同一个域的实体才能进行交互，订阅数据的实体和发布数据的实体之间的匹配由主题管理。主题是明确的标识符，主题名称在域中唯一，并与数据类型和一组特定QoS数据相关联。 DDS实体建模为类或类型化接口，后者意味着更有效的资源处理，因为处理已知的数据类型比动态分配内存更有效率。这是OMG的说法，咸鱼认为这方面提高的效率不明显也不重要，但是接口清晰对通信开发者之间更重要，使得协作开发更有效。 DDS域内信息流动的概念图。只有属于同一域的实体才能通过匹配主题发现彼此，从而在发布者和订阅者之间交换数据。 5 Fast DDS-Gen 依赖接口意味着需要一种生成工具，将类型描述转换为适当的实现，以填补接口和中间件之间的空白。该任务由专用生成工具Fast DDS Gen执行，Fast DDS Gen是一个Java应用程序，它使用接口定义语言（IDL）文件中定义的数据类型生成源代码。 6 RTPS Wire Protocol Fast DDS用于通过标准网络交换消息的协议是实时发布-订阅协议（RTPS），这是OMG联盟定义和维护的DDS互操作性有线协议。该协议通过TCP/UDP/IP等传输提供发布者-订阅者通信，并保证不同DDS实现之间的兼容性。 考虑到发布-订阅设计用于满足DDS应用领域所解决的相同需求的规范，RTPS协议映射到许多DDS概念，因此是DDS实现的自然选择。所有RTPS核心实体都与RTPS域相关联，RTPS域表示端点匹配的隔离通信平面，RTPS协议中指定的实体与DDS实体一一对应，从而允许通信发生。 7 Fast DDS主要特征 两个API层。Fast DDS包括关注可用性的高级DDS兼容层和提供对RTPS协议的更精细访问的低级RTPS兼容层。 实时行为。Fast DDS可以配置为提供实时功能，保证在指定的时间限制内做出响应。 内置发现服务器。Fast DDS基于对现有发布者和订阅者的动态发现，无需联系或设置任何服务器即可连续执行此任务。但是，也可以配置客户机服务器发现以及其他发现范例。 同步和异步发布模式。Fast DDS支持同步和异步数据发布。 尽最大努力和可靠的沟通。Fast DDS支持在尽力就好通信协议（如UDP）上的可选可靠通信模式。此外，设置可靠通信的另一种方法是使用我们的TCP传输。 传输层。Fast DDS实现了可插拔传输的体系结构。实现了五种传输：UDPv4、UDPv6、TCPv4、TCPv6和SHM（共享内存）。 安全Fast DDS可配置为提供安全通信。为此，它在三个级别实现了可插拔的安全性：远程参与者的身份验证、实体的访问控制和数据加密。 统计模块。Fast DDS可以被配置为收集和提供关于用户应用程序正在交换的数据的信息。 吞吐量控制器。支持用户可配置的吞吐量控制器，可用于限制在特定条件下发送的数据量。 即插即用连接。新的应用程序和服务被自动发现，可以随时加入和离开网络，而无需重新配置。 可扩展性和灵活性。DDS建立在全球数据空间的概念之上。中间件负责在发布者和订阅者之间传播信息。这保证了分布式网络能够适应重新配置并可扩展到大量实体。 应用程序可移植性。DDS规范包括到IDL的平台特定映射，允许使用DDS的应用程序在DDS实现之间切换，只需重新编译。 可扩展性。Fast DDS允许通过新服务扩展和增强协议，而不破坏向后兼容性和互操作性。 可配置性和模块性。Fast DDS通过代码或XML配置文件提供了一种直观的配置方式。模块化允许简单设备实现协议的一个子集，并仍然参与网络。 高性能。Fast DDS使用静态低级串行化库Fast CDR，这是一个C++库，根据RTPS规范中定义的标准CDR串行化机制进行串行化。 易于使用。该项目附带了一个开箱即用的示例，即HelloWorld示例。DDS层和RTPS层部分将对DDS和RTPS进行详细说明。 资源消耗低。 允许预分配资源，以最小化动态资源分配。 避免使用无限资源。 将复制数据的需要降至最低。 多平台。操作系统依赖项被视为可插拔模块。用户可以在其目标平台上使用Fast DDS库轻松实现平台模块。默认情况下，该项目可以在Linux、Windows和MacOS上运行。 免费开源。Fast DDS库、下面的RTPS库、生成器工具、内部依赖项（例如eProsima Fast CDR）和外部依赖项（如foonathan库）是免费的开源的。 ———————————————— 原文链接：https://blog.csdn.net/weixin_43369786/article/details/128988734","categories":[{"name":"网络通讯","slug":"网络通讯","permalink":"http://www.formeasy.cc/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"DDS","slug":"DDS","permalink":"http://www.formeasy.cc/tags/DDS/"}]},{"title":"fastDDS学习记录","slug":"DDS/fastDDS学习记录","date":"2024-12-06T08:28:42.000Z","updated":"2025-04-25T00:59:42.474Z","comments":true,"path":"2024/12/06/DDS/fastDDS学习记录/","link":"","permalink":"http://www.formeasy.cc/2024/12/06/DDS/fastDDS%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"一. Windows系统下fastDDS使用 官网下载fastDDS，已经是编译好的二级制安装文件，安装好之后，对应的fastDDS gen和需要的环境变量已经自动装好了。 直接按照网上教程，先写一个idl后缀文件，用来设置传输的数据类型 1struct HelloSeven &#123; string sevenData; &#125;; 然后运行：fastddsgen -example CMake HelloSevenPubSubMain.idl，不出意外，报错了 报错1 查了一下，cl.exe文件已经装好了，应该是cl.exe的环境变量没设置好，搜了一下，github上有一样的问题，答案里有解决方案。可以通过vs里的命令行（工具—&gt;命令行—&gt;开发者命令工具）来执行这个指令，成功，生成了一系列文件。 VS命令行工具.png 这代表已经用fastddsgen工具生成了工程文件了，下一步就是编译这个工程文件。摸索了好几次，还是用最原始的方法，就是先拿cmake软件make一下这个工程，报错，报的错是系统没有openssl的环境变量，查了一下，系统没有装openssl，去官网下载，开始装了个light版，不行，必须装完整版。装完之后，添加三个环境变量OPENSSL_ROOT_DIR OPENSSL_CRYPTO_LIBRARY OPENSSL_INCLUDE_DIR 再编译，通过了。 参考代码如下 1mkdir build cd build cmake .. 中间cmake --build时，还有报错，“MSBuild version 17.6.3+07e294721 for .NET Framework MSBUILD : error MSB1009: 项目文件不存在。”在系统变量path中添加msbuild的路径“C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild”就好了。 用vs打开工程，生成解决方案，生成了一个exe文件，叫HelloSevenPubSubMain.exe和一个lib文件。 运行示例项目，用这个exe文件给上不同的参数，分别运行publisher和subscriber，成功 publisher.png subscriber.png 2. 用docker运行fastdds 在Windows上安装docker-desktop。然后去下载fastdds的image，fastdds官网有，下载下来是一个tar文件。然后把这个image载入进docker中，在tar文件所在文件夹运行： 1docker load -i &quot;ubuntu-fastdds &lt;FastDDS-Version&gt;.tar&quot; 双引号里是tar文件的名称，改成实际文件的名称。 这时候去docker-desktop里面去看，可以看到image里已经有了这个image了。然后就是用这个image启动一个container，运行指令 1docker run -it --rm --network=host --ipc=host &lt;docker-image&gt; 其中的用实际image名替换，可以去docker-desktop里去复制， 复制image名 这样就启动了这个fastdds的image。network和host的两个参数，是为了容器之间共享内存，可以使得容器之间通过共享内存通讯，详见官方说明1.1. Leveraging Fast DDS SHM in Docker deployments — Fast DDS 2.13.1 documentation (eprosima.com) 再根据官网指示，运行一个image内部自带的例程 1root@docker-desktop:/usr/local/eprosima/fastrtps/examples/cpp/dds/HelloWorldExample/bin# tmux new-session &quot;./DDSHelloWorldExample publisher 0 1000&quot; \\; split-window &quot;./DDSHelloWorldExample subscriber&quot; \\; select-layout even-vertical 效果如下 例程运行效果 这是在同一个container中subscriber和publisher同时运行并通讯。 接着测试了开启两个container分别做publisher和subscriber，也成功进行了通讯。 例程参考1.2. Fast DDS Image — Fast DDS 2.13.1 documentation (eprosima.com) FastDDS共享内存shm模式 按照官方教程1.1. Leveraging Fast DDS SHM in Docker deployments — Fast DDS 2.13.2 documentation (eprosima.com)，测试有docker端参与的共享内存方式下的dds通讯。 用官方的这个docker配置方法 1docker run -it --rm --network=host --ipc=host --name cont1 &lt;image name&gt; 启动俩容器之后，运行共享内存专用测试程序HelloWorldExampleSharedMem，俩容器正常收发，通讯正常。 用–ipc=shareable和–ipc=container:cont1方式启动俩互相共享内存的容器后， 1docker run -it --rm --network=host --ipc=shareable --name cont1 &lt;image name&gt; docker run -it --rm --network=host --ipc=container:cont1 &lt;image name&gt; 共享内存的dds程序可以跑通，俩容器正常收发。 之前启动容器时，没有加–network=host，跑这个共享内存的fastdds就不通。看来跟网络还有关系，所以必须网络配置成host模式。在上边链接里的官方教程中也有相关说明。 两个容器的共享内存通讯通了，但是测试容器和windows共享内存跑FastDDS还是不行，应该是因为Windows和docker容器中间还隔了一个wsl，并没有共享内存。 两容器通讯 在默认bridge的网络模式下启动两个容器，hello worldexample运行，两容器通讯成功。 容器和wsl2的互联互通 在默认bridge网络模式下启动容器，然后在wsl2上启动DDSHelloWorldExample，作为publisher，在容器上运行subscriber，无法连通。 用host网络模式下启动容器，然后测试与wsl2进行dds通讯，还是无法联通。 linux下docker 容器运行fastDDS ubuntu的宿主机运行一个FastDDS的docker容器，容器网络设置为host模式，即启动时候用 1docker run -it --rm --network=host --ipc=host &lt;docker-image&gt; 在局域网另一台的Windows机中运行helloworldexample程序，一边发布，一边订阅，容器中程序成功实现同Windows系统通讯。注意要关闭防火墙，或者单独设置防火墙规则。 三.用ros常用的一组msg文件构建fastDDS的发布与订阅c++工程 拿到如下的接口数据结构描述文件夹 1F:. │ CMakeLists.txt │ darknetf.txt │ package.xml │ └─msg DeadZoneOccupancyGrid.msg GirdNormalInfo.msg GirdNormalInfo2.msg LeaderVehicle.msg LqEntryState.msg LqOccupancyGrid.msg NoObstacleFlag.msg OccupancyGridInfo.msg PercepVehicleState.msg TargetGlobal.msg TargetGlobalInfo.msg TargetLocal.msg TargetLocalInfo.msg UnderWaterOccupancyGrid.msg VehiclePose.msg WaterOccupancyGrid.msg 数据是嵌套构造的，我们需要的最外层数据是WaterOccupancyGrid.msg定义的数据。从msg文件生成idl可以通过ros2系统packages构建过程附带完成，也可以通过构建脚本手动生成，在chat某某T的协助写，编写了python脚本，将msg文件批量转换为了idl文件。 1import os # 定义类型映射关系 type_mapping = &#123; &#x27;bool&#x27;: &#x27;boolean&#x27;, &#x27;int8&#x27;: &#x27;int8&#x27;, &#x27;uint8&#x27;: &#x27;uint8&#x27;, &#x27;int16&#x27;: &#x27;int16&#x27;, &#x27;uint16&#x27;: &#x27;uint16&#x27;, &#x27;int32&#x27;: &#x27;int32&#x27;, &#x27;uint32&#x27;: &#x27;uint32&#x27;, &#x27;int64&#x27;: &#x27;int64&#x27;, &#x27;uint64&#x27;: &#x27;uint64&#x27;, &#x27;float32&#x27;: &#x27;float&#x27;, &#x27;float64&#x27;: &#x27;double&#x27;, &#x27;string&#x27;: &#x27;string&#x27; &#125; def convert_msg_type_to_idl_type(msg_type): &quot;&quot;&quot;将ROS 2的消息类型转换为IDL类型&quot;&quot;&quot; if msg_type in type_mapping: return type_mapping[msg_type] elif msg_type.endswith(&quot;[]&quot;): # 处理数组 base_type = msg_type[:-2] return f&quot;sequence&lt;&#123;type_mapping.get(base_type, base_type)&#125;&gt;&quot; else: return msg_type # 自定义类型保持不变 def convert_msg_file_to_idl(msg_file, idl_file): &quot;&quot;&quot;将一个.msg文件转换为.idl文件&quot;&quot;&quot; print(f&quot;Converting &#123;msg_file&#125; to &#123;idl_file&#125;&quot;) with open(msg_file, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as msg_f, open(idl_file, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as idl_f: msg_name = os.path.splitext(os.path.basename(msg_file))[0] # 写入IDL文件的头 idl_f.write(f&quot;module &#123;msg_name&#125; &#123;&#123;\\n&quot;) idl_f.write(&quot; struct Msg &#123;\\n&quot;) # 读取每一行并转换为IDL格式 for line in msg_f: line = line.strip() if not line or line.startswith(&#x27;#&#x27;): # 忽略空行和注释 continue parts = line.split() if len(parts) &lt; 2: print(f&quot;Skipping invalid line: &#123;line&#125;&quot;) continue msg_type, msg_field = parts[0], parts[1] idl_type = convert_msg_type_to_idl_type(msg_type) idl_f.write(f&quot; &#123;idl_type&#125; &#123;msg_field&#125;;\\n&quot;) # 写入结构体和模块结束符 idl_f.write(&quot; &#125;;\\n&quot;) idl_f.write(&quot;&#125;;\\n&quot;) print(f&quot;Finished writing &#123;idl_file&#125;&quot;) def convert_all_msg_files_to_idl(msg_dir, idl_dir): &quot;&quot;&quot;将一个目录下的所有.msg文件转换为.idl文件&quot;&quot;&quot; if not os.path.exists(idl_dir): os.makedirs(idl_dir) for root, dirs, files in os.walk(msg_dir): for file in files: if file.endswith(&#x27;.msg&#x27;): msg_file = os.path.join(root, file) idl_file = os.path.join(idl_dir, file.replace(&#x27;.msg&#x27;, &#x27;.idl&#x27;)) print(f&quot;Converting &#123;msg_file&#125; to &#123;idl_file&#125;&quot;) convert_msg_file_to_idl(msg_file, idl_file) if __name__ == &quot;__main__&quot;: # 设置msg文件目录和生成的idl文件目录 msg_directory = &#x27;./msg&#x27; # 你的.msg文件目录 idl_directory = &#x27;./idl&#x27; # 输出.idl文件的目录 # 执行转换 convert_all_msg_files_to_idl(msg_directory, idl_directory) 执行完转换之后，还需要解决数据结构在不同idl文件之间嵌套的问题，本文第一章节的内容是针对单个idl文件的工程生成，需要进行针对性的修正工作，才能针对多idl文件生成工程。 要将嵌套引用的idl文件include进idl文件中，然后要保证同一个工程的module名相同，struct名区分， 1#include &quot;GirdNormalInfo.idl&quot; //结构体的第一个元素GirdNormalInfo是自定义数据格式，需要include该结构体所在的GirdNormalInfo.idl文件 module WaterOccupancyGrid &#123; struct GirdNormalInfo2 &#123; GirdNormalInfo info; uint16 us_height; uint16 uc_target_type; &#125;; &#125;; fastddsgen指令使用时，需要将所有用到的idl文件全部放入指令中 1fastddsgen -example CMake GirdNormalInfo.idl UniHeader.idl OccupancyGridInfo.idl VehiclePose.idl GirdNormalInfo2.idl WaterOccupancyGrid.idl 这样就生成了发布和订阅的工程源文件，再通过本文第一章节的编译生成过程，就能实现发布和订阅功能了。中间有一些小问题，调试后发布和订阅功能正常。","categories":[{"name":"网络通讯","slug":"网络通讯","permalink":"http://www.formeasy.cc/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"DDS","slug":"DDS","permalink":"http://www.formeasy.cc/tags/DDS/"}]},{"title":"VS2019安装配置QT插件","slug":"Qt/VS2019安装配置QT插件","date":"2024-12-06T04:12:24.000Z","updated":"2025-04-24T06:26:41.390Z","comments":true,"path":"2024/12/06/Qt/VS2019安装配置QT插件/","link":"","permalink":"http://www.formeasy.cc/2024/12/06/Qt/VS2019%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEQT%E6%8F%92%E4%BB%B6/","excerpt":"","text":"1、介绍 Windows的Qt开发，一般采用Visual Studio安装Qt插件的方法开发Qt程序，毕竟VS开发工具还是比QtCreator开发工具强大、好用的多。 本教程采用VS2019安装配置Qt插件（qt-vsaddin-msvc2019-2.6.0.vsix），默认已经安装了VS2019（已安装“MSVC V141-VS 2017 C++ x64/x86 生成…”选项）和Qt5.14（已安装“msvc2017 32-bit”和“msvc2017 64-bit”选项）。 如果未安装则需安装VS2019和Qt5.14，安装VS2019和Qt5.14需要注意以下： 安装VS2019，则需选择“MSVCV141-VS 2017 C++ x64/x86 生成…”选项，以支持VS2017的编译器，因为Qt5.14最高支持VS2017版本编译的Qt基础库。 安装Qt5.14，选中msvc201732-bit和msvc2017 64-bit选项，VS安装Qt插件后才能配置使用Qt的基础库（包括msvc201732-bit和msvc2017 64-bit编译版本），VS是不能直接使用其MinGW的Qt基础库的，不同编译器编译的基础库由于导出和引用规则不统一，无法通用。 2、VS2019安装Qt插件 注意：断开互联网，防止qt-vsaddin插件安装后，VS2019自动升级为更高版本，更高版本的qt-vsaddin在VS2019中有缺陷。 去官网下载qt-vsaddin-msvc2019-2.6.0.vsix，然后双击安装。 点击Install按钮，开始安装VS2019的Qt插件，安装成功界面如下： 3、VS2019配置Qt插件 （1）设置Qt插件禁用自动升级 在互联网断开情况下，Qt插件安装成功后，打开VS2019开发工具后，选择VS2019扩展菜单——&gt;管理扩展，打开管理扩展窗口，选择已安装的Qt Visual StudioTools插件，取消自动更新扩展复选框，之后就可以连接互联网了。 （2）VS2019设置Qt的基础库路径 VS2019扩展菜单——&gt;QtVS Tools——&gt;Qt Options，打开Qt的基础库路径设置窗口： 点击Add按钮，选择Qt的msvc2017 64bit路径： 确定后，自动生成Version name： 同样也可以增加msvc2017 32bit的设置： 设置完成后： 窗口下方Default Qt/Win version：可设置默认msvc2017 64位还是32位的Qt库路径，以适用生成64位还是32位应用程序。 4、VS2019创建和打开Qt项目 （1）新建Qt项目 VS2019文件菜单——&gt;新建——&gt;项目，打开创建新项目窗口，下拉项目类型，最后可看到支持新建Qt各类项目（后续与Qt Creator创建项目流程基本一致）： （2）打开Qt项目 VS2019扩展菜单——&gt; QtVS Tools——&gt;“Open Qt ProjectFile(.pro)…”，弹出“打开Qt项目”窗口，选择已建的Qt项目(.pro)，VS2019像Qt Creator一样打开已建的Qt项目。 （3）设置VS2019的Qt项目属性 VS2019界面中选择Qt项目，右键点击属性： 常规——&gt;Windows SDK版本：选择已经安装的有效Windows SDK版本。 常规——&gt;平台工具集：选择VisualStudio 2017（v141）。 Qt Project Settings——&gt;Qt Installation：选择64位还是32位msvc2017，要与编译的程序是64位还是32位一致。 Qt Project Settings——&gt;Qt Modules：设置项目要依赖的Qt模块，本例支持xml和gui界面。 （4）编译运行Qt项目 VS2019中编译运行Qt项目与其他项目一样build和run。 5、VS2019的Qt项目添加和编辑Qt类、Qt文件 （1）添加Qt类 VS2019界面中选择Qt项目，右键点击添加——&gt;”Add Qt Class…”，弹出Qt添加窗口，可添加Qt Class和Qt Widgets Class，像在Qt Creator中一样添加Qt类： （2）编辑Qt类 Qt类的.h和.cpp文件双击直接在VS2019中编辑，而ui文件双击后调用Qt Desiner打开文件并编辑。 6、VS2019卸载Qt插件 VS2019菜单——&gt;管理扩展，打开管理扩展窗口，点击卸载： 确定卸载后，窗口下方提示： 关闭VS2019，则电脑立即弹出VSIXInstaller窗口，点击Modify按钮，启动卸载: 显示卸载进度： 最后卸载成功：","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"}]},{"title":"1553B命令字与消息传输","slug":"1553B/1553B命令字与消息传输","date":"2024-12-03T12:43:15.000Z","updated":"2024-12-23T02:51:03.503Z","comments":true,"path":"2024/12/03/1553B/1553B命令字与消息传输/","link":"","permalink":"http://www.formeasy.cc/2024/12/03/1553B/1553B%E5%91%BD%E4%BB%A4%E5%AD%97%E4%B8%8E%E6%B6%88%E6%81%AF%E4%BC%A0%E8%BE%93/","excerpt":"","text":"&gt;&gt;1553B简要介绍 ①1553B终端类型有总线控制器BC、远程终端RT和总线监视器MT。 ②1553B字类型有命令字、数据字、状态字。 ③1553B通讯方式为命令响应式，因此所有消息传输都必须由总线控制器发出的命令字来进行控制。 &gt;&gt;1553B 命令字定义 ①调制信号为曼彻斯特码，信号电平由高到低为“1”，由低到高为“0”。 ②总线传输速率为1Mb/s，即1us/位。 ③同步头由高到低占3位，共3微秒，与状态字同步头相同，与数据字同步头相反。 ④RT地址为11111时表示广播命令，此时T/R=0； ⑤方式域为全0（00000）或全1（11111）时表示方式命令，具体由方式码决定。 ⑥校验位为奇校验，当1—19位1的个数为偶数时校验位P=1;否则P=0。 &gt;&gt;1553B十种消息格式 说明：** 表示状态响应时间 # 表示消息间隔时间 ①BC-&gt;RT数据传输 ②RT-&gt;BC数据传输 ③RT-&gt;RT数据传输 ④广播命令数据传输 ⑤RT-&gt;RT广播命令数据传输 ⑥不带数据字的方式命令 ⑦带数据收方式命令 ⑧带数据发方式命令 ⑨不带数据广播方式命令 ⑩带数据广播方式命令 &gt;&gt;1553B命令字与消息说明 ①总线使用效率 式中：NDW表示数据字数；CW表示指令字数；SW表示 状态字数； 表示指令响应时间； 表示消息间隔时间。 ②有命令字，而不见的有数据字； ③有命令字，而不见的有状态字。 ④有数据字一定有命令字； ⑤有状态字一定有命令字； ※命令字与状态字的同步头相同，在总线上如何区分？ 答：因为命令字与状态字要么成对出现，要么只有命令字， 所以在总线上最先出现的肯定是命令字，以此可以区分。 ———————————————— 原文链接：https://blog.csdn.net/phnumber/article/details/49611913","categories":[{"name":"串行通讯","slug":"串行通讯","permalink":"http://www.formeasy.cc/categories/%E4%B8%B2%E8%A1%8C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"1553B","slug":"1553B","permalink":"http://www.formeasy.cc/tags/1553B/"}]},{"title":"MIL-STD-1553B特性必知必会","slug":"1553B/MIL-STD-1553B特性必知必会","date":"2024-12-03T12:33:18.000Z","updated":"2025-04-24T09:12:58.285Z","comments":true,"path":"2024/12/03/1553B/MIL-STD-1553B特性必知必会/","link":"","permalink":"http://www.formeasy.cc/2024/12/03/1553B/MIL-STD-1553B%E7%89%B9%E6%80%A7%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/","excerpt":"","text":"基本概念 1553B是MIL－STD－1553B 的简称，MIL-STD-1553B是一种指令/响应式串行总线标准。该总线标准由美国国防部于 1973 年制定并颁布，全称为飞机内时分制指令/响应式复用数据总线。 使用光缆代替电缆的版本称为MIL-STD-1773B。 历史背景 在20世纪60年代以前，飞机机载电子系统没有 标准的通用数据通道，各个电子设备单元之间连接往往需要大量的电缆。随着机载电子系统的不断复杂化，这种通信方式所用的电缆将会占用很大的空间和重量，而且对传输线的定义和测试也较为复杂，费用较高。为了解决这一问题，美国 SAE A2K委员会在军方和工业界的支持下于1968年决定开发标准的信号多路传输系统，并于1973年公布了MIL-STD-1553B标准。1973年的1553B多路传输数据总线成为了未来军机将采用的技术，它取代了在传感器、计算机、指示器和其他飞机设备间传递数据的庞大设备，大大减少了飞机重量，并且使用简单、灵活，此标准的修订本于1978年公布，即MIL-STD-1553B标准。1980年，美国空军又对该标准作了局部修改和补充推出了 MIL-STD-1553B Notice I。1986 年推出了 MIL-STD-1553B Notice II， 并更名为数字式时分制指令/响应式复用数据总线。。该标准作为美国国防部武器系统集成和标准化管理的基础之一，被广泛的用于飞机综合航电系统、外挂物管理与集成系统，并逐步扩展到飞行 控制等系统及坦克、舰船、航天等领域。它最初由美国空军用于飞机航空电子系统，目前已广泛应用于美国和欧洲海、陆、空三军，而且正在成为一种国际标准。我国于1987年颁布了相应的军标。 主要特点 串行通信 主从式 半双工 总线型拓扑 双冗余，热备 曼彻斯特 II 型编码 3 种传输字 10 种消息 传输字 1553B 一般以屏蔽双绞线为传输介质、采用曼彻斯特 II 型双相电平编码（即由高电平跳变为低电平 表示逻辑‘1’，由低电平跳变为高电平表示逻辑‘0’）、标准波特率为 1MHz。 1553B每 20 位构成一个传输字、前 3 位是同步位，中间 16 位是数据位，最后一位是奇偶校验位，总共有三种传输字。 命令字 CW：command word，一条消息的开头，只能由主机发出，用于主机发起对从机的命令，一条消息至少要具备一个命令字。 数据字 DW：data word，用于传输数据，主机和从机都可以发送。 状态字 SW：status word，用于从机向主机回应单播命令。只能由从机发送。 命令字详细说明： 位域 名称 说明 [15-11] RT 地址 1553B 总线上的每一个 RT 都需具有唯一的 RT 地址，一般使用范围为“00000”至“11110”。 当广播使能时，RT 地址“11111”表示当前消息为广播消息。 当系统不允许广播时，“11111”也可用来表示一个 RT 地址。 [10] T/R位 该位置‘1’时，表示 RT 将执行发送操作； 该位置‘0’时，表示 RT 将执行接收操作。 [9-5] 子地址/方式指令 为“00000”或“11111”时，表示 BC 将通过消息中的方式指 令控制 RT 执行相关操作，bit4-bit0 表示一条方式指令编码。 为其他值时表示为子地址，可见一个 节点可以有 30 个字地址。 [4-0] 数据字计数/方式指令 当指令字 bit9-bit5 位为“00000”或“11111”时，bit4-bit0 表示一条方式指令编码。 当指令字 bit9-bit5 位不为“00000”和“11111”时，bit4-bit0 表示消息中的数据字 个数。数据字的个数最多为 32 个，bit4-bit0 为“11111”表示数据字个数为 31，为“00000” 表示数据字个数为 32。 方式指令表 方式码有 5 位，即最多 32 条指令。其中 0-15 号方式码不带数据，16-31 号方式码带一个字的数据。 方式指令 功能 T/R位 是否带数据字 是否允许广播 0x00 动态总线控制 1 否 否 0x01 同步 1 否 是 0x02 发送状态字 1 否 否 0x03 开始自检 1 否 是 0x04 发送器关闭 1 否 是 0x05 取消发送器关闭 1 否 是 0x06 禁止终端标记 1 否 是 0x07 取消禁止终端标记 1 否 是 0x08 复位RT 1 否 是 0x10 发送矢量字 1 从MEMORY取字 否 0x11 带字同步 0 存储到MEMORY（也可能存储到时间标志寄存器 是 0x12 发送上一条指令字 1 从内部寄存器取字 否 0x13 发送BIT字 1 从内部寄存器或者RAM单元 否 0x14 选择的发送器关闭 0 存储到MEMORY 是 0x15 选择的发送器打开 0 存储到MEMORY 是 状态字详细说明： 位域 名称 说明 [15-11] RT 地址字段 远程终端地址 [10] 消息出错位 用来表示远程终端在已收到的消息中，有一个字或多个字没有通过规定的有效性测试。逻辑1表示消息有差错，逻辑0表示消息无差错。所有的终端应提供消息差错位。 [9] 测试手段位 它在所有条件下总置为逻辑0。该位为可选位，如果使用，指令字中的相应位置为逻辑1，用来区分指令字和状态字。 [8] 服务请求位 表示本远程终端需要服务。要求总线控制器启动与本远程终端或子系统有关的预定操作。当与单一远程终端相连的多个子系统分别请求服务时，远程终端应将它们各自的服务请求信号逻辑“或”成状态字中的单一服务请求。逻辑“或”完成后设计者必须准备好一个数据字，并以相应位置1来标志具体的请求服务子系统。状态字中的“服务请求位”，应维持到几个请求信号都处理完为止。该位仅用来激发随机发生的数据传输操作。 [7-5] 备用状态位 置为逻辑0，这些位留作今后使用 [4] 广播指令接收位 表示本远程终端接收到的上一有效指令字是广播指令字。当系统中未采用广播方式，置该位为逻辑0。 [3] 忙位 如果远程终端在响应发送、指令时置忙位，那么只发出它的状态字。该位为可选位，逻辑0表示空闲状态或者非忙状态。 [2] 子系统标志位 如果与一个远程终端相连的几个子系统都呈现故障状态时，应将它们各自的信号逻辑“或”，形成状态字中的子系统标志位，并将事先准备好的一个数据字中的相应位置1，记录它们的故障报告，用于进一步检测、分析。该位为可选位。逻辑1表示有标志，逻辑0表示无标。用来向总线控制器指出子系统故障状态，且警告总线控制器本远程终端提供的数据可能无效。 [1] 动态总线控制接收位 若置为逻辑 1，用来表示本远程终端接受符合协议本身规定的动态总线控制的授命。逻辑 0 表示不接受。该位为可选位。 [0] 终端标志位 逻辑1表示本远程终端内部存在故障，请求总线控制器干预。逻辑0表示不存在故障。该位为可选位。 传输消息 1553B 总线的信息传输以消息为单位，消息是以不同的字和状态响应间隔组成的信号序列。信息量最大长度达 32 个字，并采用指令/响应式传输协议实现半双工传输方式。 1553B 总线支持总共10种消息格式，包括： （1） BC-RT 消息； （2） RT-BC 消息； （3） RT-RT 消息； （4） 不带数据字的方式指令； （5） 发送方式指令（带数据字）； （6） 接收方式指令（带数据字）； （7） BC-RT 广播消息； （8） RT-RTs 广播消息； （9） 不带数据字的广播方式指令； （10） 带数据字的广播方式指令。 消息是构成1553B总线通讯的基本单位，如果需要完成一定的功能，就要将多个消息组织起来，形成一个新的结构叫做帧(Frame)。 关键时间参数 响应时间： 远程终端响应有效指令字的间隔时间为4.0~12.0µs。该时间为从状态字之前的最后一个字的最后一位的中间过零点到状态字同步头中间过零点的时间。 最小无响应超时： 总线控制器在一路总线上启动传输时，测量由它发出的最后一个字的最后一位的中间过零点起，到期望的状态字同步头的中间过零点的时间。当该时间超过14.0µs时，作无响应超时处理。 消息间隔： 总线控制器所发消息之间的最小间隔时间为4.0µs。该时间为从前一消息最后一位的中间过零点到邻接的消息中指令字同步头的中间过零点的时间。 设备分类 根据设备在总线系统中的功能，1553B 总线通信协议将总线上的终端单元分为总线控制器、远置终端和总线监视器三种。 总线控制器（Bus Controller，以下简称为 BC）是指启动总线上消息传输的终端，也是总线上唯一具有总线控制权的终端。按照协议规定任何时候总线上必须有且只能有一个总线控制器。BC负责总线的调度、管理，是总线通讯的发起者和组织者。 总线监视器（Bus Monitor Terminal，以下简称为 BM 或 MT）是指监视总线上的数据流，并有选择地提取有用信息的终端。BM对总线上的所有通讯过程对总线监视器来说都是可见的，因而总线监视器能够全部或选择性的监视总线的通讯过程，对通讯状态进行分析和判断，给出参与总线通讯的总线控制器和各个远置终端的运行状态和健康状态，BM在总线上不是必须的。 远置终端（Remote Terminal，以下简称为 RT）是指总线上除总线控制器和监视器之外的所有其他终端，每 个 RT 最多可以连接 30 个子系统（子系统是指通过 1553B 总线接收数据传输服务的设备或单元）。RT只能被动的接收或者发送和自己有关的数据，对远程终端来说，和自己无关的数据是透明的，远程终端根据预先设定的通讯协议接收和发送数据。 连接拓扑 1553B以总线型拓扑屏蔽双绞线连接所有终端，总线两端无节点时需要配备终端电阻，减少信号反射造成的干扰。其他节点通过较短的分支线连接到主干总线上，分支线可以是直连也可以是变压器耦合连接，变压器耦合连接方式抗干扰特性更强，分支线也允许更长，并且能规避单点短路故障。之所以采用曼彻斯特码进行编码传输是因为适用于变压器耦合，由于直接耦合不利于终端故障隔离，会因为一个终端故障而造成整个总线网络的完全瘫痪，所以协议中明确指出不推荐使用直接耦合方式。 1553B 数据总线采用双冗余结构，分别称之为总线 A 和总线 B。总线控制器可以根据需要，选择通过总线 A 传输消息或者通过总线 B 传输消息。 1553B 总线的网络结构简单、终端扩展方便、相对易于实现冗余，可以轻巧灵活地实现系统设计和设备更新。 基于 1553B 总线的分布式系统，有且只有一个BC，最多可以拥有 32 个 RT，可选择性的配备一个MT。当允许使用广播消息时， 最多可以拥有 31 个 RT。整个系统采用半双工的传输模式，以指令/响应方式异步工作。 实物图片 ———————————————— 原文链接：https://blog.csdn.net/ScilogyHunter/article/details/140693514","categories":[{"name":"串行通讯","slug":"串行通讯","permalink":"http://www.formeasy.cc/categories/%E4%B8%B2%E8%A1%8C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"1553B","slug":"1553B","permalink":"http://www.formeasy.cc/tags/1553B/"}]},{"title":"1553B通信项目开发","slug":"1553B/1553B通信项目开发","date":"2024-12-03T11:13:35.000Z","updated":"2025-04-24T09:14:01.623Z","comments":true,"path":"2024/12/03/1553B/1553B通信项目开发/","link":"","permalink":"http://www.formeasy.cc/2024/12/03/1553B/1553B%E9%80%9A%E4%BF%A1%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/","excerpt":"","text":"最近接了个项目，需要用1553B协议通信，仅作为RT端口进行通信，控制器采用ARM。 使用芯片为国产的BU61580芯片，功能和引脚和DDC。 系统组成 MIL-STD-1553B时分制指令/响应多路传输数据总线采用半双工传输方式。MIL-STD-1553B数据总线上的节点分为三种不同的终端类型:总线控制器BC( Bus controller)、 远程终端RT ( Remote Terminal) 及监视器MT ( MonitorTerminal)，典型拓扑结构见图 总线控制器BC：1553B 总线上的重要组成部分，唯一且不可或缺。一个1553B总线网络上只能有一个终端工作于BC模式，它用来启动和控制数据的传输。总线控制器按功能可分为普通模式和增强模式两种。其中，增强模式还提供了帧自动重复、自动重试及由处理器编程设置消息时间间隔等功能。 远程终端RT：各个子系统与整个1553B 总线网络的接口，不同的RT地址代表了不同的RT终端， 一个1553B总线网络最多有31个终端工作于RT模式。RT地址一共由六位组成，其中5位为地址位，一位为奇偶校验位（这里要注意，地址也有校验位，未必太严谨了点）。只有当总线控制器向某个RT发出指令后，才能启动1553B总线_上的数据传输，该RT才能 进行数据传输。远程终端按功能也分为普通模式和增强模式。在增强模式下，其提供了双缓冲模式、循环缓冲模式等存储器管理模式。后续项目设计是使用RT的增强模式。 这里的缓冲模式，是类似于FIFO的东西，设计是为了信息处理的不同步问题。有缓冲还不止一个，那就会存在对缓冲区编号的需要，这个有个重要概念后面会提到，这里不多说。 总线监控器MT：监控和记录总线上各类状况的终端，它同样是由总线控制器进行控制，但其不参与任何1553B 总线网络的传输。总线监控器有3种工作模式:字监控模式、可选择消息监控模式和同步RT/何选择消息监控模式。 协议规范 1 传输格式和方法 MIL-STD- 1553B数据总线的传输速率为1Mb/s， 以命令/响应方式进行数据消息的传输，传输字的长度为20位，其通信方式采用的是半双工方式。同时，对于故障容错采用了双冗余系统，在实际中第2条通道处于热备份状态。总线控制器启动并控制1553B数据总线上所有数据消息的传输。1553B 数据总线有10 种消息传输格式，每条消息由许多字构成，所有消息字在1553B总线上是以序列脉冲码调制形式传输的，数据编码采用ManchesterII双极性码，所有不用的位都视为0。这种编码的特点是每个码位中间有一个跳变，“1”信号的跳变是由高电平到低电平的负跳变;而“0”信号是由低电平到高电平的正跳变，信号的过 零点在中间。如图所示。 双冗余：就是AB两条线进行传输，A这边如果断开就去B线传输。 这个什么什么编码方式，简单来说：上升沿代表0，下降沿代表1，这样相对于高低电平的编码方式，会降低一半的数据带宽，不过会更严谨，容错率会更高。 传输字格式 1553B消息由三种类型的字组成:命令字、数据字和状态字。每个字有20位，前3位是同步字头，紧跟的16位是信息有效位，之后还有1位奇偶校验位。 1)命令字由3位同步字头位、5位RT地址位、1位发送/接收位、5位子地址/方式位、5位数据字计数1方式码位，以及1位奇偶校验位构成。 这里前三个字节不是标准的那什么斯特码，拉俩字节高，然后拉低就表示命令字 这里涉及到两个重要概念：终端地址和子地址。 我的理解：终端地址是每个终端的特有编号，通过终端地址可以对应找到系统中的某个终端。子地址就相当于这个终端内部的子功能，可以理解成多个FIFO缓冲区被编号了，需要读写哪个FIFO就写对应子地址。 还有一个重要的T/R位，当T/R=1时，代表命令字以后传输的字是需要由RT来发送，BC接收。当T/R=0时，代表命令字以后传输的字是需要又BC来发出，RT来接收。 然后是数据计数/方式字区域，这部分有两个复用的作用：如果接下来需要传输数据，这一区域可以代表接下来传输数据的长度（后续会传输多少次数据字），如果接下来不需要传输数据，只是进行方式设置，那就是代表的方式字（相当于控制命令，不需要数据传输的情况）。 方式字的话就按照表对应就行，我这个项目需要着重看 00011这个启动自测试方式字。 最后一位：奇偶校验位，这个就不多说了。 介绍完了最难理解的命令字，接下来数据字和状态字就好理解了。 需要强调的一点就是，命令字只能由BC发送的，而状态字只能由RT来发。 介绍完了3种字代表什么意思之后，我们来看整个传输流程。 消息格式 消息格式分为：广播和非广播模式 图上前六种为非广播模式，就是点对点传输，基于命令和响应的传输机制。都有一个共性，由BC发出命令字后才开始后续传输（状态字或是数据字）。这里就有一个1553B的协议特性：大多数情况只能有BC来启动传输。这样做的好处是避免多头传输的时候不知道听谁的。在非广播模式下，就算是RT需要传输数据到另一个RT，也需要由BC进行中转。 BC- RT的传输是由BC向要接受消息的RT发送一一个命令字，命令字中5位RT地址位指明接收消息的RT的地址。T/R位设置为“0”表示RT是接收数据，子地址指向该RT接收数据的存储空间位置，数据字计数规定了此命令要求该RT接收的数据字字数。在RT接收到此消息后，向BC返回一个状态字以此告知BC此次传输的状况，至此完成了BC到RT的传输。 RT- -BC的传输是由BC向要发送消息的RT发送一个命令字，指示该RT发送由命令字的子地址所指定的存储空间里的内容，发送的数据字个数由5位数据字计数位规定。RT在收到BC命令字后，返回BC一个状态字，并且其后紧接着是规定数目的数据字，随后BC将确认返回的消息，至此完成了RT到BC的传输。 剩下的非广播模式就好理解了，不经过BC直接由RT传输到RT。 我这个项目主要是RT和BC直接的传输，不存在RT到RT和广播模式，就不深究别的过程了。 ———————————————— 原文链接：https://blog.csdn.net/u010396127/article/details/124716384","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"1553B","slug":"1553B","permalink":"http://www.formeasy.cc/tags/1553B/"}]},{"title":"1553B总线使用介绍","slug":"1553B/1553B总线使用介绍","date":"2024-12-03T10:46:25.000Z","updated":"2025-04-24T09:14:30.402Z","comments":true,"path":"2024/12/03/1553B/1553B总线使用介绍/","link":"","permalink":"http://www.formeasy.cc/2024/12/03/1553B/1553B%E6%80%BB%E7%BA%BF%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"（1）常用场景 MIL-STD-1553B总线标准已广泛用于飞机综合航电系统、装甲车辆综合电子系统、舰船综合电子系统等航空、航天、船舶、兵器、电子等领域。 国外航电系统起步较早，MIL-STD-1553B以其高可靠、稳定的特性，在美国等早已得到认可，且对1553B总线的使用已由军用飞机扩展到坦克、船舶、卫星、导弹等领域。 我国于90年代开始进行1553B协议的研究与产品研制工作，且目前已广泛应用。 （2）总线拓扑及终端 1553B总线拓扑结构如图1所示，从图可以看出，总线包含总线控制器（BC）、远程终端（RT）或总线监控器（BM）、耦合器、终端电阻、总线组成。 BC负责总线的调度、管理，是总线通讯的发起者和组织者**。**由于1553B总线采用中央集权式的总线管理， 在整个通讯过程中， 只有总线控制器是主动参与总线通讯的， 所有的数据传输必须由总线控制器启动。 RT只能被动的接收或者发送和自己有关的数据，对远程终端来说，和自己无关的数据是透明的，远程终端根据预先设定的通讯协议接收和发送数据。 BM对总线上的所有通讯过程对总线监视器来说都是可见的，因而总线监视器能够全部或选择性的监视总线的通讯过程，对通讯状态进行分析和判断，给出参与总线通讯的总线控制器和各个远置终端的运行状态和健康状态，BM在总线上不是必须的。 1553B数据总线包括总线A和总线B，二者互为冗余备份，所有的总线设备BC、RT、BM都以并联方式共享总线，总线A与总线B之间采用变压器耦合，总线与1553B设备之间也采用变压器耦合。 1553B终端电阻和耦合器是连接总线的重要电子组件，其与1553B终端设备（板卡）连接关系如图2所示（注意：耦合器左右两侧连接终端电阻、下侧用于连接1553B终端设备）。 图1 1553B总线拓扑结构 图2 1553B耦合器、终端电阻以及实际连接关系 （3）工作方式及信息传输格式 一般1553B总线的传输速度为1Mbps，采用曼彻斯特Ⅱ 型编码，半双工工作方式。信号以串行数字脉冲编码调制形式在数据总线上传输。逻辑1为双极编码信号 1/0，即一个正脉冲继之一个负脉冲，逻辑0为双极编码信号0/1，即一个负脉冲继之一个正脉冲。曼彻斯特Ⅱ型编码方式如图3所示。 图3 1553B采用曼彻斯特II型码对0和1编码示意图 1553B消息由命令字、数据字、状态字组成，1553B消息的最小单位为1bit，每20bit形成一个字word，每个字的有效信息位为16bit，在有效信息位的前面有3bit的同步头，有效信息位的后面有1位校奇偶验位，即：**3位同步头 + 16位有效数据/命令/状态位 + 1位奇校验位。**图4~图6给出了数据命令字、数据字、状态字的具体格式信息，从消息格式可以看出，RT地址只有5bit，因此总线最多32 RT终端，一般从1~30选取作为RT地址（注意：命令字中RT地址与子地址含义是不同的）。 图4 命令字传输格式 图5 数据字传输格式 图6 状态字传输格式 1553B总线使用的重要寄存器 下面以1553B常用的寄存器为例，对各个寄存器的功能进行简单说明： 1）中断屏蔽寄存器（Interrupt Mask Register） 该寄存器主要用于控制超时、数据堆栈回滚、RT校验错误、BC/RT消息结束等中断的使能或禁止。 2）配置寄存器#1、#2（Configuration Register#1、Configuration Register#2） 用于设定1553B的工作模式，RT 状态字的软件控制、当前工作区的选择、遇错 BC 停止设置、RT 内存管理模式选择和时间标志寄存器分辨率的选择。 3）启动/复位寄存器（Start/Reset Register） 用于软件复位、BC/BM 启动、中断复位、时标复位、时间标志寄存器测试、自动重发模式下 BC 帧停止及消息停止设置、BM 消息停止设置。 4）指令堆栈指针寄存器（Command Stack Pointer Register） 在 BC、RT、BM 等模式下，向主机提供当前或刚刚处理的消息块的指令堆栈指针地址。 5）BC 控制字寄存器/ RT 子地址控制字寄存器（BC Control Word/ RT Subaddress Control Word Register） BC 模式下，存放当前消息的 BC 控制字，用于主机访问当前的 BC 控制字；RT 模式下，用于主机访问当前或最近的子地址控制字，子地址控制字用来选择内存管理模式、中断使能。 6）中断状态寄存器（Interrupt Status Register） 该寄存器向主机反映引起中断请求的具体原因。 7）配置寄存器#3\\#4\\#5（Configuration Register#3\\#4\\#5） 用以使能1553B的高级功能。 8）数据堆栈地址寄存器（Data Stack Address Register） RT 模式下，储存当前消息的数据字的地址；BM 模式下，存放当前消息的字（包括第二个指令字、数据字、RT 状态字）的地址。 9）RT 状态字寄存器（RT Status Word Register） 存放RT的状态信息。 ———————————————— 原文链接：https://blog.csdn.net/wzl862/article/details/138366137","categories":[{"name":"串行通讯","slug":"串行通讯","permalink":"http://www.formeasy.cc/categories/%E4%B8%B2%E8%A1%8C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"1553B","slug":"1553B","permalink":"http://www.formeasy.cc/tags/1553B/"}]},{"title":"从零开始搭建Hexo个人博客","slug":"Hexo/从零开始搭建Hexo个人博客","date":"2024-12-03T00:53:46.000Z","updated":"2025-04-24T06:21:47.224Z","comments":true,"path":"2024/12/03/Hexo/从零开始搭建Hexo个人博客/","link":"","permalink":"http://www.formeasy.cc/2024/12/03/Hexo/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BAHexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"一、前言 本文是基于 Hexo 框架来构建个人博客的，整个过程十分简单，如果顺利的话，可能只需要 10-20 分钟就可以完美构建部署好一个专属于你的个人博客了。 二、Hexo 基本介绍 Hexo 是一个快速、简单且功能强大的博客框架。你用 Markdown（或其他标记语言）写帖子，Hexo 会在几秒钟内生成带有漂亮主题的静态文件。 三、Hexo+Github 搭建博客网站流程 四、开始动手动脑 首先我们进入 Hexo 的官网：https://hexo.io/ 就可以看到对于 Hexo 的详细介绍，直接下滑，然后点击`Get Started`，即可进入 Hexo 使用介绍文档，也可以直接访问：https://hexo.io/docs/ 进入。 4.1 基础准备 在正式开始前，确保你已经准备好了： 1、一个 GitHub 账号，可以直接去官网注册：https://github.com 2、安装好了 Git、Node.js Git安装方法很多，最简单的是直接官网下载软件包，然后安装（Mac 和 Windows 及其他版本都有）， 1https://git-scm.com/downloads 复制代码 Mac 电脑害可以直接利用`brew install git` 进行安装（默认应该自带 git），或者 yum、apt-get 等包管理工具安装。 Node.js也可以直接去官网下载对应系统安装包，然后一步步安装即可。 1https://nodejs.org/zh-cn/download/ 复制代码 下载好后直接点击软件包，默认会给我们安装好 Node.js 和 npm（Node.js 的包管理工具）。 Windows 系统可能需要自己设置环境变量，将对应安装目录添加到系统环境变量即可，浏览器搜索下对应方法即可。 查看下 Git、Node.js 版本，确保安装无误 。 1git --version 复制代码 4.2 安装 Hexo 首先我们需要新建一个项目目录，以我为例：我会在桌面的 Project 目录下新建一个 HexoBlog 文件夹用于存放改项目相关文件。 1cd Desktop/Project/ 复制代码 这个时候如果直接运行下面语句安装 Hexo，你可能会遇到rollbackFailedOptional。 这是因为网络问题（npm 的服务器位于国外下载慢），可以使用 cnpm（淘宝团队做的国内镜像）的获取镜像或者直接修改 npm 的资源获取地址为国内的。 1# 安装cnmp 复制代码 另外我自己还遇到了文件写入权限问题， 直接修改目录文件权限即可，如： 1chmod -R 777 /usr/local/lib 复制代码 解决上面问题后，我们在安装就可以成功啦～（如下截图所示） 4.3 初始化一个 Hexo Blog 前面已经准备好了所有相关环境，接下来我们就正式来初始化一个 Hexo 博客吧～初始化的命令格式为hexo init &lt;项目名称&gt;，这里我们暂且叫做 blog。 成功初始化后，会在当前文件夹下生成一个新的文件夹`blog`，目录结构如下： 1├── _config.landscape.yml：主题配置文件，如果 复制代码 初始化项目后，我们只需在本地执行下面命令即可在本地进行预览， 首先我们需要进入到新建的项目目录下，然后执行`hexo s`即可启动项目，然后我们访问http://localhost:4000/即可查看网站啦～ 目前是默认的主题，另外还有一篇默认的博客`Hello World`。 4.4 Hexo 基本命令介绍 本地启动项目，s 表示 server 创建一个新的博客，n 表示 new 1hexo n [layout] &amp;lt;title&amp;gt; 复制代码 layout 表示文章布局，可选（post page draft），默认使用 _config.yml中的 default_layout 参数代替（post）。 title 表示文章标题，如果标题包含空格的话，请使用引号括起来。 生成静态文件，g 表示 generate 部署 Hexo 网站，d 表示 deploy 清除缓存文件 (db.json) 和已生成的静态文件 (public) 更多相关指令大家可以前往官网查看：https://hexo.io/zh-cn/docs/commands 4.5 Hexo 基本配置介绍修改 【必改部分】 站点的基本设置，首页标题、子标题、简介、关键词（英文,隔开）、作者、语言和时区，都需要修改，这样才算自己的网站嘛。 1# Site 复制代码 &gt; 踩个坑，keywords:和生活之间必须要有空格，不然会报错。 重启下 Hexo 服务，我们刷新页面，就会发现上面的修改生效啦～如果没有生效，你可以先运行下`hexo clean`先清除缓存，然后再执行`hexo s`启动服务器。 【选改部分】 访问路径相关设置 1# URL 复制代码 原主题太简陋了，我从官网主题地址：https://hexo.io/themes/中下载了amber主题，所以我们需要将配置中的主题改为amber，大家也可以选择其他主题。 1# Extensions 复制代码 4.6 将 Hexo 博客部署到 GitHub 首先我们先需要新建在 GitHub 上新建一个项目：https://github.com/new，项目名称格式需要注意，必须是用户名.github.io，如下图所示： 同时我们需要配置下 SSH 密钥，具体配置方法可以查看：mac 如何快速生成SSH key，配置github SSH公钥连接(解决git push 413问题 接着我们要修改下配置文件_config.yml，下滑到最后，将部署信息改为： 1# Deployment 复制代码 部署到 GitHub，需要安装相关工具 hexo-deployer-git。 1npm install hexo-deployer-git --save 复制代码 接下来直接输入指令配置就行了，hexo clean清除缓存数据，hexo g生成相关静态文件。 如果继续输入hexo d进行部署的时候，会报错，Deployer not found: git 这个时候不要慌，这是因为在本地 Hexo 项目目录还没有初始化 git 造成的，我们运行下面命令进行初始化即可。 我们再次输入hexo d进行部署即可，可能会要求输入 GitHub 账号和密码（配置了 ssh 公钥就不需要了，上面有说如何配置），直接输入即可，上传完成后，再刷新 GitHub 页面会发现多了一些文件，原来的 readme 也不见了，这是因为 Hexo 每次部署都会将`hexo g`生成的静态文件（在 blog/public 目录下）上传到 GitHub，并覆盖原先所有的内容。 这个时候，我们在浏览器内访问 1https://&amp;lt;你的用户名&amp;gt;.github.io/ 复制代码 即可访问我们的博客首页啦，点击博客也可以进入对应的博客页面。 通过上面，我们已经得到了一个在线的、可以随时随地访问的个人博客，整个操作过程还是很简单的，麻烦的就是上传更新文章和部署项目了，每次部署都需要输入账号密码，另外由于 GitHub 服务器在国外，国内访问速度也很堪忧，不用担心，在后面的博客优化中我们一起来解决这些问题，让模型先跑起来。 4.7 设置应用自己的域名 如果你有域名的话，还可以设置专属域名，比如我之前在阿里云买的域名点击查看，当然大家也可以买腾讯云的点击查看，国内比较靠谱的两个云服务器和域名服务公司了～ （以我自己为例）首先我们需要在阿里云域名管理后台，进行域名解析，我们直接从我们自己的域名解析到博客的 github 地址，谈及一条 CNAME 记录即可，主机记录就是我们后面通过什么链接访问，记录值就是 github 访问地址了。 然后我们需要到 GitHub 对应项目中设置项目的域名，进入项目-&gt; Settings -&gt; Page -&gt; Custom domain，将我们设置的 CNAME 域名写入即可（注意是在这个项目的设置里，并非 GitHub 的设置）。 最后我们还需要在本地项目中的 blog/source 文件夹下新建一个CNAME文件，编辑写入我们的域名，就是刚刚填入 GitHub 的，这样后面 GitHub 就能映射到我们的域名啦。 再执行下面命令，重新更新和部署项目， 部署成功后，我们直接访问https://blog.python-brief.com/（我自定义的域名）来查看我们的博客啦～ 五、其它 经过上面操作，你会发现搭建确实很简单，但是访问真的是慢！！！ 主要原因是 GitHub 服务器在国外，这个解决还比较简单，我们可以同时将项目部署到国内码云：https://gitee.com/或者 Coding：https://coding.net/，整个过程和将项目部署到 GitHub 差不多。 ———————————————— 版权说明: 本文为 InfoQ 作者【老表】的原创文章。 原文链接：https://xie.infoq.cn/article/90dc08c57463df3a1b2ad960f","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]},{"title":"MarkDownload剪裁网页插件配置使用全流程","slug":"Hexo/MarkDownload剪裁网页插件配置使用全流程","date":"2024-12-02T08:07:25.000Z","updated":"2025-04-24T06:22:22.204Z","comments":true,"path":"2024/12/02/Hexo/MarkDownload剪裁网页插件配置使用全流程/","link":"","permalink":"http://www.formeasy.cc/2024/12/02/Hexo/MarkDownload%E5%89%AA%E8%A3%81%E7%BD%91%E9%A1%B5%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%E5%85%A8%E6%B5%81%E7%A8%8B/","excerpt":"","text":"Excerpt 前言写在前面，大家有什么问题和需要可以跟我交流 需求之前一直使用 Joplin 的剪裁网页功能，但是剪裁下来后不可避免的需要使用 Joplin 对剪裁下来的内容做处理，Joplin 用起来不是很习惯，所以在想可不可以用 Obs… 前言 写在前面，大家有什么问题和需要可以跟我交流 需求 之前一直使用 Joplin 的剪裁网页功能，但是剪裁下来后不可避免的需要使用 Joplin 对剪裁下来的内容做处理，Joplin 用起来不是很习惯，所以在想可不可以用 Obsidian 来实现网页剪裁和处理，最终选择的 MarkDownload 作为剪裁的工具 下载安装 有两种方式，第一种最简单直接打开谷歌插件商城搜索 MarkDownload 就可以下载，第二种方式是从 github 下载压缩文件然后解压到扩展中，如果不方便下载可以关注微信公众号 &lt;文件夹的知识圈&gt; 回复 &lt;插件下载&gt; 获得，压缩包对应的名字为 markdownload-main.zip，解压到扩展中的流程如下 打开 MarkDownload 的 Github 仓库： https://github.com/deathau/markdownload 依次点击 Code 和 Download ZIP 如下图，会获得一个名为 markdownload-main 的压缩文件 image.png|500 3. 打开浏览器的扩展管理页面，可以按照下面步骤打开 Firefox：在地址栏输入 about:addons，然后点击“扩展”。 Google Chrome：在地址栏输入 chrome://extensions/，然后点击“扩展程序”。 Microsoft Edge: 在地址栏输入 edge://extensions/，然后点击“扩展”。 Safari: 打开 Safari 设置，点击“扩展”。 4. 在扩展管理页面打开开发者模式并点击加载已解压扩展程序，然后选择对应的压缩包程序 image.png 配置 安装完成后还需要对插件进行配置才可以正常的在 Obsidian 中使用 左键点击 MarkDownload 图标然后点击设置按钮，如下图 image.png 2. 进行设置 必要的设置 如果想下载的 markdown 文件直接放到 obsidian 文件夹需要设置这里 image.png 填写内容的地方是指文件路径，默认的下载位置是浏览器的下载位置，如果想直接下载到对应文件夹需要在 Downloads 文件夹下创建一个 Obsidian 仓库，我这里的剪切好的文件就下载到了 Downloads/resource/00 Inbox/ 文件夹下 其次是下载的 markdown 中的图片，如果不进行设置默认是在线的图片链接，Obsidian 的图片我习惯本地化保存，这里需要勾选 image.png|500 最后一个必须设置的是这里，需要选择 Indented，否则在剪切的网页中有代码的地方会变成一坨 image.png|500 其它设置 其它设置如下，有需求的可以自己自定义： Title template：设置下载的文件的文件名 Disallowed Characters (to strip out of title/filename：系统中创建文件名需要避开的符号 Front-matter template：下载文件的前面添加的模板 Back-matter template：下载文件的后面添加的模板 Append front/back template to clipped text：是否启用前后模板 Markdown conversion options：一些样式的设置 MarkDownload 支持直接导入对应的配置模板，如有需要可自取，后缀名为 json 的配置文件，导入的流程为 新建一个后缀名为 .json 的文件 打开 MarkDownload 的配置界面，拉到最下面 Import / Export 点击 Choose file 选中对应的 json 文件即可 1&#123; &quot;backmatter&quot;: &quot;&quot;, &quot;bulletListMarker&quot;: &quot;-&quot;, &quot;codeBlockStyle&quot;: &quot;indented&quot;, &quot;contextMenus&quot;: true, &quot;disallowedChars&quot;: &quot;[]#^&quot;, &quot;downloadImages&quot;: true, &quot;downloadMode&quot;: &quot;downloadsApi&quot;, &quot;emDelimiter&quot;: &quot;_&quot;, &quot;fence&quot;: &quot;```&quot;, &quot;frontmatter&quot;: &quot;---\\ncreated: &#123;date:YYYY-MM-DDTHH:mm:ss&#125; (UTC &#123;date:Z&#125;)\\ntags: [&#123;keywords&#125;]\\nsource: &#123;baseURI&#125;\\nauthor: &#123;byline&#125;\\n---\\n\\n# &#123;pageTitle&#125;\\n\\n&gt; ## Excerpt\\n&gt; &#123;excerpt&#125;\\n\\n---&quot;, &quot;headingStyle&quot;: &quot;atx&quot;, &quot;hr&quot;: &quot;___&quot;, &quot;imagePrefix&quot;: &quot;&quot;, &quot;imageRefStyle&quot;: &quot;inlined&quot;, &quot;imageStyle&quot;: &quot;obsidian-nofolder&quot;, &quot;includeTemplate&quot;: true, &quot;linkReferenceStyle&quot;: &quot;full&quot;, &quot;linkStyle&quot;: &quot;inlined&quot;, &quot;mdClipsFolder&quot;: &quot;resource/00 Inbox/&quot;, &quot;obsidianFolder&quot;: &quot;00 ING&quot;, &quot;obsidianIntegration&quot;: false, &quot;obsidianVault&quot;: &quot;notes&quot;, &quot;saveAs&quot;: false, &quot;strongDelimiter&quot;: &quot;**&quot;, &quot;title&quot;: &quot;&#123;pageTitle&#125;&quot;, &quot;turndownEscape&quot;: true &#125; ———————————————— 原文链接：https://zhuanlan.zhihu.com/p/2340252011","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]},{"title":"Butterfly主题使用及美化","slug":"Hexo/Butterfly主题使用及美化","date":"2024-12-02T07:53:29.000Z","updated":"2025-04-24T06:22:57.188Z","comments":true,"path":"2024/12/02/Hexo/Butterfly主题使用及美化/","link":"","permalink":"http://www.formeasy.cc/2024/12/02/Hexo/Butterfly%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%BE%8E%E5%8C%96/","excerpt":"","text":"本期将为大家讲解Hexo Butterfly主题的使用。 1. 主题介绍 hexo-theme-butterfly是基于 Molunerfinn 的 hexo-theme-melody 的基础上进行开发的，当前版本是v4.13.0。 主题官网：https://github.com/jerryc127/hexo-theme-butterfly 官网效果图： 2. 主题安装 2.1 下载主题 建议你使用clone最新版本的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。 切换到博客的主题根目录下打开Git Bash并执行以下命令： 1git clone https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly 下载完成后，会在项目themes目录下生成butterfly文件夹。 如果没有修改代码的需求可以直接通过npm来安装。 1npm i hexo-theme-butterfly 仅支持Hexo 5.0.0及以上版本 2.2 渲染器下载 需要安装安装pug 和 stylus 渲染器，否则启动之后访问页面会报错。 错误内容： extends includes/layout.pug block content include ./includes/mixins/post-ui.pug #recent-posts.recent-posts +postUI include includes/pagination.pug 1npm install hexo-renderer-pug hexo-renderer-stylus --save 2.3 切换主题 与所有 Hexo 主题启用的模式一样。当 克隆/下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 butterfly。 1theme: butterfly 到此，Butterfly主题安装完成。 2.4 验证主题 启动服务并访问http://localhost:4000查看效果. 1hexo clean &amp;&amp; hexo s 3. 主题配置 主题配置文件是themes/butterfly/_config.yml。 3.1 配置说明 以下是themes/butterfly/_config.yml文件的翻译版本，可以复制进去替换原文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340134113421343134413451346134713481349135013511352135313541355135613571358135913601361136213631364136513661367136813691370137113721373137413751376137713781379138013811382138313841385138613871388138913901391139213931394139513961397139813991400140114021403140414051406140714081409141014111412141314141415141614171418141914201421142214231424142514261427142814291430143114321433143414351436143714381439144014411442144314441445144614471448144914501451145214531454145514561457145814591460146114621463146414651466146714681469147014711472147314741475147614771478147914801481148214831484148514861487148814891490149114921493149414951496149714981499150015011502150315041505150615071508150915101511151215131514151515161517151815191520152115221523152415251526152715281529153015311532153315341535153615371538153915401541154215431544154515461547154815491550155115521553155415551556155715581559156015611562156315641565156615671568156915701571157215731574157515761577157815791580158115821583158415851586158715881589159015911592159315941595159615971598159916001601160216031604160516061607160816091610161116121613161416151616161716181619162016211622162316241625162616271628162916301631163216331634163516361637163816391640164116421643164416451646164716481649165016511652165316541655165616571658165916601661166216631664166516661667166816691670167116721673167416751676167716781679168016811682168316841685168616871688168916901691169216931694169516961697169816991700170117021703170417051706170717081709171017111712171317141715171617171718171917201721172217231724172517261727# Navigation bar settings (导航栏设置)# 见 https://butterfly.js.org/posts/4aa8abbe/##导航栏设置-Navigation-bar-settings# --------------------------------------nav:logo: # 图片display_title: truefixed: false # 固定导航栏# Menu 目录menu:# Home: / || fas fa-home# Archives: /archives/ || fas fa-archive# Tags: /tags/ || fas fa-tags# Categories: /categories/ || fas fa-folder-open# List||fas fa-list:# Music: /music/ || fas fa-music# Movie: /movies/ || fas fa-video# Link: /link/ || fas fa-link# About: /about/ || fas fa-heart# Code Blocks (代码块相关)# --------------------------------------highlight_theme: light # darker / pale night / light / ocean / falsehighlight_height_limit: false # 单位：像素code_word_wrap: false# 高亮工具栏highlight_theme_macStyle: false # 使用 Mac 风格highlight_copy: true # 复制按钮highlight_lang: true # 显示代码语言highlight_shrink: false # true: 收缩代码块 / false: 展开代码块 | none: 展开代码块并隐藏按钮highlight_fullpage: true # true: 添加切换全屏的按钮# Social Settings (社交图标设置)# 正式:# icon: 链接 || 描述 || 颜色social:# fab fa-github: https://github.com/xxxxx || Github || &#x27;#24292e&#x27;# fas fa-envelope: mailto:xxxxxx@gmail.com || Email || &#x27;#4a7dbe&#x27;# Image (图片设置)# --------------------------------------# Favicon（网站图标）favicon: /img/favicon.png# Avatar (头像)avatar:img: https://i.loli.net/2021/02/24/5O1day2nriDzjSu.pngeffect: false# 禁用所有横幅图片disable_top_img: false# 首页的横幅图片index_img:# 如果页面没有设置横幅，则显示顶部图片default_top_img:# 归档页面的横幅图片archive_img:# 如果标签页面没有设置横幅，则显示顶部图片# 注意：标签页面，不是标签页面（子标签页面的顶部图片）tag_img:# 标签页面的横幅图片# 格式:# - 标签名: xxxxxtag_per_img:# 如果分类页面没有设置横幅，则显示顶部图片# 注意：分类页面，不是分类页面（子分类页面的顶部图片）category_img:# 分类页面的横幅图片# 格式:# - 分类名: xxxxxcategory_per_img:# 封面cover:# 是否显示文章封面index_enable: trueaside_enable: truearchives_enable: true# 首页封面显示的位置# left/right/bothposition: both# 当没有设置封面时，显示默认封面default_cover:# - https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg# 替换无法显示的图片error_img:flink: /img/friend_404.gifpost_page: /img/404.jpg# 一个简单的 404 页面error_404:enable: falsesubtitle: &#x27;页面未找到&#x27;background: https://i.loli.net/2020/05/19/aKOcLiyPl2JQdFD.png# post_meta 页面元数据post_meta:page: # 首页date_type: created # created 或 updated 或 both 主页文章日期显示创建日或者更新日或都显示date_format: date # date 或 relative 显示日期还是相对日期categories: true # true 或 false 主页是否显示分类tags: false # true 或 false 主页是否显示标签label: true # true 或 false 显示描述性文字post:position: left # left 或 center 文章页标题位置date_type: both # created 或 updated 或 both 文章页日期显示创建日或者更新日或都显示date_format: date # date 或 relative 显示日期还是相对日期categories: true # true 或 false 文章页是否显示分类tags: true # true 或 false 文章页是否显示标签label: true # true 或 false 显示描述性文字# 在首页显示文章介绍# 1: description# 2: both (如果描述存在，则显示描述，否则显示自动摘要)# 3: auto_excerpt (默认)# false: 不显示文章介绍index_post_content:method: 3length: 500 # 如果你设置方法为 2 或 3，需要配置长度# 锚点anchor:# 当你滚动时，URL 将根据标题 id 更新auto_update: false# 点击标题滚动并更新锚点click_to_scroll: false# 图片描述文字photofigcaption: false# 复制设置# copyright: 在复制内容后面添加版权信息copy:enable: truecopyright:enable: falselimit_count: 50# 文章# --------------------------------------# toc (目录)toc:post: truepage: falsenumber: trueexpand: falsestyle_simple: false # 针对文章scroll_percent: true# 文章版权post_copyright:enable: truedecode: falseauthor_href:license: CC BY-NC-SA 4.0license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/# 赞助/打赏reward:enable: falsetext:QR_code:# - img: /img/wechat.jpg# link:# text: wechat# - img: /img/alipay.jpg# link:# text: alipay# 文章编辑# 在线轻松浏览和编辑博客源代码post_edit:enable: false# url: https://github.com/user-name/repo-name/edit/branch-name/subdirectory-name/# 例如: https://github.com/jerryc127/butterfly.js.org/edit/main/source/url:# 相关文章related_post:enable: truelimit: 6 # 显示的文章数量date_type: created # 或者 created 或 updated 文章日期显示创建日或者更新日# 文章分页# value: 1 || 2 || false# 1: 下一篇文章将链接到旧文章# 2: 下一篇文章将链接到新文章# false: 禁用分页post_pagination: 1# 显示文章的过时提醒noticeOutdate:enable: falsestyle: flat # 风格: simple/flatlimit_day: 500 # 何时显示position: top # 位置: top/bottommessage_prev: 已经有message_next: 天未更新，文章内容可能已过时。# 页脚设置# --------------------------------------footer:owner:enable: truesince: 2020custom_text:copyright: true # 主题和框架的版权# 侧边栏# --------------------------------------aside:enable: truehide: falsebutton: truemobile: true # 在移动设备上显示position: right # left or rightdisplay:archive: truetag: truecategory: truecard_author:enable: truedescription:button:enable: trueicon: fab fa-githubtext: 关注我link: https://github.com/xxxxxxcard_announcement:enable: truecontent: 这是我的博客card_recent_post:enable: truelimit: 5 # 如果设置为 0 将显示全部sort: date # date 或 updatedsort_order: # 除非你知道它如何工作，否则不要修改设置card_categories:enable: truelimit: 8 # 如果设置为 0 将显示全部expand: none # none/true/falsesort_order: # 除非你知道它如何工作，否则不要修改设置card_tags:enable: truelimit: 40 # 如果设置为 0 将显示全部color: falseorderby: random # 标签顺序，random/name/lengthorder: 1 # 排序方式。1，升序；-1，降序sort_order: # 除非你知道它如何工作，否则不要修改设置card_archives:enable: truetype: monthly # yearly 或 monthlyformat: MMMM YYYY # 例如：YYYY年MM月order: -1 # 排序方式。1，升序；-1，降序limit: 8 # 如果设置为 0 将显示全部sort_order: # 除非你知道它如何工作，否则不要修改设置card_webinfo:enable: truepost_count: truelast_push_date: truesort_order: # 除非你知道它如何工作，否则不要修改设置card_post_series:enable: trueseries_title: false # 标题显示系列名称orderBy: &#x27;date&#x27; # 按标题或日期排序order: -1 # 排序方式。1，升序；-1，降序# 网站访问人数统计busuanzi:site_uv: truesite_pv: truepage_pv: true# 网页运行时间（发布日期与现在的时间差）# 格式：Month/Day/Year Time or Year/Month/Day Timeruntimeshow:enable: falsepublish_date:# 侧边栏小部件 - 最新评论newest_comments:enable: falsesort_order:limit: 6storage: 10 # 单位：分钟，数据保存到 localStorageavatar: true# 右下角按钮# --------------------------------------# 简繁转换translate:enable: false# 按钮的文本default: 繁# 网站的语言 (1 - 繁体中文 / 2 - 简体中文）defaultEncoding: 2# 时间延迟translateDelay: 0# 简体字状态下按钮的文本msgToTraditionalChinese: &#x27;繁&#x27;# 繁体字状态下按钮的文本msgToSimplifiedChinese: &#x27;简&#x27;# 阅读模式readmode: true# 暗色模式darkmode:enable: true# 切换暗色/浅色模式的按钮button: true# 自动切换暗色/浅色模式 (自动切换 dark mode 和 light mode)# autoChangeMode: 1 跟随系统设置，如果系统不支持暗色模式，则在下午 6 点到早上 6 点之间切换暗色模式# autoChangeMode: 2 在下午 6 点到早上 6 点之间切换暗色模式# autoChangeMode: falseautoChangeMode: false# 设置浅色模式的时间。取值范围是 0 到 24。如果没有设置，默认值是 6 和 18start:end:# 在返回顶部按钮中显示滚动百分比rightside_scroll_percent: false# 除非你知道它们如何工作，否则不要修改以下设置# 选择：readmode,translate,darkmode,hideAside,toc,chat,comment# 不要重复rightside_item_order:enable: falsehide: # readmode,translate,darkmode,hideAsideshow: # toc,chat,comment# Math (數學)# --------------------------------------# 关于每页的设置# 如果你设置为 true，它将在每一页都加载 mathjax/katex 脚本 (true 表示每一页都加载 js)# 如果你设置为 false，它将根据你的设置加载 mathjax/katex 脚本 (需要在页面的 Markdown Front-matter 中添加 mathjax: true)# (false 按需加载，必须在使用的 Markdown Front-matter 中添加 mathjax: true)# MathJaxmathjax:enable: falseper_page: false# KaTeXkatex:enable: falseper_page: falsehide_scrollbar: true# 搜索# 见 https://butterfly.js.org/posts/ceeb73f/#搜索系统# --------------------------------------# Algolia 搜索algolia_search:enable: falsehits:per_page: 6# 本地搜索local_search:enable: false# 页面加载时预加载搜索数据preload: false# 每篇文章显示前 n 个结果，设置为 -1 显示所有结果top_n_per_article: 1# 将 HTML 字符串转换为可读的格式unescape: falseCDN:# Docsearchdocsearch:enable: falseappId:apiKey:indexName:option:# 分享系统# --------------------------------------# Share.js# https://github.com/overtrue/share.jssharejs:enable: truesites: facebook,twitter,wechat,weibo,qq# AddToAny# https://www.addtoany.com/addtoany:enable: falseitem: facebook,twitter,wechat,sina_weibo,facebook_messenger,email,copy_link# 评论系统# --------------------------------------comments:# 最多可以选择两个评论系统，第一个将作为默认显示# 选择：Disqus/Disqusjs/Livere/Gitalk/Valine/Waline/Utterances/Facebook Comments/Twikoo/Giscus/Remark42/Artalkuse:text: true # 在按钮旁边显示评论名称# lazyload: 当评论元素进入浏览器视口时，评论系统将被加载。# 如果你设置为 true，则评论计数将无效lazyload: falsecount: false # 在文章顶部图片中显示评论计数card_post_count: false # 在首页显示评论计数# Disqus# https://disqus.com/disqus:shortname:apikey: # 用于最新评论小部件# DisqusJS 评论系统，可以在网络审查地区加载 Disqus 评论列表，兼容原版# https://github.com/SukkaW/DisqusJSdisqusjs:shortname:apikey:option:# Livere (来必力)# https://www.livere.com/livere:uid:# Gitalk# https://github.com/gitalk/gitalkgitalk:client_id:client_secret:repo:owner:admin:option:# Valine# https://valine.js.orgvaline:appId: # Leancloud 应用 App IDappKey: # Leancloud 应用 App 密钥avatar: monsterid # Gravatar 风格 https://valine.js.org/#/avatarserverURLs: # 此配置适用于国内自定义域名用户，海外版本将自动检测（无需手动填写）bg: # Valine 背景visitor: falseoption:# Waline - 一个简单的带有后端支持的评论系统，Valine 的一个分支# https://waline.js.org/waline:serverURL: # Waline 服务器地址 URLbg: # Waline 背景pageview: falseoption:# Utterances# https://utteranc.es/utterances:repo:# 问题映射：pathname/url/title/og:titleissue_term: pathname# 主题：github-light/github-dark/github-dark-orange/icy-dark/dark-blue/photon-darklight_theme: github-lightdark_theme: photon-dark# Facebook Comments Plugin# https://developers.facebook.com/docs/plugins/comments/facebook_comments:app_id:user_id: # 可选pageSize: 10 # 显示的评论数量order_by: social # social/time/reverse_timelang: zh_TW # 语言 en_US/zh_CN/zh_TW 等# Twikoo# https://github.com/imaegoo/twikootwikoo:envId:region:visitor: falseoption:# Giscus# https://giscus.app/giscus:repo:repo_id:category_id:theme:light: lightdark: darkoption:# Remark42# https://remark42.com/docs/configuration/frontend/remark42:host: # 你的主机 URLsiteId: # 你的站点 IDoption:# Artalk# https://artalk.js.org/guide/frontend/config.htmlartalk:server:site:visitor: falseoption:# 聊天服务# --------------------------------------# 聊天按钮 [推荐]# 它将在网站右下角创建一个按钮，并隐藏原始按钮chat_btn: false# 当滚动至上部时显示原始聊天按钮，滚动下来时隐藏按钮chat_hide_show: false# Chatra# https://chatra.io/chatra:enable: falseid:# Tidio# https://www.tidio.com/tidio:enable: falsepublic_key:# Daovoice# http://dashboard.daovoice.io/appdaovoice:enable: falseapp_id:# Crisp# https://crisp.chat/en/crisp:enable: falsewebsite_id:# Messenger# https://developers.facebook.com/docs/messenger-platform/discovery/facebook-chat-plugin/messenger:enable: falsepageID:lang: zh_TW # 语言 en_US/zh_CN/zh_TW 等# 分析# --------------------------------------# Baidu Analytics# https://tongji.baidu.com/web/welcome/loginbaidu_analytics:# Google Analytics# https://analytics.google.com/analytics/web/google_analytics:# Cloudflare Analytics# https://www.cloudflare.com/zh-tw/web-analytics/cloudflare_analytics:# Microsoft Clarity# https://clarity.microsoft.com/microsoft_clarity:# 广告# --------------------------------------# Google Adsense (谷歌广告)google_adsense:enable: falseauto_ads: truejs: https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.jsclient:enable_page_level_ads: true# 手动插入广告# ad:# index:# aside:# post:# 站长验证# --------------------------------------site_verification:# - name: google-site-verification# content: xxxxxx# - name: baidu-site-verification# content: xxxxxxx# 美化/效果# --------------------------------------# 自定义主题颜色# 注意：颜色值必须用双引号引起来，如 &quot;#000&quot;，否则可能会导致错误！# theme_color:# enable: true# main: &quot;#49B1F5&quot;# paginator: &quot;#00c4b6&quot;# button_hover: &quot;#FF7242&quot;# text_selection: &quot;#00c4b6&quot;# link_color: &quot;#99a9bf&quot;# meta_color: &quot;#858585&quot;# hr_color: &quot;#A4D8FA&quot;# code_foreground: &quot;#F47466&quot;# code_background: &quot;rgba(27, 31, 35, .05)&quot;# toc_color: &quot;#00c4b6&quot;# blockquote_padding_color: &quot;#49b1f5&quot;# blockquote_background_color: &quot;#49b1f5&quot;# scrollbar_color: &quot;#49b1f5&quot;# meta_theme_color_light: &quot;ffffff&quot;# meta_theme_color_dark: &quot;#0d0d0d&quot;# 首页的 top_img 设置# 默认：top img - 全屏，site info - 中间（默认 top_img 全屏，site_info 在中间）# 网站信息的位置，例如：300px/300em/300rem/10%（首页标题距离顶部的距离）index_site_info_top:# 首页 top_img 的高度，例如：300px/300em/300remindex_top_img_height:# 分类和标签页面的用户界面设置 (category 和 tag 页的 UI 设置)# index - 与首页 UI 相同（index 值代表 UI 将与首页的 UI 一样）# default - 与归档 UI 相同，默认跟 archives 页面 UI 一样category_ui: # 留空或 indextag_ui: # 留空或 index# 拉伸行宽，使每一行宽度相等（文字两端对齐，对最后一行无效）text_align_justify: false# 设置网站背景# 可以设置为颜色或图片（可设置图片 或者 颜色）# 图片格式：url(http://xxxxxx.com/xxx.jpg)background:# 页脚背景footer_bg: false# 为 header 或 footer 添加黑色半透明遮罩mask:header: truefooter: true# 右下角按钮距离底部的位置，默认单位为像素rightside_bottom:# 开启网页进入效果enter_transitions: true# 打字效果# https://github.com/disjukr/activate-power-modeactivate_power_mode:enable: falsecolorful: true # 开启粒子动画（发光特效）shake: true # 开启 shake（抖动特效）mobile: false# 背景特效# --------------------------------------# canvas_ribbon (静止彩带背景)# 见: https://github.com/hustcc/ribbon.jscanvas_ribbon:enable: falsesize: 150alpha: 0.6zIndex: -1click_to_change: falsemobile: false# Fluttering Ribbon (动态彩带)canvas_fluttering_ribbon:enable: falsemobile: false# canvas_nest# https://github.com/hustcc/canvas-nest.jscanvas_nest:enable: falsecolor: &#x27;0,0,255&#x27; # 线条的颜色，默认: &#x27;0,0,0&#x27;；RGB 值：(R,G,B)。（注意：用 &#x27;,&#x27; 分隔）opacity: 0.7 # 线条的透明度 (0~1)，默认: 0.5zIndex: -1 # 背景的 z-index 属性，默认: -1count: 99 # 线条的数量，默认: 99mobile: false# 鼠标点击效果：烟花特效fireworks:enable: falsezIndex: 9999 # -1 或 9999mobile: false# 鼠标点击效果：爱心click_heart:enable: falsemobile: false# 鼠标点击效果：文字clickShowText:enable: falsetext:# - 我# - 爱# - 你fontSize: 15pxrandom: falsemobile: false# 网站默认的显示模式# light (默认) / darkdisplay_mode: light# 美化页面显示beautify:enable: falsefield: post # site/posttitle-prefix-icon: # &#x27;\\\\f0c1&#x27;title-prefix-icon-color: # &#x27;#F47466&#x27;# 全局字体设置# 除非你知道它们如何工作，否则不要修改以下设置font:global-font-size:code-font-size:font-family:code-font-family:# 网站标题和副标题的字体设置# 左上角网站名字 主页居中网站名字blog_title_font:font_link:font-family:# 水平分隔线图标设置hr_icon:enable: trueicon: # 字体图标的 Unicode 值，例如 &#x27;\\\\3423&#x27;icon-top:# 首页副标题subtitle:enable: false# 打字效果effect: true# 定制 typed.js# https://github.com/mattboldt/typed.js/#customizationtyped_option:# source 调用第三方服务# source: false 关闭调用# source: 1 调用一言网的一句话（简体） https://hitokoto.cn/# source: 2 调用一句网（简体） https://yijuzhan.com/# source: 3 调用今日诗词（简体） https://www.jinrishici.com/# subtitle 会先显示 source , 再显示 sub 的内容source: false# 如果关闭打字效果，subtitle 只会显示 sub 的第一行文字sub:# 加载动画preloader:enable: false# source# 1. fullpage-loading# 2. pace (progress bar)source:# pace 主题 (见 https://codebyzach.github.io/pace/)pace_css_url:# 字数统计# 见 https://butterfly.js.org/posts/ceeb73f/#字数统计wordcount:enable: falsepost_wordcount: truemin2read: truetotal_wordcount: true# 图片大图查看模式# --------------------------------------# 只能选择一个，或者两个都不选# medium-zoom# https://github.com/francoischalifour/medium-zoommedium_zoom: false# fancybox# https://fancyapps.com/fancybox/fancybox: true# 标签插件设置# --------------------------------------# series (系列文章)series:enable: trueorderBy: &#x27;title&#x27; # 按标题或日期排序order: 1 # 排序方式。1, 升序；-1, 降序number: true# abcjs (乐谱渲染)# 见 https://github.com/paulrosen/abcjsabcjs:enable: falseper_page: true# Mermaid# 见 https://github.com/mermaid-js/mermaidmermaid:enable: true# 以代码块形式书写 Mermaid 图表（以代码块形式书写 Mermaid）code_write: false# 内置主题: default/forest/dark/neutraltheme:light: defaultdark: dark# Note (Bootstrap Callout)note:# Note 标签样式值:# - simple bs-callout 旧版警告样式。默认。# - modern bs-callout 新版 (v2-v3) 警告样式。# - flat 带有背景的 flat callout 样式，类似于 Mozilla 或 StackOverflow。# - disabled 禁用所有 CSS 样式的导入。style: flaticons: trueborder_radius: 3# 对现代和平面风格的背景进行百分比的偏移量更亮 (现代: -12 | 12; 平面: -18 | 6)。# 偏移量也应用于标签变量。此选项可以与禁用的 note 标签一起使用。light_bg_offset: 0# 其他# --------------------------------------# Pjax# 它可能包含错误并且不稳定，请在发现错误时提供反馈。# https://github.com/MoOx/pjaxpjax:enable: falseexclude:# - xxxx# - xxxx# 注入 CSS 和脚本 (aplayer/meting)aplayerInject:enable: falseper_page: true# Snackbar (Toast 通知弹窗)# https://github.com/polonel/SnackBar# position 弹窗位置# 可选 top-left / top-center / top-right / bottom-left / bottom-center / bottom-rightsnackbar:enable: falseposition: bottom-leftbg_light: &#x27;#49b1f5&#x27; # 浅色模式下 Toast 通知的背景颜色bg_dark: &#x27;#1f1f1f&#x27; # 深色模式下 Toast 通知的背景颜色# https://instant.page/# prefetch (预加载)instantpage: false# https://github.com/vinta/pangu.js# 在中英文之间添加空格pangu:enable: falsefield: site # site/post# 懒加载 (图片懒加载)# https://github.com/verlok/vanilla-lazyloadlazyload:enable: falsefield: site # site/postplaceholder:blur: false# PWA# 见 https://github.com/JLHwung/hexo-offline# ---------------# pwa:# enable: false# manifest: /pwa/manifest.json# apple_touch_icon: /pwa/apple-touch-icon.png# favicon_32_32: /pwa/32.png# favicon_16_16: /pwa/16.png# mask_icon: /pwa/safari-pinned-tab.svg# Open graph 元标签# https://developers.facebook.com/docs/sharing/webmasters/Open_Graph_meta:enable: trueoption:# twitter_card:# twitter_image:# twitter_id:# twitter_site:# google_plus:# fb_admins:# fb_app_id:# 添加厂商前缀以确保兼容性css_prefix: true# 注入# 在头部 (&#x27;&lt;head&gt;&#x27; 标签之前) 和底部 (&#x27;&lt;body&gt;&#x27; 标签之前) 插入代码# 在头部 &lt;head&gt; 之前 和 底部 &lt;body&gt; 之前插入代码inject:head:# - &lt;link rel=&quot;stylesheet&quot; href=&quot;/xxx.css&quot;&gt;bottom:# - &lt;script src=&quot;xxxx&quot;&gt;&lt;/script&gt;# CDN# 除非你知道它们如何工作，否则不要修改以下设置# 非必要请不要修改CDN:# 主题内部 js 的 CDN 配置# 选项: local/jsdelivr/unpkg/cdnjs/custom# Dev 版本只能选择 (dev 版的主体只能设置为 local)internal_provider: local# 第三方 js 的 CDN 配置# 选项: local/jsdelivr/unpkg/cdnjs/custom# 当设置为 local 时，你需要安装 hexo-butterfly-extjsthird_party_provider: jsdelivr# 在 URL 中添加版本号，true 或 falseversion: true# 自定义格式# 例如: https://cdn.staticfile.org/$&#123;cdnjs_name&#125;/$&#123;version&#125;/$&#123;min_cdnjs_file&#125;custom_format:option:# abcjs_basic_js:# activate_power_mode:# algolia_js:# algolia_search:# aplayer_css:# aplayer_js:# artalk_css:# artalk_js:# blueimp_md5:# busuanzi:# canvas_fluttering_ribbon:# canvas_nest:# canvas_ribbon:# click_heart:# clickShowText:# disqusjs:# disqusjs_css:# docsearch_css:# docsearch_js:# egjs_infinitegrid:# fancybox:# fancybox_css:# fireworks:# fontawesome:# gitalk:# gitalk_css:# giscus:# instantpage:# instantsearch:# katex:# katex_copytex:# lazyload:# local_search:# main:# main_css:# mathjax:# medium_zoom:# mermaid:# meting_js:# pangu:# prismjs_autoloader:# prismjs_js:# prismjs_lineNumber_js:# pjax:# sharejs:# sharejs_css:# snackbar:# snackbar_css:# translate:# twikoo:# typed:# utils:# valine:# waline_css:# waline_js: 3.2 更改语言 首先我们要将英语改为中文；butterfly主题自带4种语言。 编辑**站点配置文件**，修改语言设置。 1language: zh-CN 3.3 设置站点信息 效果图： 打开**站点配置文件（_config.yml）修改网站各种资料，例如标题、副标题和语言**等个人资料。 123456789101112131415# Sitetitle: &#x27;他乡遇故知&#x27; #标题subtitle: &#x27;一步一句是相思&#x27; #副标题description: &#x27;台下人金榜正题名，不曾认台上旧相识&#x27; #个性签名keywords: nullauthor: 探窗 #作者language: zh-CN #语言timezone: &#x27;&#x27; #时区 3.4 设置导航菜单 效果图： 编辑 themes/butterfly/_config.yml，修改以下内容： 123456789101112131415161718192021# Menu 目錄menu:首页: / || fas fa-home归档: /archives/ || fas fa-archive标签: /tags/ || fas fa-tags目录: /categories/ || fas fa-folder-open列表||fas fa-list:音乐: /music/ || fas fa-music电影: /movies/ || fas fa-video友情链接: /link/ || fas fa-link关于我们: /about/ || fas fa-heart 3.5 代码块显示设置 效果图相当漂亮： 编辑 themes/butterfly/_config.yml，修改以下内容： 123456789101112131415161718192021# Code Blocks (代码块相关)# --------------------------------------highlight_theme: darker # darker / pale night / light / ocean / falsehighlight_height_limit: false # 单位：像素code_word_wrap: true# 高亮工具栏highlight_theme_macStyle: true # 使用 Mac 风格highlight_copy: true # 复制按钮highlight_lang: true # 显示代码语言highlight_shrink: false # true: 收缩代码块 / false: 展开代码块 | none: 展开代码块并隐藏按钮highlight_fullpage: true # true: 添加切换全屏的按钮 同时，将**站点配置文件**（_config.yml）中的highlight相关的配置注释掉。 1234567891011#highlight:# line_number: false# auto_detect: false# tab_replace: &#x27;&#x27;# wrap: false# hljs: false 3.6 设置导航栏图片 效果图如下： 编辑 themes/butterfly/_config.yml，修改以下内容： 123456789# Navigation bar settings (导航栏设置)# 见 https://butterfly.js.org/posts/4aa8abbe/##导航栏设置-Navigation-bar-settings# --------------------------------------nav:logo: /images/butterfly.png 本地图片在站点根目录的source文件夹里。 3.7 修改首页副标题 效果图： 编辑 themes/butterfly/_config.yml： 12345678910111213141516171819202122232425262728293031323334353637383940414243# 首页副标题subtitle:# 是否开启：true：开启，false：不开启enable: true# 打字效果effect: true# 定制 typed.js# https://github.com/mattboldt/typed.js/#customizationtyped_option:# source 调用第三方服务# source: false 关闭调用# source: 1 调用一言网的一句话（简体） https://hitokoto.cn/# source: 2 调用一句网（简体） https://yijuzhan.com/# source: 3 调用今日诗词（简体） https://www.jinrishici.com/# subtitle 会先显示 source , 再显示 sub 的内容source: false# 如果关闭打字效果，subtitle 只会显示 sub 的第一行文字sub:- 你在抱怨什么呢- 为明天到来的事，说人生像是没有意义- 没有选择会是唯一的路- 这不是你自己的问题，人终归要好好去生活 3.8 图片设置 图片链接地址可以是： 完整的互联网 URI，如：http://example.com/avatar.png 站点内的地址，主题或站点的source目录下。注意：是站点根目录的source文件夹里。 修改主题配置文件_config.butterfly.yml： 网站图标 1favicon: /img/favicon.png 头像 1234567# Avatar (头像)avatar:img: /images/next_icon.png #https://i.loli.net/2021/02/24/5O1day2nriDzjSu.pngeffect: false #是否一直转圈 false：不开启，true开启 主页横幅图片 123# 首页的横幅图片index_img: 文章详情页顶部图片 当没有在front-matter设置top_img和cover的情况下会显示该图 123# 如果页面没有设置横幅，则显示顶部图片default_top_img: /img/default_top_img.png 归档页横幅图片 123# 归档页面的横幅图片archive_img: tag标签页横幅图片 12345678910111213# 如果标签页面没有设置横幅，则显示顶部图片# 注意：标签页面，不是标签页面（子标签页面的顶部图片）tag_img:# 具体标签页面的横幅图片# 格式:# - 标签名: xxxxxtag_per_img: category目录页横幅图片 12345678910111213# 如果分类页面没有设置横幅，则显示顶部图片# 注意：分类页面，不是分类页面（子分类页面的顶部图片）category_img:# 具体分类页面的横幅图片，可以为不同的category设置不同的横幅图片# 格式:# - 分类名: xxxxxcategory_per_img: 文章统一封面 12345678910111213141516171819202122232425262728293031# 封面cover:# 是否显示文章封面index_enable: trueaside_enable: truearchives_enable: true# 首页封面显示的位置position: both # left/right/both# 当没有设置封面时，显示默认封面default_cover:# 当配置多张图片时，会随机选择一张作为 cover. 此时写法为- https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg- https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg- https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg- https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg- https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg 如果需要为每一篇文章设置不同的封面，可以在文章的md文件中添加配置。 123456789101112131415---title: Hello Worldtags: [hello]categories:description: hello word~top_img: /img/hello-1.pngcover: /img/hello-1.png--- 错误页面 配置了该属性后会替换无法展示的图片 1234567# 替换无法显示的图片error_img:flink: /img/friend_404.gifpost_page: /img/404.jpg 3.9 图片懒加载 新增hexo-lazyload-image模块 1npm install hexo-lazyload-image --save 编辑**站点配置文件**（_config.yml）增加配置： 12345lazyload:enable: trueloadingImg: /img/loading.gif 在图片没加载出来的时候，出现一个动图转动的图片样式。 3.10 图片大图查看 编辑 themes/butterfly/_config.yml，修改以下内容： 1234567891011121314151617# 图片大图查看模式# --------------------------------------# 只能选择一个，或者两个都不选# medium-zoom# https://github.com/francoischalifour/medium-zoommedium_zoom: false# fancybox# https://fancyapps.com/fancybox/fancybox: true 注意：这两个选项只能二选一或者不选 3.11 版权样式 编辑 themes/butterfly/_config.yml，修改以下内容： 复制的内容后面加上版权信息 123456789copy:enable: truecopyright:enable: falselimit_count: 50 文章版权信息 12345678910111213# 文章版权post_copyright:enable: truedecode: trueauthor_href:license: CC BY-NC-SA 4.0license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/ 效果图： 3.12 相关文章 效果图： 在文章最下面出现相关文章推荐。 编辑 themes/butterfly/_config.yml： 1234567related_post:enable: truelimit: 6date_type: created 3.13 打赏 效果图： 给文章结尾设置打赏按钮，可以放上收款二维码。 编辑 themes/butterfly/_config.yml： 123456789101112131415161718192021# 赞助/打赏reward:enable: truetext:QR_code:- img: /img/wechat.pnglink:text: wechat- img: /img/alipay.pnglink:text: alipay 3.14 侧边栏样式 编辑 themes/butterfly/_config.yml： 调整侧边栏出现位置 1234567891011aside:enable: truehide: falsebutton: truemobile: true # 在移动设备上显示position: right # left or right 个人信息 12345social:fab fa-github: https://github.com/xxxxx || Github || &#x27;#24292e&#x27;fas fa-envelope: mailto:xxxxxx@gmail.com || Email || &#x27;#4a7dbe&#x27; 效果图： 3.15 公告栏设置 效果图： 编辑 themes/butterfly/_config.yml： 12345card_announcement:enable: truecontent: 这是我的博客 3.16 Toc目录 效果图： 编辑 themes/butterfly/_config.yml： 12345678910111213toc:post: truepage: falsenumber: trueexpand: falsestyle_simple: falsescroll_percent: true 3.17 字数统计 效果图： 安装统计组件 1npm install hexo-wordcount --save or yarn add hexo-wordcount 编辑 themes/butterfly/_config.yml： 12345678910111213# 字数统计# 见 https://butterfly.js.org/posts/ceeb73f/#字数统计wordcount:enable: truepost_wordcount: truemin2read: truetotal_wordcount: true 3.18 文章分享功能 share.js、addtoany二选一开启。 编辑 themes/butterfly/_config.yml： 1234567891011sharejs:enable: truesites: facebook,twitter,wechat,weibo,qqaddtoany:enable: falseitem: facebook,twitter,wechat,sina_weibo,facebook_messenger,email,copy_link 效果图： Share.js AddToAny 3.19 背景特效/美化 编辑 themes/butterfly/_config.yml： 1. 鼠标点击效果 有烟火特效、爱心特效、文字特效，选择其中一个将enable设置为true就可以。 12345678910111213141516171819202122232425fireworks:enable: falsezIndex: 9999mobile: falseclick_heart:enable: falsemobile: falseclickShowText:enable: falsetext:fontSize: 15pxrandom: falsemobile: false 2. 打字效果 123456789activate_power_mode:enable: falsecolorful: trueshake: truemobile: false 3. 背景特效 12345678910111213141516171819202122232425262728293031323334353637383940414243# canvas_ribbon (静止彩带背景)# 见: https://github.com/hustcc/ribbon.jscanvas_ribbon:enable: falsesize: 150alpha: 0.6zIndex: -1click_to_change: falsemobile: false# Fluttering Ribbon (动态彩带)canvas_fluttering_ribbon:enable: falsemobile: false# canvas_nest# https://github.com/hustcc/canvas-nest.jscanvas_nest:enable: falsecolor: &#x27;0,0,255&#x27; # 线条的颜色，默认: &#x27;0,0,0&#x27;；RGB 值：(R,G,B)。（注意：用 &#x27;,&#x27; 分隔）opacity: 0.7 # 线条的透明度 (0~1)，默认: 0.5zIndex: -1 # 背景的 z-index 属性，默认: -1count: 99 # 线条的数量，默认: 99mobile: false 4. 自定义背景主题色 1234567891011121314151617181920212223242526272829303132333435363738394041# 美化/效果# --------------------------------------# 自定义主题颜色# 注意：颜色值必须用双引号引起来，如 &quot;#000&quot;，否则可能会导致错误！# theme_color:# enable: true# main: &quot;#49B1F5&quot;# paginator: &quot;#00c4b6&quot;# button_hover: &quot;#FF7242&quot;# text_selection: &quot;#00c4b6&quot;# link_color: &quot;#99a9bf&quot;# meta_color: &quot;#858585&quot;# hr_color: &quot;#A4D8FA&quot;# code_foreground: &quot;#F47466&quot;# code_background: &quot;rgba(27, 31, 35, .05)&quot;# toc_color: &quot;#00c4b6&quot;# blockquote_padding_color: &quot;#49b1f5&quot;# blockquote_background_color: &quot;#49b1f5&quot;# scrollbar_color: &quot;#49b1f5&quot;# meta_theme_color_light: &quot;ffffff&quot;# meta_theme_color_dark: &quot;#0d0d0d&quot; 5. 渐变背景 默认显示白色，可设置图片或者颜色 1234567# 设置网站背景# 可以设置为颜色或图片（可设置图片 或者 颜色）# 图片格式：url(http://xxxxxx.com/xxx.jpg)background: 增加背景渐变色步骤： 在themes/butterfly/source/css/目录下创建css文件 background.css： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#web_bg &#123;background: -webkit-linear-gradient(0deg,rgba(247, 149, 51, 0.1) 0,rgba(243, 112, 85, 0.1) 15%,rgba(239, 78, 123, 0.1) 30%,rgba(161, 102, 171, 0.1) 44%,rgba(80, 115, 184, 0.1) 58%,rgba(16, 152, 173, 0.1) 72%,rgba(7, 179, 155, 0.1) 86%,rgba(109, 186, 130, 0.1) 100%);background: -moz-linear-gradient(0deg,rgba(247, 149, 51, 0.1) 0,rgba(243, 112, 85, 0.1) 15%,rgba(239, 78, 123, 0.1) 30%,rgba(161, 102, 171, 0.1) 44%,rgba(80, 115, 184, 0.1) 58%,rgba(16, 152, 173, 0.1) 72%,rgba(7, 179, 155, 0.1) 86%,rgba(109, 186, 130, 0.1) 100%);background: -o-linear-gradient(0deg,rgba(247, 149, 51, 0.1) 0,rgba(243, 112, 85, 0.1) 15%,rgba(239, 78, 123, 0.1) 30%,rgba(161, 102, 171, 0.1) 44%,rgba(80, 115, 184, 0.1) 58%,rgba(16, 152, 173, 0.1) 72%,rgba(7, 179, 155, 0.1) 86%,rgba(109, 186, 130, 0.1) 100%);background: -ms-linear-gradient(0deg,rgba(247, 149, 51, 0.1) 0,rgba(243, 112, 85, 0.1) 15%,rgba(239, 78, 123, 0.1) 30%,rgba(161, 102, 171, 0.1) 44%,rgba(80, 115, 184, 0.1) 58%,rgba(16, 152, 173, 0.1) 72%,rgba(7, 179, 155, 0.1) 86%,rgba(109, 186, 130, 0.1) 100%);background: linear-gradient(90deg,rgba(247, 149, 51, 0.1) 0,rgba(243, 112, 85, 0.1) 15%,rgba(239, 78, 123, 0.1) 30%,rgba(161, 102, 171, 0.1) 44%,rgba(80, 115, 184, 0.1) 58%,rgba(16, 152, 173, 0.1) 72%,rgba(7, 179, 155, 0.1) 86%,rgba(109, 186, 130, 0.1) 100%);&#125; 在 themes/butterfly/_config.yml中添加样式文件引入 123456789101112131415# 注入# 在头部 (&#x27;&lt;head&gt;&#x27; 标签之前) 和底部 (&#x27;&lt;body&gt;&#x27; 标签之前) 插入代码# 在头部 &lt;head&gt; 之前 和 底部 &lt;body&gt; 之前插入代码inject:head:- &lt;link rel=&quot;stylesheet&quot; href=&quot;/css/background.css&quot;&gt;bottom:# - &lt;script src=&quot;xxxx&quot;&gt;&lt;/script&gt; 如果背景色不生效，在_config.butterfly.yml设置： 1234567# 设置网站背景# 可以设置为颜色或图片（可设置图片 或者 颜色）# 图片格式：url(http://xxxxxx.com/xxx.jpg)background: &#x27;#efefef&#x27; 6. footer 背景 footer 的背景，当设置 false 时，将与主题色一致。 123# 页脚背景footer_bg: true ———————————————— 原文链接：https://blog.csdn.net/2301_76884890/article/details/141507802","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]},{"title":"Hexo搭建个人博客网站","slug":"Hexo/Hexo搭建个人博客网站","date":"2024-11-29T08:14:29.000Z","updated":"2025-04-24T06:23:37.186Z","comments":true,"path":"2024/11/29/Hexo/Hexo搭建个人博客网站/","link":"","permalink":"http://www.formeasy.cc/2024/11/29/Hexo/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/","excerpt":"","text":"摘要 主要记录一下搭建网站的步骤，以及搭建好之后该怎么修改yml文件，使自己的网站看起来好看些，后期发布文章等等。。。此搭建全程免费，非常的不错（除了更改域名之外) 有什么附加功能大家可以一块在留言区讨论。 🔑 注释：我的内容从许多博客，帖子中汲取 接下来咱们开始进入正题 搭建网站的前置工具 部分内容参考搭建网站 WebStorm 使用WebStorm进行编写代码 用_VSCODE_也可以。 Hexo 下载完之后，我们用Hexo框架来搭建网站，这个网站中有许多已经搭建好的网站模板主题。 在本文中我们使用_butterfly_主题。 在搭建此框架之前，咱们需要下载好Nodejs和Git 可以参考Nodejs和Git这两个博客进行下载。 好的，这些东西配置好之后开始搭建网站。 Hexo配置 桌面右击，打开git bash here输入命令安装（默认位置即可，方面后续配置，不建议修改） 1npm install -g hexo-cli 接下来我们在电脑里自己想要放置博客配置和内容的地方新建一个文件夹： 比如说我在E盘建立了一个penny_blog文件夹，以后所有关于博客网站的内容都放在这个文件夹中。 初始化 接下来在新建立的文件夹下打开 git bash here 输入命令： 1hexo init 初始化之后，该文件下面会出现以下内容： 这里借用了其他博主的图片。 简单介绍下hexo的文件结构： public 最终所见网页的所有内容 node_modules 插件以及hexo所需node.js模块 _config.yml 站点配置文件，设定一些公开信息等 package.json 应用程序信息，配置hexo运行所需js包 scaffolds 模板文件夹，新建文章，会默认包含对应模板内容 themes 存放主题文件，hexo根据主题生成静态网页（速度贼快） source 用于存放用户资源（除 posts 文件夹，其余命名方式为 “ + 文件名”的文件被忽略） 我们日常写文的操作都在 source/_post下。 本地运行 接下来我们用WebStorm打开根目录文件夹（比如说:penny_blog这个根目录文件夹） 然后在终端输入： 1hexo s 这个s指的是server（本地服务器） 运行之后，会显示 点击链接 http://localhost:4000（图中黄色下划线位置）进行本地预览，默认是hexo内置的landscape 主题 在终端按Ctrl+C退出运行。 这个主题挺丑的，接下来我们更换主题，在Hexo themes可以找到许多主题，可以选择你自己喜欢的就行。我觉得butterfly这个主题特别好看，很可爱哈哈，而且功能很多。 好的接下来我们来讲一下更改主题 主题更改 以下内容参考博文butterfly主题配置 安装butterfly主题 在hexo项目根目录下(penny_blog)下载主题。 在命令端输入： 1git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly 安装pug 和 stylus 渲染器。 1npm install hexo-renderer-pug hexo-renderer-stylus --save 修改项目根目录下的_config.yml文件（称为站点配置文件） 输入以下命令开启主题 1# Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: butterfly 4. 升级建议 为了減少升级主题带来的不便，我们可以把主题文件夹中的 _config.yml 重命名为 _config.butterfly.yml，复制到 Hexo 根目录下与_config.yml同级。（本人觉得非常好，要不容易报错） Hexo会自动合并主题中的_config.yml和 _config.butterfly.yml ，如果存在同名配置，会使用_config.butterfly.yml的配置，其优先度较高。所以像和博客网址相关联的固定资料可以设置在_config.yml中，比 如博客的标题、作者信息和邮箱等等资料，而和主题样式相关的配置放在 _config.butterfly.yml 中，那么在将来你想换一个主题是很方便的。 更改好主题之后， 在终端依次输入: 1hexo clean hexo g hexo s 可以在本地看看更改好的的主题样式，长这个样子 这张图是本人已经修改了一下yml的配置内容，详细修改内容还是可以看看 butterfly主题配置这个博主写的内容，很详细。 正式上线 接下来我们需要发布自己做的网站，这里要借助github平台 GitHub Pages配置 可以通过github创建网页，而且免费，更新速度极快，刷新github仓库页面，网站也就自动更新了 新建仓库 填写内容如下，特别注意红框位置 一定要是自己的github的用户名，要不然就用不了哈！！！！ 保证仓库public，名称填写正确用户名.github.io，系统自动变更为Pages 在仓库设置中找到Pages 记住仓库地址，我们会将本地的文件上传到仓库 SSH密钥配置 如果你是在电脑上第一次使用git，请先配置SSH公钥（一种安全协议，你可以理解为登陆某网站需要的验证码） 可以参考：GitHub SSH配置 配置好ssh之后我们就可以把本地的hexo和github仓库联系起来了 将hexo部署到GitHub 打开站点配置文件 _config.yml，翻到最后有个Deployment，修改内容如下，type和branch按照图片的内容修改就好，然后repository修改成你自己的仓库链接就行，一定要注意每个名称和值之间都有个空格 如果害怕出错，直接复制我的，然后把repository链接修改成你就行： 1# Deployment ## Docs: https://hexo.io/docs/one-command-deployment deploy: type: git repository: https://github.com/pennyzhao1507288/pennyzhao1507288.github.io.git branch: master 这个时候需要先安装deploy-git ，也就是部署的命令,这样你才能用命令部署到GitHub。 1npm install hexo-deployer-git --save 然后在本地根目录下(penny_blog)打开 git bash here 依次执行以下命令: 1hexo clean //执行此命令后继续下一条 hexo g //生成博客目录 hexo s //本地预览 hexo d //部署项目 注意deploy时可能要你输入username和password。 执行完毕后，所有人就能通过你的用户名+github.io这个域名访问你的网站了。到这儿，我们就成功上线了自己的网站。 个性化设置 想要更改自己网站的一些配置 ，可以看刚刚上文的那个butterfly博文，也可以看butterfly官网的教程： butterfly教程官网 后续网站更新内容 分类和标签设置 分类（categories） 1、创建“分类”选项 1hexo new page categories 成功后会提示： 1INFO Created: ~/Documents/blog/source/categories/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1--- title: categories date: 2024-11-09 08:18:17 --- 这个时间date是系统自动生成的，是你输入命令生成index.md的时间 添加type: &quot;categories&quot;到内容中，添加后是这样的： 1--- title: categories date: 2024-11-09 08:18:17 type: &quot;categories&quot; --- 标签（tags） 然后tag标签的创建方法也是如此： 创建tags选项 1hexo new page tags 找到tags一下的index.md 初始内容为： 1--- title: categories date: 2024-11-09 08:18:17 --- 添加type 1--- title: categories date: 2024-11-09 08:18:17 type: &quot;categories&quot; --- 发布文章 接下来为你要发表的博客添加分类和标签 比如说我要发表AI的文章 那么输入命令： 1hexo n &quot;introduction to AI(1)&quot; 这样子在根目录的source下的_posts下面会生成introduction to AI(1).md 然后你就可以按照typora的格式进行写文档。 对了，在这个文档中插入图片视频这些的，得用相对路径，你要把这些资源图片视频放在hexo（比如说：penny_blog）根目录的source下的新建文件夹中（我这边是创建了一个AI新文件夹） 我是现在是在本地其他地方保存了这些图片和视频，然后再复制到hexo根目录的source中，然后生成相对路径内容。 这个转换的脚本可以用以下python代码： 1import os import sys import shutil import subprocess def hexoimg(img_path): # 获取文件名和扩展名 fname = os.path.basename(img_path) # 目标目录 dest_dir = r&quot;E:\\web\\penny_blog\\source\\AI&quot; # 修改为你实际的目录 # 确保目标目录存在 os.makedirs(dest_dir, exist_ok=True) # 复制文件到目标目录 dest_path = os.path.join(dest_dir, fname) shutil.copy(img_path, dest_path) # 生成 Markdown 格式的链接 markdown_link = f&quot;![Image](/AI/&#123;fname&#125;)&quot; # 将链接复制到剪贴板（适用于 Windows） subprocess.run(&quot;echo &quot; + markdown_link.strip() + &quot;| clip&quot;, shell=True) # 输出提示信息 print(f&quot;&#123;markdown_link&#125; Copied to Clipboard :)&quot;) if __name__ == &quot;__main__&quot;: if len(sys.argv) &lt; 2: print(&quot;Usage: python hexoimg.py path/to/your/image.jpg&quot;) else: hexoimg(sys.argv[1]) 举个例子，在终端输入： 1python hexoimg.py E:\\学习\\uni\\year3\\ai\\img\\week7_14.png 输出： 1![Image](/AI/week7_14.png) Copied to Clipboard :) 然后直接粘贴到typora中就可以了 写好之后在git命令行中依次输入 1hexo clean hexo g hexo d 就可以在github中更新，然后刷新网站就可以看到了。 搭建网站还有许多需要的知识，后续我再更新网站的时候，会继续分享心得的。 马上更新哈哈 利用giscus配置评论 我们使用Giscus来配置这个评论。 这是一个基于 GitHub Discussions 的评论 这是配置文件giscus 选择 giscus 连接到的仓库。请确保： 该仓库是公开的，否则访客将无法查看 discussion。 giscus app 已安装，否则访客将无法评论和回应。 Disscussion 功能已在你的仓库中启用。 以上三个条件满足之后就可以了，然后网页往下翻有生成好的配置： 然后在_configure_butterfly.yml 文档中找到Comments,use内容改成Giscus 1comments: # Up to two comments system, the first will be shown as default # Leave it empty if you don&#x27;t need comments # Choose: Disqus/Disqusjs/Livere/Gitalk/Valine/Waline/Utterances/Facebook Comments/Twikoo/Giscus/Remark42/Artalk # Format of two comments system : Disqus,Waline use: Giscus # Display the comment name next to the button text: true # Lazyload: The comment system will be load when comment element enters the browser&#x27;s viewport. # If you set it to true, the comment count will be invalid lazyload: true # Display comment count in post&#x27;s top_img count: true # Display comment count in Home Page card_post_count: true 然后在下方giscus的部分添加以下配置，用你自己在giscus生成的参数，这里是我的 1giscus: repo: pennyzhao1507288/pennyzhao1507288.github.io repo_id: R_kgDONMjCuQ category_id: DIC_kwDONMjCuc4CkIEb light_theme: light dark_theme: dark js: https://giscus.app/client.js option: 配置好之后，我们在博文md最后添加刚刚giscus网页中生成的配置复制到md中（比如说这个AI markdown文件中添加评论）： 完成之后 继续用 1hexo clean hexo g hexo d 更新内容到github，然后刷新网页就行了，效果如下： markdown中数学公式以及emoji显示 使用以下插件math plugin 在命令行输入 1npm un hexo-renderer-marked --save npm i hexo-renderer-markdown-it-plus --save 在根目录的 _config.yml 中添加以下内容 1markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ plugins: - plugin: name: markdown-it-mark enable: false markdown-it-emoji markdown-it-sub markdown-it-sup markdown-it-deflist markdown-it-abbr markdown-it-footnote markdown-it-ins markdown-it-mark @iktakahiro/markdown-it-katex markdown-it-toc-and-anchor 然后在_config_butterfly.yml 中的math处修改一下代码 use处添加为katex 然后在katex里的copy_tex改成true 1math: # Choose: mathjax, katex # Leave it empty if you don&#x27;t need math use: katex per_page: true hide_scrollbar: false mathjax: # Enable the contextual menu enableMenu: false # Choose: all / ams / none, This controls whether equations are numbered and how tags: none katex: # Enable the copy KaTeX formula # enable: true copy_tex: true 更多好看的markdown语法可以参考markdown语法 在hexo中的markdown语法和typora有点不同。 ———————————————— 原文链接：https://blog.csdn.net/m0_69003698/article/details/143652280","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]},{"title":"Hexo的快速开始","slug":"Hexo/Hexo的快速开始","date":"2024-11-29T05:38:13.000Z","updated":"2024-11-30T15:07:56.118Z","comments":true,"path":"2024/11/29/Hexo/Hexo的快速开始/","link":"","permalink":"http://www.formeasy.cc/2024/11/29/Hexo/Hexo%E7%9A%84%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","excerpt":"","text":"欢迎使用Hexo! 我的博客的第一篇文章，就是用Hexo搭建的。 这里 有更多它的信息. 如果在使用Hexo过程中遇到问题，你可以在 这里 找到答案，也可以在查看 GitHub。 快速开始 创建文章 1$ hexo new &quot;My New Post&quot; 更多: Writing 运行服务 1$ hexo server 更多: Server 生成静态文件 1$ hexo generate 更多: Generating 部署到远程服务器 1$ hexo deploy 更多: Deployment","categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://www.formeasy.cc/categories/%E6%8A%80%E6%9C%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://www.formeasy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"智能","slug":"智能","permalink":"http://www.formeasy.cc/categories/%E6%99%BA%E8%83%BD/"},{"name":"软件工程","slug":"软件工程","permalink":"http://www.formeasy.cc/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"},{"name":"测试","slug":"测试","permalink":"http://www.formeasy.cc/categories/%E6%B5%8B%E8%AF%95/"},{"name":"网络通讯","slug":"网络通讯","permalink":"http://www.formeasy.cc/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/"},{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.formeasy.cc/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"设计","slug":"设计","permalink":"http://www.formeasy.cc/categories/%E8%AE%BE%E8%AE%A1/"},{"name":"操作系统","slug":"操作系统","permalink":"http://www.formeasy.cc/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"串行通讯","slug":"串行通讯","permalink":"http://www.formeasy.cc/categories/%E4%B8%B2%E8%A1%8C%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.formeasy.cc/tags/Springboot/"},{"name":"LLM","slug":"LLM","permalink":"http://www.formeasy.cc/tags/LLM/"},{"name":"Other","slug":"Other","permalink":"http://www.formeasy.cc/tags/Other/"},{"name":"Redis","slug":"Redis","permalink":"http://www.formeasy.cc/tags/Redis/"},{"name":"DDS","slug":"DDS","permalink":"http://www.formeasy.cc/tags/DDS/"},{"name":"Qt","slug":"Qt","permalink":"http://www.formeasy.cc/tags/Qt/"},{"name":"Python","slug":"Python","permalink":"http://www.formeasy.cc/tags/Python/"},{"name":"kafka","slug":"kafka","permalink":"http://www.formeasy.cc/tags/kafka/"},{"name":"Neo4j","slug":"Neo4j","permalink":"http://www.formeasy.cc/tags/Neo4j/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.formeasy.cc/tags/MySQL/"},{"name":"C","slug":"C","permalink":"http://www.formeasy.cc/tags/C/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.formeasy.cc/tags/kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"http://www.formeasy.cc/tags/Docker/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.formeasy.cc/tags/Ubuntu/"},{"name":"algo","slug":"algo","permalink":"http://www.formeasy.cc/tags/algo/"},{"name":"UE","slug":"UE","permalink":"http://www.formeasy.cc/tags/UE/"},{"name":"VUE","slug":"VUE","permalink":"http://www.formeasy.cc/tags/VUE/"},{"name":"RPC","slug":"RPC","permalink":"http://www.formeasy.cc/tags/RPC/"},{"name":"VS","slug":"VS","permalink":"http://www.formeasy.cc/tags/VS/"},{"name":"vosk","slug":"vosk","permalink":"http://www.formeasy.cc/tags/vosk/"},{"name":"TEST","slug":"TEST","permalink":"http://www.formeasy.cc/tags/TEST/"},{"name":"OpenDroneMap","slug":"OpenDroneMap","permalink":"http://www.formeasy.cc/tags/OpenDroneMap/"},{"name":"MCP","slug":"MCP","permalink":"http://www.formeasy.cc/tags/MCP/"},{"name":"Editor","slug":"Editor","permalink":"http://www.formeasy.cc/tags/Editor/"},{"name":"Ollama","slug":"Ollama","permalink":"http://www.formeasy.cc/tags/Ollama/"},{"name":"python","slug":"python","permalink":"http://www.formeasy.cc/tags/python/"},{"name":"ollama","slug":"ollama","permalink":"http://www.formeasy.cc/tags/ollama/"},{"name":"UDPTCP","slug":"UDPTCP","permalink":"http://www.formeasy.cc/tags/UDPTCP/"},{"name":"proxmox","slug":"proxmox","permalink":"http://www.formeasy.cc/tags/proxmox/"},{"name":"ROS","slug":"ROS","permalink":"http://www.formeasy.cc/tags/ROS/"},{"name":"EA","slug":"EA","permalink":"http://www.formeasy.cc/tags/EA/"},{"name":"Navicat","slug":"Navicat","permalink":"http://www.formeasy.cc/tags/Navicat/"},{"name":"NVIDIA","slug":"NVIDIA","permalink":"http://www.formeasy.cc/tags/NVIDIA/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://www.formeasy.cc/tags/PostgreSQL/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://www.formeasy.cc/tags/ClickHouse/"},{"name":"MongoDB区别","slug":"MongoDB区别","permalink":"http://www.formeasy.cc/tags/MongoDB%E5%8C%BA%E5%88%AB/"},{"name":"1553B","slug":"1553B","permalink":"http://www.formeasy.cc/tags/1553B/"},{"name":"Hexo","slug":"Hexo","permalink":"http://www.formeasy.cc/tags/Hexo/"}]}